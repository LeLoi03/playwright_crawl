1. Conference SLE_3:
Conference Partner   Home 
  Conferences 
  Journals 
  Proofreading 
  Login 

  中文  |  English  |  Español  |  日本語     

 Conference Partner  » Conferences  » SLE    
  Conference Information   
   
 SLE 2025: International Conference on Software Language Engineering  
 https://www.sleconf.org/2025/   
   
 Submission Date: | 2025-02-07 
 Notification Date: | 2025-04-15 
 Conference Date: | 2025-06-12 
 Location: | Koblenz, Germany 
 Years: | 18 
  
 Viewed: 12598  Tracked: 0  Attend: 0    

  Call For Papers   
   
 Topics of Interest SLE covers software language engineering in general, rather than engineering a specific software language. Topics of interest include, but are not limited to: Software Language Design and Implementation Approaches to and methods for language design Static semantics (e.g., design rules, well-formedness constraints) Techniques for specifying behavioral/executable semantics Generative approaches (incl. code synthesis, compilation) Meta-languages, meta-tools, language workbenches AI-assisted language design and optimisation Software Language Validation Verification and formal methods for languages Testing techniques for languages Simulation techniques for languages Model-based testing AI-assisted validation Software Language Integration and Composition Coordination of heterogeneous languages and tools Mappings between languages (incl. transformation languages) Traceability between languages Deployment of languages to different platforms AI-assisted refactoring Software Language Maintenance Software language reuse Language evolution Language families and variability, language and software product lines Domain-specific approaches for any aspects of SLE (design, implementation, validation, maintenance) Empirical evaluation and experience reports of language engineering tools User studies evaluating usability Performance benchmarks Industrial applications Synergies between Language Engineering and emerging/promising research areas Generative AI in language engineering (e.g., AI-based language modelling, AI-driven code generation tools) AI and ML language engineering (e.g., ML compiler testing, code classification) Quantum language engineering (e.g., language design for quantum machines) Language engineering for physical systems (e.g., CPS, IoT, digital twins) Socio-technical systems and language engineering (e.g., language evolution to adapt to social requirements)  Last updated by Dou Sun  in 2024-10-13   

  Related Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 DSA | International Conference on Dependable Systems and Their Applications | 2023-05-25 | 2023-07-10 | 2023-08-10 
 MIS4TEL | International Conference in Methodologies and Intelligent Systems for Technology Enhanced Learning | 2019-02-11 | 2019-03-11 | 2019-06-26 
 ERMI-ISASS | ERMI International Conference on Information Science and Applied Social Sciences | 2018-01-15 | 2018-02-12 
 ADCO | International Conference on Advanced Computing | 2022-04-09 | 2022-04-18 | 2022-04-23 
 ICACCP | International Conference on Advanced Computational and Communication Paradigms | 2018-09-30 | 2018-12-01 | 2019-02-25 
 UBICNET | International Conference on Ubiquitous Communications and Network Computing | 2019-10-31 | 2019-12-11 | 2020-02-28 
 a | a* | a1 | ICSE | International Conference on Software Engineering | 2024-08-02 | 2024-11-01 | 2025-04-26 
 ICCNS | International Conference on Communication and Network Security | 2024-10-15 | 2024-10-30 | 2024-12-06 
 IC2E | International Conference on Cloud Engineering | 2024-04-12 | 2024-06-30 | 2024-09-24 
 ICMEME | International Conference on Mechanical Engineering, Materials and Energy | 2016-12-03 | 2016-12-10 
  
 3484  2953  2459  3702  2896  3458  160  1093  1355  1362    

 Short | Full Name | Submission | Conference 
 DSA | International Conference on Dependable Systems and Their Applications | 2023-05-25 | 2023-08-10 
 MIS4TEL | International Conference in Methodologies and Intelligent Systems for Technology Enhanced Learning | 2019-02-11 | 2019-06-26 
 ERMI-ISASS | ERMI International Conference on Information Science and Applied Social Sciences | 2018-01-15 | 2018-02-12 
 ADCO | International Conference on Advanced Computing | 2022-04-09 | 2022-04-23 
 ICACCP | International Conference on Advanced Computational and Communication Paradigms | 2018-09-30 | 2019-02-25 
 UBICNET | International Conference on Ubiquitous Communications and Network Computing | 2019-10-31 | 2020-02-28 
 ICSE | International Conference on Software Engineering | 2024-08-02 | 2025-04-26 
 ICCNS | International Conference on Communication and Network Security | 2024-10-15 | 2024-12-06 
 IC2E | International Conference on Cloud Engineering | 2024-04-12 | 2024-09-24 
 ICMEME | International Conference on Mechanical Engineering, Materials and Energy | 2016-12-03 | 2016-12-10 
  
 3484  2953  2459  3702  2896  3458  160  1093  1355  1362    

  Related Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 ROBOMECH Journal | 1.500 | Springer | 2197-4225 
 b | Journal of Functional Programming | 1.100 | Cambridge University Press | 0956-7968 
 ISPRS Journal of Photogrammetry and Remote Sensing | 10.60 | Elsevier | 0924-2716 
 Information Technology and Management | 2.300 | Springer | 1385-951X 
 International Journal on Bioinformatics & Biosciences | AIRCC | 1839-9614 
 c | IET Information Security | 1.300 | IET | 1751-8709 
 IEEE Transactions on Smart Grid | 8.600 | IEEE | 1949-3053 
 Cryptography and Communications | 1.200 | Springer | 1936-2447 
 International Journal of Information Management | 20.10 | Elsevier | 0268-4012 
 Information Systems and e-Business Management | 2.300 | Springer | 1617-9846 
  
 991  97  715  128  300  54  1053  473  714  485    

 Full Name | Impact Factor | Publisher 
 ROBOMECH Journal | 1.500 | Springer 
 Journal of Functional Programming | 1.100 | Cambridge University Press 
 ISPRS Journal of Photogrammetry and Remote Sensing | 10.60 | Elsevier 
 Information Technology and Management | 2.300 | Springer 
 International Journal on Bioinformatics & Biosciences | AIRCC 
 IET Information Security | 1.300 | IET 
 IEEE Transactions on Smart Grid | 8.600 | IEEE 
 Cryptography and Communications | 1.200 | Springer 
 International Journal of Information Management | 20.10 | Elsevier 
 Information Systems and e-Business Management | 2.300 | Springer 
  
 991  97  715  128  300  54  1053  473  714  485    

  Recommendation   

 Track It 0 
  Attend It 0 
  Edit CFP 
   
   Advertisment   

  4,945  Conferences | 1,179  Journals | 69,627  Researchers | 385,881,026 PV  
  Copyright © 2011-2024 myhuiban.com. All Rights Reserved. About Us  | Facebook  | X  | Post CFP or Contact Us  | Promotion    

  Call for papers data:    Conference Partner   Home 
  Conferences 
  Journals 
  Proofreading 
  Login 

  中文  |  English  |  Español  |  日本語     

 Conference Partner  » Researchers  » Dou Sun    
  Basic Information   
   
 Name: Dou Sun  
 Institution: Conference Partner  
 Registration: 2011-02-24  
 Score: 135640  

  CV   
   
 Dou SUN (孙斗) "Conference Partner" was created in 2011. It is an academic website for conferences and journals information. I built this website and maintained it in my spare time. Email: sundou82 AT gmail.com Skills: J2EE (11 years of experience, Spring, Hibernate, iBatis, JMS, RabbitMQ, Maven, Ant, ...) Web Services (11 years of experience, XML, JSON, SOAP, WSDL, BPEL, RESTful, ...) Web (14 years of experience, HTML, CSS, JavaScript, PHP, Yii, Magento, JQuery, ExtJS, NodeJS...) Projects and Working Experience: 04/2011 - now, Huawei Technologies Co., Ltd (华为技术有限公司) DC2 (Distributed Cloud Data Center) Development and Test Cloud (DTC) Media Management Cloud (iShare) Media File Archive System (iLibrary) Online Video Platform (OVP) Cloud Media Process System (CMP) 09/2007 - 09/2010, Formal Verification of Business Process. "BaiMai Project - QualiPso Program (FP6)" Research cooperation between Beihang University and THALES Corporation Managed a team of 5 members Developed the "XServices BPEL Verification Tool" 11/2006 - 12/2008, WSOP - Web Services Orchestration Platform. "Service Oriented Autonomic Software System" (863 Program) Managed a team of 11 developers Developed the "XServices Orchestration Engine" 09/2005 - 05/2009, National E-government Standards and SOA Standards of China. Cooperation with China Electronic Standardization Institute (CESI) In charge of the workflow specification in e-government standards and SOA standards Standards have been accepted and published as the industry standard and the national E-government standard Participated to draft the national standards for SOA. 09/2005 - 09/2009, Workflow System. Cooperation with the Chinese companies (Intervision, Cvicse, JianDa and etc.) Promoted the commercialization of "Web Services Workflow System" (WSWF) 02/2006 - 12/2006, XServices Suites OpenSource Project. International cooperation between OrientWare and ObjectWeb One of chief administrators of the opensource project Released the new version of "XServices Suites" 10/2005 - 06/2006 WSWF - Web Services Workflow System. "Integration and Application of Middleware Kit - Orientware" (863 Program) A core member of the develop team Integrated the WSWF into Orientware Education Background: 09/2005 - 04/2011 Ph.D, School of Computer Science and Engineering, Beihang University (北京航空航天大学), Beijing, China Ph.D project: Computer Software and Theory 10/2009 - 04/2010 Visiting Student, OASIS Team, INRIA, Sophia Antipolis, France 09/2004 - 06/2005 MSc Postgraduate, School of Computer Science and Engineering, Beihang University (北京航空航天大学), China Accepted and Transferred to Ph.D student directly after first year performance. 09/2000 - 06/2004 BSc. Undergradate,School of Computer and Communication, Hunan University (湖南大学), China Honors and Prizes: [1] The 1st Prize at OW2 Programming Contest 2009, OW2, GuiYang, China, September 2009. [2] The 1st ProActive Prize at Super Quant Monte-Carlo Challenge, V Grid Plugtests, INRIA, France, October 2008. [3] The Prize of Special Contribute for R & D, ACT Lab, Beihang University, January 2008. [4] The 2nd Prize Winner of N-Queens Contest, IV Grid Plugtests, CNIC, Beijing, October 2007. [5] The "GuangHua" Scholarship for the year of 2007, Beihang University, December 2007. Patents: [1] Directed Graph based Method for Detecting Control Cycles in WS-BPEL, No. 200810118124.4, Chinese Patent. [2]GMF based Visual Modeling Approach for BPEL, No. 200810118126.3, Chinese Patent. [3] An Automatic Method for Electronic Document Flow based on Web Services, No. 200810116992.9, Chinese Patent. [4] A Fault-tolerant Method for Services based on XESB, No. 200810102768.4, Chinese Patent, . [5] Web Services Runtime Management System and Method based on Rules, No. 200810102394.6, Chinese Patent. [6] A Dynamic Evolution in Services Coordination based on System Structure, No. 200810118123.X, Chinese Patent. [7] An Automatic Operation Method for Databse based on Web Services,No. 200510114782.2, Chinese Patent. [8] A Conversion Method between Graphics with XML documents based on BPEL, No. 200510114689.1, Chinese Patent. [9] An Approach for Processing Web Services Workflow based on Stack Model, No. 200510114563.4, Chinese Patent. Publications: [1] Dou Sun, Yongwang Zhao, Hao Zeng, Dianfu Ma. An Operational Semantics of WS-BPEL based on Abstract BPEL Machine. IEEE International Conference on Service-Oriented Computing and Applications (SOCA), 2010. [2] Dou Sun, Yongwang Zhao, Hao Zeng, Dianfu Ma. SEDA4BPEL: A Staged Event-Driven Architecture for High-Concurrency BPEL Engine. IEEE symposium on Computers and Communications (ISCC), 2010, Page(s): 744 – 749. [3] Dou Sun, Zhuqing Li, Yongwang Zhao, Dianfu Ma. Orchestra Designer: an open-source tool for scientific workflow modeling. IEEE International Workshop on Open-source Software for Scientific Computation (OSSC), 2009, Page(s): 39 – 43. [4] Yongwang Zhao, Jing Li, Dou Sun, Dianfu Ma, "Towards Verifying Global Properties of Adaptive Software based on Linear Temporal Logic", 25th International Conference on Advanced Information Networking and Applications (AINA 2011) , IEEE Computer Society, March 22 - 25, 2011, Biopolis, Singapore, pp.240-247. [5] Kexin Li, Dou Sun, Zhuqing Li, Yongwang Zhao, Dianfu Ma. Workflow Modeling Tool for Multi-User Collaboration. Annual International Conference on Advances in Distributed and Parallel Computing (ADPC), 2010. [6] Yiwei Yin, Dou Sun, Yongwang Zhao, Dianfu Ma. GMF-ALF: A Development Framework for the Graphical Modeling Tool. 3rd International Conference on Computer and Electrical Engineering (ICCEE), 2010. [7] Jian Liu, Dianfu Ma, Zhuqing Li, Dou Sun. A Formal Description of Web Services Container Architecture. 4th International Conference on Internet and Web Applications and Services (ICIW), 2009, Page(s): 30 - 36. [8] Jian Liu, Dianfu Ma, Zhuqing Li, Dou Sun. A Formal Model of Web Services Transport Layer. 5th International Conference on Networking and Services (ICNS), 2009, Page(s): 474 - 480. [9] Min Liu, Dianfu Ma, Yongwang Zhao, Dou Sun. An Approach to Preserving Consistency of SOAs in Dynamic Evolution. 4th International Conference on Internet and Web Applications and Services (ICIW), 2009, Page(s): 505 - 509. [10] Dianfu Ma, Min Liu, Yongwang Zhao, Dou Sun. Reliability Quantification of the Tree Structure Based Distributed System. 14th IEEE Pacific Rim International Symposium on Dependable Computing (PRDC), 2008, Page(s): 351 - 352. [11] Dianfu Ma, Min Liu, Yongwang Zhao, Dou Sun. Dependability of the System Based on Structured Service Collaboration Model. 4th International Conference on Next Generation Web Services Practices (NWESP), 2008, Page(s): 28 - 32. [12] Xin Zhao, Jun Han, and Dou Sun. The Design and Implementation of a BPEL Modeling Tool Supporting Automatic Layout, CONTROL & AUTOMATION [Journal], 2008 [13] Xin Zhao, Jun Han, and Dou Sun. The Research and Implementation of Visual BPEL Workflow Remote Debugging Mechanism, Application Research of Computers [Journal], 2008 [14] Yuanyuan Chen, Dou Sun, and Ying Li. Design and Implementation of a WSDM-Based Web Service Management Mechanism, CONTROL & AUTOMATION [Journal], 2008 [15] Hongjie He, Dou Sun, and Xin Zhao. A Framework for Graphic Modeling Tool, National Association of State Aquaculture Coordinators (NASAC 2007), 2007, Xi'an, China.    
   
  Tracked Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 a | a* | a1 | ICML | International Conference on Machine Learning | 2025-01-23 | 2025-07-13 
 c | b | a2 | ISCC | IEEE symposium on Computers and Communications | 2025-01-10 | 2025-03-14 | 2025-07-02 
 a | a* | a1 | CVPR | IEEE Conference on Computer Vision and Pattern Recognition | 2024-11-14 | 2025-02-26 | 2025-06-10 
 b | a | a2 | ICSOC | International Conference on Service Oriented Computing | 2024-07-10 | 2024-09-20 | 2024-12-03 
 c | b | b1 | ICPADS | International Conference on Parallel and Distributed Systems | 2024-07-07 | 2024-08-15 | 2024-10-10 
 a | a2 | BPM | International Conference on Business Process Management | 2024-03-01 | 2024-05-17 | 2024-09-01 
 c | SOCA | International Conference on Service-Oriented Computing and Applications | 2019-08-05 | 2019-08-31 | 2019-11-18 
  
 406  308  407  17  223  452  219    

 Short | Full Name | Submission | Conference 
 ICML | International Conference on Machine Learning | 2025-01-23 | 2025-07-13 
 ISCC | IEEE symposium on Computers and Communications | 2025-01-10 | 2025-07-02 
 CVPR | IEEE Conference on Computer Vision and Pattern Recognition | 2024-11-14 | 2025-06-10 
 ICSOC | International Conference on Service Oriented Computing | 2024-07-10 | 2024-12-03 
 ICPADS | International Conference on Parallel and Distributed Systems | 2024-07-07 | 2024-10-10 
 BPM | International Conference on Business Process Management | 2024-03-01 | 2024-09-01 
 SOCA | International Conference on Service-Oriented Computing and Applications | 2019-08-05 | 2019-11-18 
  
 406  308  407  17  223  452  219    

  Attend Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Conference | Location 
 b1 | FORMATS | International Conference on Formal Modeling and Analysis of Timed Systems | 2022-09-12 | Warsaw, Poland 
 b | a* | a1 | UAI | Conference on Uncertainty in Artificial Intelligence | 2022-08-01 | Eindhoven, The Netherlands 
 CYBI | International Conference on Cybernetics & Informatics | 2020-01-25 | Zurich, Switzerland 
 c | SOCA | International Conference on Service-Oriented Computing and Applications | 2010-12-13 | Perth, Australia 
  
 401  416  3522  219    

 Full Name | Conference | Location 
 International Conference on Formal Modeling and Analysis of Timed Systems | 2022-09-12 | Warsaw, Poland 
 Conference on Uncertainty in Artificial Intelligence | 2022-08-01 | Eindhoven, The Netherlands 
 International Conference on Cybernetics & Informatics | 2020-01-25 | Zurich, Switzerland 
 International Conference on Service-Oriented Computing and Applications | 2010-12-13 | Perth, Australia 
  
 401  416  3522  219    

  Tracked Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 b | Journal of Parallel and Distributed Computing | 3.400 | Elsevier | 0743-7315 
  
 18    

 Full Name | Impact Factor | Publisher 
 Journal of Parallel and Distributed Computing | 3.400 | Elsevier 
  
 18    

  Followed Researchers   

 Name | Institution | Registration | Score 
 Jing Li | Beihang University | 2011-03-04 | 222 
 Zhuqing Li | Beihang University | 2011-02-24 | 33 
  
 14  2    

 Name | Institution | Score 
 Jing Li | Beihang University | 222 
 Zhuqing Li | Beihang University | 33 
  
 14  2    

  Tracked Jobs   

 Job Title | Employer | Job Location 
 No results found. 

 Job Title | Employer | Job Location 
 No results found. 

  Viewed Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 ICAIM | International Conference on Artificial Intelligence & Materials | 2024-11-10 | 2025-02-15 | 2025-03-21 
 CWOC | International Conference on Wireless and Optical Communications | 2025-03-25 | 2025-04-01 | 2025-04-25 
 AIAC | International Conference on Artificial Intelligence and Automation Control | 2024-12-13 | 2024-12-20 
 Tau | ACM International Workshop on Timing Issues in the Specification and Synthesis of Digital Systems | 2025-01-13 | 2025-02-24 | 2025-05-01 
 FAccT | ACM Conference on Fairness, Accountability, and Transparency | 2025-01-15 | 2025-04-11 | 2025-06-03 
 RESPECT | Conference for Research on Equitable and Sustained Participation in Engineering, Computing, and Technology | 2025-01-31 | 2025-04-07 | 2025-07-14 
 MLPR | International Conference on Machine Learning and Pattern Recognition | 2025-02-20 | 2025-03-20 | 2025-07-25 
 IWOCL | International Workshop on OpenCL and SYCL | 2025-01-12 | 2025-02-24 | 2025-04-07 
 MLNN | International Conference on Machine Learning and Neural Networks | 2025-03-31 | 2025-04-18 
 IPDL | International Conference on Image Processing and Deep Learning | 2025-02-10 | 2025-04-11 
  
 5004  5003  5002  5001  5000  4999  4998  4997  4996  4995    

 Short | Full Name | Submission | Conference 
 ICAIM | International Conference on Artificial Intelligence & Materials | 2024-11-10 | 2025-03-21 
 CWOC | International Conference on Wireless and Optical Communications | 2025-03-25 | 2025-04-25 
 AIAC | International Conference on Artificial Intelligence and Automation Control | 2024-12-13 | 2024-12-20 
 Tau | ACM International Workshop on Timing Issues in the Specification and Synthesis of Digital Systems | 2025-01-13 | 2025-05-01 
 FAccT | ACM Conference on Fairness, Accountability, and Transparency | 2025-01-15 | 2025-06-03 
 RESPECT | Conference for Research on Equitable and Sustained Participation in Engineering, Computing, and Technology | 2025-01-31 | 2025-07-14 
 MLPR | International Conference on Machine Learning and Pattern Recognition | 2025-02-20 | 2025-07-25 
 IWOCL | International Workshop on OpenCL and SYCL | 2025-01-12 | 2025-04-07 
 MLNN | International Conference on Machine Learning and Neural Networks | 2025-03-31 | 2025-04-18 
 IPDL | International Conference on Image Processing and Deep Learning | 2025-02-10 | 2025-04-11 
  
 5004  5003  5002  5001  5000  4999  4998  4997  4996  4995    

  Viewed Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 Solid State Sciences | 3.400 | Elsevier | 1293-2558 
 Materials Today Communications | 3.700 | Elsevier | 2352-4928 
 Materials Science and Engineering: B | 3.900 | Elsevier | 0921-5107 
 Surface and Coatings Technology | 5.300 | Elsevier | 0257-8972 
 Polymer Degradation and Stability | 6.300 | Elsevier | 0141-3910 
 IEEE Open Journal of Signal Processing | 2.900 | IEEE | 2644-1322 
 IEEE Internet of Things Magazine | IEEE | 2576-3180 
 IEEE Communications Standards Magazine | IEEE | 2471-2825 
 IEEE Transactions on Molecular, Biological, and Multi-Scale Communications | 2.400 | IEEE | 2372-2061 
 IEEE Transactions on Cognitive Communications and Networking | 7.400 | IEEE | 2372-2045 
  
 1195  1194  1193  1192  1191  1142  1082  1081  1045  1042    

 Full Name | Impact Factor | Publisher 
 Solid State Sciences | 3.400 | Elsevier 
 Materials Today Communications | 3.700 | Elsevier 
 Materials Science and Engineering: B | 3.900 | Elsevier 
 Surface and Coatings Technology | 5.300 | Elsevier 
 Polymer Degradation and Stability | 6.300 | Elsevier 
 IEEE Open Journal of Signal Processing | 2.900 | IEEE 
 IEEE Internet of Things Magazine | IEEE 
 IEEE Communications Standards Magazine | IEEE 
 IEEE Transactions on Molecular, Biological, and Multi-Scale Communications | 2.400 | IEEE 
 IEEE Transactions on Cognitive Communications and Networking | 7.400 | IEEE 
  
 1195  1194  1193  1192  1191  1142  1082  1081  1045  1042    

 Follow 71 

 Follower 
 I L (358) 
 Selia Terisa (9) 
 Reni Samarah (9) 
 Wen Gu (13) 
 Kuse Shigeko (39) 
 Regina Liu (1058) 
 Yang Yang (298) 
 Jiayu Zhuang (34) 
 Sheen Song (86) 
 Xiaojuan Zhao (95) 
 ERMM 2021 (69) 
 Saraa Cassandra (59) 
 Joy Li (350) 
 Zhanbei Cui (63) 
 Jayleen Chen (150) 
 Sherry Zhao (32) 
 Teacher Zhao (33) 
 Lu Wang (16) 
 Hu 锰涛 (364) 
 Qiangqiang Ouyang (198) 
 Long Xin (1036) 
 Lea Jeffrey (8) 
 Dunn Carl (4062) 
 Hong-Ning Dai (14) 
 Wei Chen (163) 
 Cindy Shen (27) 
 Wang Hao (693) 
 Jim Guo (289) 
 Steve Smith (19) 
 Wei Zhang (825) 
 Youfs Youfs (3) 
 Ting Tu (42) 
 Mia Jack (98) 
 Triple Z (77) 
 翔龙 Cheng (225) 
 Zebin Wu (1135) 
 Masa Otsuka (82) 
 Wenhan Zhan (9) 
 Fei Xue (286) 
 Lei Yan (164) 
 Mingli Yu (7) 
 Muhammad Arif (568) 
 XIN SUI (74) 
 Ke Ao (7553) 
 Sunshine Wang (99) 
 Chen Liang (221) 
 Zhou Xue (186) 
 Guangyuan Piao (2478) 
 Find Hao (1035) 
 Xin Yao (11681) 
 Ting Huang (172) 
 Chris Chen (1235) 
 Huan Wang (2075) 
 Yingzheng Wang (158) 
 Kallol Krishna Karmakar (384) 
 Starking Chen (1166) 
 Sandra Evans (103) 
 Yingjun Li (133) 
 HY Feng (356) 
 Xu Wang (494) 
 Zaiqiao Meng (2935) 
 Xiaox Lee (542) 
 MC Zheng (969) 
 Anıl Uysal (112) 
 Yi Chai (291) 
 Xianqi Zhao (54) 
 Fuan Pu (483) 
 Zhenbang Liu (154) 
 Lei Xu (2) 
 Tracy Zhang (1) 
  
 65823  64176  64175  60585  57923  50414  44329  46656  46332  25434  36170  45414  40156  41992  35303  34857  34254  28350  25869  19812  16772  24376  9767  23543  22662  22449  21233  11594  19438  19205  18936  18771  18379  14895  17635  13872  16932  16199  15665  11686  12331  12168  11805  9209  6737  6294  6011  3907  3899  323  3199  779  2793  2784  2589  102  2381  2233  2192  613  2026  864  1556  1163  1039  778  213  477  257  179    
   
  Advertisment   

  4,945  Conferences | 1,179  Journals | 69,627  Researchers | 385,881,039 PV  
  Copyright © 2011-2024 myhuiban.com. All Rights Reserved. About Us  | Facebook  | X  | Post CFP or Contact Us  | Promotion    

  Important dates data

2. Conference SNPD_0:
Home | ACIS News 
  Contact Us 
  About 
  Membership 
  Conference Calendar | SERA 2024 
  ICIS 2024-Summer I 
  SNPD 2024-Summer 
  ICIS 2024-Summer III 
  BCD 2024-Summer 
  AIML 2024 
  SNPD2024-Winter 
  BCD 2025-Winter 
  EAIM 2025 
  SERA 2025 
  SNPD 2025-Summer I 
  SNPD 2025-Summer II 
  SNPD 2025-Summer III 
  SNPD 2025-Summer IV 
  SNPD2025-Winter 
  Officers 
  ACIS Publications | IJNDC 
  IJSI 
  IJBDIA 
  Springer 
  Past Conferences | Past Conferences 
  Past Conference Photos 
  SpecialSession/Workshop/Symposium Info | Organizer Instructions 
  Proposal Form 
  Review Form 
  Virtual Conference Instructions 

 SNPD 2025-Summer IV  
   
 32nd IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD2025-Summer IV)  
 Date: July 21-23, 2025  
 Toronto, Canada  

 Conference Venue  
 TBA  

 Important Dates:    
 Workshop/Special session proposal: January 12, 2025     
   
 Workshop/Special session acceptance notification: January 26, 2025     

 Submission Deadline: April 5, 2025    
 Acceptance Notification: April 19, 2025    
 Registration/Camera Ready Paper: April 30. 2025    

 The 32nd ACIS International SummerConference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD2025-Summer IV) brings together researchers, scientists, engineers, industry practitioners, and students to discuss, encourage and exchange new ideas, research results, and experiences on all aspects of computer and information science. SNPD2025-Summer IV aims to facilitate cross-fertilizations among the key technology enabling areas and is soliciting papers in these areas.  

 Call For Papers     

 Special Sessions/Workshops     

 Submission Of Papers For Review     

 Final Paper Submission Instructions     

 Special Session/Workshop Proposal Form     

 Review Form     

 Register Now     

 Fee Schedule     

 Accomodations     

 Keynote Speakers     

 Travel Information     

 PC Members     

 Program     

 ABOUT ACIS  
 ACIS provides a forum for researchers in education and industry from all over the world to interact with one another and disseminate the latest developments in the fields of computer and information science.  
   
 RECENT NEWS  
   
 QUICK LINKS  
 Home 
  Membership 
  Conference Calendar 
  Officers 
  ACIS Publications 
  Past Conferences 
  SpecialSession/Workshop/Symposium Info 
  Virtual Conference Instructions 

 CONTACT INFO  
 Michigan Office   
 619 S Mission St, Mt.  
  Mt. Pleasant, MI 48858, U.S.A.  
 Florida Office   
 4088 Basket Oak Cir.  
  Vero Beach, FL 32967, U.S.A.  
 Email: acis@acisinternational.org   

 © Copyright 2018 ACIS International. All Rights Reserved Built by GriffusTech    

  Call for papers data:undefinedImportant dates data

3. Conference RTNS_1:
View On GitHub 

 realtime-embedded-conferences  
 Tracking conferences in Real-time Embedded Systems, Design Automation, Cyber-Pyhsical Systems and Robotics!  
  Project maintained by automaticdai   Hosted on GitHub Pages — Theme by mattgraham     
 Real-Time Embedded Systems, Design Automation & Cyber-Physical Systems (Conferences Tracking)  
    
 ( Last updated:   2024-11-22 21:23:03 +0000)  
 Tracking the most influenced conferences in real-time  systems, embedded systems  , design automation  and robotics  . The idea of this tracker is to keep up-to-date information of conferences, to facilitate researchers within our community aware of the deadlines and important announcements/updates.  
 This list is updated on a frequent basis (normally weekly). The list is ordered by deadlines  before the submission deadline, otherwise it will be ordered by the conference opening date  . Deadline is in digits, with the format yyyy-mm-dd  , to reduce confusion due to conventions of different countries. The deadline is for the main conference. Brief presentations, workshops and industrial tracks often have a different (and later) deadline.  
 Contributing to this list:   This list is for the community’s common benefit thus it is therefore a shared responsibility  to make sure the contents in this list are correct to the best knowledge. If you want to add to the list or report an error, you can either (1) commit an issue in the issue list  , (2) contact me through email: xiaotian.dai (at) york.ac.uk  , and (3) fill our feedback form  . If you prefer to change it yourself, you can clone, modify and create a pull request (PR) in GitHub.  
 Caution of time zones:   Note that some of the conference deadlines are in local time zones, but most are AoE, i.e., anywhere on earth (UTC-12:00). Please be aware of the time zone, especially when the deadline is approaching. Also note that the deadlines are for the full manuscript submission, but some of the conferences may have a deadline for abstract (normally one week earlier), which will be noted in the Remarks  section, even if it is not mandatory.  
 Maintainer:   This page and the GitHub repository are maintained by Dr. Steven Xiaotian Dai   from Real-Time and Distributed Systems Group, University of York, UK. If you find this site useful, please bookmark this page and star this repository on GitHub  .  
  Conferences Tracking  
  
 Name | Deadline | Where | When | Remarks 
 ISORC 2025 | Jan 8, 2025 | Toulouse, France | May 26-28, 2025 | - Acceptance notification: March 05, 2025  
  - Camera-ready papers: March 20, 2025  
  - Conference: May 26 - 28, 2025 
 Ada-Europe 2025 | Jan 20, 2025 | Pairs, France | June 10-13, 2025 | - Submission deadline for industrial track papers, work-in-progress papers, and tutorial and workshop proposals: 24 February 2025  
  - First round notification for journal-track papers, and notification of acceptance for all other types of submissions: 28 March 2025 
 ECRTS 2025 | Feb 28, 2025 | Brussels, Belgium | TBD | - Notification: April 21, 2025  
  - Camera-ready deadline: May 16, 2025 
 IROS 2025 | Mar, 2025 (❔) | Hangzhou, China | Oct 19-25, 2025 |  
 ESWEEK 2025 (EMSOFT, CASES, CODES+ISSS, MEMOCODE) | Mar, 2025 (❔) | TBD | TBD |  
 IROS 2025 | Mar, 2025 (❔) | TBD | TBD |  
 RO-MAN 2025 | Mar 20, 2025 | Eindhoven, Netherlands | Aug 25-29, 2025 | Notification of Acceptance: May 10, 2025 
 TAROS 2025 | Apr, 2025 (❔) | TBD | TBD |  
 RTCSA 2025 | Apr, 2025 (❔) | TBD | TBD |  
 SIES 2025 | Apr, 2025 (❔) | TBD | TBD |  
 DSD 2025 | May, 2025 (❔) | Salerno, Italy | Sep 10-12, 2025 |  
 ICCD 2025 | May, 2025 (❔) | TBD | TBD |  
 RTNS 2025 | Aug, 2025 (❔) | TBD | TBD |  
 Deadline passed & upcoming ↓ |  
 RTSS 2024 | May 23, 2024 | York, UK | Dec 10-13, 2024 | Rebuttal period: Jul 12-18, 2024  
  Author Notification: July 31, 2024  
  Camera-ready papers: Sep 24, 2024 
 NG-RES 2025  (w) | Nov 17, 2024  → Nov 24, 2024 | Barcelona, Spain | Jan 20, 2025 | - Co-located with HiPEAC 2025  
  - Acceptance notification: December 15th, 2024 
 DATE 2025 | Sep 22, 2024 (*) | Lyon, France | March 31 - April 2, 2025 | - Abstract deadline: Sep 15, 2024 
 ICCPS 2025 | Oct 31, 2024  → Nov 14, 2024 | Irvine, California, USA | May 6-9, 2025 | Important Dates (AoE):   
  - Abstract submission deadline (optional): November 7, 2024 (AOE)  
  - Paper submission deadline (FIRM): October 31, 2024 (AOE)  
  - Acceptance/rejection notifications: January 23, 2025  
  - Camera-ready: March 10, 2025 
 RTAS 2025 | Oct 31, 2024  → Nov 14, 2024 | Irvine, California, USA | May 6-9, 2025 | Part of CPS-IoT Week 
 ICRA 2025 | Sep 15, 2024 | Atlanta, USA | May 19-23, 2025 | Important Dates:   
  - Submissions Open: July 15th, 2024  
  - Submission Deadline: October 15th, 2024  
  - Acceptance Notification: October 31st, 2024  
  - Competitions: May 19th – May 23rd, 2025 
 DAC 2025 | Nov 19  → Nov 20, 2024 (*) | Moscone West, San Francisco | June 22-25, 2025 | - (Research paper) Abstract deadline: Nov 12, 2024  
  - Engineering tracks: Jan 16, 2025 
  
  Notations:    
 deadline  : the deadline has passed; 
  old  → new: the information was updated; 
  (*): there is an abstract deadline (may be compulsory for some conferences); 
  (w): this is a workshop; 
  (TBA) or (TBD): the details have not yet been announced; 
  ❔: the date is not precise but based on estimations from previous years. 
   Completed & Archived (by alphabet)  
  
 Name | Deadline | Where | When | Remarks 
 Ada-Europe 2021 | — | Santander, Spain | June 7-11, 2021 | WiP and industrial paper deadline: March 31, 2021 
 Ada-Europe 2022 | 2022-01-16 | Ghent, Belgium | June 14-17, 2022 | Ada Europe 2022 will be hybrid. The conference schedule comprises a journal track, an industrial track, a work-in-progress track, a vendor exhibition, parallel tutorials, and satellite workshops.  
   
  Important Dates:  
  Feb 27, 2022: Submission deadline for industrial-track and WiP track.  
  March 14, 2022: Author notification of acceptance. 
 Ada-Europe 2023 | 2023-01-16  → 2023-02-13 | Lisbon, Portugal | June 13-16, 2023 | 27 February 2023:  Submission deadline for industrial-track papers  , work-in-progress papers  , tutorial  , and workshop proposals   
  20 March 2023:  First round notification for journal-track papers  , and notification of acceptance for all other types of submissions 
 Ada-Europe 2024 | Jan 15, 2024  → Jan 31, 2024 | Barcelona, Spain | June 11-14, 2024 | Deadline is for the journal track; Other submissions by 26 February 2024 
 CASES 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Details refer to EMSOFT. 
 CASES 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22, 2023 | See above (EMSOFT) 
 CODES+ISSS 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Details refer to EMSOFT. 
 CODES+ISSS 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22, 2023 | See above (EMSOFT) 
 CoRL 2022 | 2022-06-15 | Auckland, NZ | Dec 14-18, 2022 |  
 DATE 2021 | — | Grenoble, France  →Virtual | February 1-5, 2021 |  
 DATE 2022 | 2021-09-19 | Virtual | Feb 1-5, 2022 | Abstract deadline: 2021-09-12 
 DATE 2023 | 2022-09-25 | Antwerp, Belgium | Apr 17-19, 2023 | Abstract deadline: 18 Sep, 2022  
  Other key dates can be found: here 
 DATE 2024 | Sep 17, 2023 (*) | Spain | March 25-27, 2024 | Abstract deadline:  September 10, 2023  
  Notification of acceptance: November 14, 2023  
  Camera-ready papers: January 17, 2024 
 DAC 2021 | 2020-11-23 | San Francisco, CA, USA | Dec 5-9, 2021 | Abstract deadline: Nov 16, 2020 
 DAC 2022 | 2021-11-22 | San Francisco, CA. | July 10-14, 2022 | Abstraction Deadline: Nov 15 
 DAC 2023 | 2022-11-21 | San Francisco, USA | July 9-13, 2023 | Abstract deadline: Nov 14, 2022 
 DAC 2024 | Nov 20, 2023 (*) | San Francisco, CA | June 23-27, 2024 | Abstract Submission Deadline:  November 13, 2023 5:00 PM (PST) 
 DSD 2021 | 2021-04-01  → 2021-04-20 | Palermo, Italy | September 1-3, 2021 |  
 DSD 2022 | 2022-04-01  → 2022-05-25 | Maspalomas, Spain | August 31-September 2, 2022 | Notification of Acceptance: May 31st, 2022  
  Camera-Ready Papers: June 15th, 2022 
 DSD 2023 | 2023-04-17  → 2023-05-28 | Durres, Albania | Sep 6-8, 2023 | Submission Deadline  : April 17, 2023  
  Notification of Acceptance  : May 29, 2023  
  Camera-Ready Papers  : June 16, 2023 
 DSD 2024 | May 5, 2024  → June 3, 2024 | Paris, France | Aug 28-30, 2024 | Notification of acceptance: 12th June 2024  
  Camera ready papers: 26th June 2024 
 ECRTS 2020 | — | Modena, Italy | July 7-10, 2020 | Went to virtual due to COVID-19. 
 ECRTS 2021 | 2021-03-03 | Virtual | July 5-9, 2021 | Notification of acceptance: April 22, 2021 
 ECRTS 2022 | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Notification: April 13, 2022  
  Camera-ready deadline: May 5, 2022 
 ECRTS 2023 | 2023-03-01 | Vienna, Austria | July 11-14, 2023 | Author Notification:  Apr 22, 2023 
 ECRTS 2024 | Feb 29, 2024 | Lille, France | July 9 - 12, 2024 | Notification: April 19, 2024  
  Camera-ready deadline: May 10, 2024 
 EMSOFT 2021 | 2021-04-09 | Virtual | October 10-15, 2021 | Abstract deadline: April 2, 2021; Part of the ESWEEK. 
 EMSOFT 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Abstract Deadline: March 31, 2022  
  Full paper submission: April 07, 2022  
  Work-in-progress paper submission: June 11, 2022  
  Author notification: July 05, 2022 
 EMSOFT 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22 | Journal Track:  
  - Abstract Submission: March 16, 2023 (AoE)  
  - Full Paper Submission: March 23, 2023 (AoE, firm)  
  - Notification of Acceptance: June 30, 2023  
   
  Work-in-Progress Track:  
  - Paper Submission: May 22, 2023 (AoE, firm)  
  - Notification of Acceptance: June 19, 2023  
   
  Proposals of Workshops, Tutorials, Education Classes, and Special Sessions: March 20, 2023 
 ESWEEK 2024  (EMSOFT, CASES, CODES+ISSS, MEMOCODE) | March 31, 2024 (*) | Raleigh, NC, USA | Sep 29 - Oct 4, 2024 | Journal Track:  
  - Abstract Submission: March 24, 2024 (AoE)  
  - Full Paper Submission: March 31, 2024 (AoE, firm)  
  - Notification of Acceptance: July 14, 2024  
  Work-in-Progress and Late Breaking Tracks: June 02, 2024 (AoE, firm)  
  Workshops, Tutorials, Education Classes, and Special Sessions: March 24, 2024 
 ICCAD 2020 | — | Virtual | November 2-5, 2020 |  
 ICCAD 2021 | 2021-05-28 | Munich, Germany | November 1-4, 2021 | Abstract deadline: Friday, May 21, 2021 
 ICCAD 2022 | 2022-05-23 | San Diego, California, USA (hybrid) | Oct 30 - Nov 3, 2022 | Abstract Deadline: 16 May, 2022 
 ICCAD 2023 | 2023-05-22  (*) | San Francisco, CA, USA | Oct 29 - Nov 2, 2023 | Abstract deadline:  May 15, 2023 
 ICCPS 2022 | 2021-10-29 | Milano, Italy | May 4-6, 2022 | Part of CPS-IoT week.  
  Abstract Registration: Oct 22  
  Author Notification: Jan 17, 2022 
 ICCPS 2023 | 2022-10-31 | San Antonio, Texas | May 9-12, 2023 | Part of the CPS-IoT Week  
  Abstract Registration: Oct 24, 2022  
  Decision Notification: Jan 20, 2023 
 ICCPS 2024 | Oct 31, 2023 (*) | Hong Kong, China | May 13-16 2024 | Abstract deadline:  October 24, 2023 
 ICCD 2024 | May 12, 2024  → May 20, 2024 | Milan, Italy | Nov 18-20, 2024 | Abstract Deadline: May 5, 2024 
 ICESS 2020 | — | Virtual | Dec 10-11, 2020 |  
 ICESS 2021 | 2021-07-31  → 2021-08-14 | Shanghai, China | Dec 13-14, 2021 | Author notification: Oct 4th, 2021 
 ICESS 2022 | 2022-09-01  → 2022-09-20 | Chengdu, China | Dec 18-20, 2022 | Author Notification: 15 Oct 2022 
 ICRA 2021 | — | Xi’an, China | May 30 - June 5, 2021 | Notification of acceptance: February 28, 2021 
 ICRA 2022 | 2021-09-09 | Philadelphia (PA), USA | May 23-27, 2022 | Notification of acceptance: Jan 31, 2022 
 ICRA 2023 | 2022-09-15 | London, UK | May 29 - June 2, 2023 | Notification of paper acceptance: 31 Jan, 2023 
 ICRA 2024 | Sep 15, 2023 | Tokyo, Japan | May 13-17, 2024 |  
 IROS 2020 | — | Las Vegas, USA  → Virtual | Oct 25 - Nov 25, 2020 | Changed to Virtual; Free registration. 
 IROS 2021 | 2021-03-05 | Prague, Czech Republic | Sep 27 - Oct 1, 2021 |  
 IROS 2022 | 2022-03-01 | Kyoto, Japan | Oct 23-27, 2022 | Submission deadline with RA-letter option: Feb 24, 2022 
 IROS 2023 | 2023-03-01 | Detroit, US | Oct 1-5, 2023 | The theme of IROS 2023 is “ The Next Generation of Robotics  ,” so the conference aims to particularly highlight the contributions of younger researchers and to help accelerate the future contributions of all those just entering the field.  
  Note: IROS no longer offers an RA-L + IROS submission option. Papers accepted at RA-L, T-RO, RAM, and T-ASE between August 1, 2022, and April 30, 2023 will be given the option to present at IROS2023.  
  Author Notification  : June 30, 2023 
 IROS 2024 | March 1, 2024 | Abu Dhabi | Oct 14-18, 2024 |  
 ISORC 2022 | 2022-02-12 | Västerås, Sweden | May 17-19, 2022 | Rebuttal period: March 23-25, 2022  
  Acceptance notification: April 4, 2022  
  Camera-ready papers: April 20, 2022 
 ISORC 2023 | 2023-01-28  → 2023-03-04 | Nashville, Tennessee, USA | May 23 - 25, 2023 | IEEE International Symposium on Real-Time Distributed Computing   
  Important Dates  :  
  - Acceptance Notification: April 04, 2023 
 ISORC 2024 | Feb 4, 2023 | Carthage, Tunis, Tunisia | May 22-25, 2024 |  
 LCTES 2021 | 2021-03-08 | Virtual | June 20-25, 2021 | Notification of acceptance: Apr 9, 2021 
 LCTES 2022 | 2022-03-07  → 2022-03-14 | San Diego, California, USA | June 13-17, 2022 | Paper notification: April 8, 2022  
  Artifact submission: April 16, 2022  
  Artifact decision: May 2, 2022  
  Camera-ready deadline: May 6, 2022 
 LCTES 2023 | 2023-03-16  → 2023-03-24 | Orlando, Florida | Jun 18, 2023 |  
 MEMOCODE 2023 | 2023-05-05  → 2023-05-26  (*) | Hamburg, Germany | Sep 17-22, 2023 | Abstract deadline:  Apr 28, 2023  → May 12, 2023 
 NeurIPS 2022 | 2022-05-19 | New Orleans - Hybrid | Nov 28 - Dec 9, 2022 | Abstract submission: May 16, 2022 
 NG-RES 2022  (w) | 2022-04-04 | Budapest, Hungary | June 22, 2022 | Workshop on next generation real-time systems @ HiPEAC conference.  
  Author notification: May 11th, 2022 
 NG-RES 2023  (w) | 2022-11-20  → 2022-11-27 | Toulouse, France | Jan 18, 2023 | Workshop on Next Generation Real-Time Embedded Systems. Co-located with HiPEAC 2023.  
  Author notification: Nov 20, 2022  
  Camera ready: Dec 31, 2022 
 NOCS 2022 | 2022-04-29  → 2022-05-20 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK.  
  Abstract submission: 13 May, 2022  
  Author notification: 8 July, 2022 
 NOCS 2023 | 2023-04-21  → 2023-05-08  (*) | Hamburg, Germany | Sep 17-22 | Abstract deadline: Apr 14, 2023  → May 8, 2023 
 OPERA 2023  (w) | Sep 3, 2023  → Sep 15, 2023 | Taipei, Taiwan | Dec 5, 2023 | Co-located with RTSS 2023  
   
  Important Dates:   
  - Notification (tentative): October 1st, 2023  
  - Camera-ready deadline (tentative): October 15th, 2023 
 OSPERT 2022  (w) | 2022-04-27  → 2022-05-04 | Modena, Italy | July 5, 2022 | Workshop on Operating Systems Platforms for Embedded Real-Time applications.  
  Held in conjunction with ECRTS. 
 OSPERT 2023  (w) | 2023-05-11  → 2023-05-18 | Vienna, Austria | July 11, 2023 | in conjunction with ECRTS’23  
  Notification of Acceptance:  May 30, 2023  
  Final submissions  : June 18, 2023 
 OSPERT 2024  (w) | May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS’24 
 RAGE 2022  (w) | 2022-03-20 | San Francisco, CA | July 10, 2022 | 1st Real-time And intelliGent Edge computing workshop (RAGE) — associated with DAC 2022. Topics cover real-time edge computing, QoS for virtualization, predictability in edge-to-cloud, predictability in middleware and real-time network protocols, etc.  
  Notification to authors: April 11th 2022 
 RAGE 2023  (w) | 2023-02-01  → 2023-02-15 | San Antonio, Texas | May 9, 2023 | Workshop on Real-time And intelliGent Edge computing   
  @ CPS-IoT Week 2023  
  Author Notification:  Mar 1st, 2023 
 RAGE 2024  (w) | Jan 25, 2024  → Feb 11, 2024 | Hong Kong | May 13th, 2024 | Workshop on Real-time And intelliGent Edge computing   
  @ CPS-IoT Week 2024  
  Author Notification:  Mar 1st, 2024 
 RO-MAN 2022 | 2022-03-15 | Naples, Italy | Aug 29 - Sep 2, 2022 | Author Notification: May 30, 2022  
  Camera Ready: June 15, 2022 
 RO-MAN 2023 | 2023-03-17  → 2023-03-31 | Busan, Korea | Aug 28-31 | Important Dates:   
  - Submission Deadline: March 17, 2023  
  - Notification of Acceptance: May 26, 2023  
  - Camera-Ready Deadline: June 30, 2023  
  - LBR Paper Submission: June 2, 2023  
  - LBR Acceptance Notification: June 30, 2023 
 RSS 2021 | 2021-03-01 | Virtual | July 12-16, 2021 | Notification of acceptance: May 10, 2021 
 RSS 2022 | 2022-01-28 | New York City | June 27-July 1, 2022 |  
 RSS 2023 | 2023-02-03 | Daegu, Korea | Jun 23 - 28, 2023 |  
 RTAS 2021 | — | Nashville, Tennessee, USA  → Virtual | May 18-21, 2021 |  
 RTAS 2022 | 2021-10-29 | Milano, Italy | May 4-6, 2022 | Part of CPS-IoT week.  
  Rebuttal Period: Jan 3-5, 2022  
  Author Notification: Jan 17, 2022 
 RTAS 2023 | 2022-10-31 | San Antonio, Texas | May 9-12, 2023 | Part of the CPS-IoT Week  
  Author Notification: Jan 20, 2023  
  BP submission deadline: Feb 10, 2023  
  AE submission deadline: Feb 24, 2023  
  Camera-Ready: March 17, 2023 
 RTAS 2024 | Oct 31, 2023 | Hong Kong, China | May 13-16, 2024 | Author notification: January 20, 2024 
 RTCSA 2022 | 2022-04-15  → 2022-04-29 | Taiwan - Hybrid | August 23-25, 2022 | Abstract Deadline: April 22, 2022  
  Co-located with NVMSA 2022. 
 RTCSA 2023 | 2023-04-14  → 2023-04-28  (*) | Niigata, Japan | Aug 30 - Sep 1, 2023 | Abstract deadline: Apr 7, 2023  → Apr 21, 2023 
 RTCSA 2024 | Apr 5, 2024 (*) | Sokcho, South Korea | Aug 21-23, 2024 | Abstract Deadline: March 29, 2024 
 RTSOPS 2022  (w) | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Workshop on Real-Time Scheduling Open Problems Seminar. Associated with ECRTS. 
 RTSOPS 2024  (w) | May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS’24 
 RTSS 2020 | — | Virtual | Dec 1-4, 2020 |  
 RTSS 2021 | 2021-05-27 | Dortmund, Germany  → Fully Virtual | Dec 7-10, 2021 | Submissions can go to either the real-time system track (Track 1) or the design and application track (Track 2). 
 RTSS 2022 | 2022-05-26 | Houston, USA | Dec 5-8, 2022 | Rebuttal Period: 15-21 July, 2022  
  Paper Notification: August 5, 2022 
 RTSS 2023 | 2023-05-25 | Taipei, Taiwan | Dec 5-8, 2023 | Rebuttal Period:  July 14, 2023 to July 20, 2023  
  Paper Notification:   
  August 4, 2023  
  Camera-Ready Deadline:   
  October 6, 2023 
 RTNS 2021 | — | Nantes, France  →Virtual | April 7-9, 2021 | Went to fully virtual due to COVID-19. 
 RTNS 2022 | 2022-02-24  → 2022-03-09 | Paris, France | June 7-8, 2022 | Author notification: April 20, 2022  
  Camera ready: May 4, 2022 
 RTNS 2023 | 2023-01-25 (*) | Dortmund, Germany | June 6-8, 2023 | This is the 2nd round of the new Double Submission Model   
  Important Dates  :  
  - Abstract Deadline: Jan 23th, 2023  
  - Author Notification: Mar 4th, 2023 
 RTNS 2024 | Aug 16, 2024 (*) | Porto, Portugal | Nov 7-8, 2024 | Important Dates  (3rd round):  
  - Abstract Deadline : Aug 14th, 2024  
  - Author Notification: Oct 7, 2024 
 RT-Cloud 2022  (w) | 2022-02-02  → 2022-05-04 | Modena, Italy | July 5, 2022 | Workshop on Real-Time Cloud Computing. Associated with ECRTS.  
  Author Notification: May 4, 2022 
 SIES 2024 | Apr 30, 2024  → June 30, 2024 | Chengdu, China | Oct 23-25, 2024 |  
 TAROS 2020 | — | Nottingham, UK | Sep 16, 2020 |  
 TAROS 2021 | 2021-05-28 | Virtual | September 8-10, 2021 | Author Notification: July 1, 2021 
 TAROS 2022 | 2022-05-20 | Culham Science Centre, UK | Sep 7-9, 2022 | Confirmation of acceptance: June 10th, 2022 
 TAROS 2024 | Apr 30, 2024  → May 12, 2024 | London, UK | Aug 21-23, 2024 | Author Notification: June 15, 2024  
  Final submission: June 30, 2024  
  Conference: August 21-23, 2024 
 TCRS 2023  (w) | 2023-02-10 | San Antonio, Texas | May 9, 2023 | Workshop on Time-Centric Reactive Software   
  @ CPS-IoT Week 2023  
  Author Notification: Mar 3rd, 2023 
 WCET 2022  (w) | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Workshop on Worst-case Execution Times. Associated with ECRTS. 
 WCET 2023  (w) | 2023-05-11  → 2023-05-18 | Vienna, Austria | July 11, 2023 | in conjunction with ECRTS’23  
  Acceptance notification  : May 30 
 WCET 2024  (w) | May 9, 2024  → May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS’24 
 WMC 2022  (w) | 2022-09-05  → 2022-09-12 | Houston, USA | Dec 5, 2022 | Workshop on Mixed-Criticality Systems. (cfp)   
  Associated with RTSS 2022.  
  Notification of acceptance: Oct 10, 2022  
  Final version: Oct 24, 2022 
 WMC 2023  (w) | Sep 3, 2023 | Taipei, Taiwan | Dec 5, 2023 | Co-located with RTSS 2023  
   
  Important Dates:   
  - Author Notification: October 01, 2023  
  - Camera Ready: October 15, 2023 
  
  Journal List  
 Top journals for Real-Time Systems, Embedded Systems, Design Automation, and Parallel Computing  
  
 Name | Publisher 
 ACM Transactions on Embedded Computing Systems (TECS) | ACM 
 ACM Transactions on Computer Systems (TOCS) | ACM 
 ACM Transactions on Parallel Computing (TOPC) | ACM 
 ACM Transactions on Cyber-Physical Systems (TCPS) | ACM 
 ACM Transactions on Modeling and Computer Simulation (TOMACS) | ACM 
 ACM Transactions on Design Automation of Electronic Systems (TODAES) | ACM 
 ACM Journal on Emerging Technologies in Computing Systems (JETC) | ACM 
 ACM Transactions on Internet of Things (TIOT) | ACM 
 ACM Transactions on Sensor Networks (TOSN) | ACM 
 Formal Aspects of Computing: Applicable Formal Methods (FAC) | ACM 
 IEEE Transactions on Computers (TC) | IEEE 
 IEEE Transactions on Computer-Aided Design of Integrated Circuits And System (TCAD) | IEEE 
 IEEE Transactions on Parallel and Distributed Systems (TPDS) | IEEE 
 IEEE Embedded Systems Letters (ESL) | IEEE 
 Microprocessors and Microsystems (MICPRO) | Elsevier 
 Journal of Systems Architecture (JSA) | Elsevier 
 Real-Time Systems Journal (RTSJ) | Springer 
  
 Top journals for Robotics, Control, Vision and Learning  
  
 Name | Publisher 
 ACM Transactions on Human-Robot Interaction (THRI) | ACM 
 IEEE Transactions on Robotics (TRO) | IEEE 
 IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) | IEEE 
 IEEE Robotics and Automation Letters (RA-L) | IEEE 
 IEEE Robotics and Automation Magazine (RAM) | IEEE 
 Robotics and Autonomous Systems (RAS) | Elsevier 
 Journal of Intelligent and Robotic Systems (JINT) | Springer 
 International Journal of Computer Vision (IJCV) | Springer 
 International Journal of Robotics Research (IJRR) | SAGE 
 Journal of Machine Learning Research (JMLR) | Microtome 
 Journal of Field Robotics (JFR) | Wiley 
  
  Useful Links  
 IEEE TCRTS 
  ACM SIGBED 
  ACM SIGBED Blog 
  ACM SIGDA 
  Conference Ranks 
  Scimago Journal & Country Rank 
  An Incomplete List of Conferences in Computer Science 

  Call for papers data:26 th  Ada-Europe  
 International Conference on  
  Reliable Software Technologies  
  (AEiC 2022)  
   
 14-17 June 2022, Ghent, Belgium  

 Welcome 

 Call for Contributions  
 Call for contributions available in PDF  . Please distribute!  
  General Information  
 The 26th Ada-Europe International Conference on Reliable Software Technologies (AEiC 2022)  , will take place in Ghent, Belgium in dual mode, with a solid core of inpresence activities accompanied by digital support for remote participation. The conference schedule comprises a journal track, an industrial track a work-in-progress (WiP) track, a vendor exhibition, parallel tutorials, and satellite workshops.  
 Journal-track submissions | present research advances supported by solid theoretical foundation and thorough evaluation. 
  WiP-track submissions | illustrate a novel research idea that is still at an initial stage, between conception and first prototype. 
  Industrial-track submissions | highlight the practitioners' side of a challenging case study or industrial project. 
  Tutorial submissions | guide attenders through a hands-on familiarization with innovative developments or with useful features related to critical software. 
   
  Call for Journal‐track Submissions  
 Following the journal‐first model  inaugurated in 2019, the conference includes a journal‐track  that seeks original and high‐quality submissions that describe mature research work in the scope of the conference. Accepted papers for this track will be published in the "Reliable Software Technologies ( AEiC2022  )" Special Issue of the Journal of Systems Architecture (JSA).  

 Submissions should be made online at Editorial Manager  by selecting the “VSI:AEiC2022” option for the paper type. Details on the special issue can be found on this page.  General information for submitting to the JSA can be found at the Journal of Systems Architecture website  .  
  In order to speed up publication, the JSA has adopted the Virtual Special Issue model, whereby acceptance decisions are made on a rolling basis. On that account, authors are encouraged to submit as early as they can, no later than 16 January 2022. Authors who have successfully passed the first round of review will be invited to present their work at the conference  . Ada‐Europe, the main conference sponsor, will cover the Open Access fees for the first four papers  to gain final acceptance which do not already enjoy OA from personalized bilateral agreements with the Publisher.  
 Prospective authors may direct all enquiries regarding this track to the corresponding chair, Jérôme Hugues  .  
  Call for Industrial‐track Submissions  
 The conference seeks industrial practitioner presentations  that deliver insight on the challenges of developing reliable software. Given their applied nature, such contributions will be subject to a dedicated practitioner‐peer review process.  

 Interested authors shall submit a short (one‐to‐two pages) abstract  , by 27 February 2022 via Easy Chair  , strictly in PDF following the Ada User Journal  style.  
  The abstract of the accepted contributions will be included in the conference booklet. The corresponding authors will get a presentation slot in the prime‐time technical program of the conference, and will also be invited to expand their contributions into full‐fledged articles for publication in the Ada User Journal, which will form the proceedings of the Industrial track of the Conference.  
 The Industrial Track welcomes contributions that fit the general scope of the conference  , and actively address the perspective of practitioners on the topic of interest. Especially welcome are submissions of the following kind:  
 Experience with languages, tools, methodologies, and products for the achievement of safety and reliability in large or complex projects and systems. 
  Lessons learned in the design, implementation and deployment of reliable software, high-integrity systems, real-time and embedded systems, etc. 
  Insights into language tools and libraries that incorporate or target reliability in software. 
  Reports and highlights from ongoing or completed challenging projects where software is a critical component of the system. 
  Practical hands-on sharing of knowledge gained in the practice of building reliable software. 
  Reliable Software Technologies 
   
 Prospective authors may direct all enquiries regarding this track to the corresponding chair Alejandro R. Mosteo  .  
  Call for Work‐in‐Progress‐track Submissions  
 The Work‐in‐Progress track seeks two kinds of submissions: (a) ongoing research  , and (b) early‐stage ideas  . Ongoing research  submissions are 4‐page papers that describe research results that are not mature enough to be submitted to the journal track as yet. Early‐stage ideas  , are 1‐page papers that pitch new research directions that fall in the scope of the conference.  
 Topics addressed by the WIP track are close by the journal track:  
 Real-Time and Safety-Critical Systems 
  High-Integrity Systems and Reliability 
  Reliability-oriented Programming Languages 
  Experience Reports 
   
 The WIP track is expected to address emerging areas where reliability is a first class requirement. WIP submissions may cover new application domains, new technologies, and new methods related to reliable software, such as autonomous systems, IoT, Industries 4.0, IA for critical systems, Cloud/Edge, security, energy management, etc.  
 Both kinds of submission must be original and shall undergo anonymous peer review. Submissions by recent MSc graduates and PhD students are especially sought.  

 Authors shall submit their work by 27 February 2022, via Easy Chair  , strictly in PDF, following the Ada User Journal  style.  
  The abstract of the accepted contributions will be included in the conference booklet. The corresponding authors will get a presentation slot in the prime‐time technical program of the conference, and will also be offered the opportunity to expand their contributions into 4‐page articles for publication in the Ada User Journal which will form the proceedings of the WiP track of the Conference.  
 Prospective authors may direct all enquiries regarding this track to the corresponding chair Frank Singhoff  .  
  Academic Listing  
 The Journal of Systems Architecture  , publication venue of the journal‐track proceedings of the conference, was ranked Q1 (SJR) in the year 2020, also featuring 72 th  percentile in CiteScope (Scopus). The Ada User Journal  , venue of all other technical proceedings of the conference, is indexed by Scopus and by EBSCOhost in the Academic Search Ultimate database.  
  Awards  
 Ada‐Europe will offer an honorary award for the best technical presentation  , to be announced in the closing session of the conference.  
  Call for Tutorials  
 The conference seeks tutorials  in the form of educational seminars on themes falling within the scope of the conference, with hands‐on or practical elements, and a topical slant oriented to selected targets in the typical conference audience.  
 The conference audience includes professionals who work in critical systems or develop features for them students in computer science or engineering education academic researchers in the field of conference interest, or people who merely approach software development as a hobby.  
 If you have developed or learned of libraries, tools, compilers, methodologies or programming languages related with critical systems that may ease the software development job of others, you would be a natural candidate for offering a tutorial.  

 Tutorial proposals include:  
 A title 
  A short abstract (between 100 and 200 words) 
  A bulleted-list outline of the presentation topics 
  The proposed duration (half day or full day) 
  The intended target and level of the contents (introductory, intermediate, or advanced) 
  A statement motivating attendance. 
   
 Tutorials should be delivered in presence unless exceptional circumstances should dictate otherwise. Tutorial proposals should indicate whether additional audience might be remote.  
 Submissions shall be sent by e‐mail to the Tutorial and Workshop Chair  , Aurora Agar Armario  , with subject line: "[AEiC 2022: tutorial proposal]".  
  The authors of accepted full‐day tutorials will receive a complimentary conference registration halved for half‐day tutorials. The Ada User Journal  will offer space for the publication of summaries of the accepted tutorials.  
  Call for Workshops  
 The conference welcomes satellite workshops centred on themes that fall within the conference scope. Proposals may be submitted for half‐ or full‐day events, to be scheduled at either end of the conference proper.  

 Workshop proposals shall be submitted by e‐mail to the Tutorial and Workshop Chair  , Aurora Agar Armario  , with subject line: "[AEiC 2022: workshop proposal]  
  Workshop organizers shall also commit to producing the proceedings of the event, for publication in the Ada User Journal  .  
  Call for Exhibitors  
 The conference will include a vendor and technology exhibition. Interested providers should direct inquiries to the Exhibition & Sponsorship Chair  , Ahlan Marriott  .  

  Important dates data

4. Conference SMC_3:
IEEE.org 
  IEEE Xplore  Digital Library 
  IEEE Standards Association 
  Spectrum Online 
  More IEEE Sites 
  Login 

 Skip to content    

 Search   Search    

           Join SMC    

 Main Navigation  
   About SMCS | Governance 
  Awards 
  History 
  IEEE Fellow Program 
  Volunteer Information 
  Website Update Request 
  Mentorship Program 
  Brand Materials 
  Membership 
  Conferences | Obtaining SMC Conference Sponsorship 
  Calendar 
  Publications | eNewsletter 
  IEEE Access: IEEE Systems, Man, and Cybernetics Society Section 
  IEEE Systems, Man, and Cybernetics Letters (SMC-L) 
  SMC Magazine 
  Transactions on SMC: Systems 
  Transactions on Human-Machine Systems 
  Transactions on Cybernetics 
  Transactions on Computational Social Systems 
  IEEE/CAA Journal of Automatica Sinica 
  Journal Highlights 
  Technical Activities | Cybernetics 
  Human Machine Systems 
  Systems Science and Engineering 
  Chapters & Communities | Chapters 
  Distinguished Lecturer Program 
  Student Activities 
  Young Professionals 
  SMC Women in Engineering 
  Equity, Diversity, and Inclusion 
  Information for Authors 

 Home   » Conferences   » Calendar   » SMC Society Conferences    
 About SMCS | Governance | Board of Governers | SMCS Documents 
  Society Committees 
  Nominations | Nomination Form 
  Constitution | Article I 
  Article II 
  Article III 
  Article IV 
  Article V 
  Article VI 
  Article VII 
  Article VIII 
  Article IX 
  Article X 
  Article XI 
  Bylaws | Article I 
  Article II 
  Article III 
  Article IV 
  Awards | Joseph G. Wohl Outstanding Career Award 
  Norbert Wiener Award 
  Andrew P. Sage Best Transactions Paper Award 
  Best Associate Editor Award 
  Outstanding Contribution Award 
  Most Active Technical Committee Award 
  Outstanding SMC Chapter Award 
  Outstanding SMC Student Chapter Award 
  Franklin V. Taylor Memorial Award 
  SMC Best Student Paper Award 
  Lotfi A. Zadeh Pioneer Award 
  Early Career Award 
  Meritorious Service Award 
  Outstanding Service to Humanity Award 
  History | 2014 Archives 
  2015 Archives 
  2016 Archives 
  2017 Archives 
  2018 Archives 
  2019 Archives 
  2020 Archives 
  IEEE Fellow Program 
  Volunteer Information | Business Class Travel Procedures 
  Recording of BoG and ExCom Meetings 
  Website Update Request 
  Mentorship Program 
  Brand Materials 
  Membership 
  Conferences | Obtaining SMC Conference Sponsorship 
  Calendar | SMC Society Conferences 
  Financially Co-Sponsored Conferences 
  Technically Co-Sponsored Conferences 
  SMC Related Conferences 
  Summer School 
  Distinguished Lecturers 
  Publications | eNewsletter 
  IEEE Access: IEEE Systems, Man, and Cybernetics Society Section | IEEE Access: IEEE Systems, Man, and Cybernetics Society Section 
  IEEE Systems, Man, and Cybernetics Letters (SMC-L) 
  SMC Magazine | Information for Authors 
  Special Section General Guidelines 
  Current Issue 
  Associate Editors 
  Transactions on SMC: Systems | Submissions 
  Information for Authors 
  Information for Accepted Papers 
  Current Issue 
  Special Issues 
  Senior Editors / Associate Editors 
  Transactions on Human-Machine Systems | Current Issue 
  Information for Authors 
  Special Issues 
  Submissions 
  Associate Editors 
  Information for Accepted Papers 
  Information for Reviewers 
  ORCID Information 
  Transactions on Cybernetics | Current Issue 
  Submissions 
  Special Issues 
  Associate Editors 
  Information for Authors 
  Transactions on Computational Social Systems | Contents 
  Templates 
  Submissions 
  Information for Authors 
  Call for Papers and Special Issues 
  IEEE/CAA Journal of Automatica Sinica | Templates 
  Submissions 
  Associate Editors 
  Call for Papers and Special Issues 
  Information for Authors 
  Journal Highlights 
  Technical Activities | Cybernetics | Awareness Computing 
  Big Data Computing 
  Brain-Inspired Cognitive Systems 
  Cognitive Situation Management 
  Computational Collective Intelligence 
  Computational Cybernetics 
  AI-Based Smart Manufacturing Systems 
  Computational Intelligence 
  Computational Life Science 
  Computational Psychophysiology 
  Cyber-enabled World 
  Cyber-Medical Systems 
  Cybernetics for Cyber-Physical Systems 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Evolving Intelligent Systems 
  Granular Computing 
  Information Assurance & Intelligent Multimedia-Mobile Communications 
  Intelligent Industrial Systems 
  Intelligent Internet Systems 
  Intelligent Vehicular Systems & Control 
  Knowledge Acquisition in Intelligent Systems 
  Machine Learning 
  Medical Informatics 
  Social and Economic Security 
  Social Computing and Social Intelligence 
  Soft Computing 
  Quantum Cybernetics 
  Human Machine Systems | Biometrics and Applications 
  Brain-Machine Interface Systems 
  Cognitive Computing 
  Companion Technology 
  Computer Supported Cooperative Work in Design 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Environmental Sensing, Networking and Decision-Making (ESND) 
  Human Centered Transportation Systems 
  Humanized Crowd Computing 
  Human-Machine Interaction for Connected and Automated Vehicles 
  Information Systems for Design and Marketing 
  Interactive and Wearable Computing and Devices 
  Shared Control 
  Visual Analytics and Communication 
  Systems Science and Engineering | Autonomous Bionic Robotic Aircraft 
  Bio-mechatronics and Bio-robotics Systems 
  Blockchain 
  Conflict Resolution 
  Cyber-Physical Cloud Systems 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Discrete Event Systems 
  Distributed Intelligent Systems 
  Enterprise Architecture and Engineering 
  Enterprise Information Systems 
  Flexible Electronic Systems 
  Grey Systems 
  Homeland Security 
  Intelligent Learning in Control Systems 
  Intelligent Power and Energy Systems 
  Intelligent Systems to Human-Aware Sustainability 
  Intelligent Transportation Systems 
  Logistics Informatics and Industrial Security Systems 
  Medical Mechatronics 
  Model-Based Systems Engineering 
  Robotics and Intelligent Sensing 
  Service Systems and Organization 
  Systems Biology 
  System of Systems 
  Chapters & Communities | Chapters | Americas 
  Europe/Africa 
  Asia 
  Support for Chapters 
  Distinguished Lecturer Program | Operating Procedures 
  Distinguished Lecturers 
  Ambassador Program 
  Student Activities | Student Branch Chapters 
  Resources 
  Young Professionals 
  SMC Women in Engineering 
  Equity, Diversity, and Inclusion 
  Information for Authors 

 SMC Society Conferences  
  
 All upcoming and past conferences run by the SMC Society.  
 SMC 2028 in Europe/Africa  
 SMC 2027 in Ho Chi Minh City, Vietnam  
 SMC 2026 in Bellevue, WA, USA  
 SMC 2025 in Vienna, Austria  
 SMC 2024 in Kuching City, Malaysia  
 SMC 2023 in Hawaii, USA  
 SMC 2022 in Prague, Czech Republic  
   
 No event found!   

 The SMC Society Mission  
   The mission of the Systems, Man, and Cybernetics Society is to serve the interests of its members and the community at large by promoting the theory, practice, and interdisciplinary aspects of systems science and engineering  , human-machine systems  , and cybernetics  . It is accomplished through conferences, publications, and other activities that contribute to the professional needs of its members.   

 Contact & Support 
  Accessibility 
  Nondiscrimination Policy 
  Privacy & Opting Out of Cookies 
  Feedback 

 © 2024, IEEE Systems, Man, and Cybernetics Society – All rights reserved. Use of this website signifies your agreement to the IEEE Terms and Conditions. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.  

  Call for papers data:IEEE.org 
  IEEE Xplore  Digital Library 
  IEEE Standards Association 
  Spectrum Online 
  More IEEE Sites 
  Login 

 Skip to content    

 Search   Search    

           Join SMC    

 Main Navigation  
   About SMCS | Governance 
  Awards 
  History 
  IEEE Fellow Program 
  Volunteer Information 
  Website Update Request 
  Mentorship Program 
  Brand Materials 
  Membership 
  Conferences | Obtaining SMC Conference Sponsorship 
  Calendar 
  Publications | eNewsletter 
  IEEE Access: IEEE Systems, Man, and Cybernetics Society Section 
  IEEE Systems, Man, and Cybernetics Letters (SMC-L) 
  SMC Magazine 
  Transactions on SMC: Systems 
  Transactions on Human-Machine Systems 
  Transactions on Cybernetics 
  Transactions on Computational Social Systems 
  IEEE/CAA Journal of Automatica Sinica 
  Journal Highlights 
  Technical Activities | Cybernetics 
  Human Machine Systems 
  Systems Science and Engineering 
  Chapters & Communities | Chapters 
  Distinguished Lecturer Program 
  Student Activities 
  Young Professionals 
  SMC Women in Engineering 
  Equity, Diversity, and Inclusion 
  Information for Authors 

 Home   » About SMCS   » Awards   » Andrew P. Sage Best Transactions Paper    
 About SMCS | Governance | Board of Governers | SMCS Documents 
  Society Committees 
  Nominations | Nomination Form 
  Constitution | Article I 
  Article II 
  Article III 
  Article IV 
  Article V 
  Article VI 
  Article VII 
  Article VIII 
  Article IX 
  Article X 
  Article XI 
  Bylaws | Article I 
  Article II 
  Article III 
  Article IV 
  Awards | Joseph G. Wohl Outstanding Career Award 
  Norbert Wiener Award 
  Andrew P. Sage Best Transactions Paper Award 
  Best Associate Editor Award 
  Outstanding Contribution Award 
  Most Active Technical Committee Award 
  Outstanding SMC Chapter Award 
  Outstanding SMC Student Chapter Award 
  Franklin V. Taylor Memorial Award 
  SMC Best Student Paper Award 
  Lotfi A. Zadeh Pioneer Award 
  Early Career Award 
  Meritorious Service Award 
  Outstanding Service to Humanity Award 
  History | 2014 Archives 
  2015 Archives 
  2016 Archives 
  2017 Archives 
  2018 Archives 
  2019 Archives 
  2020 Archives 
  IEEE Fellow Program 
  Volunteer Information | Business Class Travel Procedures 
  Recording of BoG and ExCom Meetings 
  Website Update Request 
  Mentorship Program 
  Brand Materials 
  Membership 
  Conferences | Obtaining SMC Conference Sponsorship 
  Calendar | SMC Society Conferences 
  Financially Co-Sponsored Conferences 
  Technically Co-Sponsored Conferences 
  SMC Related Conferences 
  Summer School 
  Distinguished Lecturers 
  Publications | eNewsletter 
  IEEE Access: IEEE Systems, Man, and Cybernetics Society Section | IEEE Access: IEEE Systems, Man, and Cybernetics Society Section 
  IEEE Systems, Man, and Cybernetics Letters (SMC-L) 
  SMC Magazine | Information for Authors 
  Special Section General Guidelines 
  Current Issue 
  Associate Editors 
  Transactions on SMC: Systems | Submissions 
  Information for Authors 
  Information for Accepted Papers 
  Current Issue 
  Special Issues 
  Senior Editors / Associate Editors 
  Transactions on Human-Machine Systems | Current Issue 
  Information for Authors 
  Special Issues 
  Submissions 
  Associate Editors 
  Information for Accepted Papers 
  Information for Reviewers 
  ORCID Information 
  Transactions on Cybernetics | Current Issue 
  Submissions 
  Special Issues 
  Associate Editors 
  Information for Authors 
  Transactions on Computational Social Systems | Contents 
  Templates 
  Submissions 
  Information for Authors 
  Call for Papers and Special Issues 
  IEEE/CAA Journal of Automatica Sinica | Templates 
  Submissions 
  Associate Editors 
  Call for Papers and Special Issues 
  Information for Authors 
  Journal Highlights 
  Technical Activities | Cybernetics | Awareness Computing 
  Big Data Computing 
  Brain-Inspired Cognitive Systems 
  Cognitive Situation Management 
  Computational Collective Intelligence 
  Computational Cybernetics 
  AI-Based Smart Manufacturing Systems 
  Computational Intelligence 
  Computational Life Science 
  Computational Psychophysiology 
  Cyber-enabled World 
  Cyber-Medical Systems 
  Cybernetics for Cyber-Physical Systems 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Evolving Intelligent Systems 
  Granular Computing 
  Information Assurance & Intelligent Multimedia-Mobile Communications 
  Intelligent Industrial Systems 
  Intelligent Internet Systems 
  Intelligent Vehicular Systems & Control 
  Knowledge Acquisition in Intelligent Systems 
  Machine Learning 
  Medical Informatics 
  Social and Economic Security 
  Social Computing and Social Intelligence 
  Soft Computing 
  Quantum Cybernetics 
  Human Machine Systems | Biometrics and Applications 
  Brain-Machine Interface Systems 
  Cognitive Computing 
  Companion Technology 
  Computer Supported Cooperative Work in Design 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Environmental Sensing, Networking and Decision-Making (ESND) 
  Human Centered Transportation Systems 
  Humanized Crowd Computing 
  Human-Machine Interaction for Connected and Automated Vehicles 
  Information Systems for Design and Marketing 
  Interactive and Wearable Computing and Devices 
  Shared Control 
  Visual Analytics and Communication 
  Systems Science and Engineering | Autonomous Bionic Robotic Aircraft 
  Bio-mechatronics and Bio-robotics Systems 
  Blockchain 
  Conflict Resolution 
  Cyber-Physical Cloud Systems 
  Cyber Humanities 
  Cyber Systems and Engineering 
  Discrete Event Systems 
  Distributed Intelligent Systems 
  Enterprise Architecture and Engineering 
  Enterprise Information Systems 
  Flexible Electronic Systems 
  Grey Systems 
  Homeland Security 
  Intelligent Learning in Control Systems 
  Intelligent Power and Energy Systems 
  Intelligent Systems to Human-Aware Sustainability 
  Intelligent Transportation Systems 
  Logistics Informatics and Industrial Security Systems 
  Medical Mechatronics 
  Model-Based Systems Engineering 
  Robotics and Intelligent Sensing 
  Service Systems and Organization 
  Systems Biology 
  System of Systems 
  Chapters & Communities | Chapters | Americas 
  Europe/Africa 
  Asia 
  Support for Chapters 
  Distinguished Lecturer Program | Operating Procedures 
  Distinguished Lecturers 
  Ambassador Program 
  Student Activities | Student Branch Chapters 
  Resources 
  Young Professionals 
  SMC Women in Engineering 
  Equity, Diversity, and Inclusion 
  Information for Authors 

 Andrew P. Sage Best Transactions Paper  
  
 Description  
 To recognize the authors of the best paper published annually in the IEEE Transactions on Systems, Man and Cybernetics (SMC).  ( established in 1998  )  
 Prize  
 $500 for each author up to a maximum of $2,500 for multiple authors, and a Plaque for each author.  
 Funding  
 Funded by the IEEE Systems, Man, and Cybernetics Society through an endowment administered by the IEEE Foundation.  
 Eligibility  
 Authors of papers published in the IEEE Transactions on Systems, Man, and Cybernetics during the previous two calendar years.  
 Basis for Judging  
 Originality, technical merit, potential impact to the SMCS Field of Interest, and presentation quality.  
 Presentation  
 At the IEEE International Conference on Systems, Man, and Cybernetics.  
  Past Awardees  
 2024  
 X. Li, H. Shao, S. Lu, J. Xiang, B. Cai | For the paper “Highly efficient fault diagnosis of rotating machinery under time-varying speeds using LSISMM and small infrared thermal images.” IEEE Transactions on Systems, Man, and Cybernetics: Systems, 52(12): 7328-7340, December 2022. 
  Yu Gu, Xiang Zhang, Yantong Wang, Meng Wang, Huan Yan, Yusheng Ji, Zhi Liu Jianhua Li, and Mianxiong Dong | For the paper “WiGRUNT: WiFi-enabled gesture recognition using dual-attention network,” in IEEE Transactions on Human-Machine Systems, vol. 52, no. 4, pp. 736–746, Aug. 2022 
  Huijun Gao, Zhengkai Li, Xinghu Yu and Jianbin Qiu | For the paper “Hierarchical multiobjective heuristic for PCB assembly optimization in a beam-head surface mounter,” IEEE Transactions on Cybernetics, vol. 52, no. 7, pp. 6911-6924, July 2022 
  Wang, Y., Liu, Z., Xu, J., & Yan, W. | For the paper “Heterogeneous network representation learning approach for ethereum identity identification.” IEEE Transactions on Computational Social Systems, 10(3), 890-899, June 2023. 
  2023  
 Tianfu Li, Zhibin Zhao, Chuang Sun, Li Cheng, Xuefeng Chen, Ruqiang Yan, and Robert X. Gao | For the paper “WaveletKernelNet: An Interpretable Deep Neural Network for Industrial Intelligent Diagnosis,” IEEE Transactions on Systems, Man, and Cybernetics: Systems, Vol. 52, No. 4, April 2022, pp. 2302-2312 -190. 
  Lin Guo, Zongxing Lu, and Ligang Yao | For the paper “Human-Machine Interaction Sensing Technology Based on Hand Gesture Recognition: A Review,”IEEE Transactions on Human-Machine Systems, Vol. 51, No. 4, August 2021, pp. 300–309. 
  Yongming Li, Fuyi Qu, and Shaocheng Tong | For the paper “Observer-Based Fuzzy Adaptive Finite-Time Containment Control of Nonlinear Multiagent Systems With Input Delay,” IEEE Transactions on Cybernetics, Vol. 51, No. 1, January 2021, pp. 126–137. 
  Xiaokang Zhou, Wei Liang, Kevin I-Kai Wang, and Laurence T. Yang | For the paper “Deep Correlation Mining Based on Hierarchical Hybrid Networks for Heterogeneous Big Data Recommendations,” IEEE Transactions on Computational Social Systems, Vol. 8, Issue 1, February 2021, pp. 171-178. 
  2022  
 Derui Ding, Qing-Long Han, Xiaohua Ge, and Jun Wang | For the paper “Secure State Estimation and Control of Cyber-Physical Systems: A survey,” IEEE Transactions on Systems, Man, and Cybernetics: Systems, Vol. 51, No. 1, pp. 176-190, 2021. 
  Aniana Cruz, Gabriel Pires, Ana Lopes, Carlos Carona, and Urbano J. Nunes | For the paper “A Self-Paced BCI with a Collaborative Controller for Highly Reliable Wheelchair Driving: Experimental Tests With Physically Disabled Individuals,” IEEE Transactions on Human-Machine Systems, Vol. 51, No. 2, pp. 109-119, 2021. 
  Chao Deng, Wei-Wei Che, and Zheng-Guang Wu | For the paper “A Dynamic Periodic Event-Triggered Approach to Consensus of Heterogeneous Linear Multiagent Systems With Time-Varying Communication Delays,” IEEE Transactions on Cybernetics, Vol. 51, No. 4, pp. 1812-1821, 2021. 
  Usman Naseem, Imran Razzak, Matloob Khushi, Peter W. Eklund and Jinman Kim | For the paper “COVIDSenti: A Large-Scale Benchmark Twitter Data Set for COVID-19 Sentiment Analysis,” IEEE Transactions on Computational Social Systems, Vol. 8, Iss. 4, pp. 1003-1015, 2021. 
  2021  
 Shuai Wang, Liwei Ouyang, Yong Yuan, Xiaochun Ni, Xuan Han, and Fei-Yue Wang | For the paper entitled “Blockchain-Enabled Smart Contracts: Architecture, Applications, and Future Trends,” published in the IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 49, no. 11, pp. 2266-2277, November 2019. 
  Wen Qi, Hang Su, and Andrea Aliverti | For the paper entitled “A Smartphone-Based Adaptive Recognition and Real-Time Monitoring System for Human Activities,” published in the IEEE Transactions on Human-Machine Systems, vol. 50, no. 5, pp. 414-423, October 2020. 
  Lei Liu, Yan-Jun Liu, and Shaocheng Tong | For the paper entitled “Neural Networks-Based Adaptive Finite-Time Fault-Tolerant Control for a Class of Strict-Feedback Switched Nonlinear Systems,” published in the IEEE Transactions on Cybernetics, vol. 49, no. 7, pp. 2536-2545, July 2019. 
  Lifang Li, Quingpeng Zhang, Xiao Wang, Jun Zhang, Tao Wang, Tian-Lu Gao, Wei Duan, Kelvin Kam-fai Tsoi, and Fei-Yue Wang | For the paper entitled “Characterizing the Propagation of Situational Information in Social Media During the COVID-19 Epidemic: A Case Study on Weibo,” published in the IEEE Transactions on Computational Social Systems, vol. 7, iss. 2, pp. 556-562, April 2020. 
  2020  
 Xiakang Zhou, Wei Liang, Kevin I-Kai Wang, and Shohei Shimizu | For the paper “Multi-Modality Behavioral Influence Analysis for Personalized Recommendations in Health Social Media Environment”, IEEE Transactions on Computational Social Systems, Vol. 6, No. 5, October 2019, pp. 888-897 
  Ruoxu Ren, Terence Hung, and Kay Chen Tan | For the paper “A Generic Deep-Learning-Based Approach for Automated Surface Inspection”, IEEE Transactions on Cybernetics, Vol. 48, No. 3, March 2018, pp. 929-940 
  Guy Hoffman | For the paper “Evaluating Fluency in Human-Robot Collaboration”, IEEE Transactions on Human-Machine Systems, Vol. 49, No. 3, June 2019, pp. 209-218 
  Derui Ding, Zidong Wang, Qing-Long Han, an Guoliang Wei | For the paper “Security Control for Discrete-Time Stochastic Nonlinear Systems Subject to Deception Attacks”, IEEE Transactions on Systems, Man and Cybernetics: Systems, Vol. 48, No. 5, May 2018, pp. 779-789 
  2019  
 Yong Yuan, Fei-Yue Wang, and Daniel Zeng | For the paper entitled “Competitive Analysis of Bidding Behavior on Sponsored Search Advertising Markets” published in the IEEE Transactions on Computational Social Systems, vol. 4, no. 3, pp. 179-190, September 2017. 
  Lei Ding, Qing-Long Han, Xiaohua Ge, and Xian-Ming Zhang | For the paper entitled “An Overview of Recent Advances in Event-Triggered Consensus of Multiagent Systems” published in the IEEE Transactions on Cybernetics, vol. 48, no. 4, pp. 1110-1123, April 2018. 
  Max Mulder, Daan M. Pool, David A. Abbink, Erwin R. Boer, Peter M.T. Zaal, Frank M. Drop, Kasper van der El, and Marinus M. van Paasen | For the paper entitled “Manual Control Cybernetics: State-of-the-Art and Current Trends” published in the IEEE Transactions on Human-Machine Systems, vol. 48, no. 5, pp. 468-485, October 2018. 
  Qi Zhou, Lijie Wang, Chengwei Wu, Hongyi Li, and Haiping Du | For the paper entitled “Adaptive Fuzzy Control for Non Strict-Feedback Systems With Input Saturation and Output Constraint” published in the IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 47, no. 1, pp. 1-12, January 2017. 
  2018  
 Qinglai Wei, Derong Liu, and Hanquan Lin | For the paper entitled “Value Iteration Adaptive Dynamic Programming for Optimal Control of Discrete-Time Nonlinear Systems,” 
  Shaocheng Tong, Lili Zhang, and Yongming Li | For the paper entitled “A Personalizable Driver Steering Model Capable of Predicting Driver Behaviors in Vehicle Collision Avoidance Maneuvers,” 
  Shaocheng Tong, Lili Zhang, and Yongming Li | For the paper entitled “Observed-Based Adaptive Fuzzy Decentralized Tracking Control for Switched Uncertain Nonlinear Large-Scale Systems With Dead Zones,” 
  2017  
 Jun Yu, Dacheng Tao, Meng Wang, Yong Rui, Yuichi Saito, Makoto Itoh, Toshiyuki Inagaki, Wei He, Yitting Dong, Changyin Sun 
  2016  
 Hongyi Li, Xingjian Jing, Hak-Keung Lam, Peng Shi, Ignacio Javier Perez, Franisco Javier Csbrerizo, Sergio Alonso, Enrique Herrara-Viedma, Ziho Kang, Steven J. Landry 
  2015  
 Huaguang Zhang, Lili Cui, Yanhong Luo | “For their paper “Near-Optimal Control for Nonzero-Sum Differential Games of Continuous-Time Nonlinear Systems Using Single-Network ADP” ( | Transactions on Cybernetics | , 43(1):206-216, February 2013.)” 
  2014  
 Giancarlo Fortino, Roberta Giannantonio, Raffaele Gravina, Philip Kuryloski, Roozbeh Jafari | “For their paper “Enabling effective programming and flexible management of efficient body sensor network applications” ( | Transactions on Human Machine Systems | 43(1):115-133) 
  2012  
 Neil Higgins, Valeriy Vyatkin, Nirmal-Kumar C. Nair, Karlheinz Schwarz 
  2011  
 Kumlachew M. Woldemariam, Gary G. Yen 
  2010  
 Ji Hyun Yang, Zhi-Hong Mao, Louis Tijerina, Tom Pilutti, Joseph F. Coughlin, Eric Feron 
  2009  
 Lucian Busoniu, Robert Babuska, Brt De Schutter 
  2008  
 Tal Oron-Gilad 
  2007  
 Wee Kheng Leow, Marcelo H. Ang, Jr., Kian Hsiang Low, Richard D. Gilson, Joshua L. Downs 
  2006  
 Raj Subha, Kai Ghoebel, Dean K. Frederick 
  2005  
 Veysel Gazi, Kevin M. Passino 
  2003  
 Ludmila I. Kuncheva 
  2000  
 Krishna Pattipati, | Mojdeh Shakeri, | Vijaya Raghavan 

 The SMC Society Mission  
   The mission of the Systems, Man, and Cybernetics Society is to serve the interests of its members and the community at large by promoting the theory, practice, and interdisciplinary aspects of systems science and engineering  , human-machine systems  , and cybernetics  . It is accomplished through conferences, publications, and other activities that contribute to the professional needs of its members.   

 Contact & Support 
  Accessibility 
  Nondiscrimination Policy 
  Privacy & Opting Out of Cookies 
  Feedback 

 © 2024, IEEE Systems, Man, and Cybernetics Society – All rights reserved. Use of this website signifies your agreement to the IEEE Terms and Conditions. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.  

  Important dates data

5. Conference SNPD_1:
Home | ACIS News 
  Contact Us 
  About 
  Membership 
  Conference Calendar | SERA 2024 
  ICIS 2024-Summer I 
  SNPD 2024-Summer 
  ICIS 2024-Summer III 
  BCD 2024-Summer 
  AIML 2024 
  SNPD2024-Winter 
  BCD 2025-Winter 
  EAIM 2025 
  SERA 2025 
  SNPD 2025-Summer I 
  SNPD 2025-Summer II 
  SNPD 2025-Summer III 
  SNPD 2025-Summer IV 
  SNPD2025-Winter 
  Officers 
  ACIS Publications | IJNDC 
  IJSI 
  IJBDIA 
  Springer 
  Past Conferences | Past Conferences 
  Past Conference Photos 
  SpecialSession/Workshop/Symposium Info | Organizer Instructions 
  Proposal Form 
  Review Form 
  Virtual Conference Instructions 

 SNPD 2025-Summer I  
  29th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD2025-Summer I)  
 Date: June 25-27, 2025  
 Busan, South Korea   

 Conference Venue  
 Paradise Hotel  
 Haeundae Beach, Busan  

 Important Dates:    
 Workshop/Special session proposal: January 10, 2025     
   
 Workshop/Special session acceptance notification: January 24, 2025     

 Submission Deadline: April 1, 2025    
 Acceptance Notification: April 18, 2025    
 Registration/Camera Ready Paper: April 30. 2025    

 The 29th IEEE/ACIS International SummerConference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD2025-Summer I) brings together researchers, scientists, engineers, industry practitioners, and students to discuss, encourage and exchange new ideas, research results, and experiences on all aspects of computer and information science. SNPD2025-Summer I aims to facilitate cross-fertilizations among the key technology enabling areas and is soliciting papers in these areas.  

 Call For Papers     

 Special Sessions/Workshops     

 Submission Of Papers For Review     

 Final Paper Submission Instructions     

 Special Session/Workshop Proposal Form     

 Review Form     

 Register Now     

 Fee Schedule     

 Accomodations     

 Keynote Speakers     

 Travel Information     

 PC Members     

 Program     

 ABOUT ACIS  
 ACIS provides a forum for researchers in education and industry from all over the world to interact with one another and disseminate the latest developments in the fields of computer and information science.  
   
 RECENT NEWS  
   
 QUICK LINKS  
 Home 
  Membership 
  Conference Calendar 
  Officers 
  ACIS Publications 
  Past Conferences 
  SpecialSession/Workshop/Symposium Info 
  Virtual Conference Instructions 

 CONTACT INFO  
 Michigan Office   
 619 S Mission St, Mt.  
  Mt. Pleasant, MI 48858, U.S.A.  
 Florida Office   
 4088 Basket Oak Cir.  
  Vero Beach, FL 32967, U.S.A.  
 Email: acis@acisinternational.org   

 © Copyright 2018 ACIS International. All Rights Reserved Built by GriffusTech    

  Call for papers data:undefinedImportant dates dataundefined

6. Conference SNPD_2:
Skip to main content    

 542,000+ Visitors Annually!  

 Search form  
       
 Search    

 Home 
  About Us 
  News 
  Contact Us 

 542,000+ Visitors Annually!  

        Menu  

 AI Apps for Education 
  Tools and Trends 
  Training and Resources | AI in Higher Education Resource Hub 
  Training and Resources Overview 
  Adobe Connect 
  Zoom 
  Videoconferencing 
  College & University 
  Upcoming Conferences 
  Webinar Series 

 Home 
  Upcoming Conferences 
  IEEE/ACS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, 32nd 

  IEEE/ACS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, 32nd  
 Event date  
 Monday, July 21, 2025  to Wednesday, July 23, 2025     
 Organizer  
 Sponsored by the Institute of Electrical and Electronics Engineers (IEEE) and the International Association for Computer and Information Science (ACIS)   
 City  
 Toronto   
 Country  
 Canada   
 URL 1  
 https://acisinternational.org/conferences/snpd-2025-summer-iv/    
 URL 2  
 https://acisinternational.org/conferences/    

 Subscribe to Online Learning News   

 Provincial Land Acknowledgement  
 Contact North | Contact Nord respectfully acknowledges that our work, and the work of our community partners, takes place on traditional Indigenous territories across the province.  
 We are grateful to be able to work and live in these territories. We are thankful to the First Nations, Métis and Inuit people who have cared for these territories since time immemorial and who continue to strengthen Ontario and all communities across the province.  

 Contact North  | Contact Nord  is a not-for-profit corporation funded by the Government of Ontario.  

 Accessibility 
  Disclaimer 
  Key to Success 
  Privacy Policy 
  Job Postings 
  Contact Us 
  New Report Shows Online Learning is Thriving Across Canada 

 Follow Contact North  

 Visit studyonline.ca   

   teachonline.ca  by http://contactnorth.ca  is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License  .  

 Menu Toggle Icon - open  Click here to open the menu      Menu Toggle Icon - close  Click here to close the menu     Menu  
   
  Twitter    Facebook     

 Search form  
       
 Search    

 Home 
  About Us 
  News 
  Contact Us 

 AI Apps for Education 
  Tools and Trends 
  Training and Resources | AI in Higher Education Resource Hub 
  Training and Resources Overview 
  Adobe Connect 
  Zoom 
  Videoconferencing 
  College & University 
  Upcoming Conferences 
  Webinar Series 

 Accessibility Standards for Customer Service 
  Disclaimer 
  Privacy Policy 

  Call for papers data:Important dates data

7. Conference SOCA_0:
SCImago Journal Country & Rank    SCImago Institutions Rankings    SCImago Media Rankings    SCImago Iber    SCImago Research Centers Ranking    SCImago Graphica    Ediciones Profesionales de la Información     

  Scimago Journal & Country Rank   
       
  menu   
 Home 
  Journal Rankings 
  Country Rankings 
  Viz Tools 
  Help 
  About Us 

 IEEE International Conference on Service-Oriented Computing and Applications, SOCA' 09  
 Country  
 United States   
   
   Universities and research institutions in United States   
   Media Ranking in United States   
   
 Subject Area and Category  
  
 Computer Science | Computational Theory and Mathematics 
  Hardware and Architecture 
  Software 

 Publisher  

 H-Index  
 9  
   
 Publication type  
 Conferences and Proceedings  
   
 ISSN  
 -  
   
 Coverage  
 -  

  Join the conversation about this journal    

 SJR   

 The SJR is a size-independent prestige indicator that ranks journals by their 'average prestige per article'. It is based on the idea that 'all citations are not created equal'. SJR is a measure of scientific influence of journals that accounts for both the number of citations received by a journal and the importance or prestige of the journals where such citations come from It measures the scientific influence of the average article in a journal, it expresses how central to the global scientific discussion an average article of the journal is.  
  
 Year | SJR 
 2010 | 0.156 
 2011 | 0.160 
 2012 | 0.147 

 Total Documents   

 Evolution of the number of published documents. All types of documents are considered, including citable and non citable documents.  
  
 Year | Documents 
 2010 | 0 
 2011 | 0 
 2012 | 0 

 Citations per document   

 This indicator counts the number of citations received by documents from a journal and divides them by the total number of documents published in that journal. The chart shows the evolution of the average number of times documents published in a journal in the past two, three and four years have been cited in the current year. The two years line is equivalent to journal impact factor ™ (Thomson Reuters) metric.  
  
 Cites per document | Year | Value 
 Cites / Doc. (4 years) | 2010 | 0.458 
 Cites / Doc. (4 years) | 2011 | 0.604 
 Cites / Doc. (4 years) | 2012 | 0.625 
 Cites / Doc. (3 years) | 2010 | 0.458 
 Cites / Doc. (3 years) | 2011 | 0.604 
 Cites / Doc. (3 years) | 2012 | 0.625 
 Cites / Doc. (2 years) | 2010 | 0.458 
 Cites / Doc. (2 years) | 2011 | 0.604 
 Cites / Doc. (2 years) | 2012 | 0.000 

 Total Cites   
 Self-Cites   

 Evolution of the total number of citations and journal's self-citations received by a journal's published documents during the three previous years.  
  Journal Self-citation is defined as the number of citation from a journal citing article to articles published by the same journal.  
  
 Cites | Year | Value 
 Self Cites | 2010 | 0 
 Self Cites | 2011 | 0 
 Self Cites | 2012 | 0 
 Total Cites | 2010 | 22 
 Total Cites | 2011 | 29 
 Total Cites | 2012 | 30 

 External Cites per Doc   
 Cites per Doc   

 Evolution of the number of total citation per document and external citation per document (i.e. journal self-citations removed) received by a journal's published documents during the three previous years. External citations are calculated by subtracting the number of self-citations from the total number of citations received by the journal’s documents.  
  
 Cites | Year | Value 
 External Cites per document | 2010 | 0.458 
 External Cites per document | 2011 | 0.604 
 External Cites per document | 2012 | 0.625 
 Cites per document | 2010 | 0.458 
 Cites per document | 2011 | 0.604 
 Cites per document | 2012 | 0.625 

 % International Collaboration   

 International Collaboration accounts for the articles that have been produced by researchers from several countries. The chart shows the ratio of a journal's documents signed by researchers from more than one country; that is including more than one country address.  
  
 Year | International Collaboration 
 2010 | 0 
 2011 | 0 
 2012 | 0 

 Citable documents   
 Non-citable documents   

 Not every article in a journal is considered primary research and therefore "citable", this chart shows the ratio of a journal's articles including substantial research (research articles, conference papers and reviews) in three year windows vs. those documents other than research articles, reviews and conference papers.  
  
 Documents | Year | Value 
 Non-citable documents | 2010 | 2 
 Non-citable documents | 2011 | 2 
 Non-citable documents | 2012 | 2 
 Citable documents | 2010 | 46 
 Citable documents | 2011 | 46 
 Citable documents | 2012 | 46 

 Cited documents   
 Uncited documents   

 Ratio of a journal's items, grouped in three years windows, that have been cited at least once vs. those not cited during the following year.  
  
 Documents | Year | Value 
 Uncited documents | 2010 | 33 
 Uncited documents | 2011 | 30 
 Uncited documents | 2012 | 29 
 Cited documents | 2010 | 15 
 Cited documents | 2011 | 18 
 Cited documents | 2012 | 19 

 % Female Authors   

 Evolution of the percentage of female authors.  
  
 Year | Female Percent 
 2010 | 0.00 
 2011 | 0.00 
 2012 | 0.00 

 Documents cited by public policy (Overton)   

 Evolution of the number of documents cited by public policy documents according to Overton database.  
  
 Documents | Year | Value 
 Overton | 2010 | 0 
 Overton | 2011 | 0 
 Overton | 2012 | 0 

 Documents related to SDGs (UN)   

 Evolution of the number of documents related to Sustainable Development Goals defined by United Nations. Available from 2018 onwards.  
  
 Documents | Year | Value 

  Show this widget in your own website   
  
  Just copy the code below and paste within your html code:    
   
   SCImago Graphica   
  Explore, visually communicate and make sense of data with our new data visualization tool   .   

 Metrics based on Scopus® data as of March 2024   

 Loading comments…   

 Leave a comment  
 Name   * Required   
 Email  
  (will not be published)    * Required   
  * Required   

 * Required  Cancel      
 The users of Scimago Journal & Country Rank have the possibility to dialogue through comments linked to a specific journal. The purpose is to have a forum in which general doubts about the processes of publication in the journal, experiences and other issues derived from the publication of papers are resolved. For topics on particular articles, maintain the dialogue through the usual channels with your editor.  

 Developed by:  
    Powered by:  
    Follow us on @ScimagoJR   
   
  Scimago Lab  , Copyright 2007-2024. Data Source: Scopus®   
  Legal Notice   
 Privacy Policy   

  Call for papers data:Important dates data

8. Conference RTNS_2:
Skip to content       
  Navigation Menu  
 Toggle navigation     

    Sign in    
   
 Product | GitHub Copilot  Write better code with AI 
  Security  Find and fix vulnerabilities 
  Actions  Automate any workflow 
  Codespaces  Instant dev environments 
  Issues  Plan and track work 
  Code Review  Manage code changes 
  Discussions  Collaborate outside of code 
  Code Search  Find more, search less 
    Explore  All features 
  Documentation 
  GitHub Skills 
  Blog 
  Solutions | By company size  Enterprises 
  Small and medium teams 
  Startups 
   By use case  DevSecOps 
  DevOps 
  CI/CD 
  View all use cases 
    By industry  Healthcare 
  Financial services 
  Manufacturing 
  Government 
  View all industries 
    View all solutions 
  Resources | Topics  AI 
  DevOps 
  Security 
  Software Development 
  View all 
    Explore  Learning Pathways 
  White papers, Ebooks, Webinars 
  Customer Stories 
  Partners 
  Open Source | GitHub Sponsors  Fund open source developers 
   The ReadME Project  GitHub community articles 
   Repositories  Topics 
  Trending 
  Collections 
  Enterprise | Enterprise platform  AI-powered developer platform 
   Available add-ons  Advanced Security  Enterprise-grade security features 
  GitHub Copilot  Enterprise-grade AI features 
  Premium Support  Enterprise-grade 24/7 support 
  Pricing 

 Search or jump to...       
   Search code, repositories, users, issues, pull requests...  
 Search       

 Clear       

   Search syntax tips    

 Provide feedback  

  We read every piece of feedback, and take your input very seriously.  
   Include my email address so I can be contacted     
  Cancel  Submit feedback    
   Saved searches  
 Use saved searches to filter your results more quickly  

  Name       
 Query     
 To see all available qualifiers, see our documentation  .  

  Cancel  Create saved search    
      
  Sign in    
 Sign up  Reseting focus    

   You signed in with another tab or window. Reload  to refresh your session.  You signed out in another tab or window. Reload  to refresh your session.  You switched accounts on another tab or window. Reload  to refresh your session.     Dismiss alert    

   automaticdai   /  realtime-embedded-conferences    Public    
   
 Notifications | You must be signed in to change notification settings 
  Fork 8 
  Star  94 

 Tracking conferences in Real-time Embedded Systems, Design Automation, Cyber-Pyhsical Systems and Robotics!  
   automaticdai.github.io/realtime-embedded-conferences/     
   94  stars    8  forks    Branches     Tags     Activity     
   Star     
   
   Notifications  You must be signed in to change notification settings    

 Code 
  Issues  1 
  Pull requests  0 
  Actions 
  Projects  0 
  Security 
  Insights 
     Additional navigation options  Code 
  Issues 
  Pull requests 
  Actions 
  Projects 
  Security 
  Insights 

 automaticdai/realtime-embedded-conferences  

 main    

    Branches       Tags      

 Go to file      

    Code            

   Folders and files  
  
 Name | Name | Last commit message | Last commit date 
 Latest commit  

 History  
    215 Commits 
 _includes | _includes |  
 assets/  css | assets/  css |  
 README.md | README.md |  
 _config.yml | _config.yml |  
 View all files 

 Repository files navigation  
 README 

 Real-Time Embedded Systems, Design Automation & Cyber-Physical Systems (Conferences Tracking)  

 ( Last updated:   {{ site.time }})  
 Tracking the most influenced conferences in real-time  systems, embedded systems  , design automation  and robotics  . The idea of this tracker is to keep up-to-date information of conferences, to facilitate researchers within our community aware of the deadlines and important announcements/updates.  
 This list is updated on a frequent basis (normally weekly). The list is ordered by deadlines  before the submission deadline, otherwise it will be ordered by the conference opening date  . Deadline is in digits, with the format yyyy-mm-dd  , to reduce confusion due to conventions of different countries. The deadline is for the main conference. Brief presentations, workshops and industrial tracks often have a different (and later) deadline.  
 Contributing to this list:   This list is for the community's common benefit thus it is therefore a shared responsibility  to make sure the contents in this list are correct to the best knowledge. If you want to add to the list or report an error, you can either (1) commit an issue in the issue list  , (2) contact me through email: xiaotian.dai (at) york.ac.uk  , and (3) fill our feedback form  . If you prefer to change it yourself, you can clone, modify and create a pull request (PR) in GitHub.  
 Caution of time zones:   Note that some of the conference deadlines are in local time zones, but most are AoE, i.e., anywhere on earth (UTC-12:00). Please be aware of the time zone, especially when the deadline is approaching. Also note that the deadlines are for the full manuscript submission, but some of the conferences may have a deadline for abstract (normally one week earlier), which will be noted in the Remarks  section, even if it is not mandatory.  
 Maintainer:   This page and the GitHub repository are maintained by Dr. Steven Xiaotian Dai   from Real-Time and Distributed Systems Group, University of York, UK. If you find this site useful, please bookmark this page and star this repository on GitHub  .  
  Conferences Tracking  

 Name | Deadline | Where | When | Remarks 
 ISORC 2025 | Jan 8, 2025 | Toulouse, France | May 26-28, 2025 | - Acceptance notification: March 05, 2025  
  - Camera-ready papers: March 20, 2025  
  - Conference: May 26 - 28, 2025 
 Ada-Europe 2025 | Jan 20, 2025 | Pairs, France | June 10-13, 2025 | - Submission deadline for industrial track papers, work-in-progress papers, and tutorial and workshop proposals: 24 February 2025  
  - First round notification for journal-track papers, and notification of acceptance for all other types of submissions: 28 March 2025 
 ECRTS 2025 | Feb 28, 2025 | Brussels, Belgium | TBD | - Notification: April 21, 2025  
  - Camera-ready deadline: May 16, 2025 
 IROS 2025 | Mar, 2025 (❔) | Hangzhou, China | Oct 19-25, 2025 |  
 ESWEEK 2025 (EMSOFT, CASES, CODES+ISSS, MEMOCODE) | Mar, 2025 (❔) | TBD | TBD |  
 IROS 2025 | Mar, 2025 (❔) | TBD | TBD |  
 RO-MAN 2025 | Mar 20, 2025 | Eindhoven, Netherlands | Aug 25-29, 2025 | Notification of Acceptance: May 10, 2025 
 TAROS 2025 | Apr, 2025 (❔) | TBD | TBD |  
 RTCSA 2025 | Apr, 2025 (❔) | TBD | TBD |  
 SIES 2025 | Apr, 2025 (❔) | TBD | TBD |  
 DSD 2025 | May, 2025 (❔) | Salerno, Italy | Sep 10-12, 2025 |  
 ICCD 2025 | May, 2025 (❔) | TBD | TBD |  
 RTNS 2025 | Aug, 2025 (❔) | TBD | TBD |  
 Deadline passed & upcoming ↓ |  
 RTSS 2024 | May 23, 2024 | York, UK | Dec 10-13, 2024 | Rebuttal period: Jul 12-18, 2024  
  Author Notification: July 31, 2024  
  Camera-ready papers: Sep 24, 2024 
 NG-RES 2025  (w) | Nov 17, 2024  → Nov 24, 2024 | Barcelona, Spain | Jan 20, 2025 | - Co-located with HiPEAC 2025  
  - Acceptance notification: December 15th, 2024 
 DATE 2025 | Sep 22, 2024 (*) | Lyon, France | March 31 - April 2, 2025 | - Abstract deadline: Sep 15, 2024 
 ICCPS 2025 | Oct 31, 2024  → Nov 14, 2024 | Irvine, California, USA | May 6-9, 2025 | Important Dates (AoE):   
  - Abstract submission deadline (optional): November 7, 2024 (AOE)  
  - Paper submission deadline (FIRM): October 31, 2024 (AOE)  
  - Acceptance/rejection notifications: January 23, 2025  
  - Camera-ready: March 10, 2025 
 RTAS 2025 | Oct 31, 2024  → Nov 14, 2024 | Irvine, California, USA | May 6-9, 2025 | Part of CPS-IoT Week 
 ICRA 2025 | Sep 15, 2024 | Atlanta, USA | May 19-23, 2025 | Important Dates:   
  - Submissions Open: July 15th, 2024  
  - Submission Deadline: October 15th, 2024  
  - Acceptance Notification: October 31st, 2024  
  - Competitions: May 19th – May 23rd, 2025 
 DAC 2025 | Nov 19  → Nov 20, 2024 (*) | Moscone West, San Francisco | June 22-25, 2025 | - (Research paper) Abstract deadline: Nov 12, 2024  
  - Engineering tracks: Jan 16, 2025 
  
   Notations:    
 deadline  : the deadline has passed; 
  old  → new: the information was updated; 
  (*): there is an abstract deadline (may be compulsory for some conferences); 
  (w): this is a workshop; 
  (TBA) or (TBD): the details have not yet been announced; 
  ❔: the date is not precise but based on estimations from previous years. 
   Completed & Archived (by alphabet)  

 Name | Deadline | Where | When | Remarks 
 Ada-Europe 2021 | --- | Santander, Spain | June 7-11, 2021 | WiP and industrial paper deadline: March 31, 2021 
 Ada-Europe 2022 | 2022-01-16 | Ghent, Belgium | June 14-17, 2022 | Ada Europe 2022 will be hybrid. The conference schedule comprises a journal track, an industrial track, a work-in-progress track, a vendor exhibition, parallel tutorials, and satellite workshops.  
   
  Important Dates:  
  Feb 27, 2022: Submission deadline for industrial-track and WiP track.  
  March 14, 2022: Author notification of acceptance. 
 Ada-Europe 2023 | 2023-01-16  → 2023-02-13 | Lisbon, Portugal | June 13-16, 2023 | 27 February 2023:  Submission deadline for industrial-track papers  , work-in-progress papers  , tutorial  , and workshop proposals   
  20 March 2023:  First round notification for journal-track papers  , and notification of acceptance for all other types of submissions 
 Ada-Europe 2024 | Jan 15, 2024  → Jan 31, 2024 | Barcelona, Spain | June 11-14, 2024 | Deadline is for the journal track; Other submissions by 26 February 2024 
 CASES 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Details refer to EMSOFT. 
 CASES 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22, 2023 | See above (EMSOFT) 
 CODES+ISSS 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Details refer to EMSOFT. 
 CODES+ISSS 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22, 2023 | See above (EMSOFT) 
 CoRL 2022 | 2022-06-15 | Auckland, NZ | Dec 14-18, 2022 |  
 DATE 2021 | --- | Grenoble, France  →Virtual | February 1-5, 2021 |  
 DATE 2022 | 2021-09-19 | Virtual | Feb 1-5, 2022 | Abstract deadline: 2021-09-12 
 DATE 2023 | 2022-09-25 | Antwerp, Belgium | Apr 17-19, 2023 | Abstract deadline: 18 Sep, 2022  
  Other key dates can be found: here 
 DATE 2024 | Sep 17, 2023 (*) | Spain | March 25-27, 2024 | Abstract deadline:  September 10, 2023  
  Notification of acceptance: November 14, 2023  
  Camera-ready papers: January 17, 2024 
 DAC 2021 | 2020-11-23 | San Francisco, CA, USA | Dec 5-9, 2021 | Abstract deadline: Nov 16, 2020 
 DAC 2022 | 2021-11-22 | San Francisco, CA. | July 10-14, 2022 | Abstraction Deadline: Nov 15 
 DAC 2023 | 2022-11-21 | San Francisco, USA | July 9-13, 2023 | Abstract deadline: Nov 14, 2022 
 DAC 2024 | Nov 20, 2023 (*) | San Francisco, CA | June 23-27, 2024 | Abstract Submission Deadline:  November 13, 2023 5:00 PM (PST) 
 DSD 2021 | 2021-04-01  → 2021-04-20 | Palermo, Italy | September 1-3, 2021 |  
 DSD 2022 | 2022-04-01  → 2022-05-25 | Maspalomas, Spain | August 31-September 2, 2022 | Notification of Acceptance: May 31st, 2022  
  Camera-Ready Papers: June 15th, 2022 
 DSD 2023 | 2023-04-17  → 2023-05-28 | Durres, Albania | Sep 6-8, 2023 | Submission Deadline  : April 17, 2023  
  Notification of Acceptance  : May 29, 2023  
  Camera-Ready Papers  : June 16, 2023 
 DSD 2024 | May 5, 2024  → June 3, 2024 | Paris, France | Aug 28-30, 2024 | Notification of acceptance: 12th June 2024  
  Camera ready papers: 26th June 2024 
 ECRTS 2020 | --- | Modena, Italy | July 7-10, 2020 | Went to virtual due to COVID-19. 
 ECRTS 2021 | 2021-03-03 | Virtual | July 5-9, 2021 | Notification of acceptance: April 22, 2021 
 ECRTS 2022 | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Notification: April 13, 2022  
  Camera-ready deadline: May 5, 2022 
 ECRTS 2023 | 2023-03-01 | Vienna, Austria | July 11-14, 2023 | Author Notification:  Apr 22, 2023 
 ECRTS 2024 | Feb 29, 2024 | Lille, France | July 9 - 12, 2024 | Notification: April 19, 2024  
  Camera-ready deadline: May 10, 2024 
 EMSOFT 2021 | 2021-04-09 | Virtual | October 10-15, 2021 | Abstract deadline: April 2, 2021; Part of the ESWEEK. 
 EMSOFT 2022 | 2022-04-07 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK. (cfp)   
  Abstract Deadline: March 31, 2022  
  Full paper submission: April 07, 2022  
  Work-in-progress paper submission: June 11, 2022  
  Author notification: July 05, 2022 
 EMSOFT 2023 | 2023-03-23 (*) | Hamburg, Germany | Sep 17-22 | Journal Track:  
  - Abstract Submission: March 16, 2023 (AoE)  
  - Full Paper Submission: March 23, 2023 (AoE, firm)  
  - Notification of Acceptance: June 30, 2023  
   
  Work-in-Progress Track:  
  - Paper Submission: May 22, 2023 (AoE, firm)  
  - Notification of Acceptance: June 19, 2023  
   
  Proposals of Workshops, Tutorials, Education Classes, and Special Sessions: March 20, 2023 
 ESWEEK 2024  (EMSOFT, CASES, CODES+ISSS, MEMOCODE) | March 31, 2024 (*) | Raleigh, NC, USA | Sep 29 - Oct 4, 2024 | Journal Track:  
  - Abstract Submission: March 24, 2024 (AoE)  
  - Full Paper Submission: March 31, 2024 (AoE, firm)  
  - Notification of Acceptance: July 14, 2024  
  Work-in-Progress and Late Breaking Tracks: June 02, 2024 (AoE, firm)  
  Workshops, Tutorials, Education Classes, and Special Sessions: March 24, 2024 
 ICCAD 2020 | --- | Virtual | November 2-5, 2020 |  
 ICCAD 2021 | 2021-05-28 | Munich, Germany | November 1-4, 2021 | Abstract deadline: Friday, May 21, 2021 
 ICCAD 2022 | 2022-05-23 | San Diego, California, USA (hybrid) | Oct 30 - Nov 3, 2022 | Abstract Deadline: 16 May, 2022 
 ICCAD 2023 | 2023-05-22  (*) | San Francisco, CA, USA | Oct 29 - Nov 2, 2023 | Abstract deadline:  May 15, 2023 
 ICCPS 2022 | 2021-10-29 | Milano, Italy | May 4-6, 2022 | Part of CPS-IoT week.  
  Abstract Registration: Oct 22  
  Author Notification: Jan 17, 2022 
 ICCPS 2023 | 2022-10-31 | San Antonio, Texas | May 9-12, 2023 | Part of the CPS-IoT Week  
  Abstract Registration: Oct 24, 2022  
  Decision Notification: Jan 20, 2023 
 ICCPS 2024 | Oct 31, 2023 (*) | Hong Kong, China | May 13-16 2024 | Abstract deadline:  October 24, 2023 
 ICCD 2024 | May 12, 2024  → May 20, 2024 | Milan, Italy | Nov 18-20, 2024 | Abstract Deadline: May 5, 2024 
 ICESS 2020 | --- | Virtual | Dec 10-11, 2020 |  
 ICESS 2021 | 2021-07-31  → 2021-08-14 | Shanghai, China | Dec 13-14, 2021 | Author notification: Oct 4th, 2021 
 ICESS 2022 | 2022-09-01  → 2022-09-20 | Chengdu, China | Dec 18-20, 2022 | Author Notification: 15 Oct 2022 
 ICRA 2021 | --- | Xi'an, China | May 30 - June 5, 2021 | Notification of acceptance: February 28, 2021 
 ICRA 2022 | 2021-09-09 | Philadelphia (PA), USA | May 23-27, 2022 | Notification of acceptance: Jan 31, 2022 
 ICRA 2023 | 2022-09-15 | London, UK | May 29 - June 2, 2023 | Notification of paper acceptance: 31 Jan, 2023 
 ICRA 2024 | Sep 15, 2023 | Tokyo, Japan | May 13-17, 2024 |  
 IROS 2020 | --- | Las Vegas, USA  → Virtual | Oct 25 - Nov 25, 2020 | Changed to Virtual; Free registration. 
 IROS 2021 | 2021-03-05 | Prague, Czech Republic | Sep 27 - Oct 1, 2021 |  
 IROS 2022 | 2022-03-01 | Kyoto, Japan | Oct 23-27, 2022 | Submission deadline with RA-letter option: Feb 24, 2022 
 IROS 2023 | 2023-03-01 | Detroit, US | Oct 1-5, 2023 | The theme of IROS 2023 is “ The Next Generation of Robotics  ,” so the conference aims to particularly highlight the contributions of younger researchers and to help accelerate the future contributions of all those just entering the field.  
  Note: IROS no longer offers an RA-L + IROS submission option. Papers accepted at RA-L, T-RO, RAM, and T-ASE between August 1, 2022, and April 30, 2023 will be given the option to present at IROS2023.  
  Author Notification  : June 30, 2023 
 IROS 2024 | March 1, 2024 | Abu Dhabi | Oct 14-18, 2024 |  
 ISORC 2022 | 2022-02-12 | Västerås, Sweden | May 17-19, 2022 | Rebuttal period: March 23-25, 2022  
  Acceptance notification: April 4, 2022  
  Camera-ready papers: April 20, 2022 
 ISORC 2023 | 2023-01-28  → 2023-03-04 | Nashville, Tennessee, USA | May 23 - 25, 2023 | IEEE International Symposium on Real-Time Distributed Computing   
  Important Dates  :  
  - Acceptance Notification: April 04, 2023 
 ISORC 2024 | Feb 4, 2023 | Carthage, Tunis, Tunisia | May 22-25, 2024 |  
 LCTES 2021 | 2021-03-08 | Virtual | June 20-25, 2021 | Notification of acceptance: Apr 9, 2021 
 LCTES 2022 | 2022-03-07  → 2022-03-14 | San Diego, California, USA | June 13-17, 2022 | Paper notification: April 8, 2022  
  Artifact submission: April 16, 2022  
  Artifact decision: May 2, 2022  
  Camera-ready deadline: May 6, 2022 
 LCTES 2023 | 2023-03-16  → 2023-03-24 | Orlando, Florida | Jun 18, 2023 |  
 MEMOCODE 2023 | 2023-05-05  → 2023-05-26  (*) | Hamburg, Germany | Sep 17-22, 2023 | Abstract deadline:  Apr 28, 2023  → May 12, 2023 
 NeurIPS 2022 | 2022-05-19 | New Orleans - Hybrid | Nov 28 - Dec 9, 2022 | Abstract submission: May 16, 2022 
 NG-RES 2022  (w) | 2022-04-04 | Budapest, Hungary | June 22, 2022 | Workshop on next generation real-time systems @ HiPEAC conference.  
  Author notification: May 11th, 2022 
 NG-RES 2023  (w) | 2022-11-20  → 2022-11-27 | Toulouse, France | Jan 18, 2023 | Workshop on Next Generation Real-Time Embedded Systems. Co-located with HiPEAC 2023.  
  Author notification: Nov 20, 2022  
  Camera ready: Dec 31, 2022 
 NOCS 2022 | 2022-04-29  → 2022-05-20 | Shanghai, China - Hybrid | Oct 7-14, 2022 | Part of the ESWEEK.  
  Abstract submission: 13 May, 2022  
  Author notification: 8 July, 2022 
 NOCS 2023 | 2023-04-21  → 2023-05-08  (*) | Hamburg, Germany | Sep 17-22 | Abstract deadline: Apr 14, 2023  → May 8, 2023 
 OPERA 2023  (w) | Sep 3, 2023  → Sep 15, 2023 | Taipei, Taiwan | Dec 5, 2023 | Co-located with RTSS 2023  
   
  Important Dates:   
  - Notification (tentative): October 1st, 2023  
  - Camera-ready deadline (tentative): October 15th, 2023 
 OSPERT 2022  (w) | 2022-04-27  → 2022-05-04 | Modena, Italy | July 5, 2022 | Workshop on Operating Systems Platforms for Embedded Real-Time applications.  
  Held in conjunction with ECRTS. 
 OSPERT 2023  (w) | 2023-05-11  → 2023-05-18 | Vienna, Austria | July 11, 2023 | in conjunction with ECRTS'23  
  Notification of Acceptance:  May 30, 2023  
  Final submissions  : June 18, 2023 
 OSPERT 2024  (w) | May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS'24 
 RAGE 2022  (w) | 2022-03-20 | San Francisco, CA | July 10, 2022 | 1st Real-time And intelliGent Edge computing workshop (RAGE) --- associated with DAC 2022. Topics cover real-time edge computing, QoS for virtualization, predictability in edge-to-cloud, predictability in middleware and real-time network protocols, etc.  
  Notification to authors: April 11th 2022 
 RAGE 2023  (w) | 2023-02-01  → 2023-02-15 | San Antonio, Texas | May 9, 2023 | Workshop on Real-time And intelliGent Edge computing   
  @ CPS-IoT Week 2023  
  Author Notification:  Mar 1st, 2023 
 RAGE 2024  (w) | Jan 25, 2024  → Feb 11, 2024 | Hong Kong | May 13th, 2024 | Workshop on Real-time And intelliGent Edge computing   
  @ CPS-IoT Week 2024  
  Author Notification:  Mar 1st, 2024 
 RO-MAN 2022 | 2022-03-15 | Naples, Italy | Aug 29 - Sep 2, 2022 | Author Notification: May 30, 2022  
  Camera Ready: June 15, 2022 
 RO-MAN 2023 | 2023-03-17  → 2023-03-31 | Busan, Korea | Aug 28-31 | Important Dates:   
  - Submission Deadline: March 17, 2023  
  - Notification of Acceptance: May 26, 2023  
  - Camera-Ready Deadline: June 30, 2023  
  - LBR Paper Submission: June 2, 2023  
  - LBR Acceptance Notification: June 30, 2023 
 RSS 2021 | 2021-03-01 | Virtual | July 12-16, 2021 | Notification of acceptance: May 10, 2021 
 RSS 2022 | 2022-01-28 | New York City | June 27-July 1, 2022 |  
 RSS 2023 | 2023-02-03 | Daegu, Korea | Jun 23 - 28, 2023 |  
 RTAS 2021 | --- | Nashville, Tennessee, USA  → Virtual | May 18-21, 2021 |  
 RTAS 2022 | 2021-10-29 | Milano, Italy | May 4-6, 2022 | Part of CPS-IoT week.  
  Rebuttal Period: Jan 3-5, 2022  
  Author Notification: Jan 17, 2022 
 RTAS 2023 | 2022-10-31 | San Antonio, Texas | May 9-12, 2023 | Part of the CPS-IoT Week  
  Author Notification: Jan 20, 2023  
  BP submission deadline: Feb 10, 2023  
  AE submission deadline: Feb 24, 2023  
  Camera-Ready: March 17, 2023 
 RTAS 2024 | Oct 31, 2023 | Hong Kong, China | May 13-16, 2024 | Author notification: January 20, 2024 
 RTCSA 2022 | 2022-04-15  → 2022-04-29 | Taiwan - Hybrid | August 23-25, 2022 | Abstract Deadline: April 22, 2022  
  Co-located with NVMSA 2022. 
 RTCSA 2023 | 2023-04-14  → 2023-04-28  (*) | Niigata, Japan | Aug 30 - Sep 1, 2023 | Abstract deadline: Apr 7, 2023  → Apr 21, 2023 
 RTCSA 2024 | Apr 5, 2024 (*) | Sokcho, South Korea | Aug 21-23, 2024 | Abstract Deadline: March 29, 2024 
 RTSOPS 2022  (w) | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Workshop on Real-Time Scheduling Open Problems Seminar. Associated with ECRTS. 
 RTSOPS 2024  (w) | May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS'24 
 RTSS 2020 | --- | Virtual | Dec 1-4, 2020 |  
 RTSS 2021 | 2021-05-27 | Dortmund, Germany  → Fully Virtual | Dec 7-10, 2021 | Submissions can go to either the real-time system track (Track 1) or the design and application track (Track 2). 
 RTSS 2022 | 2022-05-26 | Houston, USA | Dec 5-8, 2022 | Rebuttal Period: 15-21 July, 2022  
  Paper Notification: August 5, 2022 
 RTSS 2023 | 2023-05-25 | Taipei, Taiwan | Dec 5-8, 2023 | Rebuttal Period:  July 14, 2023 to July 20, 2023  
  Paper Notification:   
  August 4, 2023  
  Camera-Ready Deadline:   
  October 6, 2023 
 RTNS 2021 | --- | Nantes, France  →Virtual | April 7-9, 2021 | Went to fully virtual due to COVID-19. 
 RTNS 2022 | 2022-02-24  → 2022-03-09 | Paris, France | June 7-8, 2022 | Author notification: April 20, 2022  
  Camera ready: May 4, 2022 
 RTNS 2023 | 2023-01-25 (*) | Dortmund, Germany | June 6-8, 2023 | This is the 2nd round of the new Double Submission Model   
  Important Dates  :  
  - Abstract Deadline: Jan 23th, 2023  
  - Author Notification: Mar 4th, 2023 
 RTNS 2024 | Aug 16, 2024 (*) | Porto, Portugal | Nov 7-8, 2024 | Important Dates  (3rd round):  
  - Abstract Deadline : Aug 14th, 2024  
  - Author Notification: Oct 7, 2024 
 RT-Cloud 2022  (w) | 2022-02-02  → 2022-05-04 | Modena, Italy | July 5, 2022 | Workshop on Real-Time Cloud Computing. Associated with ECRTS.  
  Author Notification: May 4, 2022 
 SIES 2024 | Apr 30, 2024  → June 30, 2024 | Chengdu, China | Oct 23-25, 2024 |  
 TAROS 2020 | --- | Nottingham, UK | Sep 16, 2020 |  
 TAROS 2021 | 2021-05-28 | Virtual | September 8-10, 2021 | Author Notification: July 1, 2021 
 TAROS 2022 | 2022-05-20 | Culham Science Centre, UK | Sep 7-9, 2022 | Confirmation of acceptance: June 10th, 2022 
 TAROS 2024 | Apr 30, 2024  → May 12, 2024 | London, UK | Aug 21-23, 2024 | Author Notification: June 15, 2024  
  Final submission: June 30, 2024  
  Conference: August 21-23, 2024 
 TCRS 2023  (w) | 2023-02-10 | San Antonio, Texas | May 9, 2023 | Workshop on Time-Centric Reactive Software   
  @ CPS-IoT Week 2023  
  Author Notification: Mar 3rd, 2023 
 WCET 2022  (w) | 2022-02-02 | Modena, Italy | July 5–8, 2022 | Workshop on Worst-case Execution Times. Associated with ECRTS. 
 WCET 2023  (w) | 2023-05-11  → 2023-05-18 | Vienna, Austria | July 11, 2023 | in conjunction with ECRTS'23  
  Acceptance notification  : May 30 
 WCET 2024  (w) | May 9, 2024  → May 16, 2024 | Lille, France | July 9, 2024 | Co-located with ECRTS'24 
 WMC 2022  (w) | 2022-09-05  → 2022-09-12 | Houston, USA | Dec 5, 2022 | Workshop on Mixed-Criticality Systems. (cfp)   
  Associated with RTSS 2022.  
  Notification of acceptance: Oct 10, 2022  
  Final version: Oct 24, 2022 
 WMC 2023  (w) | Sep 3, 2023 | Taipei, Taiwan | Dec 5, 2023 | Co-located with RTSS 2023  
   
  Important Dates:   
  - Author Notification: October 01, 2023  
  - Camera Ready: October 15, 2023 
  
   Journal List  
      
 Top journals for Real-Time Systems, Embedded Systems, Design Automation, and Parallel Computing  

 Name | Publisher 
 ACM Transactions on Embedded Computing Systems (TECS) | ACM 
 ACM Transactions on Computer Systems (TOCS) | ACM 
 ACM Transactions on Parallel Computing (TOPC) | ACM 
 ACM Transactions on Cyber-Physical Systems (TCPS) | ACM 
 ACM Transactions on Modeling and Computer Simulation (TOMACS) | ACM 
 ACM Transactions on Design Automation of Electronic Systems (TODAES) | ACM 
 ACM Journal on Emerging Technologies in Computing Systems (JETC) | ACM 
 ACM Transactions on Internet of Things (TIOT) | ACM 
 ACM Transactions on Sensor Networks (TOSN) | ACM 
 Formal Aspects of Computing: Applicable Formal Methods (FAC) | ACM 
 IEEE Transactions on Computers (TC) | IEEE 
 IEEE Transactions on Computer-Aided Design of Integrated Circuits And System (TCAD) | IEEE 
 IEEE Transactions on Parallel and Distributed Systems (TPDS) | IEEE 
 IEEE Embedded Systems Letters (ESL) | IEEE 
 Microprocessors and Microsystems (MICPRO) | Elsevier 
 Journal of Systems Architecture (JSA) | Elsevier 
 Real-Time Systems Journal (RTSJ) | Springer 
  
  Top journals for Robotics, Control, Vision and Learning  

 Name | Publisher 
 ACM Transactions on Human-Robot Interaction (THRI) | ACM 
 IEEE Transactions on Robotics (TRO) | IEEE 
 IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) | IEEE 
 IEEE Robotics and Automation Letters (RA-L) | IEEE 
 IEEE Robotics and Automation Magazine (RAM) | IEEE 
 Robotics and Autonomous Systems (RAS) | Elsevier 
 Journal of Intelligent and Robotic Systems (JINT) | Springer 
 International Journal of Computer Vision (IJCV) | Springer 
 International Journal of Robotics Research (IJRR) | SAGE 
 Journal of Machine Learning Research (JMLR) | Microtome 
 Journal of Field Robotics (JFR) | Wiley 
  
   Useful Links  
      
 IEEE TCRTS 
  ACM SIGBED 
  ACM SIGBED Blog 
  ACM SIGDA 
  Conference Ranks 
  Scimago Journal & Country Rank 
  An Incomplete List of Conferences in Computer Science 
   {% include counter.html %}  

 About  
 Tracking conferences in Real-time Embedded Systems, Design Automation, Cyber-Pyhsical Systems and Robotics!  
   automaticdai.github.io/realtime-embedded-conferences/     
 Topics  
 robotics  embedded-systems  real-time-systems  design-automation    
   
 Resources  
   Readme    
    Activity     
 Stars  
   94  stars    
 Watchers  
   7  watching    
 Forks  
   8  forks    
 Report repository    

 Releases   
 No releases published   

 Packages 0    
 No packages published  

 Contributors 2    
 automaticdai  Steven X. Dai 
  federeghe  Federico Reghenzani 

 Languages  
      
 HTML  74.7% 
  SCSS  25.3% 

 Footer  
    © 2024 GitHub, Inc.    
 Footer navigation  
 Terms 
  Privacy 
  Security 
  Status 
  Docs 
  Contact 
  Manage cookies 
  Do not share my personal information 

       You can’t perform that action at this time.   

  Call for papers data:26 th  Ada-Europe  
 International Conference on  
  Reliable Software Technologies  
  (AEiC 2022)  
   
 14-17 June 2022, Ghent, Belgium  

 Welcome 

 Call for Contributions  
 Call for contributions available in PDF  . Please distribute!  
  General Information  
 The 26th Ada-Europe International Conference on Reliable Software Technologies (AEiC 2022)  , will take place in Ghent, Belgium in dual mode, with a solid core of inpresence activities accompanied by digital support for remote participation. The conference schedule comprises a journal track, an industrial track a work-in-progress (WiP) track, a vendor exhibition, parallel tutorials, and satellite workshops.  
 Journal-track submissions | present research advances supported by solid theoretical foundation and thorough evaluation. 
  WiP-track submissions | illustrate a novel research idea that is still at an initial stage, between conception and first prototype. 
  Industrial-track submissions | highlight the practitioners' side of a challenging case study or industrial project. 
  Tutorial submissions | guide attenders through a hands-on familiarization with innovative developments or with useful features related to critical software. 
   
  Call for Journal‐track Submissions  
 Following the journal‐first model  inaugurated in 2019, the conference includes a journal‐track  that seeks original and high‐quality submissions that describe mature research work in the scope of the conference. Accepted papers for this track will be published in the "Reliable Software Technologies ( AEiC2022  )" Special Issue of the Journal of Systems Architecture (JSA).  

 Submissions should be made online at Editorial Manager  by selecting the “VSI:AEiC2022” option for the paper type. Details on the special issue can be found on this page.  General information for submitting to the JSA can be found at the Journal of Systems Architecture website  .  
  In order to speed up publication, the JSA has adopted the Virtual Special Issue model, whereby acceptance decisions are made on a rolling basis. On that account, authors are encouraged to submit as early as they can, no later than 16 January 2022. Authors who have successfully passed the first round of review will be invited to present their work at the conference  . Ada‐Europe, the main conference sponsor, will cover the Open Access fees for the first four papers  to gain final acceptance which do not already enjoy OA from personalized bilateral agreements with the Publisher.  
 Prospective authors may direct all enquiries regarding this track to the corresponding chair, Jérôme Hugues  .  
  Call for Industrial‐track Submissions  
 The conference seeks industrial practitioner presentations  that deliver insight on the challenges of developing reliable software. Given their applied nature, such contributions will be subject to a dedicated practitioner‐peer review process.  

 Interested authors shall submit a short (one‐to‐two pages) abstract  , by 27 February 2022 via Easy Chair  , strictly in PDF following the Ada User Journal  style.  
  The abstract of the accepted contributions will be included in the conference booklet. The corresponding authors will get a presentation slot in the prime‐time technical program of the conference, and will also be invited to expand their contributions into full‐fledged articles for publication in the Ada User Journal, which will form the proceedings of the Industrial track of the Conference.  
 The Industrial Track welcomes contributions that fit the general scope of the conference  , and actively address the perspective of practitioners on the topic of interest. Especially welcome are submissions of the following kind:  
 Experience with languages, tools, methodologies, and products for the achievement of safety and reliability in large or complex projects and systems. 
  Lessons learned in the design, implementation and deployment of reliable software, high-integrity systems, real-time and embedded systems, etc. 
  Insights into language tools and libraries that incorporate or target reliability in software. 
  Reports and highlights from ongoing or completed challenging projects where software is a critical component of the system. 
  Practical hands-on sharing of knowledge gained in the practice of building reliable software. 
  Reliable Software Technologies 
   
 Prospective authors may direct all enquiries regarding this track to the corresponding chair Alejandro R. Mosteo  .  
  Call for Work‐in‐Progress‐track Submissions  
 The Work‐in‐Progress track seeks two kinds of submissions: (a) ongoing research  , and (b) early‐stage ideas  . Ongoing research  submissions are 4‐page papers that describe research results that are not mature enough to be submitted to the journal track as yet. Early‐stage ideas  , are 1‐page papers that pitch new research directions that fall in the scope of the conference.  
 Topics addressed by the WIP track are close by the journal track:  
 Real-Time and Safety-Critical Systems 
  High-Integrity Systems and Reliability 
  Reliability-oriented Programming Languages 
  Experience Reports 
   
 The WIP track is expected to address emerging areas where reliability is a first class requirement. WIP submissions may cover new application domains, new technologies, and new methods related to reliable software, such as autonomous systems, IoT, Industries 4.0, IA for critical systems, Cloud/Edge, security, energy management, etc.  
 Both kinds of submission must be original and shall undergo anonymous peer review. Submissions by recent MSc graduates and PhD students are especially sought.  

 Authors shall submit their work by 27 February 2022, via Easy Chair  , strictly in PDF, following the Ada User Journal  style.  
  The abstract of the accepted contributions will be included in the conference booklet. The corresponding authors will get a presentation slot in the prime‐time technical program of the conference, and will also be offered the opportunity to expand their contributions into 4‐page articles for publication in the Ada User Journal which will form the proceedings of the WiP track of the Conference.  
 Prospective authors may direct all enquiries regarding this track to the corresponding chair Frank Singhoff  .  
  Academic Listing  
 The Journal of Systems Architecture  , publication venue of the journal‐track proceedings of the conference, was ranked Q1 (SJR) in the year 2020, also featuring 72 th  percentile in CiteScope (Scopus). The Ada User Journal  , venue of all other technical proceedings of the conference, is indexed by Scopus and by EBSCOhost in the Academic Search Ultimate database.  
  Awards  
 Ada‐Europe will offer an honorary award for the best technical presentation  , to be announced in the closing session of the conference.  
  Call for Tutorials  
 The conference seeks tutorials  in the form of educational seminars on themes falling within the scope of the conference, with hands‐on or practical elements, and a topical slant oriented to selected targets in the typical conference audience.  
 The conference audience includes professionals who work in critical systems or develop features for them students in computer science or engineering education academic researchers in the field of conference interest, or people who merely approach software development as a hobby.  
 If you have developed or learned of libraries, tools, compilers, methodologies or programming languages related with critical systems that may ease the software development job of others, you would be a natural candidate for offering a tutorial.  

 Tutorial proposals include:  
 A title 
  A short abstract (between 100 and 200 words) 
  A bulleted-list outline of the presentation topics 
  The proposed duration (half day or full day) 
  The intended target and level of the contents (introductory, intermediate, or advanced) 
  A statement motivating attendance. 
   
 Tutorials should be delivered in presence unless exceptional circumstances should dictate otherwise. Tutorial proposals should indicate whether additional audience might be remote.  
 Submissions shall be sent by e‐mail to the Tutorial and Workshop Chair  , Aurora Agar Armario  , with subject line: "[AEiC 2022: tutorial proposal]".  
  The authors of accepted full‐day tutorials will receive a complimentary conference registration halved for half‐day tutorials. The Ada User Journal  will offer space for the publication of summaries of the accepted tutorials.  
  Call for Workshops  
 The conference welcomes satellite workshops centred on themes that fall within the conference scope. Proposals may be submitted for half‐ or full‐day events, to be scheduled at either end of the conference proper.  

 Workshop proposals shall be submitted by e‐mail to the Tutorial and Workshop Chair  , Aurora Agar Armario  , with subject line: "[AEiC 2022: workshop proposal]  
  Workshop organizers shall also commit to producing the proceedings of the event, for publication in the Ada User Journal  .  
  Call for Exhibitors  
 The conference will include a vendor and technology exhibition. Interested providers should direct inquiries to the Exhibition & Sponsorship Chair  , Ahlan Marriott  .  

  Important dates data

9. Conference SoCG_0:
CG Week 2025     Home 
  Program 
  SoCG 
  YRF 
  Challenge 
  Media 
  Workshops 
  Awards 
  Registration 
  Practicalities 

 Call for Papers: The 41st SoCG - June 23-27, 2025   
 The 41st International Symposium on Computational Geometry (SoCG 2025) is planned to be held in Kanazawa, Japan, June 23–27, 2025, as part of the Computational Geometry (CG) Week. We invite high quality submissions that describe original research on computational problems in a geometric and/or topological setting. Topics of interest include, but are not limited to:  
 Design, analysis, and implementation of geometric algorithms and data structures; 
  Computational complexity of geometric problems; 
  Implementation and experimental evaluation of geometric algorithms and heuristics, including mathematical, numerical, and algebraic aspects; 
  Discrete and combinatorial geometry; 
  Computational topology, topological data analysis, and topological combinatorics; 
  Applications of computational geometry or topology in any field. 

 Important Dates   
 November 26, 2024 (Tuesday): | Abstracts and paper registration due (23:59 AoE (anywhere on Earth)) 
  December 3, 2024 (Tuesday): | Papers due (23:59 AoE (anywhere on Earth)) 
  February 6, 2025 (Thursday): | Notification of acceptance/rejection 
  mid March 2025: | Final versions of accepted papers due 
  June 23–27, 2025: | Symposium 

 SoCG 2025 Conference Webpage   
 http://socg25.github.io/    
   
 SoCG 2025 HotCRP Submission Webpage   
 https://socg25.hotcrp.com/    
   
 Code of conduct   
 SoCG is dedicated to providing an environment that is free from harassment, bullying, discrimination, and retaliation for all participants. Starting in 2025, CG Week including SoCG will be organized as an event of the CG Society  . All members of the Society are bound by its Code of Conduct  . Only members of the Society can give a presentation and hence at least one author of each accepted paper must become a member of the Society. Society membership is free.  

 Submission Guidelines   
 Paper types | When writing or evaluating a SoCG paper, it is important to keep in mind that there are different types of contributions, each with its own strengths. To ensure that a submission is evaluated on its own merits, authors will need to identify the main strengths of their submission, as captured by four possible paper types. PC members and external reviewers will be asked to take into account these paper types together with their associated evaluation criteria when they evaluate a paper. There are no quotas for the paper types and submissions can be labeled with more than one paper type at the time of submission. | Mathematical Foundations: | A typical paper will contain theorems and proofs describing new results in discrete or combinatorial geometry, discrete differential geometry or topology, or in topological combinatorics. The paper will primarily be evaluated on its technical depth, the importance of the results, the elegance of the solution, the connection of the problem studied to computational geometry and topology, and the potential future impact on algorithm development. 
  Algorithmic Complexity: | A typical paper will contain algorithms, data structures, theorems, proofs, or lower bound constructions describing new results on computational geometry problems. The paper will primarily be evaluated on the (mathematical or computational) relevance and importance of the problem studied, its technical depth, the elegance of the solution, and the potential future impact of the results or the proposed new methods and techniques. 
  Experiments and Implementation: | A typical paper will make a clear contribution to the implementation and evaluationp of geometric algorithms, such as exact, approximate, or algebraic computation, algorithms engineering, or the experimental evaluation of competing algorithmic approaches. The paper will primarily be evaluated on the completeness and the expected impact of the proposed implementation, the soundness of the experiments, the quality and quantity of testing, and on the general amount of knowledge gained. 
  Applications: | A typical paper will describe the modeling and algorithmic choices made when developing or adapting computational geometry techniques for an application area. The paper will be primarily evaluated on the soundness of the modeling decisions, the ingenuity of the solution, the effectiveness of the proposed method, and the expected impact in the application area. One might also consider the lesson learned regarding the applicability or suitability of computational geometry tools to the specific area. 
  Double Blind and PC submissions | SoCG will employ a lightweight double-blind reviewing process, and will allow PC members (other than the PC chairs) to submit to the conference as well. Submissions should not reveal the identity of the authors in any way. In particular, authors' names, affiliations, funding information, and email addresses should not appear in the submission. Authors should ensure that any references to their own related work is in the third person (e.g., not "We build on our previous work ..." but rather "We build on the work of ..."). Particular care needs to be taken if there is any accompanying software or data, which needs to be linked anonymously (for example, via a DropBox anonymous folder or Anonymous GitHub  , perhaps with a subset of synthetic data if the real data is not anonymized). Upon registering a submission, the authors will declare conflicts of interest with PC members, as well as listing email address or domain level conflicts (i.e. “Haitao Wang (University of Utah)”, “All (Graz University of Technology)”) of other professional or personal conflicts. This includes past advisors and students, people with the same affiliation, and any recent/frequent coauthors and collaborators. Please refer to the SoCG 2025 Conflict of Interest Guidelines  for a detailed discussion of possible conflicts of interest. | The purpose of lightweight double-blind reviewing is to help PC members and external reviewers come to an initial judgment about the paper without bias, not to make it impossible for them to discover the authors if they were to try. Authors should feel free to disseminate their ideas or draft versions of their paper as they normally would. For example, authors may post drafts of their papers on the web, submit them to arXiv, and give talks on their research ideas. We encourage authors with further questions on double-blind reviewing to contact the PC chairs, or to see the more detailed discussion in the proposal  that preceded the vote to move to double blind. 
  Format | Submissions must be formatted in accordance with the LIPIcs proceedings guidelines  . Authors are required to use the LaTeX class file socg-lipics-v2021.cls  (V0.9, Sep 19, 2022), with the option “anonymous”; note that the class file is a wrapper around the standard LIPIcs class. The LIPIcs style and instructions are available here  ; the SoCG class file is available here  , and instructions on how to use it are available here  . Submissions must not exceed 500 lines, excluding front matter (title), references, and a clearly marked appendix (further described below), but including all other lines (in abstract, algorithms, tables, captions, etc.). The class files provide line counting which should be accurate in most cases. Authors should refrain from putting excessive amounts of text in parts in which lines are not counted automatically. If authors need constructs that contain uncounted lines of text, they should compensate for this by reducing the final line count accordingly. It is the sole responsibility of the authors not to exceed 500 lines even if some lines are not counted automatically. 
  Contents of the submission | Papers should be submitted in the form of an extended abstract, which begins with the title of the paper, as well as a short abstract. This should be followed by the main body of the paper that begins with a precise statement of the problem considered, a succinct summary of the results obtained (emphasizing the significance, novelty, and potential impact of the research), and a clear comparison with related work. The remainder of the extended abstract should provide sufficient details to allow the program committee to evaluate the validity, quality, and relevance of the contribution. Clarity of presentation is very important; the entire extended abstract should be written carefully, taking into consideration that it will be read and evaluated by both experts and non-experts, often under tight time constraints. | In addition, authors are asked to avoid "et al." in citations in favor of an equal mention of all authors' surnames. For instance, if the number of authors is large, consider writing "The authors in [#] show" instead of "A et al. [#] show". 
  Appendix and additional data | All details needed to verify the results must be provided. Supporting materials, including proofs of theoretical claims and experimental details, that do not fit in the 500-line limit should be given in an appendix. If more appropriate, the full version may be given as the appendix. In both cases, however, the authors should include in the main part specific pointers to the relevant locations in the appendix. The appendix will be read by the program committee members and subreviewers at their discretion and will not be published as part of the proceedings. Thus, the paper without the appendix should be able to stand on its own. Experimental and implementation results (independent of paper type) must be reproducible and verifiable. Authors of all types of papers are encouraged to put accompanying software and relevant data, if there is any, in a repository accessible to the reviewers. 
  Previous or simultaneous submissions | Results previously published or accepted for publication in the proceedings of another conference cannot be submitted. Simultaneous submissions of the results to another conference with published proceedings are not allowed. Exempted are workshops and conferences without formal proceedings, but possibly with handouts containing short abstracts. In particular, submissions of papers that have appeared or will be submitted to EuroCG are allowed, since EuroCG does not publish formal proceedings, while submissions of papers that have appeared in CCCG are not allowed. Results that have already been accepted (with or without revision) for publication in a journal at the time of their submission to the symposium are not allowed. 
  Strict guidelines | Submissions deviating from the above guidelines risk being rejected without further consideration. 
  Guidelines for reviewers | The guidelines for reviewers are available here  . 

 Accepted Papers   
 Presentation | An author of each accepted paper is expected to attend the symposium and present the paper (approximately 20 minutes). Note that SoCG 2025 will be organized as an event of the CG Society  and hence the presenting author(s) must be a member of the Society. Society membership is free. 
  Best paper award | An accepted paper may be selected as the best paper. All papers are eligible. | Best student paper award | An accepted paper may be selected as the best student paper. A paper is eligible if all authors are students at the time of submission. This must be indicated in the submission process. There is a box provided for this purpose on the submission server. | Best student presentation award | Based on the feedback from the audience, a presentation during the symposium by a student may be selected as the best student presentation. | In exceptional cases, each of these awards may be granted to more than one paper/presentation. 
  Invited papers and special issues | Authors of the best paper will be invited to submit an extended version of their paper to the Journal of the ACM  , and authors of one (or more) most highly ranked papers may be invited to submit their full paper to the journal TheoretiCS  . Authors of a selection of accepted papers from the symposium will be invited to submit extended versions of their papers to special issues of Discrete & Computational Geometry  and Journal of Computational Geometry  . 
  Format | Final proceedings versions of accepted papers must respect the same formatting constraints as the submissions ( LIPIcs proceedings format  with socg-lipics-v2021  ; 500-line limit, excluding front matter and references), but must not comprise any appendix. If any supporting material (including complete proofs of theoretical claims and experimental details) does not fit in the specified limit, then the full version of the paper containing this information must be referenced in the conference version and made available at a public repository, such as arXiv  , by the time the final version is submitted. Where applicable, we encourage the authors to make accompanying software and/or data publicly accessible, with proper references in the paper. 

 Program Committee   
 Mikkel Abrahamsen, University of Copenhagen 
  Oswin Aichholzer, Graz University of Technology (co-chair) 
  Hugo Akitaya, University of Massachusetts Lowell 
  Mark de Berg, Eindhoven University of Technology 
  Sujoy Bhore, Indian Institute of Technology Bombay 
  Ahmad Biniaz, University of Windsor 
  Håvard Bakke Bjerkevik, SUNY Albany 
  Gerth Stølting Brodal, Aarhus University 
  Hsien-Chih Chang, Dartmouth College 
  Siu-Wing Cheng, Hong Kong University of Science and Technology 
  Vida Dujmović, University of Ottawa 
  David Eppstein, University of California, Irvine 
  Emily Fox, University of Texas at Dallas 
  Jie Gao, Rutgers University 
  Dan Halperin, Tel Aviv University 
  Tao Hou, University of Oregon 
  Christian Knauer, University of Bayreuth 
  Francis Lazarus, Université Grenoble Alpes 
  Chih-Hung Liu, National Taiwan University 
  Daniel Lokshtanov, University of California Santa Barbara 
  Anna Lubiw, University of Waterloo 
  Amir Nayyeri, Oregon State University 
  Eunjin Oh, Pohang University of Science and Technology 
  Tim Ophelders, Utrecht University and TU Eindhoven 
  Irene Parada, UPC BarcelonaTech 
  Rahul Saladi, Indian Institute of Science 
  Patrick Schnider, University of Basel and ETH Zürich 
  Raimund Seidel, Saarland University 
  Don Sheehy, North Carolina State University 
  Shakhar Smorodinsky, Ben-Gurion University 
  Jonathan Spreer, University of Sydney 
  Takeshi Tokuyama, Kwansei Gakuin University 
  Torsten Ueckerdt, Karlsruhe Institute of Technology 
  Pavel Valtr, Charles University 
  Kasturi Varadarajan, University of Iowa 
  Haitao Wang, University of Utah (co-chair) 
  Jinhui Xu, University at Buffalo 
  Jie Xue, New York University Shanghai 

  CG Week 2025   

  Call for papers data:Important dates data

10. Conference RTNS_3:
Close    

   Nearby     Filter      Events   
    Companies   
    Experts   
    Hubs   

   Add Event    
   
   Login   

  Add a review    
 07 - 08 Jun 2023    
 RTNS : International conference on Real-Time Networks and Systems  
   
  Conference    
   Dortmund  , Germany     
  1  Follower    

  Select   Select   Save   Share    
 Follow  Attended?    

 About | Exhibitors | Speakers | Reviews | Deals 
  
 Average post reach is 38.2k users. Start networking today!  
    
 Write a post here...   
   
 Post  

 Listed In  
  Telecommunication     

 Average post reach is 38.2k users. Start networking today!  
    
 Write a post here...   
   
 Post  

 Timings  
 09:00 AM-06:00 PM (expected)  
  Not Verified | Entry Fees  
 Check Official Website 
 Estimated Turnout  
 100 - 500 Delegates   
 Based on previous editions | Event Type  
  Conference 
 Editions  
 Jun 2023  

  Frequency  Not Available | Official Links  
 Website  Contacts    

  Report Error   
  Claim this event 
 Organizer  
  Follow Company   
  Queries about the event?  Ask Organizer     
   
 EasyChair Conference System   UK  291  Total Events 
 51.514000  7.465000  Venue Map & Directions  
 Booking.com     
 Venue to be announced   
 Dortmund  , Germany   
 Add Venue 

 Write a Review  
   Add Your Review    

   Edition Jun 2023     
 How did you participate in this event?  
   
  Visitor     
  Exhibitor     
     Speaker     

 Followers [ Users who have shown interest for this Event ]  Join Community   Invite    

 asarebediako godwin   
  Salesman at Glo  
  Accra, Ghana    
 Connect    

  Add Profile    

  Invite users with similar interest    
    Alhassan Omran   
  Dortmund, Germany    
 Invite    

    Ruslan Pavlenko   
 CEO  
  Dortmund, Germany    
 Invite    

    shagufta shagufta   
 Research assisstant  
  Dortmund, Germany    
 Invite    

    fanny chrell   
 Administrative Manager  
  Dortmund, Germany    
 Invite    

    Nikhil   
 Exporter  
  Dortmund, Germany    
 Invite    

    Alexis Eason   
  Dortmund, Germany    
 Invite    

    Percy Arfeen   
  Dortmund, Germany    
 Invite    

    Elizabeth Cornell Awuku   
 Researcher  
  Dortmund, Germany    
 Invite    

 View More    
  
 51.514000  7.465000  Venue Map & Directions  
   Venue to be announced   
 Dortmund  , Germany   
 Add Venue   
   
 More Events Around Dortmund  
  
 Dec 10 2024 | Wind Turbine Blades   
  Düsseldorf, Germany 
 Dec 14 2024 | Design Summit Dortmund   
  Dortmund, Germany 
 Feb 05 2025 | Die Non Profit Organization Conference   
  Düsseldorf, Germany 
 Feb 25 2025 | Communication And Information Technology For Control Centers And Mobile Use Conference   
  Essen, Germany 
 Apr 02 2025 | Advanced Battery Power Conference   
  Münster, Germany 

   Dortmund   Hagen   Bochum   

 https://10times.com/hub/telecommunication-hub   

 Next step - Complete your profile   To mark your interest in RTNS : International conference on Real-Time Networks and Systems    
 Reach over 2M+ audience with 1 post!   
 Talk About Event  Ask Questions  Share Success    

 Complete your event journey   

 Network   
     
 Broadcast   
     
 Plan   
     
 Attend   
     
 Feedback   

 Related Events  
  
 Mar 06 2025 | Ip Institut   
  Long Beach, USA 
 Jan 19 2025 | International Conference on Electronics, Information, and Communication   
  Osaka, Japan 
 Jan 11 2025 | International Conference on Intelligent Computing and Communication Systems   
  Khewra, India 
 Jan 22 2025 | TRUE Network Annual Conference   
  Online 
 Mar 02 2025 | Oracle Energy and Water Customer Edge Conference   
  Nashville, USA 

 More Events Around Dortmund  
  
 Dec 10 2024 | Wind Turbine Blades   
  Düsseldorf, Germany 
 Dec 14 2024 | Design Summit Dortmund   
  Dortmund, Germany 
 Feb 05 2025 | Die Non Profit Organization Conference   
  Düsseldorf, Germany 
 Feb 25 2025 | Communication And Information Technology For Control Centers And Mobile Use Conference   
  Essen, Germany 
 Apr 02 2025 | Advanced Battery Power Conference   
  Münster, Germany 

   Dortmund   Hagen   Bochum   
  
 Featured Hotels in Dortmund  
  
 Hotel der Lennhof   
     from EUR 118 
 Hotel Drei Linden   
   from EUR 115 
 Dorint An den Westfalenhallen D..   
     from EUR 109 
 Hotel Senator   
    from EUR 60.48 
  
 More Hotels    

   All Events 
  Conferences 
  Telecommunication Conferences 
  Telecommunication Conferences in Germany 
  Telecommunication Events in Dortmund 

                                         Loading...   

  Selected    

  About Us  FOR PARTNERS  Event Data Intelligence  BROWSE    
 Career | Join us  Event Management Software  List Event | Partner Login  All Events  - by Country  | by Industry     
 Media & Press Releases  Event Apps  Event Marketing  Trade Shows  - by Country  | by Industry     
 Help Center | FAQ  Event Website  Testimonials  Conferences  - by Country  | by Industry     
 Feedback  Event Venues  Blog  Companies    
  By continuing past this page, you agree to our Terms of Service  , Cookie Policy, Privacy Policy  and Content Policies. All trademarks are properties of their respective owners   
 © 2014-2024 - Ten Times Online Private Limited. All rights reserved.    

           Call for papers data:Important dates data

11. Conference SoCG_1:
CG Week 2025     Home 
  Program 
  SoCG 
  YRF 
  Challenge 
  Media 
  Workshops 
  Awards 
  Registration 
  Practicalities 

 News   
 September 18, 2024: | SoCG 2025 CFP | is online! 
  September 18, 2024: | CG Week 2025 website is online! 

 General Information   
 About | The Computational Geometry Week (CG Week) is the premier international forum for advances in computational geometry and its many applications. | CG Week combines a number of events, most notably the 41st International Symposium on Computational Geometry (SoCG 2025), the associated Media Exposition (CG:ME), workshops, the Young Researchers Forum (CG:YRF), and the CG Challenge (CG:SHOP). | The 2025 edition is planned to take place in Kanazawa, Japan, June Mon. 23 - Fri. 27, 2025. 

 Code of Conduct   
 CG Week is dedicated to providing an environment that is free from harassment, bullying, discrimination, and retaliation for all participants. Starting in 2025, CG Week will be organized as an event of the CG Society  . All members of the Society are bound by its Code of Conduct  . Only members of the Society can give a presentation and hence at least one author of each accepted paper must become a member of the Society. Society membership is free.  

 Local Organization   
 Organizing Committee: | Tonan Kamata, JAIST, Japan 
  Yoshio Okamoto, The University of Electro-Communications, Japan 
  Yota Otachi, Nagoya University, Japan 
  Toshiki Saitoh, Kyushu Institute of Technology, Japan 
  Tomoko Taniguchi, JAIST, Japan 
  Ryuhei Uehara, JAIST, Japan (chair) 
  Giovanni Viglietta, University of Aizu, Japan 
  Contact | The local organizing committee can be contacted at socg25@ml.jaist.ac.jp  . 

  CG Week 2025   

  Call for papers data:Important dates data

12. Conference SNPD_3:
Close    

   Nearby     Filter      Events   
    Companies   
    Experts   
    Hubs   

   Add Event    
   
   Login   

  Add a review    
 04 - 06 Dec 2024     
 International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing 2024  
   
  Conference    
   Taichung  , Taiwan     
        7  Followers    

  Select   Select   Save   Share    
 Interested  Request a Booth    
 Going    

 About | Exhibitors | Speakers | Reviews | Deals 
  
 Excited about the event? Spread the word and invite your network!   
  Share    

 The IEEE/ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD 2024-Winter) is a platform for researchers, engineers, and industry practitioners to share ideas and research results in computer and information science. Papers are solicited in relevant areas.  
 Highlights  
 Popular among visitors for 
  Top 100 in Science & Research in Taiwan     
   
 Listed In  
  Science & Research    IT & Technology     

 Excited about the event? Spread the word and invite your network!   
  Share    

 Timings  
 09:00 AM-06:00 PM (expected)  
  Not Verified | Entry Fees  
 Check Official Website 
 Estimated Turnout  
 100 - 500  Delegates   
 Based on previous editions | Event Type  
  Conference 
 Editions  
 Dec 2024  Interested     
  +4 more editions   
   
  Frequency  Annual | Official Links  
 Website  Contacts         

  Report Error   
  Claim this event 
 Different Located Editions  Taiyuan, China   05 - 07 Jul 2023   1 Followers    

 Kyoto, Japan   04 - 06 Jul 2022   1 Followers    

 Tân Phú, Vietnam   28 - 30 Jan 2021   2 Followers    

 5 more event 
 Organizer  
   Send Stall Book Request   
  Queries about the event?  Ask Organizer     
   
 International Association for Computer and Information Science (ACIS)   USA  43  Total Events 
 24.163000  120.675000  Venue Map & Directions  
 Booking.com     
 Venue to be announced   
 Taichung  , Taiwan   
 Add Venue 

 Frequently Asked Questions Contact Organizer   
  What type of products / services will be showcased in the event?   
     
 Parallel & Distributed Computing,Software Engineering etc. are some of the products / services to be showcased in International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing.   
   Helpful    

  Can I get a list of speakers participating in the event?   
     
 To get the speaker list on mail register at the link  .   
   Helpful    

  Can I get a list of exhibitors participating in the event?   
     
 To get the exhibitor list on mail register at the link  .   
   Helpful    

  Ask More Questions    

 Write a Review  
   Add Your Review    

   Edition Dec 2024     
 How would you like to participate in this event?  
   
  Visitor     
  Exhibitor     
     Speaker     

 Followers [ Users who have shown interest for this Event ]  Join Community   Invite    
 All Profiles  Student [1]  Member [1]  Exhibitor [1]   All Countries  Taiwan  Malaysia  Pakistan     
 Sort By  Top Profiles  Recommended     

 Lodhi   
  Exhibitor at HHL  
  Sialkot, Pakistan    
 Connect    

 Vonny Cristina Tan   
  Student at Tunghai University  
  Taichung, Taiwan    
 Connect    

 co duong   
  Full stack developer at 林醫  
  Taichung, Taiwan    
 Connect    

 Luke Wee   
  .Net Developer at CMG Technologies Shd Bhd  
  Kuala Lumpur, Malaysia    
 Connect    

 Lo WEN HUI   
  Computer at Peking university, Beijing city, China  
  Hsinchu, Taiwan    
 Connect    

 yukai lin   
  Artificial intelligence at Ntut  
  New Taipei, Taiwan    
 Connect    

 Ian   
  Member at TIE  
  Taipei, Taiwan    
 Connect    

  Add Profile   
  View More    

 24.163000  120.675000  Venue Map & Directions  
   Venue to be announced   
 Taichung  , Taiwan   
 Add Venue   
   
 More Events Around Taichung  
  
 Dec 20 2024 | International Conference on Social Sciences and Intelligence Management (SSIM)   
  Wufeng District, Taiwan 
 Feb 11 2025 | International Conference on Control & Automation   
  Taichung, Taiwan 
 Apr 25 2025 | International Conference on Technology Knowledge & Society   
  Changhua, Taiwan 

   Taichung   Wufeng District   Huwei Township   

 https://10times.com/hub/technology-hub   

 Next step - Complete your profile   To mark your interest in International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing    
 Don’t go alone!   
  7 attendees are in—find your event partner!    

 Complete your event journey   

 Network   
     
 Broadcast   
     
 Plan   
     
 Attend   
     
 Feedback   

 Related Events  
  
 Jan 13 2025 | PepTalk    
  San Diego, USA 
 Dec 12 2024 | Global Games Show    
  Dubai, UAE 
 Jan 13 2025 | BioLogic Summit    
  San Diego, USA 
 Dec 12 2024 | Global AI Show Dubai    
  Dubai, UAE 
 Feb 03 2025 | Summit For Clinical Ops Executives    
  Orlando, USA 

 More Events Around Taichung  
  
 Dec 20 2024 | International Conference on Social Sciences and Intelligence Management (SSIM)   
  Wufeng District, Taiwan 
 Feb 11 2025 | International Conference on Control & Automation   
  Taichung, Taiwan 
 Apr 25 2025 | International Conference on Technology Knowledge & Society   
  Changhua, Taiwan 

   Taichung   Wufeng District   Huwei Township   
  
 Featured Hotels in Taichung  
  
 Lu-Kang Traveler Inns   
    from TWD 1680 
 A Day in Lukang Homestay   
   from TWD 3180 
 鹿境水岸Deer Paradise   
   from TWD 1900 
 Lukang Yian B&B   
   from TWD 3180 
  
 More Hotels    

   All Events 
  Conferences 
  Science & Research Conferences 
  Science & Research Events in Taiwan 
  Science & Research Events in Taichung 

                                         Loading...   

  Selected    

  About Us  FOR PARTNERS  Event Data Intelligence  BROWSE    
 Career | Join us  Event Management Software  List Event | Partner Login  All Events  - by Country  | by Industry     
 Media & Press Releases  Event Apps  Event Marketing  Trade Shows  - by Country  | by Industry     
 Help Center | FAQ  Event Website  Testimonials  Conferences  - by Country  | by Industry     
 Feedback  Event Venues  Blog  Companies    
  By continuing past this page, you agree to our Terms of Service  , Cookie Policy, Privacy Policy  and Content Policies. All trademarks are properties of their respective owners   
 © 2014-2024 - Ten Times Online Private Limited. All rights reserved.    

           Call for papers data:           
  Close    

   Nearby     Filter      Events   
    Companies   
    Experts   
    Hubs   

   Add Event    
   
   Login   

 Science & Research Events  
 Microbiology  Scientific Instruments  Optics  Bioinformatics    

     9,500+ Followers    
 Follow    Share    

    Sign in  to unlock all features    
 Save Filter     With multiple categories and locations    

 Calendar     Select Date   
 Select Date        Today     Tomorrow     This Weekend     This Week     Next Week     Next 3 Months     December, 2024  740     December, 2024  (740)     
   January, 2025  (291)     
   February, 2025  (291)     
   March, 2025  (393)     
   April, 2025  (344)     
   May, 2025  (304)     
   June, 2025  (356)     
   July, 2025  (249)     
   August, 2025  (164)     
   September, 2025  (206)     
   October, 2025  (152)     
   November, 2025  (881)     
   
 View More    

 Format     Trade Shows, Conferences, ...   
   Trade Shows    Conferences    Workshops    

 Location      
   Near Me   
   London  3568     Dubai  2224     Singapore  63     Paris  1220     
       
    USA  33.2k     UK  6839     Germany  6452     India  2916     
 View More    

 Category    
       
   Science & Research  4006     Education & Training  29.5k     Medical & Pharma  12.2k     IT & Technology  10.5k     Banking & Finance  8649     Business Services  7193     Industrial Engineering  4960     Building & Construction  4478     Entertainment & Media  4439     Wellness, Health & Fitness  3831     
 View More   Related Topic   
   Scientific Instruments  334     Aerospace  335     Computer & Gadgets  1497     Industrial Products  1016     Chemicals & Dyes  1266     Biotechnology  503     Drugs & Medicines  2401     Renewable Energy  1571     Motorcycle & Bicycles  253     Stationery  226     
 View More    

 Designation    
       
   Accountants     Database Administrators     Advertising Managers     Aerospace Engineers     Insurance Agents     
 View More    

   Entry Fee       
   Free    Paid    

   Rating       
             & up               & up               & up     

   Members       
   500+    100 to 500    

 Social Events      Curated list of specialty shows in Science & Research    

 Create Filter     With multiple categories and locations    

 All Events 

 Trending  Date    
 1  2  3  4  5  »    

 Coming up in Orlando    1165 following  Summit For Clinical Ops Executives    
 Medical & Pharma   Science & Research     
   
  Coming up in San Diego    937 following  PepTalk    
 Medical & Pharma   Science & Research     

 Date | Event Name | Venue | Description | Type |  
 Wed, 18 - Sun, 22 Dec 2024 | International Healthcare and Medical conference     
 12th edition | Calgary  , Canada | Challenges and Innovations in Healthcare and Medicine .From Health Care to Whole Person Care. | Conference  Medical & Pharma   Science & Research    Paid entry | Interested   1944    
 4.0 
 Tue, 17 - Thu, 19 Dec 2024 | International Conference on Management, Economics & Social Science (ICMESS) | Calgary  , Canada | Advancement in management, Economics and Sciences | Conference  Science & Research  Banking & Finance     Paid entry | Interested   647    
 3.8 
 Featured Events   
  GBS    Thu, 12 - Fri, 13 Dec 2024   
   
 Dubai    
   
  PepTalk    Mon, 13 - Thu, 16 Jan 2025   
   
 San Diego    
   
  SCOPE    Mon, 03 - Thu, 06 Feb 2025   
   
 Orlando 
 Thu, 12 - Fri, 13 Dec 2024 | Global Blockchain Show Dubai (GBS) | Dubai  , UAE | The Ultimate Blockchain Season Finale | Tradeshow  Science & Research  IT & Technology   Blockchain     Paid entry | Interested   81 
 Mon, 13 - Thu, 16 Jan 2025 | PepTalk       
 24th edition | San Diego  , USA | The Protein Science and Production Week | Conference  Medical & Pharma   Science & Research  Machine Learning     Paid entry | Interested   937    
 4.5 
 Wed, 11 - Sun, 15 Dec 2024 | Canada International Conference on Engineering and Sciences     
 8th edition | Calgary  , Canada | Latest Advancement In Engineering and Science | Conference  Industrial Engineering   Science & Research    Paid entry | Interested   395    
 3.7 
 Sun, 19 - Tue, 21 Jan 2025 | International Conference on Science, Engineering & Technology     
 288th edition | Toronto  , Canada | Science, Engineering & Technology Conference in Canada | Conference  Science & Research  IT & Technology     Paid entry | Interested   1162    
 3.8 
 Mon, 02 - Thu, 05 Dec 2024 | GeoSmart India (GSI) | Hyderabad  , India | GeoInnovation - Advancing Geospatial Knowledge in the National Development Agenda | Tradeshow  Science & Research  IT & Technology   Artificial Intelligence   Smart Cities | Interested   121    
 4.8 
 Tue, 28 - Fri, 31 Jan 2025 | Canada International Conference on Health and Medical Research | Calgary  , Canada | “Preventive Health in a Changing World” | Conference  Medical & Pharma   Science & Research    Paid entry | Interested   1788    
 4.6 
 Mon, 03 - Thu, 06 Feb 2025 | Summit For Clinical Ops Executives (SCOPE)       
 online edition available   
 • 16th edition | Orlando  , USA  & Online | Driving Innovation in Clinical Trials & Digital Health | Conference  Medical & Pharma   Science & Research    Paid entry | Interested   1165    
 4.5 
 Mon, 02 - Tue, 03 Dec 2024 | International Conference on Food Sciences and Health (ICFSH) | Sydney  , Australia | The Food Sciences and Health International Research Conference facilitates knowledge exchange and research presentation among scholars, researchers, and industry professionals. It covers food sciences,... | Conference  Science & Research  Food & Beverages | Interested   146    
 4.0 
 Sun, 01 - Thu, 05 Dec 2024 | Radiological Society of North America (RSNA Annual Meeting) | Chicago  , USA | RSNA offers valuable resources for radiology professionals, including AI education and training, an Imaging AI Certificate Program, and access to top experts in the field through online and in-person... | Conference  Medical & Pharma   Science & Research | Interested   177    
 4.0 
 Sun, 01 - Mon, 02 Dec 2024 | International Conference on Natural Science and Environment (ICNSE) | Dhaka  , Bangladesh | International Conference on Natural Science and Environment (ICNSE - 2024) will be held in Dhaka, Bangladesh during 01st-02nd Dec 2024 as the Conference of ICNSE - 2024. ICNSE - 2024 is sponsored by International... | Conference  Science & Research  Environment & Waste | Interested   556    
 4.5 
 Tue, 03 - Wed, 04 Dec 2024 | International Conference on Social Science And Humanities ((ICSSH)) | Munich  , Germany | ICSSH aims to unite academics and experts in Science Technology and Management. The conference is organized by the International Academy of Science, Technology, Engineering, and Management. Accepted papers... | Conference  Science & Research  Education & Training   Social Sciences | Interested   166    
 3.8 
 Wed, 04 - Thu, 05 Dec 2024 | International Conference on Complementary & Alternative Medicine (CAM)     
 3 days to go | Vancouver  , Canada | Current Research in Complementary & Alternative Medicine | Conference  Medical & Pharma   Science & Research  Alternative Medicine     Paid entry | Interested   43 
 Thu, 12 Dec 2024 | International Conference - Science, Technology and Innovation | Mexico City  , Mexico | International Conference - Science, Technology and Innovation will consolidate and strengthen the cooperation, and sharing of knowledge, ability, and experience accumulated in the field of scientific transdisciplinary.... | Conference  Science & Research  IT & Technology | Interested   71 
 Mon, 10 - Tue, 11 Feb 2025 | Nursing Care Conference-Global Edition       
 1st edition | Altamonte Springs  , USA | Health Promotion and Prevention | Conference  Medical & Pharma   Science & Research  Nursing     Paid entry | Interested   282 
 Wed, 04 - Fri, 06 Dec 2024 | Regional Annual Assembly of the Egyptian Scientific Society of Bronchology     
 online edition available | Cairo  , Egypt  & Online | Regional Annual Assembly of the Egyptian Scientific Society of Bronchology is dedicated to broncho-pulmonary medicine with a special interest in bronchoscopy and interventional pulmonology. Its mission... | Conference  Medical & Pharma   Science & Research | Interested   115    
 3.5 
 Tue, 10 - Wed, 11 Dec 2024 | International Conference on Medical, Biological and Pharmaceutical Sciences ((ICMBPS)) | Budapest  , Hungary | ICMBPS aims to unite academics and experts in Science Technology and Management. Organized by the International Academy of Science, Technology, Engineering, and Management, accepted papers will be published... | Conference  Medical & Pharma   Science & Research | Interested   127    
 5.0             
   3 more events happening alongside 
 Sun, 01 - Mon, 02 Dec 2024 | International Conference on Chemical and Biochemical Engineering (ICCBE) | Dhaka  , Bangladesh | International Conference on Chemical and Biochemical Engineering (ICCBE - 2024) will be held in Dhaka, Bangladesh during 01st-02nd Dec 2024 as the Conference of ICCBE - 2024. ICCBE - 2024 is sponsored... | Conference  Science & Research | Interested   272    
 4.3 
 Thu, 05 Dec 2024 | International Artificial Intelligence Summit     
 4 days to go | Brussels  , Belgium | Advancing AI Governance. Is a Global Approach Possible? | Conference  Science & Research  IT & Technology | Interested   58 
 Fri, 06 - Sun, 08 Dec 2024 | ESMO Asia Congress     
 5 days to go | Singapore | ESMO Asia is a yearly conference centered on diverse cancer studies in Asia. It serves as a forum for exchanging and debating the latest research, trials, and treatment methods in the field. The event... | Conference  Medical & Pharma   Science & Research | Interested   103    
 4.4 
 Mon, 02 - Wed, 04 Dec 2024 | Commercial Biomanufacturing Ireland | Dublin  , Ireland | The leading conference for technology, manufacturing, and supply chain in the cell and gene therapy industry. Over 300 attendees, 50 speakers, and 50 exhibitors will participate in the event spanning three... | Conference  Medical & Pharma   Science & Research  Supply Chain | Interested   7 
 Featured Events   
  Nursing Care Conference-Global Edition    Mon, 10 - Tue, 11 Feb 2025   
   
 Altamonte Springs    
   
  Bioprocessing Summit Europe    Tue, 18 - Thu, 20 Mar 2025   
   
 Barcelona    
   
  AWasia    Wed, 04 - Thu, 05 Dec 2024   
   
 Bangkok 
 Thu, 05 - Fri, 06 Dec 2024 | International Conference on Recent Advances in Medical Science (ICRAMS)       
 4 days to go | Sydney  , Australia | International Conference on Recent Advances in Medical Science aims to be a leading forum for presenting novel advances in the fields of Social Science and Economics. It fosters communication among researchers... | Conference  Medical & Pharma   Science & Research | Interested   151    
 3.4 
 Mon, 09 - Tue, 10 Dec 2024 | International Conference on Environment and Natural Science (ICENS) | Athens  , Greece | The International Conference on Environment and Natural Science is a platform for researchers to present ongoing research, build relationships, and collaborate. Organized by ISERD, it offers publication... | Conference  Science & Research  Environment & Waste | Interested   98    
 5.0 
 Tue, 10 - Thu, 12 Dec 2024 | Heritage Middle East Museum and Exhibition Technologies Fair and Conference | Abu Dhabi  , UAE | Museum industry to discuss and showcase advancements in technology and conservation. | Tradeshow  Science & Research  Education & Training | Interested   57    
 4.0 
 Tue, 07 - Thu, 09 Jan 2025 | Dubai International Pharmaceutical & Technologies Conference & Exhibition (DUPHAT) | Dubai  , UAE | Dubai International Pharmaceutical & Technologies Conference & Exhibition plays an important role in the pharmaceutical industry of the MENA region. Initially conceptualized as a conference and exhibition... | Tradeshow  Medical & Pharma   Science & Research | Interested   1434    
 4.1 
 Tue, 10 Dec 2024 | International Conference on Management, Education, and Social Science (5th MESS) | Online | Provide wider network and research ecosystem for further collaboration and projects. | Conference  Science & Research    Paid entry | Interested   14    
 4.5 
 Sun, 15 - Wed, 18 Dec 2024 | Antibody Engineering & Therapeutics Conference | San Diego  , USA | The Antibody Engineering & Therapeutics Conference aims to expedite the commercial success of the upcoming antibody generations. Discussions include the latest research in immuno-oncology, cellular engagers,... | Conference  Medical & Pharma   Science & Research  Bioinformatics | Interested   549    
 3.9 
 Mon, 09 - Wed, 11 Dec 2024 | International Conference on Stem Cells, Regenerative Medicine & Tissue Engineering | Paris  , France | Frontiers in Stem Cell Research | Conference  Medical & Pharma   Science & Research | Interested   9 
 Sat, 28 - Sun, 29 Dec 2024 | International Conference on Mechanical and Aerospace Engineering (ICMAE) | Mississauga  , Canada | Promote research and developmental activities in Mechanical and Aerospace Engineering. | Conference  Industrial Engineering   Science & Research | Interested   260    
 4.5             
   1 more event happening alongside 
 Tue, 04 - Sat, 08 Feb 2025 | International Conference on Engineering and Natural Science     
 12th edition | Calgary  , Canada | Holistic Approach In Engineering and The Natural Science | Conference  Science & Research    Paid entry | Interested   231    
 4.8 
 Mon, 09 - Fri, 13 Dec 2024 | Geospatial Innovation Week Cairo | Cairo  , Egypt | Tradeshow  Science & Research | Interested   9 
 Wed, 04 - Thu, 05 Dec 2024 | International Conference on Engineering & Technology (ICET)     
 3 days to go | New Delhi  , India | Conference  Science & Research  IT & Technology | Interested   243    
 4.3 
 Wed, 11 - Fri, 13 Dec 2024 | Society of Cosmetic Chemists Future Annual Meeting & Expo (SCC78)     
 1st edition | Los Angeles  , USA | Where the world connects for the best cosmetic science education! | Tradeshow  Science & Research  Education & Training | Interested   13 
 Fri, 06 Dec 2024 | International Conference on Computer Science, Industrial Electronics (ICCSIE)     
 5 days to go | Bengaluru  , India | International Conference on Computer Science, Industrial Electronics(ICCSIE) will be held in Bangalore,India during 06th Dec 2024. ICCSIE is organized by Industrial Electronics and Electrical Engineers... | Conference  Science & Research  IT & Technology | Interested   206    
 4.0             
   1 more event happening alongside 
 Thu, 02 - Fri, 03 Jan 2025 | International Conference on Green Energy and Environmental Technology (ICGEET)     
 online edition available | Singapore  & Online | International Conference on Green Energy and Environmental Technology (ICGEET-2024) will be held in Vancouver,Canada during 29th Mar-30th Mar 2024.Energy and environment are co-related in the technological... | Conference  Science & Research  Environment & Waste | Interested   46    
 5.0 
 Tue, 17 - Wed, 18 Dec 2024 | International Conference on Science Technology and Management (ICSTM) | Las Vegas  , USA | IASTEM - International Conference on Science Technology and Management (ICSTM) - 2024) will be held in Las Vegas, United States of America during 17th - 18th Dec 2024. ICSTM is to bring together innovative... | Conference  Science & Research  IT & Technology | Interested   100    
          
   1 more event happening alongside 
 Wed, 04 - Thu, 05 Dec 2024 | International Conference on Environment and Natural Science (ICENS)     
 3 days to go | Phnom Penh  , Cambodia | Conference  Science & Research  Environment & Waste | Interested   123    
 5.0             
   2 more events happening alongside 
 Mon, 09 - Wed, 11 Dec 2024 | International Conference on Stem Cell and Regenerative Medicine | Zürich  , Switzerland | Advances in Stem Cell Research and Clinical Applications. | Conference  Medical & Pharma   Science & Research  Regenerative Medicine     Paid entry | Interested   7 
 Mon, 09 - Tue, 10 Dec 2024 | International Conference on Law and Political Science (ICLPS) | Badhoevedorp  , Netherlands | Conference  Science & Research  Education & Training | Interested   6 
 1  2  3  4  5  » 

   Loading...   
    
 More about Science & Research      
 X   
  Discover upcoming Science & Research events that promise to be transformative for professionals and enthusiasts alike. These gatherings encompass a wide spectrum of opportunities including Scientific Meetings, Research Events, Science Research Conferences, Scientific Conferences, Science and Engineering Research Events, Science & Research Trade Shows, and Research Expos, all designed to showcase the latest advancements and breakthroughs in the realm of science and research.Scientific Conferences are invaluable hubs for experts and researchers to exchange knowledge, present groundbreaking findings, and explore emerging trends. These events offer a dynamic platform for collaboration and networking, fostering an environment where ideas flourish and new partnerships are forged.Science & Research Trade Shows and Research Expos provide a hands-on experience with cutting-edge technologies and innovations. Attendees have the unique opportunity to interact directly with industry-leading exhibitors, gaining insights into the latest tools and methodologies that are driving progress in the field of science and research.For those at the forefront of scientific exploration, Science and Engineering Research Events are essential. These gatherings bring together the brightest minds in the field, providing a forum for the exchange of ideas, methodologies, and findings. This dynamic environment is fertile ground for advancing knowledge and driving innovation.Furthermore, these events offer a platform for cross-disciplinary collaboration, where professionals from various scientific fields converge to address complex challenges and push the boundaries of human knowledge.Our curated list of 3957 upcoming Science & Research events are poised to be catalysts for innovation and progress. By participating in these carefully curated gatherings, you position yourself at the forefront of industry developments, gain invaluable insights, and forge connections with key players in the field. Don't miss out on these transformative events that could shape the trajectory of your scientific endeavors.  

  Premium   
  
 Thu, 12 - Fri, 13 Dec 2024   
   Global Blockchain Show Dubai      
 Dubai  , UAE    
 Science & Research   IT & Technology 
 81 Members 

 Mon, 13 - Thu, 16 Jan 2025   
   PepTalk      
 San Diego  , USA    
 Medical & Pharma   Science & Research 
 937 Members 

 Mon, 03 - Thu, 06 Feb 2025   
   Summit For Clinical Ops Executives      
 Orlando  , USA  & Online   
 Medical & Pharma   Science & Research 
 1165 Members 

 Mon, 10 - Tue, 11 Feb 2025   
   Nursing Care Conference-Global Edition      
 Altamonte Springs  , USA    
 Medical & Pharma   Science & Research 
 282 Members 

 Tue, 18 - Thu, 20 Mar 2025   
   Bioprocessing Summit Europe      
 Barcelona  , Spain  & Online   
 Medical & Pharma   Science & Research 
 672 Members 

 Wed, 04 - Thu, 05 Dec 2024   
   Affiliate World Asia      
 Bangkok  , Thailand    
 Business Services 
 285 Members 

 Thu, 05 - Sat, 07 Dec 2024   
   SIAL INDIA      
 New Delhi  , India    
 Food & Beverages 
 13.0k Members 

 Wed, 11 - Fri, 13 Dec 2024   
   Oil & Gas Annual Conference and Expo      
 New Delhi  , India    
 Power & Energy 
 2922 Members 

 Thu, 12 - Fri, 13 Dec 2024   
   Global AI Show Dubai      
 Dubai  , UAE    
 IT & Technology 
 200 Members 

 Thu, 12 - Fri, 13 Dec 2024   
   Global Games Show      
 Dubai  , UAE    
 IT & Technology 
 33 Members 

 Fri, 03 - Sun, 05 Jan 2025   
   Florida' s Largest Home Show      
 Tampa  , USA    
 Home & Office 
 3815 Members 

 Mon, 06 - Thu, 09 Jan 2025   
   Hong Kong Toys & Games Fair      
 Hong Kong  & Online   
 Baby, Kids & Maternity 
 2245 Members 

 Mon, 06 - Thu, 09 Jan 2025   
   Hong Kong International Stationery and School Supplies Fair      
 Hong Kong  & Online   
 Home & Office 
 1048 Members 

 Mon, 06 - Thu, 09 Jan 2025   
   Hong Kong Baby Products Fair      
 Hong Kong  & Online   
 Baby, Kids & Maternity 
 750 Members 

 Mon, 13 - Thu, 16 Jan 2025   
   BioLogic Summit      
 San Diego  , USA  & Online   
 Medical & Pharma   IT & Technology 
 361 Members 

 Fri, 31 Jan - Sun, 02 Feb 2025   
   Home Design and Remodeling Show      
 Fort Lauderdale  , USA  & Online   
 Building & Construction   Home & Office 
 3311 Members 

 Mon, 10 - Wed, 12 Feb 2025   
   Texworld Apparel Sourcing Paris      
 Paris  , France    
 Apparel & Clothing   Fashion & Beauty 
 12.1k Members 

 Tue, 04 - Fri, 07 Mar 2025   
   APPPEXPO Shanghai International Printing Exhibition      
 Shanghai  , China    
 Packing & Packaging 
 3197 Members 

 Mon, 17 - Thu, 20 Mar 2025   
   International Battery Seminar & Exhibit      
 Orlando  , USA    
 Electric & Electronics   Power & Energy 
 1380 Members 

 Tue, 29 Apr - Thu, 01 May 2025   
   Australia Tools & Grinding Expo      
 Brisbane  , Australia    
 Building & Construction   Industrial Engineering 
 2050 Members 

 Mon, 19 - Thu, 22 May 2025   
   Bakery China      
 Shanghai  , China    
 Food & Beverages 
 2856 Members 

 Wed, 13 - Fri, 15 Aug 2025   
   Shanghai International Automotive Innovation Technology Week      
 Shanghai  , China    
 Auto & Automotive 
 3 Members 

 Tue, 03 - Thu, 05 Dec 2024   
   International Indo Africa B2B Investment & Trade Expo      
 Nairobi  , Kenya    
 Business Services 
 2468 Members 

 Tue, 03 - Thu, 05 Dec 2024   
   Drug Discovery Chemistry Europe      
 Barcelona  , Spain  & Online   
 Medical & Pharma 
 485 Members 

 Wed, 04 - Sat, 07 Dec 2024   
   Plast Eurasia Istanbul      
 Büyükçekmece  , Turkey    
 Packing & Packaging   Industrial Engineering 
 987 Members 

 Thu, 05 - Sat, 07 Dec 2024   
   Private Label Fair Asia      
 Shanghai  , China    
 Packing & Packaging   Home & Office 
 592 Members 

 Thu, 05 Dec 2024   
   CEDIA Tech + Business Summit      
 Houston  , USA    
 IT & Technology   Home & Office 
 136 Members 

 Fri, 06 - Sun, 08 Dec 2024   
   International Seminar and Workshop in Aesthetic Medicine      
 Tangerang  , Indonesia    
 Medical & Pharma   Education & Training 
 205 Members 

 Mon, 09 - Thu, 12 Dec 2024   
   Annual Advanced Automotive Battery Conference      
 Las Vegas  , USA    
 Auto & Automotive   Power & Energy 
 431 Members 

 Tue, 10 - Thu, 12 Dec 2024   
   Battery Minerals & Mines Summit      
 Las Vegas  , USA    
 Power & Energy 
 412 Members 

   Loading...   

      Loading...   

  Selected    

   Important dates data

13. Conference SoCG_2:
Conference Partner   Home 
  Conferences 
  Journals 
  Proofreading 
  Login 

  中文  |  English  |  Español  |  日本語     

 Conference Partner  » Conferences  » SoCG    
  Conference Information   
   
 SoCG 2025: ACM Symposium on Computational Geometry  
 https://socg25.github.io/   
   
 Submission Date: | 2024-11-26 
 Notification Date: | 2025-02-06 
 Conference Date: | 2025-06-23 
 Location: | Kanazawa, Japan 
 Years: | 41 
  
 CCF: b  CORE: a  QUALIS: a2  Viewed: 25524  Tracked: 4  Attend: 0    

  Call For Papers   
   
 The 41st International Symposium on Computational Geometry (SoCG 2025) is planned to be held in Kanazawa, Japan, June 23–27, 2025, as part of the Computational Geometry (CG) Week. We invite high quality submissions that describe original research on computational problems in a geometric and/or topological setting. Topics of interest include, but are not limited to: Design, analysis, and implementation of geometric algorithms and data structures; Computational complexity of geometric problems; Implementation and experimental evaluation of geometric algorithms and heuristics, including mathematical, numerical, and algebraic aspects; Discrete and combinatorial geometry; Computational topology, topological data analysis, and topological combinatorics; Applications of computational geometry or topology in any field.  Last updated by Dou Sun  in 2024-10-01   

  Acceptance Ratio   

 Year | Submitted | Accepted | Accepted(%) 
 2021 | 164 | 58 | 35.4% 
 2020 | 205 | 70 | 34.1% 
 2019 | 166 | 60 | 36.1% 
 2018 | 206 | 73 | 35.4% 
 2017 | 148 | 59 | 39.9% 
 2016 | 161 | 61 | 37.9% 
 2015 | 154 | 59 | 38.3% 
  
 3906  3720  3721  3339  3330  3331  3332    

  Related Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 2MAE | International Conference on Mechanical, Material and Aerospace Engineering | 2018-03-15 | 2018-04-05 | 2018-05-10 
 c | b | b2 | GMP | Geometric Modeling and Processing | 2024-12-09 | 2025-04-14 | 2025-05-28 
 ICBC | IEEE International Conference on Blockchain and Cryptocurrency | 2024-12-23 | 2025-03-05 | 2025-06-02 
 a | a2 | ICCS | International Conference on Computational Science | 2024-02-02 | 2024-04-01 | 2024-07-02 
 ICCMCE | International Conference on Chemical Machinery and Control Engineering | 2020-02-27 | 2020-04-10 
 ICPRAM | International Conference on Pattern Recognition Applications and Methods | 2024-10-02 | 2024-12-04 | 2025-02-23 
 NanoMT | International Conference on Frontiers of Nanomaterials and Nanotechnology | 2024-09-13 | 2024-09-15 | 2024-09-13 
 ICCSPA | International Conference on Communications, Signal Processing and their Applications | 2022-09-15 | 2022-10-28 | 2022-12-27 
 ICCIT'' | International Conference on Computer and Information Technology | 2021-10-01 | 2021-11-05 | 2021-12-18 
 c | CVM | International Conference on Computational Visual Media | 2024-10-09 | 2024-12-13 | 2025-04-19 
  
 2603  380  2955  185  3586  2853  3377  1588  1958  2906    

 Short | Full Name | Submission | Conference 
 2MAE | International Conference on Mechanical, Material and Aerospace Engineering | 2018-03-15 | 2018-05-10 
 GMP | Geometric Modeling and Processing | 2024-12-09 | 2025-05-28 
 ICBC | IEEE International Conference on Blockchain and Cryptocurrency | 2024-12-23 | 2025-06-02 
 ICCS | International Conference on Computational Science | 2024-02-02 | 2024-07-02 
 ICCMCE | International Conference on Chemical Machinery and Control Engineering | 2020-02-27 | 2020-04-10 
 ICPRAM | International Conference on Pattern Recognition Applications and Methods | 2024-10-02 | 2025-02-23 
 NanoMT | International Conference on Frontiers of Nanomaterials and Nanotechnology | 2024-09-13 | 2024-09-13 
 ICCSPA | International Conference on Communications, Signal Processing and their Applications | 2022-09-15 | 2022-12-27 
 ICCIT'' | International Conference on Computer and Information Technology | 2021-10-01 | 2021-12-18 
 CVM | International Conference on Computational Visual Media | 2024-10-09 | 2025-04-19 
  
 2603  380  2955  185  3586  2853  3377  1588  1958  2906    

  Related Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 b | Computer Vision and Image Understanding | 4.300 | Elsevier | 1077-3142 
 b | Parallel Computing | 2.000 | Elsevier | 0167-8191 
 Journal of Information Science and Engineering | 1.100 | Institute of Information Science | 0000-0000 
 b | IEEE Transactions on Affective Computing | 9.600 | IEEE | 1949-3045 
 Mobile Media & Communication | 3.100 | SAGE | 2050-1579 
 Science, Technology, & Human Values | 3.100 | SAGE | 0162-2439 
 b | Performance Evaluation | 1.000 | Elsevier | 0166-5316 
 Journal of Medical Systems | 3.500 | Springer | 0148-5598 
 b | Evolutionary Computation | 4.600 | MIT Press | 1063-6560 
 Journal of Intelligent Transportation Systems | 2.800 | Taylor & Francis | 1547-2450 
  
 178  20  605  181  786  781  21  783  179  784    

 Full Name | Impact Factor | Publisher 
 Computer Vision and Image Understanding | 4.300 | Elsevier 
 Parallel Computing | 2.000 | Elsevier 
 Journal of Information Science and Engineering | 1.100 | Institute of Information Science 
 IEEE Transactions on Affective Computing | 9.600 | IEEE 
 Mobile Media & Communication | 3.100 | SAGE 
 Science, Technology, & Human Values | 3.100 | SAGE 
 Performance Evaluation | 1.000 | Elsevier 
 Journal of Medical Systems | 3.500 | Springer 
 Evolutionary Computation | 4.600 | MIT Press 
 Journal of Intelligent Transportation Systems | 2.800 | Taylor & Francis 
  
 178  20  605  181  786  781  21  783  179  784    

  Recommendation   

 Track It 4 
  Attend It 0 
  Edit CFP 

 Tracker 
 Research Survey (234) 
 Tang E (12) 
 ANAN DU (1053) 
 Kathy Happy (1206) 
  
 69033  27523  6607  11167    
   
  Advertisment   

  4,945  Conferences | 1,179  Journals | 69,627  Researchers | 385,881,092 PV  
  Copyright © 2011-2024 myhuiban.com. All Rights Reserved. About Us  | Facebook  | X  | Post CFP or Contact Us  | Promotion    

  Call for papers data:    Conference Partner   Home 
  Conferences 
  Journals 
  Proofreading 
  Login 

  中文  |  English  |  Español  |  日本語     

 Conference Partner  » Researchers  » Dou Sun    
  Basic Information   
   
 Name: Dou Sun  
 Institution: Conference Partner  
 Registration: 2011-02-24  
 Score: 135640  

  CV   
   
 Dou SUN (孙斗) "Conference Partner" was created in 2011. It is an academic website for conferences and journals information. I built this website and maintained it in my spare time. Email: sundou82 AT gmail.com Skills: J2EE (11 years of experience, Spring, Hibernate, iBatis, JMS, RabbitMQ, Maven, Ant, ...) Web Services (11 years of experience, XML, JSON, SOAP, WSDL, BPEL, RESTful, ...) Web (14 years of experience, HTML, CSS, JavaScript, PHP, Yii, Magento, JQuery, ExtJS, NodeJS...) Projects and Working Experience: 04/2011 - now, Huawei Technologies Co., Ltd (华为技术有限公司) DC2 (Distributed Cloud Data Center) Development and Test Cloud (DTC) Media Management Cloud (iShare) Media File Archive System (iLibrary) Online Video Platform (OVP) Cloud Media Process System (CMP) 09/2007 - 09/2010, Formal Verification of Business Process. "BaiMai Project - QualiPso Program (FP6)" Research cooperation between Beihang University and THALES Corporation Managed a team of 5 members Developed the "XServices BPEL Verification Tool" 11/2006 - 12/2008, WSOP - Web Services Orchestration Platform. "Service Oriented Autonomic Software System" (863 Program) Managed a team of 11 developers Developed the "XServices Orchestration Engine" 09/2005 - 05/2009, National E-government Standards and SOA Standards of China. Cooperation with China Electronic Standardization Institute (CESI) In charge of the workflow specification in e-government standards and SOA standards Standards have been accepted and published as the industry standard and the national E-government standard Participated to draft the national standards for SOA. 09/2005 - 09/2009, Workflow System. Cooperation with the Chinese companies (Intervision, Cvicse, JianDa and etc.) Promoted the commercialization of "Web Services Workflow System" (WSWF) 02/2006 - 12/2006, XServices Suites OpenSource Project. International cooperation between OrientWare and ObjectWeb One of chief administrators of the opensource project Released the new version of "XServices Suites" 10/2005 - 06/2006 WSWF - Web Services Workflow System. "Integration and Application of Middleware Kit - Orientware" (863 Program) A core member of the develop team Integrated the WSWF into Orientware Education Background: 09/2005 - 04/2011 Ph.D, School of Computer Science and Engineering, Beihang University (北京航空航天大学), Beijing, China Ph.D project: Computer Software and Theory 10/2009 - 04/2010 Visiting Student, OASIS Team, INRIA, Sophia Antipolis, France 09/2004 - 06/2005 MSc Postgraduate, School of Computer Science and Engineering, Beihang University (北京航空航天大学), China Accepted and Transferred to Ph.D student directly after first year performance. 09/2000 - 06/2004 BSc. Undergradate,School of Computer and Communication, Hunan University (湖南大学), China Honors and Prizes: [1] The 1st Prize at OW2 Programming Contest 2009, OW2, GuiYang, China, September 2009. [2] The 1st ProActive Prize at Super Quant Monte-Carlo Challenge, V Grid Plugtests, INRIA, France, October 2008. [3] The Prize of Special Contribute for R & D, ACT Lab, Beihang University, January 2008. [4] The 2nd Prize Winner of N-Queens Contest, IV Grid Plugtests, CNIC, Beijing, October 2007. [5] The "GuangHua" Scholarship for the year of 2007, Beihang University, December 2007. Patents: [1] Directed Graph based Method for Detecting Control Cycles in WS-BPEL, No. 200810118124.4, Chinese Patent. [2]GMF based Visual Modeling Approach for BPEL, No. 200810118126.3, Chinese Patent. [3] An Automatic Method for Electronic Document Flow based on Web Services, No. 200810116992.9, Chinese Patent. [4] A Fault-tolerant Method for Services based on XESB, No. 200810102768.4, Chinese Patent, . [5] Web Services Runtime Management System and Method based on Rules, No. 200810102394.6, Chinese Patent. [6] A Dynamic Evolution in Services Coordination based on System Structure, No. 200810118123.X, Chinese Patent. [7] An Automatic Operation Method for Databse based on Web Services,No. 200510114782.2, Chinese Patent. [8] A Conversion Method between Graphics with XML documents based on BPEL, No. 200510114689.1, Chinese Patent. [9] An Approach for Processing Web Services Workflow based on Stack Model, No. 200510114563.4, Chinese Patent. Publications: [1] Dou Sun, Yongwang Zhao, Hao Zeng, Dianfu Ma. An Operational Semantics of WS-BPEL based on Abstract BPEL Machine. IEEE International Conference on Service-Oriented Computing and Applications (SOCA), 2010. [2] Dou Sun, Yongwang Zhao, Hao Zeng, Dianfu Ma. SEDA4BPEL: A Staged Event-Driven Architecture for High-Concurrency BPEL Engine. IEEE symposium on Computers and Communications (ISCC), 2010, Page(s): 744 – 749. [3] Dou Sun, Zhuqing Li, Yongwang Zhao, Dianfu Ma. Orchestra Designer: an open-source tool for scientific workflow modeling. IEEE International Workshop on Open-source Software for Scientific Computation (OSSC), 2009, Page(s): 39 – 43. [4] Yongwang Zhao, Jing Li, Dou Sun, Dianfu Ma, "Towards Verifying Global Properties of Adaptive Software based on Linear Temporal Logic", 25th International Conference on Advanced Information Networking and Applications (AINA 2011) , IEEE Computer Society, March 22 - 25, 2011, Biopolis, Singapore, pp.240-247. [5] Kexin Li, Dou Sun, Zhuqing Li, Yongwang Zhao, Dianfu Ma. Workflow Modeling Tool for Multi-User Collaboration. Annual International Conference on Advances in Distributed and Parallel Computing (ADPC), 2010. [6] Yiwei Yin, Dou Sun, Yongwang Zhao, Dianfu Ma. GMF-ALF: A Development Framework for the Graphical Modeling Tool. 3rd International Conference on Computer and Electrical Engineering (ICCEE), 2010. [7] Jian Liu, Dianfu Ma, Zhuqing Li, Dou Sun. A Formal Description of Web Services Container Architecture. 4th International Conference on Internet and Web Applications and Services (ICIW), 2009, Page(s): 30 - 36. [8] Jian Liu, Dianfu Ma, Zhuqing Li, Dou Sun. A Formal Model of Web Services Transport Layer. 5th International Conference on Networking and Services (ICNS), 2009, Page(s): 474 - 480. [9] Min Liu, Dianfu Ma, Yongwang Zhao, Dou Sun. An Approach to Preserving Consistency of SOAs in Dynamic Evolution. 4th International Conference on Internet and Web Applications and Services (ICIW), 2009, Page(s): 505 - 509. [10] Dianfu Ma, Min Liu, Yongwang Zhao, Dou Sun. Reliability Quantification of the Tree Structure Based Distributed System. 14th IEEE Pacific Rim International Symposium on Dependable Computing (PRDC), 2008, Page(s): 351 - 352. [11] Dianfu Ma, Min Liu, Yongwang Zhao, Dou Sun. Dependability of the System Based on Structured Service Collaboration Model. 4th International Conference on Next Generation Web Services Practices (NWESP), 2008, Page(s): 28 - 32. [12] Xin Zhao, Jun Han, and Dou Sun. The Design and Implementation of a BPEL Modeling Tool Supporting Automatic Layout, CONTROL & AUTOMATION [Journal], 2008 [13] Xin Zhao, Jun Han, and Dou Sun. The Research and Implementation of Visual BPEL Workflow Remote Debugging Mechanism, Application Research of Computers [Journal], 2008 [14] Yuanyuan Chen, Dou Sun, and Ying Li. Design and Implementation of a WSDM-Based Web Service Management Mechanism, CONTROL & AUTOMATION [Journal], 2008 [15] Hongjie He, Dou Sun, and Xin Zhao. A Framework for Graphic Modeling Tool, National Association of State Aquaculture Coordinators (NASAC 2007), 2007, Xi'an, China.    
   
  Tracked Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 a | a* | a1 | ICML | International Conference on Machine Learning | 2025-01-23 | 2025-07-13 
 c | b | a2 | ISCC | IEEE symposium on Computers and Communications | 2025-01-10 | 2025-03-14 | 2025-07-02 
 a | a* | a1 | CVPR | IEEE Conference on Computer Vision and Pattern Recognition | 2024-11-14 | 2025-02-26 | 2025-06-10 
 b | a | a2 | ICSOC | International Conference on Service Oriented Computing | 2024-07-10 | 2024-09-20 | 2024-12-03 
 c | b | b1 | ICPADS | International Conference on Parallel and Distributed Systems | 2024-07-07 | 2024-08-15 | 2024-10-10 
 a | a2 | BPM | International Conference on Business Process Management | 2024-03-01 | 2024-05-17 | 2024-09-01 
 c | SOCA | International Conference on Service-Oriented Computing and Applications | 2019-08-05 | 2019-08-31 | 2019-11-18 
  
 406  308  407  17  223  452  219    

 Short | Full Name | Submission | Conference 
 ICML | International Conference on Machine Learning | 2025-01-23 | 2025-07-13 
 ISCC | IEEE symposium on Computers and Communications | 2025-01-10 | 2025-07-02 
 CVPR | IEEE Conference on Computer Vision and Pattern Recognition | 2024-11-14 | 2025-06-10 
 ICSOC | International Conference on Service Oriented Computing | 2024-07-10 | 2024-12-03 
 ICPADS | International Conference on Parallel and Distributed Systems | 2024-07-07 | 2024-10-10 
 BPM | International Conference on Business Process Management | 2024-03-01 | 2024-09-01 
 SOCA | International Conference on Service-Oriented Computing and Applications | 2019-08-05 | 2019-11-18 
  
 406  308  407  17  223  452  219    

  Attend Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Conference | Location 
 b1 | FORMATS | International Conference on Formal Modeling and Analysis of Timed Systems | 2022-09-12 | Warsaw, Poland 
 b | a* | a1 | UAI | Conference on Uncertainty in Artificial Intelligence | 2022-08-01 | Eindhoven, The Netherlands 
 CYBI | International Conference on Cybernetics & Informatics | 2020-01-25 | Zurich, Switzerland 
 c | SOCA | International Conference on Service-Oriented Computing and Applications | 2010-12-13 | Perth, Australia 
  
 401  416  3522  219    

 Full Name | Conference | Location 
 International Conference on Formal Modeling and Analysis of Timed Systems | 2022-09-12 | Warsaw, Poland 
 Conference on Uncertainty in Artificial Intelligence | 2022-08-01 | Eindhoven, The Netherlands 
 International Conference on Cybernetics & Informatics | 2020-01-25 | Zurich, Switzerland 
 International Conference on Service-Oriented Computing and Applications | 2010-12-13 | Perth, Australia 
  
 401  416  3522  219    

  Tracked Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 b | Journal of Parallel and Distributed Computing | 3.400 | Elsevier | 0743-7315 
  
 18    

 Full Name | Impact Factor | Publisher 
 Journal of Parallel and Distributed Computing | 3.400 | Elsevier 
  
 18    

  Followed Researchers   

 Name | Institution | Registration | Score 
 Jing Li | Beihang University | 2011-03-04 | 222 
 Zhuqing Li | Beihang University | 2011-02-24 | 33 
  
 14  2    

 Name | Institution | Score 
 Jing Li | Beihang University | 222 
 Zhuqing Li | Beihang University | 33 
  
 14  2    

  Tracked Jobs   

 Job Title | Employer | Job Location 
 No results found. 

 Job Title | Employer | Job Location 
 No results found. 

  Viewed Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 ICAIM | International Conference on Artificial Intelligence & Materials | 2024-11-10 | 2025-02-15 | 2025-03-21 
 CWOC | International Conference on Wireless and Optical Communications | 2025-03-25 | 2025-04-01 | 2025-04-25 
 AIAC | International Conference on Artificial Intelligence and Automation Control | 2024-12-13 | 2024-12-20 
 Tau | ACM International Workshop on Timing Issues in the Specification and Synthesis of Digital Systems | 2025-01-13 | 2025-02-24 | 2025-05-01 
 FAccT | ACM Conference on Fairness, Accountability, and Transparency | 2025-01-15 | 2025-04-11 | 2025-06-03 
 RESPECT | Conference for Research on Equitable and Sustained Participation in Engineering, Computing, and Technology | 2025-01-31 | 2025-04-07 | 2025-07-14 
 MLPR | International Conference on Machine Learning and Pattern Recognition | 2025-02-20 | 2025-03-20 | 2025-07-25 
 IWOCL | International Workshop on OpenCL and SYCL | 2025-01-12 | 2025-02-24 | 2025-04-07 
 MLNN | International Conference on Machine Learning and Neural Networks | 2025-03-31 | 2025-04-18 
 IPDL | International Conference on Image Processing and Deep Learning | 2025-02-10 | 2025-04-11 
  
 5004  5003  5002  5001  5000  4999  4998  4997  4996  4995    

 Short | Full Name | Submission | Conference 
 ICAIM | International Conference on Artificial Intelligence & Materials | 2024-11-10 | 2025-03-21 
 CWOC | International Conference on Wireless and Optical Communications | 2025-03-25 | 2025-04-25 
 AIAC | International Conference on Artificial Intelligence and Automation Control | 2024-12-13 | 2024-12-20 
 Tau | ACM International Workshop on Timing Issues in the Specification and Synthesis of Digital Systems | 2025-01-13 | 2025-05-01 
 FAccT | ACM Conference on Fairness, Accountability, and Transparency | 2025-01-15 | 2025-06-03 
 RESPECT | Conference for Research on Equitable and Sustained Participation in Engineering, Computing, and Technology | 2025-01-31 | 2025-07-14 
 MLPR | International Conference on Machine Learning and Pattern Recognition | 2025-02-20 | 2025-07-25 
 IWOCL | International Workshop on OpenCL and SYCL | 2025-01-12 | 2025-04-07 
 MLNN | International Conference on Machine Learning and Neural Networks | 2025-03-31 | 2025-04-18 
 IPDL | International Conference on Image Processing and Deep Learning | 2025-02-10 | 2025-04-11 
  
 5004  5003  5002  5001  5000  4999  4998  4997  4996  4995    

  Viewed Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 Solid State Sciences | 3.400 | Elsevier | 1293-2558 
 Materials Today Communications | 3.700 | Elsevier | 2352-4928 
 Materials Science and Engineering: B | 3.900 | Elsevier | 0921-5107 
 Surface and Coatings Technology | 5.300 | Elsevier | 0257-8972 
 Polymer Degradation and Stability | 6.300 | Elsevier | 0141-3910 
 IEEE Open Journal of Signal Processing | 2.900 | IEEE | 2644-1322 
 IEEE Internet of Things Magazine | IEEE | 2576-3180 
 IEEE Communications Standards Magazine | IEEE | 2471-2825 
 IEEE Transactions on Molecular, Biological, and Multi-Scale Communications | 2.400 | IEEE | 2372-2061 
 IEEE Transactions on Cognitive Communications and Networking | 7.400 | IEEE | 2372-2045 
  
 1195  1194  1193  1192  1191  1142  1082  1081  1045  1042    

 Full Name | Impact Factor | Publisher 
 Solid State Sciences | 3.400 | Elsevier 
 Materials Today Communications | 3.700 | Elsevier 
 Materials Science and Engineering: B | 3.900 | Elsevier 
 Surface and Coatings Technology | 5.300 | Elsevier 
 Polymer Degradation and Stability | 6.300 | Elsevier 
 IEEE Open Journal of Signal Processing | 2.900 | IEEE 
 IEEE Internet of Things Magazine | IEEE 
 IEEE Communications Standards Magazine | IEEE 
 IEEE Transactions on Molecular, Biological, and Multi-Scale Communications | 2.400 | IEEE 
 IEEE Transactions on Cognitive Communications and Networking | 7.400 | IEEE 
  
 1195  1194  1193  1192  1191  1142  1082  1081  1045  1042    

 Follow 71 

 Follower 
 I L (358) 
 Selia Terisa (9) 
 Reni Samarah (9) 
 Wen Gu (13) 
 Kuse Shigeko (39) 
 Regina Liu (1058) 
 Yang Yang (298) 
 Jiayu Zhuang (34) 
 Sheen Song (86) 
 Xiaojuan Zhao (95) 
 ERMM 2021 (69) 
 Saraa Cassandra (59) 
 Joy Li (350) 
 Zhanbei Cui (63) 
 Jayleen Chen (150) 
 Sherry Zhao (32) 
 Teacher Zhao (33) 
 Lu Wang (16) 
 Hu 锰涛 (364) 
 Qiangqiang Ouyang (198) 
 Long Xin (1036) 
 Lea Jeffrey (8) 
 Dunn Carl (4062) 
 Hong-Ning Dai (14) 
 Wei Chen (163) 
 Cindy Shen (27) 
 Wang Hao (693) 
 Jim Guo (289) 
 Steve Smith (19) 
 Wei Zhang (825) 
 Youfs Youfs (3) 
 Ting Tu (42) 
 Mia Jack (98) 
 Triple Z (77) 
 翔龙 Cheng (225) 
 Zebin Wu (1135) 
 Masa Otsuka (82) 
 Wenhan Zhan (9) 
 Fei Xue (286) 
 Lei Yan (164) 
 Mingli Yu (7) 
 Muhammad Arif (568) 
 XIN SUI (74) 
 Ke Ao (7553) 
 Sunshine Wang (99) 
 Chen Liang (221) 
 Zhou Xue (186) 
 Guangyuan Piao (2478) 
 Find Hao (1035) 
 Xin Yao (11681) 
 Ting Huang (172) 
 Chris Chen (1235) 
 Huan Wang (2075) 
 Yingzheng Wang (158) 
 Kallol Krishna Karmakar (384) 
 Starking Chen (1166) 
 Sandra Evans (103) 
 Yingjun Li (133) 
 HY Feng (356) 
 Xu Wang (494) 
 Zaiqiao Meng (2935) 
 Xiaox Lee (542) 
 MC Zheng (969) 
 Anıl Uysal (112) 
 Yi Chai (291) 
 Xianqi Zhao (54) 
 Fuan Pu (483) 
 Zhenbang Liu (154) 
 Lei Xu (2) 
 Tracy Zhang (1) 
  
 65823  64176  64175  60585  57923  50414  44329  46656  46332  25434  36170  45414  40156  41992  35303  34857  34254  28350  25869  19812  16772  24376  9767  23543  22662  22449  21233  11594  19438  19205  18936  18771  18379  14895  17635  13872  16932  16199  15665  11686  12331  12168  11805  9209  6737  6294  6011  3907  3899  323  3199  779  2793  2784  2589  102  2381  2233  2192  613  2026  864  1556  1163  1039  778  213  477  257  179    
   
  Advertisment   

  4,945  Conferences | 1,179  Journals | 69,627  Researchers | 385,881,095 PV  
  Copyright © 2011-2024 myhuiban.com. All Rights Reserved. About Us  | Facebook  | X  | Post CFP or Contact Us  | Promotion    

  Important dates data

14. Conference SoCS_0:
So CS    

 International Symposium on Combinatorial Search (SoCS)   
   
 Welcome!  
 Heuristic search and combinatorial optimization  are currently very active areas of research. For example, researchers investigate how to search in real-time, how to search with limited (possibly external) memory, how to solve sequences of similar search problems faster than with isolated searches, how to improve the runtime of the searches over time, how to trade-off between the runtime and memory consumption of the search and the resulting solution quality, and how to focus the searches with sophisticated heuristics such as pattern databases. Their results are published in different conferences such as IJCAI, AAAI, ICAPS, NIPS, ICRA, and IROS.  
 The International Symposium on Combinatorial Search (SoCS) is meant to bring these researchers together to exchange their ideas and cross-fertilize the field. Thus, in addition to seeking separate answers to questions like how to design more accurate memory-based heuristics, more I/O-efficient disk-based search algorithms, or more efficient clause-learning strategies, the symposium is intended to stimulate thoughts on combining various techniques that originated in different areas of search.  
 The Eighteenth International Symposium on Combinatorial Search (SoCS 2025)  will be held from 11 to 15 August in Glasgow, Scotland. SoCS 2025 is co-located with CP 2025  and SAT 2025  .  
 To stay informed on search-related events, please join the search-list on Google groups  .  

  Home Page    
  Organization  Previous Symposia  Proceedings  Videos  Contact   

 Print 
  Login 
  (search-conference.org)  

  Call for papers data:Important dates data

15. Conference SOCA_1:
IEEE.org 
  IEEE Computer Society 

 Home 
  Conferences 
  Executive Committee 
  Membership 
  Contact 

 Upcoming Conferences  
 The 2025 IEEE Conference on Artificial Intelligence (IEEE CAI), Santa Clara, California, USA, May 5-7, 2025 

 2024, 20th IEEE International Conference on e-Business Engineering (ICEBE 2024 ), October 11-13, 2024 Shanghai, China 
  2024 18th IEEE International Congress on Intelligent and Service-Oriented Systems Engineering (CISOSE), July 15-18, 2024, Shanghai, China 
   Past Conferences  
 2024 IEEE/ACM Sixth International Conference on Internet-of-Things Design and Implementation ( I | oTDI | ), May 13-16, 2024 — Hong Kong 
  2024 12th The IEEE International Conference on Cloud Engineering (IC2E), September 24-27, 2024, Paphos, Cyprus 
  2023, 19th IEEE International Conference on e-Business Engineering (ICEBE 2023 ), November 4-6, 2023 Sydney, Australia 
  2023 17th IEEE International Conference On Service-Oriented System Engineering (SOSE), July 17-20, 2023, Athens, Greece 
  2023 IEEE/ACM Sixth International Conference on Internet-of-Things Design and Implementation ( I | oTDI | ), May 9-12, 2023 — San Antonio, Texas, USA 
  2023 IEEE International Conference on Business Informatics (BIS), 2023, June 21-23, Prague, Czech 
  18th IEEE International Conference on e-Business Engineering (ICEBE 2022), October 14-16, 2022 Bournemouth, UK 
  2022 16th IEEE International Conference On Service-Oriented System Engineering (SOSE), August 15-18, 2022, San Francisco Bay Area, USA 
  2022 10th The IEEE International Conference on Cloud Engineering (IC2E), September 26-30, 2022, San Francisco, USA 
  IEEE Infrastructure Conference 2022, September 26-30, 2022, San Francisco | , | USA. 
  2022 IEEE International Conference on Business Informatics (BIS), 2022, June 15-17, Amsterdam, Netherlands 
  2022 IEEE/ACM Sixth International Conference on Internet-of-Things Design and Implementation ( I | oTDI | ), 2022, May 3-6, Milan, Italy 
  17th IEEE International Conference on e-Business Engineering (ICEBE 2021), November 12-14, 2021 Guangzhou, China 
  2021 15th IEEE International Conference On Service-Oriented System Engineering (SOSE), August 23-26, 2021 Oxford, UK 
  2021 9th The IEEE International Conference on Cloud Engineering (IC2E), October 4-8, 2021 San Francisco, USA 
  IEEE Infrastructure Conference 2021, October 6-7, 2021, San Francisco | , | USA (Hybrid Event) 
  32rd IEEE International Conference on Business Informatics (BIS), 2021, September 1-3, Bolzano, IT (Virtual Event) 
  2021 IEEE/ACM Sixth International Conference on Internet-of-Things Design and Implementation ( IoTDI  ), 2021, May 18-21, USA (Virtual Event) 
    
 13th IEEE International Conference on e-Business Engineering (ICEBE 2016), November 4-6, Macau, China 
  9th IEEE International Conference on Service Oriented Computing & Applications (SOCA 2016), November 4-6, Macau, China 
  18th IEEE Conference on Business Informatics (CBI 2016), August 29 – September 1, Paris, France 
  IEEE International Conference on Internet-of-Things Design and Implementation (IoTDI 2016), April 4-8, 2016, Berlin, Germany 
  IEEE International Conference on Cloud Engineering (IC2E 2016), April 4-8, 2016, Berlin, Germany 
  10th IEEE Symposium on Service-Oriented System Engineering (SOSE 2016), March 29 – April 1, Oxford, UK 
   
 IEEE IC2E Series Conferences  
 IEEE International Conference on Cloud Engineering, March 9 – 12, 2015, Tempa, AZ, USA 
  IEEE International Conference on Cloud Engineering, March 10 – 14, 2014, Boston, MA, USA 
  IEEE International Conference on Cloud Engineering, March 25 – 28, 2013, San Francisco, CA, USA 
  IEEE CBI/CEC/EEE series conferences (founded 1998)  
 17th IEEE Conference on Business Informatics (CBI 2015), 13th-16th July, 2015, Liston, Portugal 
  16th IEEE International Conference on Business Informatics (CBI), 2014 
  15th IEEE International Conference on Business Informatics (CBI), 15-18 July, 2013, Vienna, Austria 
  The 14th IEEE International Conference on Business Informatics (CEC), Sept. 9-11, 2012. Hangzhou, China 
  13th IEEE International Conference on Commerce and Enterprise Computing (CEC 2011), Luxembourg, September 5-7, 2011 
  12th IEEE International Conference on Commerce and Enterprise Computing (CEC 2010), Shanghai, China, October 20-22, 2010 
  11th IEEE International Conference on Commerce and Enterprise Computing (CEC 2009) and 6th IEEE Conference on Enterprise Computing, E-Commerce, and E-Services (EEE), Vienna, Austria, July 20-23, 2009 | Business Process Modeling Notation (BPMN 2009) 
  Data Engineering Issues in E-Commerce and Services (DEECS09) 
  Management for Business Processes and Services (M4BPS 2009) 
  Real-time SOA 
  Emails in e-Commerce and Enterprise Context (E3C) 
  Security and Trust in Commerce(STC 2009) 
  10th IEEE International Conference on Commerce and Enterprise Computing (CEC’08) and 5th IEEE International Conference on Enterprise Computing, E-Commerce and E-Services (EEE’ 08), Crystal City, Washington, DC USA, July 21-24, 2008 | Workshop on Data-Centric Service-Oriented Architecture (DC-SOA 2008) 
  Workshop on Semantic Web meets the Deep Web (SWDW’08) 
  The 3rd Web Services Challenge (WS-Challenge) 
  9th IEEE International Conference on Commerce and Enterprise Computing (CEC’07) and 4th IEEE International Conference on Enterprise Computing, E-Commerce and E-Services (EEE’07), Tokyo, Japan, July 23-26, 2007 | Workshop on Web Mining for E-commerce and E-services (WMEE07) 
  Workshop on Global Business Services Delivery Platforms 
  Workshop on NGN (Next Generation Networks) and their impact on E-Commerce and Enterprise Computing (NGN-EC2) 
  8th IEEE International Conference on Commerce and Enterprise Computing (CEC’06) and 3th IEEE International Conference on Enterprise Computing, E-Commerce and E-Services (EEE’06), San Francisco, California, June 26-29, 2006 | The 2nd International Workshop on Data Engineering Issues in E-Commerce and Services (DEECS 2006) 
  The Third IEEE International Workshop on Mobile Commerce and Wireless Services (WMCS’06) 
  2nd International Workshop on Business Service Networks (BSN ’06) 
  2nd International Workshop on Service oriented Solutions for Cooperative Organizations (SoS4CO ’06) 
  7th IEEE Conference on E-Commerce Technology (CEC 2005), Munich, Germany, July 19-22, 2005 | Workshop on Business Transformation: Towards a Theory of Business Agility (BT’05) 
  Workshop on Mobile Commerce and Services (WMCS) 
  Workshop on Service oriented Solutions for Cooperative Organizations 
  2nd IEEE International Conference E-Technology, E-Commerce and E-Service (EEE 2005), Hong Kong, China, March 29-April 1, 2005 | Workshop on Business Services Networks (BSN), March 29, 2005 
  6th IEEE Conference on E-Commerce Technology (CEC 2004), San Diego, California, USA, July 6-9, 2004 
  First IEEE International Conference on e-Technology, e-Commerce and e-Service (EEE 2004), Taipei, March 28-31, 2004 
  5th IEEE Conference on E-Commerce (CEC 2003), Newport Beach, California, USA, June 2003 
  4th International Workshop on Advanced Issues of E-Commerce and Web-based Information Systems (WECWI 02), Newport Beach, California, USA, June 26-28, 2002 
  3rd International Workshop on Advanced Issues of E-Commerce and Web-based Information Systems (WECIS 01), MILPITAS, CA 95035, USA, June 21-22, 2001 
  2nd International Workshop on Advanced issues of E-Commerce and Web-Based Information Systems (WECWIS 00), MILPITAS, CA 95035 June 8-9, 2000 
  First International Workshop on Advanced Issues of E-Commerce and Web-based Information Systems (WECWIS 99), Santa Clara, California, April 8-9, 1999 
  IEEE Workshop on Dependable and Real-Time E-Commerce Systems (DARE 1998) Denvor, Colorado, June 2, 1998, Co-Sponsored by IEEE Computer Society Technical Committee on Real-Time Systems and IBM Institute for Advanced Commerce Held in conjunction with the 4th IEEE Real-Time Technology and Application Symposium 
  IEEE ICEBE series conferences (founded 2004)  
 12th IEEE International Conference on e-Business Engineering (ICEBE 2015), 23-25 October, 2015, Beijing, China 
  IEEE International Conference on e-Business Engineering (ICEBE 2014), Guangzhou, China, 5-7 November 2014 
  IEEE International Conference on e-Business Engineering (ICEBE 2013), Coventry, UK, 11-13 September 2013 
  The 9th IEEE International Conference on e-Business Engineering (ICEBE), Sept. 9-11, 2012. Hangzhou, China 
  8th IEEE International Conference on e-Business Engineering (ICEBE 2011), Beijing, China, October 19-21, 2011 
  7th IEEE International Conference on e-Business Engineering (ICEBE 2010), Shanghai, China, October 20-22, 2010 
  6th IEEE International Conference on e-Business Engineering (ICEBE 2009), Macau, China, October 21-23, 2009 | The 2nd Workshop on Advances in RFID (AIR’09) 
  3rd Workshop on E-Marketplace Integration and Interoperability (EM2I’09) 
  5th Workshop on Service-Oriented Applications, Integration and Collaboration (SOAIC’09) 
  3rd Workshop on Service-Oriented Knowledge Management (SOKM’09) 
  2nd Workshop on Business Intelligence Methodologies and Applications (BIMA’09) 
  2nd Workshop on Data and Knowledge Engineering for E-service and E-business (DKEEE’09) 
  Student Workshop of 2009 IEEE International Conference on e-Business Engineering 
  First Workshop on Applications and Services on Cloud (ASOC’09) 
  5th IEEE International Conference on E-Business Engineering (ICEBE 2008), Xi’An, China, October 22-24, 2008 | Workshop on Advances in RFID (AIR’08) 
  2nd Workshop on E-Marketplace Integration and Interoperability (EM2I’08) 
  4th Workshop on Service-Oriented Applications, Integration and Collaboration (SOAIC’08) 
  2nd Workshop on Service-Oriented Knowledge Management (SOKM’08) 
  Workshop on Business Intelligence Methodologies and Applications (BIMA’08) 
  Workshop on Data and Knowledge Engineering for E-service and E-business (DKEEE’08) 
  4th IEEE International Conference on e-Business Engineering (ICEBE 2007), Hong Kong, China, October 24-26, 2007 | 3rd Workshop on Service-Oriented Applications, Integration and Collaboration (SOAIC 2007) 
  First Workshop on Service-Oriented Knowledge Management (SOKM 2007) 
  Student Workshop: e-Business Technologies for Real-World Problems 
  3rd IEEE International Conference on e-Business Engineering (ICEBE 2006), Shanghai, China, October 24-26, 2006 | Track on 2nd Service-Oriented Applications, Integration and Collaboration (SOAIC-2006) 
  2nd IEEE International Conference on e-Business Engineering (ICEBE 2005), Beijing, China, October 18-20, 2005 
  First IEEE International Conference on e-Commerce Technology for Dynamic E-Busines (CEC 2004 EAST), Beijing, China, September 13-15, 2004 
  IEEE SOCA Series Conferences  
 8th IEEE International Conference on Service Oriented Computing & Applications (SOCA 2015), Rome, Italy, 19th – 21st October, 2015 
  The IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2014), 17-19 Nov, Matsue, Japan 
  The IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013), 16-18 Dec, Hawaii, USA 
  The IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2012), Taipei, Taiwan, December, 2012. 
  IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2011), University of California, Irvine, USA, December 12-14, 2011 
  IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2010), Perth, Australia, December 13-15, 2010 
  IEEE International Conference on Service-Oriented Computing and Applications (SOCA’09), Taipei, December 14-15, 2009 
  IEEE International Conference on Service-Oriented Computing and Applications (SOCA’07), Newport Beach, California, June 19-20, 2007 
  IEEE SOSE Series Conferences (Founded 2005)  
 9th IEEE Symposium on Service-Oriented System Engineering (SOSE 2015), March 30 – April 3, 2015, San Francisco, USA 
  8th International Symposium on Service-Oriented System Engineering (SOSE 2014), Oxford, UK, April 7-10, 2014 
  7th International Symposium on Service-Oriented System Engineering (SOSE 2013), 25 – 28 March, 2013, San Francisco Bay, USA. 
  6th International Symposium on Service-Oriented System Engineering (SOSE 2011), University of California, Irvinie, USA, Dec. 12-14, 2011 
  5th International Symposium on Service-Oriented System Engineering (SOSE 2010), Nanjing, China, June. 4-5, 2010 
  4th International Symposium on Service-Oriented System Engineering (SOSE 2008) (in-cooperation), Jhongli, Dec. 18-19, 2008 
  3rd IEEE International Symposium on Service-Oriented System Engineering (SOSE 2007), Hong Kong, China, Oct 24-26, 2007 
  2nd IEEE International Symposium on Service-Oriented System Engineering (SOSE 2006), Shanghai, China, Oct 25-26, 2006 
  First IEEE International Workshop on Service-Oriented System Engineering (SOSE 2005), Beijing, China, October 20-21, 2005 
  TCBIS Sponsored Conferences & Workshops  
 First Pacific Rim International Workshop on Electronic Commerce (PRIWEC 2006), Tokyo, Japan, March 27-28, 2006 
  International Conference on Next Generation Web Services Practices (NWeSP’05)(in-cooperation), Seoul, Korea, August 23-27, 2005 

 Privacy 
  Security 
  Advertising 
  Site Map 
  Contact 
  Press Room 
  Feedback 
    
 This Site and All Contents (Unless Otherwise Noted) are © 2018, IEEE. All Rights Reserved.   

 Home 
  Conferences 
  Executive Committee 
  Membership 
  Contact 

      Type to search or hit ESC to close    
   
 See all results      

     Call for papers data: 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Call for Papers 
 A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. | Call for Papers | A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors 
 Call for Papers 
 A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. | General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Call for Papers 
 A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. | Call for Papers | A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Call for Papers 
 A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. | Call for Papers | A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors 
 Call for Papers 
 A pdf version of Call for Papers can be downloaded here   
 Service-oriented computing is considered today a key technology for the development of robust and high quality intelligent distributed and embedded applications. Extensive research and development in the past few years has pushed SOA technology into state-of-the-art application areas such as context-aware, cloud-connected, mobile enterprise systems. However, many of the critical components on building reliable, robust, and user-centric sensor-based SOA systems are still open for research. Hence, it is timely to reexamine SOA research opportunities and identify new research challenges for next generation SOA.  
 One of the future SOA applications is large-scale cyber-physical systems (CPSs) that include deep interactions between cyber-sides and physical-sides through massive sensors, actuators, mobile devices, and computing servers connected by heterogeneous networks. The services of large-scale CPSs have challenging requirements such as accurate timeliness, high reliability, and dynamic adaptability. Many of the service components are deployed on resource limited embedded systems and are performance sensitive; others are deployed on cloud servers providing highly parallel services. Thus, SOA may provide effective solutions for managing the ever-increasing complexity while meeting the challenging requirements of CPS services on largely distributed, heterogeneous and dynamic resource environments.  
 The 2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013) will be held in Kauai, Hawaii, with topics of general service oriented computing and also the focused area of SOA for large-scale CPSs. The conference includes three days of parallel tracks program, special-topic workshops/ tutorials, and panel discussion. We invite submissions of high quality papers describing fully developed results or ongoing work on the topics such as:  
   
 Service-oriented architecture, engineering, and applications 
  Large-scale cyber-physical systems 
  Intelligent service composition, management and maintenance 
  Configurable and reconfigurable service middleware 
  Dependable and trustworthy services 
  Streaming and real-time data analytics 
  Mobile service engineering and applications 
  Security and privacy for intelligent service applications 
  Context-aware connected embedded computing 
  Service composition with multi-dimensional QoS 
  Service networks for smart home, smart transportation, and smart infrastructure 
  Sustainability issues on large-scale CPS applications 
   
 Authors are invited to submit original, unpublished research papers that are not being considered in another forum. Manuscripts will be limited to 8 (IEEE style) pages. Please follow the IEEE Computer Society Press Proceedings Author Guidelines to prepare your papers with 8.5'' x 11'', two-column format. The paper formatting instructions are available at http://www.computer.org/portal/web/cscps/formatting. Electronic submission of manuscripts (in PDF) is required through the paper submission system in the SOCA 2013 homepage http://conferences.computer.org/soca. All papers submitted to SOCA 2013 will be peer-reviewed by at least 3 reviewers. Papers that are selected for presentation at SOCA 2013 will appear in the Proceedings of SOCA 2013 and be included in IEEE Xplore and indexed by EI. Each paper accepted for SOCA 2013 requires at least one author to register at the full rate (IEEE member or non-IEEE member). At least one author is required to attend the conference and present the paper. The best papers from the proceedings will be selected for publication in the Springer Journal on Service-Oriented Computing and Applications (SOCA) as well as special issues in international journals to be announced. Furthermore, a Best Paper Award will be presented to the best paper selected from the accepted full papers. 
 © 2012-2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013). All rights reserved. 

  Important dates data 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Important Dates 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Important Dates | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors 
 Important Dates 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Important Dates 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Important Dates | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors | General Information | Home | Organizing Committee | Program Committee | Call for Papers | Workshops | - KiBP Workshop | - KASTLES Workshop | - WESA Workshop | Contact Us | Paper Submission | Important Dates | Paper Submission | Final Paper Submission | Registration | Program | Venue | Keynote/Panel | Program | Travel Information | Accommodation | Sponsors | Important Dates 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Important Dates | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 General Information 
 Home 
 Organizing Committee 
 Program Committee 
 Call for Papers 
 Workshops 
 - KiBP Workshop 
 - KASTLES Workshop 
 - WESA Workshop 
 Contact Us 
 Paper Submission 
 Important Dates 
 Paper Submission 
 Final Paper Submission 
 Registration 
 Program 
 Venue 
 Keynote/Panel 
 Program 
 Travel Information 
 Accommodation 
 Sponsors 
 Important Dates 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 | Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 | Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 | Acceptance Notification | October 5, 2013 | Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 | Conference and Workshop Program | December 16-18, 2013 
 Abstract Submission Due | July 16, 2013 extended to Aug. 5, 2013 
 Paper Submission Due | July 31, 2013 extended to Aug. 10, 2013 
 Acceptance Notification | October 5, 2013 
 Camera Ready Submission | October 15, 2013 extended to Oct. 25, 2013 
 Conference and Workshop Program | December 16-18, 2013 
 © 2012-2013 IEEE International Conference on Service-Oriented Computing and Applications (SOCA 2013). All rights reserved.

16. Conference SODA_0:
Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Conferences & Events 
  SIAM Conferences 
  SODA25 

 In Person   
 SIAM Conferences   
   
 ACM-SIAM Symposium on Discrete Algorithms (SODA25)  
 Reserve Your Room    
   
 Event Details  
 January 12 –  15 , 2025 
  New Orleans, Louisiana, U.S. 
  Astor Crowne Plaza - New Orleans French Quarter 
  Stay Connected  
 Facebook 
  #SIAMDA25 

 In This Section 
  Registration 
  Lodging & Support 
  Program 
  Submissions 
  More 

 Deadlines   
 Early Registration Deadline | December 9, 2024 
  Reserve Now: Hotel Reservation Deadline | December 9, 2024 
  Deadline Passed: Submissions Due | July 5, 2024 

 About the Conference  
 SODA is sponsored by the SIAM Activity Group on Discrete Mathematics  and the ACM Special Interest Group on Algorithms and Computation Theory  .  
    This symposium focuses on research topics related to the design and analysis of efficient algorithms and data structures for discrete problems. The scope includes theoretical analysis, as well as experimental validation, of discrete algorithms, and the mathematical problems related to their development or limitations. The scope also includes aspects of combinatorics and discrete mathematics related to discrete algorithms. Papers that raise important algorithmic problems that can benefit from theoretical investigation and analysis, are encouraged.  
 SODA will be held jointly with:  
  SIAM Symposium on Algorithm Engineering and Experiments (ALENEX)   
  SIAM Symposium on Simplicity in Algorithms (SOSA)   
 Connect to others attending the event on LinkedIn.   

 Included Themes  
 Aspects of combinatorics and discrete mathematics, such as:   
 Combinatorial structures 
  Discrete optimization 
  Graph theory 
  Random structures 
  Core topics in discrete algorithms, such as:   
 Algorithm analysis 
  Data structures 
  Experimental algorithmics 
  Lower bounds 
  Mathematical programming 
  Algorithmic aspects of other areas of computer science, such as:   
 Algorithmic fairness 
  Combinatorial scientific computing 
  Communication networks and the internet 
  Computational geometry and topology 
  Computer systems 
  Cryptography, security and privacy 
  Databases and information retrieval 
  Distributed and parallel computing 
  Game theory and mechanism design 
  Machine learning 
  Quantum computing 
  Scheduling and resource allocation 

 Program Committee Co-chairs  
 Yossi Azar  
 Tel-Aviv University, Israel  

 Debmalya Panigrahi  
 Duke University, U.S.  

 Program Committee  
 Amir Abboud  
 Weizmann Institute of Science, Israel  

 Alexandr Andoni  
 Columbia University, U.S.  

 Soheil Behnezad  
 Northeastern University, U.S.  

 Sayan Bhattacharya  
 University of Warwick, United Kingdom  

 Arnab Bhattacharyya  
 National University of Singapore, Singapore  

 Luca Becchetti  
 University of Rome, Italy  

 Petra Berenbrink  
 University of Hamburg, Germany  

 Niv Buchbinder  
 Tel Aviv University, Israel  

 Harry Buhrman  
 Quantinuum (UK), QuSoft and University of Amsterdam, The Netherlands  

 Sergio Cabello  
 University of Ljubljana, Slovenia  

 Yang Cai  
 Yale University, U.S.  

 Parinya Chalermsook  
 Aalto University, Finland  

 Eshan Chattopadhyay  
 Cornell University, U.S.  

 Chandra Chekuri  
 University of Illinois, Urbana-Champaign, U.S.  

 Keerti Choudhary  
 IIT Delhi, India  

 Maria Chudnovsky  
 Princeton University, U.S.  

 Ilan Cohen  
 Bar-Ilan University, Israel  

 Vincent Cohen-Addad  
 Google Research, Switzerland  

 Andrea Coladangelo  
 University of Washington, Seattle, U.S.  

 Jose Correa  
 University of Chile, Chile  

 Rachel Cummings  
 Columbia University, U.S.  

 Jelena Diakonikolas  
 University of Wisconsin, Madison, U.S.  

 Shahar Dobzinski  
 Weizmann Institute of Science, Israel  

 Anne Driemel  
 University of Bonn, Germany  

 Esther Ezra  
 Bar-Ilan University, Israel  

 Emily Fox  
 University of Texas, Dallas, U.S.  

 Nick Gravin  
 Shanghai University of Finance and Economics, China  

 Kasper Green Larsen  
 Aarhus University, Denmark  

 Anupam Gupta  
 New York University, U.S.  

 Tom Gur  
 University of Cambridge, United Kingdom  

 Sungjin Im  
 University of California, Merced, U.S.  

 Michael Kapralov  
 EPFL, Switzerland  

 Telikepalli Kavitha  
 Tata Institute of Fundamental Research, India  

 Dominik Kempa  
 Stony Brook University, U.S.  

 Arindam Khan  
 Indian Institute of Science, India  

 Samir Khuller  
 Northwestern University, U.S.  

 Ravi Kumar  
 Google Research, U.S.  

 O-joung Kwon  
 Hanyang University, South Korea  

 Bundit Lakhenukit  
 Shanghai University of Finance and Economics, China  

 Hung Le  
 University of Massachusetts, Amherst, U.S.  

 Jian Li  
 Tsinghua University, China  

 Yang Liu  
 Institute for Advanced Studies, U.S.  

 William Kuszmaul  
 Harvard University, U.S.  

 Shachar Lovett  
 University of California, San Diego, U.S.  

 Sepideh Mahabadi  
 Microsoft Research, U.S.  

 Nicole Megow  
 University of Bremen, Germany  

 Raghu Meka  
 University of California, Los Angeles, U.S.  

 Divyarthi Mohan  
 Tel Aviv University, Israel  

 Ankur Moitra  
 Massachusetts Institute of Technology, U.S.  

 Shay Mozes  
 Reichman University, Israel  

 Bento Natura  
 Columbia University, U.S.  

 Neil Olver  
 London School of Economics, United Kingdom  

 Krzysztof Onak  
 Boston University, U.S.  

 Seth Pettie  
 University of Michigan, Ann Arbor, U.S.  

 Michał Pilipczuk  
 University of Warsaw, Poland  

 Max Probst Gutenberg  
 ETH Zurich, Switzerland  

 Rajmohan Rajaraman  
 Northeastern University, U.S.  

 Aviad Rubinstein  
 Aviad Rubinstein,  

 Barna Saha  
 University of California, San Diego, U.S.  

 Laura Sanita  
 Bocconi University, Italy  

 Piotr Sankowski  
 IDEAS NCBR and University of Warsaw, Poland  

 Aravind Srinivasan  
 University of Maryland, College Park, U.S.  

 Vera Traub  
 University of Bonn, Germany  

 Madhur Tulsiani  
 Toyota Technological Institute at Chicago, U.S.  

 Seeun William Umboh  
 The University of Melbourne, Australia  

 Sergei Vassilvitskii  
 Google Research, U.S.  

 Magnus Wahlstrom  
 Royal Holloway, University of London, United Kingdom  

 Kangning Wang  
 Stanford University, U.S.  

 Fan Wei  
 Duke University, U.S.  

 Nicole Wein  
 University of Michigan, Ann Arbor, U.S.  

 Mary Wootters  
 Stanford University, U.S.  

 Steering Committee Chair  
 Piotr Indyk  
 Massachusetts Institute of Technology, U.S.  

 Steering Committee  
 Julia Chuzhoy  
 Toyota Technological Institute at Chicago, U.S.  

 Robert Krauthgamer  
 The Weizmann Institute of Science, Israel  

 Sang-il Oum  
 KAIST, South Korea  

 Blair Sullivan  
 The University of Utah, U.S.  

 Shanghua Teng  
 University of Southern California, U.S.  

 Thank You to Our Sponsors  

 Get Involved  
 Sponsor, exhibit, or check out past content in our video and presentation archive.  

 Ways to Sponsor   
 SIAM invites you to show support of this conference through sponsorship opportunities ranging from support of receptions, audio-video needs, to awards for student travel, and more.   

 Ways to Exhibit   
 Learn about opportunities to become an exhibitor at a SIAM conference.   

 Featured Lectures & Videos   
 View slides, recordings, and video from past SIAM conferences.   

 Become a Member   
 SIAM members get 20-30% off registration for our conferences, plus deep discounts on SIAM books, journals, activity group membership, and more. Start reaping the benefits!   

 Make the Most of Your Experience   
 About SIAM Conferences  
   
 Find all of the information you'll need to prepare for and navigate SIAM conferences, including conference guidelines and how to propose a new conference.  
   
 Explore Conferences 

 Statement on Equity, Diversity, and Inclusion  
 As a professional society, SIAM is committed to empowering equitable, diverse, and inclusive participation in all aspects of our community. SIAM will provide a climate that encourages the open expression and exchange of ideas, that is free from all forms of discrimination, harassment, and retaliation, and that is welcoming and comfortable to all members and to those who participate in its activities.  
 In pursuit of this commitment, SIAM is dedicated to the philosophy of equality of opportunity and treatment for all participants regardless of gender, gender identity or expression, sexual orientation, race, color, national or ethnic origin, religion or religious belief, age, marital status, disabilities, veteran status, and field of expertise.  
 This philosophy extends from SIAM’s governing structures and bodies to its conferences, publications, awards, and to all its organized activities.  
 We expect all members of SIAM and participants in SIAM activities to work towards this commitment to equity, diversity, and inclusion.  
 If you have experienced or observed behavior that is not consistent with the principles expressed above, you are encouraged to report any violation using the SIAM hotline, hosted by the third-party hotline provider, EthicsPoint. The information you provide will be sent to us by EthicsPoint on a totally confidential and anonymous basis if you should choose. You have our guarantee that your comments will be heard. Please submit reports.   
 Read all of SIAM's conference guidelines and policies  , including the Statement on Potentially Offensive Material.  
 Read more about the ACM-SIAM SODA Code of Conduct  .  

 Contact Us  
   
 Questions about SIAM conferences? Get in touch with our staff.  
 Contact SIAM Conferences Staff    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Call for papers data:  Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Publications 
  SIAM Journals 
  SIAM Undergraduate Research Online (SIURO) 

 SIAM Undergraduate Research Online  
 SIAM Undergraduate Research Online  (SIURO) is a web-based publication devoted to undergraduate research in applied and computational mathematics. Access is free and open to the public.  
   
 Read Current Issue  Submit a Paper    
   
 Related Links  
 Sign Up for Email Updates 

 In This Section 
  SIAM Undergraduate Research Online E-Alert 
  Editorial Policy 
  Editorial Board 
  Instructions for Authors 
  More 

 SIURO consists of articles written by undergraduate students in applied and computational mathematics, offering an opportunity for students to publish research they have completed as part of their undergraduate education and providing undergraduates incentives for conducting research.  
 The publication represents a wide range of applied topics, including but not limited to analysis, discrete mathematics, statistics, operations research, optimization, dynamical systems, modeling, and computation. Typical areas of application include but are not limited to physical, life, financial, and management sciences and engineering.  
 Each paper must be submitted with a letter from a project advisor. Faculty advisers or sponsors are listed as "project advisor" on the published paper.  
 SIURO provides an opportunity for undergraduate students to share their results and experience a full paper review process. High school students may also submit their work.  
 The project advisor may be a faculty member at the student’s institution or at an institution the student is visiting, or someone associated with a non-academic organization or government lab who supervised the research. 
  The project advisor’s letter must document the fact that the research was done while the student was an undergraduate and list the student’s graduation date or anticipated graduation date. 
  Project advisors will be listed separately from the authors with a “project advisor” byline. 

 Announcements   
 Authors: Prepare your papers using LaTex 2e macros to aid editor and referee review 

 From the Current Volume  
 Check out the latest volume and dive into advanced research and findings by undergraduate students.  
 See more   
   
 Volume 17  Accurately Classifying Out-Of-Distribution Data in Facial Recognition   
 November 13, 2024    
 By  Gianluca Barone (Corresponding author – Rowan University) 
  Aashrit Cunchala (University of Pittsburgh) 
  Rudy Nunez (Emory University) 

 Volume 17  Optimizing Energy Functional in Wave and Heat Equations with Initial Conditions in a Class of Rearrangements   
 October 30, 2024    
 By  Renjing Wang (Corresponding author – Xi'an Jiaotong-Liverpool University, China) 

 Volume 17  Travelling Waves of the Diffusive Streeter-Phelps Equations with Braun-Berthouex BOD Decay   
 October 24, 2024    
 By  Alexandra Lawryshyn (Corresponding author – University of Guelph, Ontario, Canada) 

 Browse Articles by Volume  
   
 Volume 17   
 2024   
   
 Volume 16   
 2023   
   
 Volume 15   
 2022   
   
 Volume 14   
 2021   
   
 Volume 13   
 2020   
   
 Volume 12   
 2019   
   
 Volume 11   
 2018   
   
 Volume 10   
 2017   
   
 Volume 9   
 2016   
   
 Volume 8   
 2015   
   
 Volume 7   
 2014   
   
 Volume 6   
 2013   
   
 Volume 5   
 2012   
   
 Volume 4   
 2011   
   
 Volume 3   
 2010   
   
 Volume 2, Issue 2   
 Fall 2009   
   
 Volume 2, Issue 1   
 Spring 2009   
   
 Volume 1, Issue 2   
 Fall 2008   
   
 Volume 1, Issue 1   
 Summer 2008   

 Show more    

 Publish with SIURO   
 Become an Author  
   
 SIURO offers undergraduate and high school students the early opportunity to publish their research while becoming part of the scientific community.  
   
 Learn More 
    
 SIURO is one of the best publications for undergraduate research in applied and computational mathematics. Beyond getting their results out into the world, when students publish their papers in SIURO, they have the edifying experience of taking their original work through the peer-review process.  
   Joanna Wares  University of Richmond     

 Get Involved with SIURO  
 We welcome submissions from undergraduate and high school students in applied and computational mathematics.  

 Editorial Information   
 Get the scoop on our reviewer guidelines, editorial policy, and more.   

 Instructions for Authors   
 Interested in submitting a paper to SIURO?   

 Contact Us  
   
 Questions about SIURO? Get in touch with our staff.  
 Contact SIURO Staff    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Important dates data

17. Conference SoCS_1:
Search this site   

 Skip to main content     

 Skip to navigation     

 SoCS 2025   Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 
   
 SoCS 2025     
 Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 
  More | Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 

 SoCS 2025   
 The 18th International Symposium on Combinatorial Search   
 August 12-15, 2025   
 University of Glasgow, Scotland, United Kingdom   
 co-located with CP and SAT   
  
  Photo credits: Glasgow Life     

 The 18th International Symposium on Combinatorial Search (SoCS 2025)  will be hosted at the University of Glasgow in Scotland, United Kingdom. The conference will be co-located with   
 The 31st International Conference on Principles and Practice of Constraint Programming (  CP 2025   ) and 
  The 18th International Conference on Theory and Applications of Satisfiability Testing  (SAT 2025)   . 
  The SoCS conference, together with its doctoral program, will be organized on August 12-15, 2025.  The joint conference will be organized on August 10-15, 2025.   
  
  Heuristic search and combinatorial optimization  are very active research areas in artificial intelligence, robotics, planning, discrete optimization, and other areas of computer science and operations research. The International Symposium on Combinatorial Search (SoCS) is meant to bring researchers in such areas together to exchange their ideas and cross-fertilize the field.   
 SoCS serves researchers and submissions in all fields that use combinatorial search, including artificial intelligence, planning, robotics, constraint programming, meta-reasoning, operations research, navigation, and bioinformatics. We especially invite submissions presenting real-world applications of heuristic search.   

 SoCS 2024 is kindly supported by:   

 If you want your logo to appear here, please contact  conference chairs   .   

 Google Sites   

 Report abuse   

 Page details   

 Page updated     
   
 Google Sites   
   
 Report abuse   

  Call for papers data:Important dates data  

   Search this site   

 Skip to main content     

 Skip to navigation     

 SoCS 2025   Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 
   
 SoCS 2025     
 Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 
  More | Home 
  Important Dates 
  Venue 
  Doctoral Consortium 
  Organizers 

 Important Dates   

  Photo credits: Glasgow Life     

  Submission deadline:  March, 2025   
 SoCS 2025 conference:  12-15, 2025   
 Joint conference  :  August  10  -15, 2025   

 Google Sites   

 Report abuse   

 Page details   

 Page updated     
   
 Google Sites   
   
 Report abuse

18. Conference SOCA_2:
CISOSE 2025   Mon 21 - Thu 24 July 2025 Tucson, Arizona, United States    

 Toggle navigation        
 Attending | Venue: University of Arizona 
  Equity, Diversity and Inclusion Plan: Equity, Diversity and Inclusion Plan 
  Sponsorship Opportunities: Sponsorship Opportunities 
  Traveling to Tucson 
  Tracks | CISOSE 2025 
  IEEE AI TEST2025 
  IEEE BigDataService 2025 
  IEEE DAPPS 2025 
  IEEE FITYR 2024 
  IEEE FTS 2025 
  IEEE IMC 2025 
  IEEE JCC 2025 
  IEEE SOSE 2025 
  Papers 
  Organization | CISOSE 2025 Committees 
  Organizing Committee 
  Track Committees 
  IEEE BigDataService 2025 | General Chairs 
  Publicity Chairs 
  Program Committee Chairs 
  Publication Chairs 
  IEEE DAPPS 2025 | Organizing Commitee 
  Program Committee 
  IEEE SOSE 2025 
  Papers 
  Contributors 
  People Index 
  Search 
   Series 
  Sign in 
  Sign up 

  CISOSE 2025  ( series  ) /  IEEE SOSE 2025 CISOSE 2025   
   
 About 
  Starting in 2005, SOSE is a pioneering IEEE-sponsored international conference devoted to research in engineering service-oriented systems. It covers all aspects of Service-Oriented Engineering, from architectures, techniques, tools, and languages to methodologies. Continuing the tradition of the last sixteen editions of SOSE Symposia, the 18th SOSE intends to provide a forum for researchers and practitioners to exchange the latest observations, insights, achievements, and visions in Service-Oriented System Engineering.  
 This year’s conference is scheduled to take place in Tucson, Arizona, USA, from 21-24 July 2025. SOSE 2025 is part of the IEEE International Congress On Intelligent And Service-Oriented Systems Engineering, offering a broad spectrum of international events, sharing renowned keynotes, and fostering exchange among researchers and practitioners (see common homepage for all colocated events). SOSE invites original submissions in all the areas of system engineering and software engineering methods, techniques, tools, applications, and experiments for software services. For details, important dates and accepted paper categories, please see the Call for Papers Pages.  
 Submission Deadline: April 1st, 2025 
  Top papers will be invited to extended version manuscripts at Cluster Computing.  
 https://link.springer.com/collections/dihehbcebj 

 Questions? Use the CISOSE IEEE SOSE contact form  .    
    
 Important Dates   AoE (UTC-12h)     

 Tue 1 Apr 2025   
  Paper Submission Deadline 

 IEEE SOSE    
   
 Jacopo Soldani Track Chair    
 University of Pisa, Italy   
 Italy 
  Guido Wirtz Track Chair    
 University of Bamberg   
 Germany 

 x  Wed 4 Dec 13:50    

  CISOSE 2025   
  contact form    
  using conf.researchr.org  ( v1.67.1  )  
   Support page    
     
 Tracks  
 IEEE AI TEST2025   
  IEEE BigDataService 2025   
  IEEE DAPPS 2025   
  IEEE FITYR 2024   
  IEEE FTS 2025   
  IEEE IMC 2025   
  IEEE JCC 2025   
  IEEE SOSE 2025   
  Papers    

 Attending  
 Venue: University of Arizona   
  Equity, Diversity and Inclusion Plan: Equity, Diversity and Inclusion Plan   
  Sponsorship Opportunities: Sponsorship Opportunities   
  Traveling to Tucson    
 Sign Up    

  Call for papers data:CISOSE 2025   Mon 21 - Thu 24 July 2025 Tucson, Arizona, United States    

 Toggle navigation        
 Attending | Venue: University of Arizona 
  Equity, Diversity and Inclusion Plan: Equity, Diversity and Inclusion Plan 
  Sponsorship Opportunities: Sponsorship Opportunities 
  Traveling to Tucson 
  Tracks | CISOSE 2025 
  IEEE AI TEST2025 
  IEEE BigDataService 2025 
  IEEE DAPPS 2025 
  IEEE FITYR 2024 
  IEEE FTS 2025 
  IEEE IMC 2025 
  IEEE JCC 2025 
  IEEE SOSE 2025 
  Papers 
  Organization | CISOSE 2025 Committees 
  Organizing Committee 
  Track Committees 
  IEEE BigDataService 2025 | General Chairs 
  Publicity Chairs 
  Program Committee Chairs 
  Publication Chairs 
  IEEE DAPPS 2025 | Organizing Commitee 
  Program Committee 
  IEEE SOSE 2025 
  Papers 
  Contributors 
  People Index 
  Search 
   Series 
  Sign in 
  Sign up 

  CISOSE 2025  ( series  ) /  Papers CISOSE 2025   
   
 About 
  Call for Papers 
  This page will soon grow in content and contain information about the scope of this research track.  
   
 Call for Papers  
  
 This is a placeholder text.  
 You can expect more information about the call for papers soon.  
 This page will have information about the submission and selection process and list the important dates.  

 Program Committee    
   
 No members yet 

 x  Wed 4 Dec 13:50    

  CISOSE 2025   
  contact form    
  using conf.researchr.org  ( v1.67.1  )  
   Support page    
     
 Tracks  
 IEEE AI TEST2025   
  IEEE BigDataService 2025   
  IEEE DAPPS 2025   
  IEEE FITYR 2024   
  IEEE FTS 2025   
  IEEE IMC 2025   
  IEEE JCC 2025   
  IEEE SOSE 2025   
  Papers    

 Attending  
 Venue: University of Arizona   
  Equity, Diversity and Inclusion Plan: Equity, Diversity and Inclusion Plan   
  Sponsorship Opportunities: Sponsorship Opportunities   
  Traveling to Tucson    
 Sign Up    

  Important dates data

19. Conference SoCG_3:
Main List  | New Announcement  | Search  | About    

 41st International Symposium on Computational Geometry (SoCG 2025)   
 co.combinatorics    
 Google calendar  iCalendar .ics    
 Start Date  2025-06-23  End Date  2025-06-27  Institution   City  Kanazawa  Country  Japan  Meeting Type  conference  Homepage  https://socg25.github.io/socg.html  Contact Name   Created  9/23/24, 1:09 AM  Modified  9/23/24, 1:09 AM   Description  
 none   
 Problems?  
 If you notice a problem with this entry, please contact the curators  by email.  
   
 https://mathmeetings.net  Trouble? Comments? Contact Niles Johnson    

  Call for papers data:Important dates data        
  Skip to main content  Solutions  For Individuals   

 For Business  Overview   
   
  Small Business   
   
  New Business   
   
  Startups   

 For Enterprise  Overview   
   
  Frontline Workers   
   
  Work Safer   

 Developers  Education  Nonprofits    
   
  Products     
 Gmail   

 Calendar   

 Drive   

 Meet   

 Docs   

 Sheets   

 Slides   

 Chat   

 Vids   

 Admin console  Add-ons    
   
  Industries  Industries  Healthcare and Life Sciences   
   
  Retail   
   
  Manufacturing   
   
  Government and Public Sector   
   
  Professional Services   
   
  Technology   

 Departments  Sales   
   
  Marketing   
   
  Human Resources   

 Security    
   
  AI    
 Pricing    
 Resources  Discover  Security and trust   
   
  Blog   
   
  Customer stories   

 Learn  FAQs   
   
  Training and certification   
   
  Live and on-demand events   
   
  Video conferencing   

 Connect  Partners   
   
  Marketplace   
   
  Integrations   
   
  Refer Google Workspace   

 Support for admins  Support for users    

 Skip to main content  Solutions  Solutions   
   
 For Individuals   
 Overview   
 Google Workspace Individual   

 For Business   
 Overview   
 Google Workspace Business   
   
  Small Business   
 Small business productivity tools   
   
  New Business   
 Tools for new businesses   
   
  Startups   
 Startup productivity tools   

 For Enterprise   
 Overview   
 Google Workspace Enterprise   
   
  Frontline Workers   
 Google Workspace for the frontline   
   
  Work Safer   
 Protect organizations from cyberattacks   

 Developers  Education  Nonprofits    
 close     
   Products  Products   
 See all apps     

 Gmail   
 Custom business email   

 Calendar   
 Shared calendars   

 Drive   
 Cloud storage   

 Meet   
 Video and voice conferencing   

 Docs   
 Word processing   

 Sheets   
 Spreadsheets   

 Slides   
 Presentation builder   

 Chat   
 Messaging for teams   

 Vids   
 Video editor   

 Admin console  Add-ons    
 close     
   Industries  Industries   
   
 Industries   
 Healthcare and Life Sciences   
   
  Retail   
   
  Manufacturing   
   
  Government and Public Sector   
   
  Professional Services   
   
  Technology   

 Departments   
 Sales   
   
  Marketing   
   
  Human Resources   

 Security    
 close     
   AI    
 Pricing    
 Resources  Resources   
 See more     
   
 Discover   
 Security and trust   
 Keep your data safe and compliant   
   
  Blog   
 Latest product news and stories   
   
  Customer stories   
 Case studies and videos   

 Learn   
 FAQs   
 Answers to commonly asked questions   
   
  Training and certification   
 On-demand or classroom training   
   
  Live and on-demand events   
 Explore events and webinars   
   
  Video conferencing   
 Learn about Google Meet   

 Connect   
 Partners   
 Find the right partner   
   
  Marketplace   
 Browse and install apps   
   
  Integrations   
 Partner and custom integrations   
   
  Refer Google Workspace   
 Earn rewards with our Referral Program   

 Support for admins  Support for users    
 close     
     
 Try Calendar for work    
 For small business   For enterprise    Sign in   Try Calendar for work    
 For small business   For enterprise    Sign in     
   
 Solutions  Solutions   
   
 For Individuals   
 Overview   
 Google Workspace Individual   

 For Business   
 Overview   
 Google Workspace Business   
   
  Small Business   
 Small business productivity tools   
   
  New Business   
 Tools for new businesses   
   
  Startups   
 Startup productivity tools   

 For Enterprise   
 Overview   
 Google Workspace Enterprise   
   
  Frontline Workers   
 Google Workspace for the frontline   
   
  Work Safer   
 Protect organizations from cyberattacks   

 Developers  Education  Nonprofits    
 close     
   Products  Products   
 See all apps     

 Gmail   
 Custom business email   

 Calendar   
 Shared calendars   

 Drive   
 Cloud storage   

 Meet   
 Video and voice conferencing   

 Docs   
 Word processing   

 Sheets   
 Spreadsheets   

 Slides   
 Presentation builder   

 Chat   
 Messaging for teams   

 Vids   
 Video editor   

 Admin console  Add-ons    
 close     
   Industries  Industries   
   
 Industries   
 Healthcare and Life Sciences   
   
  Retail   
   
  Manufacturing   
   
  Government and Public Sector   
   
  Professional Services   
   
  Technology   

 Departments   
 Sales   
   
  Marketing   
   
  Human Resources   

 Security    
 close     
   AI    
 Pricing    
 Resources  Resources   
 See more     
   
 Discover   
 Security and trust   
 Keep your data safe and compliant   
   
  Blog   
 Latest product news and stories   
   
  Customer stories   
 Case studies and videos   

 Learn   
 FAQs   
 Answers to commonly asked questions   
   
  Training and certification   
 On-demand or classroom training   
   
  Live and on-demand events   
 Explore events and webinars   
   
  Video conferencing   
 Learn about Google Meet   

 Connect   
 Partners   
 Find the right partner   
   
  Marketplace   
 Browse and install apps   
   
  Integrations   
 Partner and custom integrations   
   
  Refer Google Workspace   
 Earn rewards with our Referral Program   

 Support for admins  Support for users    
 close     

 Sign in   Try Calendar for work    
 For small business   For enterprise    Sign in   Try Calendar for work    
 For small business   For enterprise      

   Shareable Online Calendar  
   
 Spend less time planning and more time doing with a shareable calendar that works across Google Workspace.  
 Sign in  Try Calendar for work   
   
 For small business   For enterprise      

 Your plans, at your fingertips  
   
 Google Calendar brings all of your calendars together in one place, so you can manage work, personal life, and everything in between.  

 Tackle your to-dos  

   Add a task  
 Add your task from right in Google Calendar, Gmail, or the Google Tasks app.  

   Set a due date  
 Pick the day or time you’ll want to complete the task by.  

   Check it off  
 Mark your tasks as complete to keep track of what you've accomplished.  

   Add a task  
 Add your task from right in Google Calendar, Gmail, or the Google Tasks app.  

   Set a due date  
 Pick the day or time you’ll want to complete the task by.  

   Check it off  
 Mark your tasks as complete to keep track of what you've accomplished.  

 A smarter way to schedule  
   
 Save time scheduling meetings by layering multiple calendars in a single view. Plus, keep everyone in the loop with shared calendars.  
   Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  
   
   Teams and organizations can easily schedule meetings and book rooms.  

 Stay on top of your plans  
   
 When you get an email about an event, like a concert, flight, or reservation, Google Calendar automatically adds it to your schedule.  

 Find the time, every day  

   Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 See how you spend your time  
   
 Time Insights analyzes your schedule to show how you spend your time, and who you’re spending it with.  

 Make time for others  
   
 Appointment Schedules  allow you to share your availability via a booking page, so external stakeholders, clients, and partners can book time with you.  

 Simplify your day  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 RSVP options  
 Respond to meeting invitations with a location-specific RSVP.  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 Working location  
 Let your colleagues know where you'll be working from.  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 Working hours  
 Set and share your daily working routine.  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 RSVP options  
 Respond to meeting invitations with a location-specific RSVP.  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 Working location  
 Let your colleagues know where you'll be working from.  

     Premium feature    
 This feature is available on Google Workspace Business  and Enterprise  plans.  

 Working hours  
 Set and share your daily working routine.  

 Curious about Google Calendar?  
 Take a look at our FAQs to learn more.  

 Yes. Calendar migration options are available for many types of calendars, including both Microsoft® and IBM®. For more information on the tools available for data migrations into Google Workspace, see Migrate your organization’s data to Google Workspace  . For information on allowing Microsoft Exchange and Google Calendar to work together, examine the Calendar Interop  tool. For additional information about syncing Google Calendar and IBM Notes, see Options when migrating from IBM Notes  . 
  We focus on keeping your information secure in Google Calendar. To help you create and view your calendar entries, they’re stored in our world-class data centers. Your Google Account comes with built-in security designed to detect and block threats like spam, phishing and malware. Plus, you can always control your privacy settings in your Google Account  . 
  Yes! Anyone with a personal Google account can create one booking page that allows others to book time with you. Workspace subscribers get access to premium features including the ability to create an unlimited number of booking pages, collect payment through Stripe, verify booker emails, send email reminders, and check multiple calendar for availability. 
  Yes. You can create a calendar that's accessible to everyone in your organization (or a subset of users). For example, you might want a group calendar  for events like team holidays and regular meetings. 
  If you have a Google Account through your work, school, or other group, you can add meeting rooms  and other resources (like projectors) to your event. You can add a location to any event by clicking “location” when creating the event. 
     
 Need more help?  
 Browse tips and step-by-step guides made for both new users and power users.  
 Help center    
   
 Get live support  
 Get access to a team of Google experts who can answer your Workspace questions and guide you to a solution.  
 Get support    

 Show the world how it's done.  
 Sign in  Try Calendar for work   
   
 For small business   For enterprise      

 Sign up for the Google Workspace newsletter   
                         Email     
 Country  Afghanistan  Albania  American Samoa  Andorra  Anguilla  Antarctica  Antigua and Barbuda  Argentina  Armenia  Aruba  Australia  Austria  Azerbaijan  Bahamas  Bahrain  Bangladesh  Barbados  Belarus  Belgium  Belize  Benin  Bermuda  Bhutan  Bolivia  Bosnia and Herzegovina  Botswana  Bouvet Island  Brazil  British Indian Ocean Territory  British Virgin Islands  Brunei  Bulgaria  Burkina Faso  Burundi  Cambodia  Cameroon  Canada  Cape Verde  Cayman Islands  Central African Republic  Chad  Chile  China  Christmas Island  Cocos [Keeling] Islands  Colombia  Comoros  Congo [DRC]  Congo [Republic]  Cook Islands  Costa Rica  Croatia  Cyprus  Czech Republic  Côte d’Ivoire  Denmark  Djibouti  Dominica  Dominican Republic  Ecuador  Egypt  El Salvador  Equatorial Guinea  Eritrea  Estonia  Ethiopia  Falkland Islands [Islas Malvinas]  Faroe Islands  Fiji  Finland  France  French Guiana  French Polynesia  French Southern Territories  Gabon  Gambia  Georgia  Germany  Ghana  Gibraltar  Greece  Greenland  Grenada  Guadeloupe  Guam  Guatemala  Guinea  Guinea-Bissau  Guyana  Haiti  Heard Island and McDonald Islands  Honduras  Hong Kong  Hungary  Iceland  India  Indonesia  Iraq  Ireland  Israel  Italy  Jamaica  Japan  Jordan  Kazakhstan  Kenya  Kiribati  Kuwait  Kyrgyzstan  Laos  Latvia  Lebanon  Lesotho  Liberia  Libya  Liechtenstein  Lithuania  Luxembourg  Macau  Macedonia [FYROM]  Madagascar  Malawi  Malaysia  Maldives  Mali  Malta  Marshall Islands  Martinique  Mauritania  Mauritius  Mayotte  Mexico  Micronesia  Moldova  Monaco  Mongolia  Montserrat  Morocco  Mozambique  Namibia  Nauru  Nepal  Netherlands  Netherlands Antilles  New Caledonia  New Zealand  Nicaragua  Niger  Nigeria  Niue  Norfolk Island  Northern Mariana Islands  Norway  Oman  Pakistan  Palau  Palestine  Panama  Papua New Guinea  Paraguay  Peru  Philippines  Pitcairn Islands  Poland  Portugal  Puerto Rico  Qatar  Romania  Russia  Rwanda  Réunion  Saint Helena  Saint Kitts and Nevis  Saint Lucia  Saint Pierre and Miquelon  Saint Vincent and the Grenadines  Samoa  San Marino  Saudi Arabia  Senegal  Seychelles  Sierra Leone  Singapore  Slovakia  Slovenia  Solomon Islands  Somalia  South Africa  South Georgia and the South Sandwich Islands  South Korea  Spain  Sri Lanka  Suriname  Svalbard and Jan Mayen  Swaziland  Sweden  Switzerland  São Tomé and Príncipe  Taiwan  Tajikistan  Tanzania  Thailand  Timor-Leste  Togo  Tokelau  Tonga  Trinidad and Tobago  Tunisia  Turkey  Turkmenistan  Turks and Caicos Islands  Tuvalu  U.S. Outlying Islands  U.S. Virgin Islands  Uganda  Ukraine  United Arab Emirates  United Kingdom  United States  Uruguay  Uzbekistan  Vanuatu  Vatican City  Venezuela  Vietnam  Wallis and Futuna  Western Sahara  Yemen  Zambia  Zimbabwe     
   
  Also sign me up for Google Cloud emails with news, product updates, event information, special offers, and more. (Optional and you can unsubscribe at a later time).   
    
 I understand my personal data will be processed in accordance with Google’s Privacy Policy  .   
   
 Sign up     

 Follow our Blog    

 Included applications  Gmail     
 Meet     
 Chat     
 Calendar     
 Drive     
 Docs     
 Sheets     
 Slides     
 Forms     
 Sites     
 Keep     
 Apps Script     
   
  Security and management  Admin     
 Endpoint     
 Vault     
 Work Insights     
   
  Solutions  New Business     
 Small Business     
 Enterprise     
 Retail     
 Manufacturing     
 Professional Services     
 Technology     
 Healthcare     
 Government     
 Education     
 Nonprofits     
 Artificial Intelligence     
   
  Pricing  Compare pricing plans     
   
  Add-ons  Gemini for Workspace     
 Meet hardware     
 Google Voice     
 AppSheet     
   
  Resources  Working remotely     
 Security     
 Customer Stories     
 FAQs     
 Partners     
 Marketplace     
 Integrations     
 Training & Certification     
 Refer Google Workspace     
   
  Learning and support  Admin Help     
 Setup and Deployment Center     
 Learning Center for Users     
 Forums for Admins     
 Google Workspace Dashboard     
 What's New in Google Workspace     
 Find a Google Workspace Partner     
 Join the community of IT Admins     
 Press     
   
  More from Google  Google Cloud     
 Google Domains     
 Chrome Enterprise     
 Google Business Solutions     
 Google Ads     
 Business Messages     
 Join User Studies     

 Included applications | Gmail 
  Meet 
  Chat 
  Calendar 
  Drive 
  Docs 
  Sheets 
  Slides 
  Forms 
  Sites 
  Keep 
  Apps Script 
  Security and management | Admin 
  Endpoint 
  Vault 
  Work Insights 
  Solutions | New Business 
  Small Business 
  Enterprise 
  Retail 
  Manufacturing 
  Professional Services 
  Technology 
  Healthcare 
  Government 
  Education 
  Nonprofits 
  Artificial Intelligence 
  Pricing | Compare pricing plans 
  Add-ons | Gemini for Workspace 
  Meet hardware 
  Google Voice 
  AppSheet 
  Resources | Working remotely 
  Security 
  Customer Stories 
  FAQs 
  Partners 
  Marketplace 
  Integrations 
  Training & Certification 
  Refer Google Workspace 
  Learning and support | Admin Help 
  Setup and Deployment Center 
  Learning Center for Users 
  Forums for Admins 
  Google Workspace Dashboard 
  What's New in Google Workspace 
  Find a Google Workspace Partner 
  Join the community of IT Admins 
  Press 
  More from Google | Google Cloud 
  Google Domains 
  Chrome Enterprise 
  Google Business Solutions 
  Google Ads 
  Business Messages 
  Join User Studies 

 About Google 
  Google Products 
  Privacy 
  Terms 
  Manage cookies 
   English   
 Change Language   

 Bahasa Indonesia  Čeština  Dansk  Deutsch  Deutsch – Schweiz  English  English – Australia  English – Canada  English – India  English – Indonesia  English – Ireland  English – Malaysia  English – New Zealand  English – Philippines  English – Singapore  English – South Africa  English – United Kingdom  Español  Español (Latinoamérica)  Español (Latinoamérica) – Argentina  Español (Latinoamérica) – Estados Unidos  Español (Latinoamérica) – México  Français  Français – Canada  Français – Suisse  Magyar  Nederlands  Norsk  Polski  Português (Brasil)  Português (Portugal)  Suomi  Svenska  Tiếng Việt  Türkçe  Русский  Українська  עברית  العربية  العربية – مصر  ไทย  한국어  中文 (香港)  中文（简体中文）  中文（繁體中文）  日本語

20. Conference SODA_1:
Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Conferences & Events 
  SIAM Conferences 
  SODA25 
  Submissions 

 ACM-SIAM Symposium on Discrete Algorithms (SODA25)   
 Submissions  
   
 Related Links  
 SODA25 Home 
  Registration 
  Lodging & Support 
  Program 

 Deadlines   
 Early Registration Deadline | December 9, 2024 
  Reserve Now: Hotel Reservation Deadline | December 9, 2024 
  Deadline Passed: Submissions | July 5, 2024 

 Important Submission Information  
 Submissions are due by 11:59 p.m. on July 5, 2024, anywhere on earth. Submissions received after this time will not be considered. All submissions must be in PDF format and submitted electronically.  
 There is a single submission deadline for both registering and submitting a paper; there is not a separate abstract deadline.   
 Submissions authored by program committee members (with the exception of the PC chair and vice chair) are allowed. Utmost care will be taken to avoid COIs with PC submissions, ensuring that such submissions receive no unfair advantage, and that the reviews and the discussion remain confidential from the authors. PC submissions are not eligible for the best paper award.  
 Anonymous Submissions   
 The conference will employ a fairly lightweight double-blind reviewing process. Submissions should not reveal the identity of the authors in any way. In particular, authors’ names, affiliations, and email addresses should not appear at the beginning or in the body of the submission. Authors should not include obvious references that reveal their own identity, and should ensure that any references to their own related work are in the third person (e.g., not “We build on our previous work…” but rather “We build on the work of…”).  
 The purpose of this double-blind process is to help PC members and external reviewers come to an initial judgment about the paper without bias, and not to make it impossible for them to discover who the authors are if they were to try. Nothing should be done in the name of anonymity that weakens the submission or makes the job of reviewing the paper more difficult. In particular, important references should not be omitted or anonymized. In addition, authors should feel free to disseminate their ideas or draft versions of their paper as they normally would. For example, authors may post drafts of their papers on the web, submit them to arXiv, and give talks on their research ideas.  
 We note that a similar policy has recently been incorporated in several other major venues in TCS.  
 Rebuttal Phase  
 Authors will have an opportunity to respond to initial reviews during a rebuttal phase. The initial reviews will be released to authors by September 6, and author-responses are due on September 10. Further instructions will be sent to the authors at that time.  

 General Information  
  
 Acceptance Notification | The Program Committee will distribute acceptance notices and final paper submission instructions to authors of accepted papers by early October 2024. These instructions must be followed to ensure inclusion in the conference proceedings.  
 SIAM will distribute a follow-up notice and post a list of accepted papers in October 2024. 
  Speaker Cancellation | The Organizing Committee expects every speaker in a scheduled presentation to register and attend.  
 If it becomes necessary for a speaker to cancel a presentation, he or she should try to find an alternate presenter immediately, preferably a co-author. See SIAM Policy on Substitute Speakers and Remote Presentations  . Contact SIAM at [email protected]   immediately with any change to a scheduled presentation.  
 A “no-show” or cancelled presentation can cause serious inconvenience to the attendees and organizers. The committee thanks all speakers in advance for their compliance to this request. 
  Proceedings | The proceedings will be posted online in early January 2025. 

 Submission Instructions  
 Submission Link  
 Authors are required to submit their papers electronically, in PDF format (without security restrictions on copying or printing).  
 The submission server is available at https://soda25.hotcrp.com  .   
 For questions related to SODA submissions, contact the PC Chairs Yossi Azar and Debmalya Panigrahi at [email protected]   .  
 Paper Selection  
 Selection of papers will be based on the extent to which the results and the presentation yield new insights for the design, use, or analysis of efficient algorithms. We encourage submissions from researchers in the discrete mathematics, and experimental and applied algorithms communities.  
 Submission Format  
 Submissions should start with a title page consisting of the title of the paper, and an abstract of 1-2 paragraphs summarizing the paper's contributions. There is no page limit and authors are encouraged to use the "full version" of their paper as the submission. The submission should contain within the initial ten pages following the title page a clear presentation of the merits of the paper, including a discussion of the paper's importance within the context of prior work and a description of the key technical and conceptual ideas used to achieve its main claims. The submission should be addressed to a broad spectrum of theoretical computer science and discrete mathematics researchers. Proofs must be provided which can enable the main mathematical claims of the paper to be fully verified. Although there is no bound on the length of a submission, material other than the abstract, references, and the first ten pages will be read at the committee's discretion. Authors are encouraged to put the references at the very end of the submission.  
 The submission should be typeset using 11-point or larger fonts, in a single-column, single-space (between lines) format with ample spacing throughout and 1-inch margins all around, on letter-size (8 ½ x 11 inch) paper.  
 A submission that deviates from these guidelines risks summary rejection without consideration of its merits. All submissions will be treated as confidential, and will only be disclosed to the committee and selected subreviewers, although the program committee may also interact with program chairs of other (past or future) conferences to learn about closely related submissions.  
 Papers eligible for the Best Student Paper award should indicate their eligibility at the time of submission. There is a box provided for this purpose on the submission server. Note that any paper whose authors are all full-time students at the time of submission is eligible for the award. Visit the Special Events page  for details.  
 The Program Committee will distribute acceptance notices and final paper submission instructions to authors of accepted papers by early October 2024. These instructions must be followed to ensure inclusion in the conference proceedings.  
 SIAM will distribute a follow-up notice and post a list of accepted papers in October 2024.  
 Simultaneous Submissions  
 Results previously published in another conference proceedings or journal (or scheduled for publication prior to SODA) will not be accepted at SODA. Simultaneous submissions of the results to another conference with a published proceedings is not allowed. At the time that the author signs SODA's copyright transfer agreement, the author must affirm that no copyright transfer agreement permitting the publication of a similar paper in a journal or elsewhere has been signed.  
 The authors should consult the PC chair in the case of any doubt regarding this policy.  
 Paper Awards  
 Visit the  Special Events  page for details.   

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Call for papers data:  Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Publications 
  SIAM Journals 
  SIAM Undergraduate Research Online (SIURO) 

 SIAM Undergraduate Research Online  
 SIAM Undergraduate Research Online  (SIURO) is a web-based publication devoted to undergraduate research in applied and computational mathematics. Access is free and open to the public.  
   
 Read Current Issue  Submit a Paper    
   
 Related Links  
 Sign Up for Email Updates 

 In This Section 
  SIAM Undergraduate Research Online E-Alert 
  Editorial Policy 
  Editorial Board 
  Instructions for Authors 
  More 

 SIURO consists of articles written by undergraduate students in applied and computational mathematics, offering an opportunity for students to publish research they have completed as part of their undergraduate education and providing undergraduates incentives for conducting research.  
 The publication represents a wide range of applied topics, including but not limited to analysis, discrete mathematics, statistics, operations research, optimization, dynamical systems, modeling, and computation. Typical areas of application include but are not limited to physical, life, financial, and management sciences and engineering.  
 Each paper must be submitted with a letter from a project advisor. Faculty advisers or sponsors are listed as "project advisor" on the published paper.  
 SIURO provides an opportunity for undergraduate students to share their results and experience a full paper review process. High school students may also submit their work.  
 The project advisor may be a faculty member at the student’s institution or at an institution the student is visiting, or someone associated with a non-academic organization or government lab who supervised the research. 
  The project advisor’s letter must document the fact that the research was done while the student was an undergraduate and list the student’s graduation date or anticipated graduation date. 
  Project advisors will be listed separately from the authors with a “project advisor” byline. 

 Announcements   
 Authors: Prepare your papers using LaTex 2e macros to aid editor and referee review 

 From the Current Volume  
 Check out the latest volume and dive into advanced research and findings by undergraduate students.  
 See more   
   
 Volume 17  Accurately Classifying Out-Of-Distribution Data in Facial Recognition   
 November 13, 2024    
 By  Gianluca Barone (Corresponding author – Rowan University) 
  Aashrit Cunchala (University of Pittsburgh) 
  Rudy Nunez (Emory University) 

 Volume 17  Optimizing Energy Functional in Wave and Heat Equations with Initial Conditions in a Class of Rearrangements   
 October 30, 2024    
 By  Renjing Wang (Corresponding author – Xi'an Jiaotong-Liverpool University, China) 

 Volume 17  Travelling Waves of the Diffusive Streeter-Phelps Equations with Braun-Berthouex BOD Decay   
 October 24, 2024    
 By  Alexandra Lawryshyn (Corresponding author – University of Guelph, Ontario, Canada) 

 Browse Articles by Volume  
   
 Volume 17   
 2024   
   
 Volume 16   
 2023   
   
 Volume 15   
 2022   
   
 Volume 14   
 2021   
   
 Volume 13   
 2020   
   
 Volume 12   
 2019   
   
 Volume 11   
 2018   
   
 Volume 10   
 2017   
   
 Volume 9   
 2016   
   
 Volume 8   
 2015   
   
 Volume 7   
 2014   
   
 Volume 6   
 2013   
   
 Volume 5   
 2012   
   
 Volume 4   
 2011   
   
 Volume 3   
 2010   
   
 Volume 2, Issue 2   
 Fall 2009   
   
 Volume 2, Issue 1   
 Spring 2009   
   
 Volume 1, Issue 2   
 Fall 2008   
   
 Volume 1, Issue 1   
 Summer 2008   

 Show more    

 Publish with SIURO   
 Become an Author  
   
 SIURO offers undergraduate and high school students the early opportunity to publish their research while becoming part of the scientific community.  
   
 Learn More 
    
 SIURO is one of the best publications for undergraduate research in applied and computational mathematics. Beyond getting their results out into the world, when students publish their papers in SIURO, they have the edifying experience of taking their original work through the peer-review process.  
   Joanna Wares  University of Richmond     

 Get Involved with SIURO  
 We welcome submissions from undergraduate and high school students in applied and computational mathematics.  

 Editorial Information   
 Get the scoop on our reviewer guidelines, editorial policy, and more.   

 Instructions for Authors   
 Interested in submitting a paper to SIURO?   

 Contact Us  
   
 Questions about SIURO? Get in touch with our staff.  
 Contact SIURO Staff    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Important dates data

21. Conference SoCS_2:
CG Week 2025     Home 
  Program 
  SoCG 
  YRF 
  Challenge 
  Media 
  Workshops 
  Awards 
  Registration 
  Practicalities 

 Call for Papers: The 41st SoCG - June 23-27, 2025   
 The 41st International Symposium on Computational Geometry (SoCG 2025) is planned to be held in Kanazawa, Japan, June 23–27, 2025, as part of the Computational Geometry (CG) Week. We invite high quality submissions that describe original research on computational problems in a geometric and/or topological setting. Topics of interest include, but are not limited to:  
 Design, analysis, and implementation of geometric algorithms and data structures; 
  Computational complexity of geometric problems; 
  Implementation and experimental evaluation of geometric algorithms and heuristics, including mathematical, numerical, and algebraic aspects; 
  Discrete and combinatorial geometry; 
  Computational topology, topological data analysis, and topological combinatorics; 
  Applications of computational geometry or topology in any field. 

 Important Dates   
 November 26, 2024 (Tuesday): | Abstracts and paper registration due (23:59 AoE (anywhere on Earth)) 
  December 3, 2024 (Tuesday): | Papers due (23:59 AoE (anywhere on Earth)) 
  February 6, 2025 (Thursday): | Notification of acceptance/rejection 
  mid March 2025: | Final versions of accepted papers due 
  June 23–27, 2025: | Symposium 

 SoCG 2025 Conference Webpage   
 http://socg25.github.io/    
   
 SoCG 2025 HotCRP Submission Webpage   
 https://socg25.hotcrp.com/    
   
 Code of conduct   
 SoCG is dedicated to providing an environment that is free from harassment, bullying, discrimination, and retaliation for all participants. Starting in 2025, CG Week including SoCG will be organized as an event of the CG Society  . All members of the Society are bound by its Code of Conduct  . Only members of the Society can give a presentation and hence at least one author of each accepted paper must become a member of the Society. Society membership is free.  

 Submission Guidelines   
 Paper types | When writing or evaluating a SoCG paper, it is important to keep in mind that there are different types of contributions, each with its own strengths. To ensure that a submission is evaluated on its own merits, authors will need to identify the main strengths of their submission, as captured by four possible paper types. PC members and external reviewers will be asked to take into account these paper types together with their associated evaluation criteria when they evaluate a paper. There are no quotas for the paper types and submissions can be labeled with more than one paper type at the time of submission. | Mathematical Foundations: | A typical paper will contain theorems and proofs describing new results in discrete or combinatorial geometry, discrete differential geometry or topology, or in topological combinatorics. The paper will primarily be evaluated on its technical depth, the importance of the results, the elegance of the solution, the connection of the problem studied to computational geometry and topology, and the potential future impact on algorithm development. 
  Algorithmic Complexity: | A typical paper will contain algorithms, data structures, theorems, proofs, or lower bound constructions describing new results on computational geometry problems. The paper will primarily be evaluated on the (mathematical or computational) relevance and importance of the problem studied, its technical depth, the elegance of the solution, and the potential future impact of the results or the proposed new methods and techniques. 
  Experiments and Implementation: | A typical paper will make a clear contribution to the implementation and evaluationp of geometric algorithms, such as exact, approximate, or algebraic computation, algorithms engineering, or the experimental evaluation of competing algorithmic approaches. The paper will primarily be evaluated on the completeness and the expected impact of the proposed implementation, the soundness of the experiments, the quality and quantity of testing, and on the general amount of knowledge gained. 
  Applications: | A typical paper will describe the modeling and algorithmic choices made when developing or adapting computational geometry techniques for an application area. The paper will be primarily evaluated on the soundness of the modeling decisions, the ingenuity of the solution, the effectiveness of the proposed method, and the expected impact in the application area. One might also consider the lesson learned regarding the applicability or suitability of computational geometry tools to the specific area. 
  Double Blind and PC submissions | SoCG will employ a lightweight double-blind reviewing process, and will allow PC members (other than the PC chairs) to submit to the conference as well. Submissions should not reveal the identity of the authors in any way. In particular, authors' names, affiliations, funding information, and email addresses should not appear in the submission. Authors should ensure that any references to their own related work is in the third person (e.g., not "We build on our previous work ..." but rather "We build on the work of ..."). Particular care needs to be taken if there is any accompanying software or data, which needs to be linked anonymously (for example, via a DropBox anonymous folder or Anonymous GitHub  , perhaps with a subset of synthetic data if the real data is not anonymized). Upon registering a submission, the authors will declare conflicts of interest with PC members, as well as listing email address or domain level conflicts (i.e. “Haitao Wang (University of Utah)”, “All (Graz University of Technology)”) of other professional or personal conflicts. This includes past advisors and students, people with the same affiliation, and any recent/frequent coauthors and collaborators. Please refer to the SoCG 2025 Conflict of Interest Guidelines  for a detailed discussion of possible conflicts of interest. | The purpose of lightweight double-blind reviewing is to help PC members and external reviewers come to an initial judgment about the paper without bias, not to make it impossible for them to discover the authors if they were to try. Authors should feel free to disseminate their ideas or draft versions of their paper as they normally would. For example, authors may post drafts of their papers on the web, submit them to arXiv, and give talks on their research ideas. We encourage authors with further questions on double-blind reviewing to contact the PC chairs, or to see the more detailed discussion in the proposal  that preceded the vote to move to double blind. 
  Format | Submissions must be formatted in accordance with the LIPIcs proceedings guidelines  . Authors are required to use the LaTeX class file socg-lipics-v2021.cls  (V0.9, Sep 19, 2022), with the option “anonymous”; note that the class file is a wrapper around the standard LIPIcs class. The LIPIcs style and instructions are available here  ; the SoCG class file is available here  , and instructions on how to use it are available here  . Submissions must not exceed 500 lines, excluding front matter (title), references, and a clearly marked appendix (further described below), but including all other lines (in abstract, algorithms, tables, captions, etc.). The class files provide line counting which should be accurate in most cases. Authors should refrain from putting excessive amounts of text in parts in which lines are not counted automatically. If authors need constructs that contain uncounted lines of text, they should compensate for this by reducing the final line count accordingly. It is the sole responsibility of the authors not to exceed 500 lines even if some lines are not counted automatically. 
  Contents of the submission | Papers should be submitted in the form of an extended abstract, which begins with the title of the paper, as well as a short abstract. This should be followed by the main body of the paper that begins with a precise statement of the problem considered, a succinct summary of the results obtained (emphasizing the significance, novelty, and potential impact of the research), and a clear comparison with related work. The remainder of the extended abstract should provide sufficient details to allow the program committee to evaluate the validity, quality, and relevance of the contribution. Clarity of presentation is very important; the entire extended abstract should be written carefully, taking into consideration that it will be read and evaluated by both experts and non-experts, often under tight time constraints. | In addition, authors are asked to avoid "et al." in citations in favor of an equal mention of all authors' surnames. For instance, if the number of authors is large, consider writing "The authors in [#] show" instead of "A et al. [#] show". 
  Appendix and additional data | All details needed to verify the results must be provided. Supporting materials, including proofs of theoretical claims and experimental details, that do not fit in the 500-line limit should be given in an appendix. If more appropriate, the full version may be given as the appendix. In both cases, however, the authors should include in the main part specific pointers to the relevant locations in the appendix. The appendix will be read by the program committee members and subreviewers at their discretion and will not be published as part of the proceedings. Thus, the paper without the appendix should be able to stand on its own. Experimental and implementation results (independent of paper type) must be reproducible and verifiable. Authors of all types of papers are encouraged to put accompanying software and relevant data, if there is any, in a repository accessible to the reviewers. 
  Previous or simultaneous submissions | Results previously published or accepted for publication in the proceedings of another conference cannot be submitted. Simultaneous submissions of the results to another conference with published proceedings are not allowed. Exempted are workshops and conferences without formal proceedings, but possibly with handouts containing short abstracts. In particular, submissions of papers that have appeared or will be submitted to EuroCG are allowed, since EuroCG does not publish formal proceedings, while submissions of papers that have appeared in CCCG are not allowed. Results that have already been accepted (with or without revision) for publication in a journal at the time of their submission to the symposium are not allowed. 
  Strict guidelines | Submissions deviating from the above guidelines risk being rejected without further consideration. 
  Guidelines for reviewers | The guidelines for reviewers are available here  . 

 Accepted Papers   
 Presentation | An author of each accepted paper is expected to attend the symposium and present the paper (approximately 20 minutes). Note that SoCG 2025 will be organized as an event of the CG Society  and hence the presenting author(s) must be a member of the Society. Society membership is free. 
  Best paper award | An accepted paper may be selected as the best paper. All papers are eligible. | Best student paper award | An accepted paper may be selected as the best student paper. A paper is eligible if all authors are students at the time of submission. This must be indicated in the submission process. There is a box provided for this purpose on the submission server. | Best student presentation award | Based on the feedback from the audience, a presentation during the symposium by a student may be selected as the best student presentation. | In exceptional cases, each of these awards may be granted to more than one paper/presentation. 
  Invited papers and special issues | Authors of the best paper will be invited to submit an extended version of their paper to the Journal of the ACM  , and authors of one (or more) most highly ranked papers may be invited to submit their full paper to the journal TheoretiCS  . Authors of a selection of accepted papers from the symposium will be invited to submit extended versions of their papers to special issues of Discrete & Computational Geometry  and Journal of Computational Geometry  . 
  Format | Final proceedings versions of accepted papers must respect the same formatting constraints as the submissions ( LIPIcs proceedings format  with socg-lipics-v2021  ; 500-line limit, excluding front matter and references), but must not comprise any appendix. If any supporting material (including complete proofs of theoretical claims and experimental details) does not fit in the specified limit, then the full version of the paper containing this information must be referenced in the conference version and made available at a public repository, such as arXiv  , by the time the final version is submitted. Where applicable, we encourage the authors to make accompanying software and/or data publicly accessible, with proper references in the paper. 

 Program Committee   
 Mikkel Abrahamsen, University of Copenhagen 
  Oswin Aichholzer, Graz University of Technology (co-chair) 
  Hugo Akitaya, University of Massachusetts Lowell 
  Mark de Berg, Eindhoven University of Technology 
  Sujoy Bhore, Indian Institute of Technology Bombay 
  Ahmad Biniaz, University of Windsor 
  Håvard Bakke Bjerkevik, SUNY Albany 
  Gerth Stølting Brodal, Aarhus University 
  Hsien-Chih Chang, Dartmouth College 
  Siu-Wing Cheng, Hong Kong University of Science and Technology 
  Vida Dujmović, University of Ottawa 
  David Eppstein, University of California, Irvine 
  Emily Fox, University of Texas at Dallas 
  Jie Gao, Rutgers University 
  Dan Halperin, Tel Aviv University 
  Tao Hou, University of Oregon 
  Christian Knauer, University of Bayreuth 
  Francis Lazarus, Université Grenoble Alpes 
  Chih-Hung Liu, National Taiwan University 
  Daniel Lokshtanov, University of California Santa Barbara 
  Anna Lubiw, University of Waterloo 
  Amir Nayyeri, Oregon State University 
  Eunjin Oh, Pohang University of Science and Technology 
  Tim Ophelders, Utrecht University and TU Eindhoven 
  Irene Parada, UPC BarcelonaTech 
  Rahul Saladi, Indian Institute of Science 
  Patrick Schnider, University of Basel and ETH Zürich 
  Raimund Seidel, Saarland University 
  Don Sheehy, North Carolina State University 
  Shakhar Smorodinsky, Ben-Gurion University 
  Jonathan Spreer, University of Sydney 
  Takeshi Tokuyama, Kwansei Gakuin University 
  Torsten Ueckerdt, Karlsruhe Institute of Technology 
  Pavel Valtr, Charles University 
  Kasturi Varadarajan, University of Iowa 
  Haitao Wang, University of Utah (co-chair) 
  Jinhui Xu, University at Buffalo 
  Jie Xue, New York University Shanghai 

  CG Week 2025   

  Call for papers data:Important dates data

22. Conference SOCA_3:
[AISWorld] Call For Papers - SOCA 2024, September 9-13, 2024, Poznań, Poland THE 13th INTERNATIONAL CONFERENCE ON SERVICE-ORIENTED COMPUTING AND AI (SOCA 2024)  
 Peter Huang  huangzhenqiu0825 at gmail.com   
  Sun May 26 22:39:11 EDT 2024   
 Previous message (by thread): | [AISWorld] Information Systems Faculty - Temporary Full-Time - non-tenure track 2024-2025 Faculty International 
  Messages sorted by: | [ date ] | [ thread ] | [ subject ] | [ author ] 
   Dear Colleagues: We cordially invite you to share your latest research results related to Service-Oriented Computing and Artificial Intelligence at the IEEE SOCA 2024 International conference. https://www.soca-ieee.org/  --------------------------- CALL FOR PAPERS --------------------------- The 2024 IEEE 13th International Conference on Service-Oriented Computing and AI (SOCA 2024), upholding its nearly two-decade legacy will be a forum where traditional Service-Oriented Computing research meets with new and trending approaches based on state of the art AI advancements. As a global platform, it invites a diverse group of researchers, practitioners, and industry leaders to discuss ideas and results on services and AI, and its implications across software systems, including areas like Generative Service Design, Intelligent Service Composition AI-as-a-service (AIaaS), and Service Prompt Engineering. SOCA 2024 is set to take place from September 9-13, 2024, in Poznan Poland, as part of a multi-conference event. Topics of interest include, but are not limited to: Foundations of Service-Oriented Computing: - Service composition - Service design - Service discovery - Service engineering - Service orchestration - Quality of service Foundations of Intelligent Service Computing: - Architectures and frameworks for intelligent service computing - Integration of AI techniques - Intelligent service discovery, composition, and orchestration - NLP for service interoperation and interpretation - Prompt engineering for services Cloud Services and Big Data: - Cloud, fog, edge computing - Cloud service management - Cloud sustainability and Green ICT - Computing continuum - Data-driven service quality assessment and improvement - Big data analytics for services Physical Services and IoT: - Pervasive Service-Oriented Architectures and IoT - Smart Cities, Smart Buildings, Smart Grids - IoT as a service - Coordination and orchestration for IoT Services and Humans: - Human-robot collaboration in service delivery and assistance - Personalized and context-aware service provisioning - Human-AI interaction and collaboration in ISC systems - Conversational AI interfaces and interactive workflows in ISC Security, Privacy, and Trust: - Security and privacy challenges in AI-driven service ecosystems - Trustworthiness and reliability of intelligent service providers - Ethical considerations in intelligent services Service-Oriented Computing and Applications: - Real-world applications of intelligent service computing in various domains (e.g., healthcare, finance, e-commerce, logistics, energy transportation) - Quantum service architectures and experiences - Robotics and service architectures for robotics - Success stories and lessons learned from service deployments ---------------------------- IMPORTANT DATES ---------------------------- Paper Submission Deadline: June 17, 2024 Author Notification: July 17, 2024 Registration deadline: July 31, 2024 Camera Ready Submission: July 31, 2024 --------------------------------------------- SUBMISSION --------------------------------------------- Authors are invited to submit their original research work that has not previously been submitted or published in any other venue. We seek for both research (full) and work-in-progress (short) papers. • Research papers should explore a specific technology problem and propose a complete solution to it, with experimental results, and should be limited with 8 pages including Figures, Tables & References. • Work-in-progress papers are expected to present either work currently in progress or less developed but highly innovative ideas and should be limited with 6 pages including Figures, Tables & References. At maximum, two additional pages are permitted with an over-length page charge. Extended versions of selected excellent papers will be considered for publication in special issues of prestige journals (SCI/EI indexed). All papers should be prepared using the IEEE Computer Society Proceedings Format (two column, 10 point, single-spaced, US Letter, no margin smaller than one inch). Templates can be found at: https://www.ieee.org/conferences/publishing/templates.html     
 Previous message (by thread): | [AISWorld] Information Systems Faculty - Temporary Full-Time - non-tenure track 2024-2025 Faculty International 
  Messages sorted by: | [ date ] | [ thread ] | [ subject ] | [ author ] 
   More information about the AISWorld mailing list   
   Call for papers data:undefinedImportant dates data

23. Conference SIN_3:
About 
  Call for papers 
  Paper Submission 
  Registration 
  Important dates 
  Keynotes 
  Organisers 
  Past events 
  Contact us 

 SINCONF 2023  
 16th International Conference on Security of Information and Networks  
 November 20-21, 2023  
 Manipal University Jaipur, Rajasthan, India (Host)  
 Hasan Kalyoncu University, Gaziantep, Türkiye  
 IEEE Record # 60469 | Scopus | IEEE Xplore  
 Conference schedule    

 SINCONF 2023  
 16th International Conference on Security of Information and Networks  
 November 20-21, 2023  
 Manipal University Jaipur, Rajasthan, India (Host)  
 Hasan Kalyoncu University, Gaziantep, Türkiye  
 IEEE Record # 60469 | Scopus | IEEE Xplore  
 Conference schedule    

 SINCONF 2023  
 16th International Conference on Security of Information and Networks  
 November 20-21, 2023  
 Manipal University Jaipur, Rajasthan, India (Host)  
 Hasan Kalyoncu University, Gaziantep, Türkiye  
 IEEE Record # 60469 | Scopus | IEEE Xplore  
 Conference schedule    

 ABOUT CONFERENCE  
 The 16th SIN 2023 conference will serve as a platform for knowledge sharing about the recent trends and advancements in Security of Information and Networks and how these domains are playing role in research and market development of the industries. It will provide a great opportunity for the students and faculties to interact and share ideas with the top-notch in the field face to face. This knowledge sharing may inspire and thrill many young minds and help them bring collaborations and global partners to work together. This conference is organized by Manipal University Jaipur in partnership with multiple universities.  

  ABOUT MANIPAL UNIVERSITY JAIPUR  
 The Manipal Education Group is an established leader in the field of education, research and healthcare. In a span of over six decades, it has transformed the lives of more than 3,00,000 students from over 59 countries. The group includes five Universities – Manipal Academy of Higher Education (MAHE, Karnataka), Sikkim Manipal University (Sikkim), American University of Antigua (Caribbean Islands), Manipal International University (Malaysia) and Manipal University Jaipur (Jaipur). Manipal University Jaipur (MUJ) was launched in 2011 on an invitation from the Government of Rajasthan, as a self-financed State University. MUJ has redefined academic excellence in the region, with the Manipal way of learning; one that inspires students of all disciplines to learn and innovate through hands on practical experience.  

 ABOUT JAIPUR  
 Jaipur is the capital of India’s Rajasthan state. It evokes the royal family that once ruled the region and that, in 1727, founded what is now called the Old City, or “Pink City” for its trademark building color. At the center of its stately street grid (notable in India) stands the opulent, colonnaded City Palace complex. With gardens, courtyards and museums, part of it is still a royal residence  
 https://www.tourism.rajasthan.gov.in/   
 https://www.incredibleindia.org/content/incredible-india-v2/en.html   

 1 / 6   
    
 2 / 6   
    
 3 / 6   
    
 4 / 6   
    
 5 / 6   
    
 6 / 6   

 MUJ is the first state university in Rajasthan to receive A+ Grade with 3.28 score accredited by NAAC. It is accredited by NBA for five programs including Computer Science & Engineering and Information Technology. MUJ achieved 84th rank in NIRF in Engineering category in the year 2021.   
    
 Jaipur, being one of the fastest growing cities in India, has increasing demand for quality higher education in the region. Following an allotment of 122 Acres of land at Dehmi Kalan village near Jaipur, the permanent campus of the University has come up at a fast pace and is by far one of the best campuses in the region. The multi-disciplinary university offers career-oriented courses at all levels, i.e., UG, PG and doctoral and across diverse streams, including Engineering, Architecture, Planning, Fashion Design, Fine Arts, Hospitality, Humanities, Journalism and Mass Communication, Basic Sciences, Law, Commerce, Computer Applications, Management, etc. Some PG programmes are also available in the research mode. MUJ boasts of best-in-class infrastructure, including state-of-the-art research facilities and a modern, digital library. In line with Manipal University’s legacy of providing quality education to its students, the campus uses the latest in technology to impart education.  

 Call for papers  
 Download Call for Papers Document    

 Paper Categories  
   
   Research Contributions  Submissions must not substantially duplicate work that any of the authors has published elsewhere or has submitted simultaneously to any other conference or workshop that has published proceedings. The maximum length for the proceedings is 8 pages for full papers, and 6 pages for short papers.  
   
   Student Contributions  Doctoral / Masters Students are encouraged to propose papers on ongoing research. Please add "(Student contribution)" to the title. The maximum length for the proceedings is 6 pages for student papers.  
   
   Industrial Contributions  Authors from industry and government enterprises are welcome to submit original papers that describe their experiences, challenges, and applications in security. The maximum length for the proceedings is 8 pages.  

 Scope and Theme  
 The 16th International Conference on Security of Information and Networks (SIN-2023) provides an excellent international forum for sharing knowledge and results in theory, methodology, and applications of Security in information and networks. Papers, special sessions, tutorials, and workshops addressing all aspects and issues of security in information and networks are being pursued. The conference invites significant contributions from researchers and industrial working on the development of cryptographic algorithms, security schemes, cryptanalysis, application security, system security, cloud security, and network security. The conference aims to provide a platform for researchers and practitioners from both academia as well as industry to meet and share cutting-edge advancements in the field of information and network security.  

  Hosted by  
 Manipal University Jaipur, India   

 Partner  
 Hasan Kalyoncu University, Türkiye 
  CES-Lab, Tunisia. 
  Edinburgh Napier University, United Kingdom 
  Istanbul Technical University, Turkey 
  Southern Federal University, Russia 
  Cardiff University, Wales 
  MNIT, India 
  Rutgers University, USA 
  Macquarie University, Australia 

 Topics of Interest  
 Authors are solicited to contribute to the conference by submitting articles that illustrate research results, project outputs, surveys, and industrial experiences that describe significant advances in the following areas, but are not limited to:  
   
 Network defense  
 Tools and development platforms  
   
 Malware analysis  
 Security in cyber-physical systems, Security in Blockchain  
   
 Security in space science  
 Key management and distribution  
   
 Virus and worm analysis  
 Big-data trust, security, and privacy  
   
 Security in mobile devices  
 Security and privacy social networks  
   
 Cloud and system security  
 Security-aware software engineering  
   
 Artificial intelligence security  
 Security in embedded systems and IoT  
 Machine learning techniques and applications in security  
   
 Web and application security  
 Security education and innovative curriculum  
   
 Security in biometric systems  
 Symmetric and asymmetric key cryptography  
   
 Privacy and trust management  
 Computational intelligence techniques in security  
   
 Access control, firewall, and IDS  
 Security ontology, policies, protocols, models, and certifications  

 Proposal/Paper Submission  
  
 Papers must be submitted electronically via the SIN 2023 submission page at | https://cmt3.research.microsoft.com/SINCONF2023 

 Papers should be written according to the IEEE conference proceedings format | (https:// www.ieee.org/ conferences/ publishing/ templates.html) 

 SIN2023 conference follows the double-blind review process. Authors should not include the author’s name and affiliation, mailing address, telephone, fax, and email of the principal author on the paper. 

 All accepted papers will be published by IEEE Xplore subject to meeting the IEEE Xplore’s scope and quality requirements. Each accepted paper must be registered and presented during the conference to be included in the proceedings. 

 All proposals for organizing workshops, tutorials, demos, and special sessions are expected at the conference e-mail | sinconf2023@gmail.com 

 Technical Sponsor  

 Registration Fees  
  
 Category | IEEE Members | Non-IEE Members | Non-Authors/ Attendee 
 Student Authors | Professional Authors | Student Authors | Professional Authors |  
 Indian Authors (INR) | 11,000 | 14,000 | 13,000 | 16,000 | 4000 
 International Authors (USD) | 275 | 300 | 300 | 350 | 150 

  Registration fee is inclusive of 18% GST.  

  Registration Fee covers:  
  
 Entry to all sessions (Keynote, Technical paper presentations, Industry expert talks, etc.) 

 Refreshments and lunch during sessions on conference dates 

 Conference kit 

 NB: Paper registration covers the registering author; other authors may register as an attendee. 

  Registration Process for authors  
 Step 1: Please pay the paper registration fee  (Please remove all payment options except applicable from Payment Description)  
  Payment Link   
  Payment Link for International authors   
   
  * how to filling out payment form   
  
  Step 2: Please fill the following Registration form after the payment.  Registration form Link   
  
  Step 3: Please submit the CRC copy after the registration form submission.  CRC submission form Link   
  
  Important Instructions:  To complete a successful registration, at least one author must register before the deadline. 
  The registration fee includes participation in the conference, meals, and a conference kit. 
  Boarding and lodging expenses will be the responsibility of the participant. 
  A standard page limit of 6 pages will apply to all submitted manuscripts. 
  Presentation certificates will be issued to presenters only. The certificate will include the names of all authors, but only the presenter's affiliation. 
  If the same author has multiple papers accepted for publication and presentation, each paper requires a separate registration fee to be included in the proceedings. 
  Please remove all payment options except applicable from Payment Description 

  Registration Process for attendee  
 Step 1: Please pay the paper registration fee   
  (Please mention in the field Paper ID: 1 and in the field Paper Title: Sinconf.  
  Please remove all payment options except applicable from Payment Description)  Payment Link   
   
  * how to filling out payment form   
  
  Step 2: Please fill the following Registration form after the payment.  Registration form Link   

 Important Dates  
   
 01  Submission Deadline  
 31 August 2023   

 02  Notification to Authors  
 20 September 2023   

 03  Final Manuscript Due  
 10 October 2023   

 04  Paper Registration Deadline  
 30 September 2023   

 05  Registration HARD Deadline  
 25 October 2023  

 KEYNOTES  

 Erol Gelenbe   
 Institute of Theoretical & Applied Informatics Polish Academy of Sciences & Laboratoire I3S Univ. Cote d’Azur & Cognitive Networks Ltd, UK  
 more info     

 Dr. MANOJ KUMAR   
 Research Cluster Leader- Cyber and Network Security, University of Wollongong, Dubai  
  
  more info     

 Prof. Priyadarsi Nanda   
 Senior Lecturer at the University of Technology Sydney (UTS)  
  
  more info     

 Prof. Amit Dua   
 Associate Professor in Computer Science and Information System Department in BITS Pilani  
 more info     

 Dr. Dalal N Alharthi   
 Assistant Professor, the University of Arizona, Tucson, USA.  
  
  more info     

 Some Methods to Improve IoT Performance and Cybersecurity  
  
  Erol Gelenbe  
 Institute of Theoretical & Applied Informatics Polish Academy of Sciences & Laboratoire I3S Univ. Cote d’Azur & Cognitive Networks Ltd, UK  
 https://en.wikipedia.org/wiki/Erol_Gelenbeseg@iitis.pl    
 Abstract:  The relative simplicity and lightweight nature of many IoT devices, and their widespread connectivity via the Internet and other wired and wireless networks, raise issues regarding both their performance and vulnerability. Indeed, their connectivity patterns based on the need to frequently forward and receive data have given rise to the « Massive Access Problem (MAP) of the IoT » which is a form of congestion caused by the IoT’s synchronized and repetitive data transmission patterns. On the other hand, the opportunity that IoT devices present to malicious third parties for generating highly contagious distributed denial of service (DDoS) and Botnet attacks, is also a subject of concern that is widely studied. Thus this presentation will discuss our recent results and research directions that address both of these issues. Regarding the MAP, we will outline the Quasi-Deterministic Transmission Policy (QDTP), and its main theoretical result, and present trace-driven measurements, which show that QDTP can effectively mitigate MAP. We will also show how a Machine Learning approach using novel Auto-Associative Dense Random Neural Networks can detect DDoS attacks with a high degree of accuracy, and discuss the potential of « low cost » online learning to protect IoT gateways and devices against Cyberattacks. The speaker gratefully acknowledges research funding from the EC as part of the H2020 GHOST, SerIoT, and IoTAC projects.  
 Biography:  Erol Gelenbe, FIEEE’86 FACM’03 FIET’03 FIFIP’19 FRSS’20, a graduate of METU (Ankara, Turkey), is renowned for mathematical and data-driven modelling of computer systems, the Internet, neuronal networks, and gene regulatory networks. Recipient of the 2010 NYU Distinguished Alumnus Award in Engineering, he is ranked by the AMS Mathematics Genealogy Project in the Top 25 individuals who are the “all-time worldwide” most prolific Ph.D. supervisors in the Mathematical Sciences. He won the Grand Prix France Telecom of the French Academy of Sciences (1996), the Mustafa Prize(2017) for his invention of G-Networks and the Random Neural Network, and the ACM SIGMETRICS (2008) Award stated that he is “the single individual who … made the greatest overall contribution to the field of Computer System and Network Performance Evaluation through original research, mentoring and doctoral training, creation and direction of world-class research groups, wide-ranging international collaboration”. His career has included chairs and named professorships at the Universities of Liege, Paris-Saclay, Paris-Descartes, NJIT, Duke University, University of Central Florida, Imperial College, and now the Polish Academy of Sciences. Active in European research and industry collaborations, a Fellow of the French National Academy of Technologies, the Academy of Sciences of Belgium, Poland, and Turkey, and an Honorary Fellow of the Hungarian and Islamic Academies of Sciences he is the incoming chair of the Informatics Section of Academia Europaea.  
   
 Close    

 Prof. Amit Dua  
 Associate Professor in Computer Science and Information System Department in BITS Pilani  
 profile    
 Biography:  Dr Amit Dua is Associate Professor in Computer Science and Information System Department in BITS Pilani. Dr Amit is also the Honorary Adjunct Distinguished Scientist-Professor at Scientific Innovation Research Group (SIRG) and Head of Blockchain Branch (India) of SIRG.  
  Dr. Amit is associated with NeuroLabs International under Dana Brain Health Institute, Iran as Honorary Adjunct Research Scientist for the period of August 22, 2022 to August 21, 2025.  
  Dr Amit is the Founder and CEO of Yushu Excellence Technologies Pvt. Ltd. A strat-up incubated at BITS Pilani incubation center and blossoming under the guidance of BITS Pilani.  
  He is certified Life coach and expert in Neuro-Linguistic Programming, and Hypnosis. Amit is an Advanced Pranic healer.  
  Amit finds great joy in training people in Blockchain technology. He is working towards his mission of changing 10Million lives  
  He is the Amazon Best Selling Author of 3 books on Machine Learning, Cybercrimes and Cyber Hygiene and Blockchain Technology.  
  Dr. Amit has been awarded as Top 10 life coaches of 2022 and Top 10 Most Influential Indian Personalities of 2022.  
   
 Close    

 Prof. Priyadarsi Nanda  
 Senior Lecturer at the University of Technology Sydney (UTS)  
   
 Biography:  Dr. Priyadarsi Nanda is a Senior Lecturer at the University of Technology Sydney (UTS) with more than 32 years of experience and a strong researcher specialising in research and development of Cybersecurity, IoT security, Internet Traffic Engineering, wireless sensor network security and many more related areas. His most significant work has been in the area of Intrusion detection and prevention systems (IDS/IPS) using image processing techniques, Sybil attack detection in IoT based applications, intelligent firewall design. In Cybersecurity research, he has published over 120 high quality refereed research papers including Transactions in Computers, Transactions in Parallel Processing and Distributed Systems (TPDS), Future Generations of Computer Systems (FGCS) as well as many ERA Tier A/A* conference articles. In 2017, his work in cyber security research has earned him and his team the prestigious Oman research council's national award for best research. Dr. Nanda has successfully supervised 17 HDR at UTS (14 PhD + 3 Masters), and currently, supervising 8 PhD students.  
   
 Close    

 Dr. Dalal N Alharthi  
 Assistant Professor, the University of Arizona, Tucson, USA  
 Dalal N Alharthi | UA Profiles (arizona.edu)    
 Degrees:   
 Ph.D. Computer Science 
  University of California Irvine 
  M.S. Computer Science 
  University of California Irvine 
  M.P.A. Public Administration 
  King Saud University 
  B.S. Computer Science 
   
 Work Experience:   
 University of Arizona, Arizona (2021 - Ongoing) 
  Palo Alto Networks (2020 - 2021) 
  Farmers Insurance (2019 - 2020) 
   
 Awards:   
 SANS 
  SANS SEC588 Challenge Coin, Spring 2022 
  Division of Teaching Excellence and Innovation (DTEI) Fellow 
  University of California Irvine, Summer 2020 
   
 Licensure & Certification:   
 Division of Teaching Excellence and Innovation (DTEI) Fellow, University of California Irvine (2020) 
  Cybersecurity Boot Camp (6 months program), University of California Irvine (2019) 
  Entelligence Certified IT Professional, Entelligence (2020) 
  AWS Certified Solutions Architect, Amazon Web Services (AWS) (2020) 
  CompTIA Security+, CompTIA (2020) 

 Close    

 Dr. MANOJ KUMAR  
 PostDoc, Ph.D., M.Sc. (Ireland), M. Tech, B. Tech  
   
 Dr. Manoj Kumar completed his Ph.D. from The Northcap University and M.Sc. (Information Security and Digital Forensics) from Technological University Dublin, Ireland in 2013. He received fully-funded scholarship for his M.Tech and M.Sc. program from Irish Government. Dr. Kumar have more than 13 years of research, teaching, and corporate experience. He is currently working on the post of Associate Professor-Cyber Security in the University of Wollongong in Dubai, UAE and Research Head for Network and Cyber Security Cluster. His specializations are Digital Forensics, Machine Learning, Information Security, Image Processing, IOT and Computer Networking. He has published over 140 articles in International refereed journals and conferences. Dr. Kumar is member of numerous renowned professional bodies including IEEE, ACM, IAENG, ISTS and UACEE and many more.  
 He delivered several guest lectures, seminars and chaired the session at various reputed international conferences. He published three textbooks and eight edited books for the most famed publishers like Springer, CRC Press, IOP, Bentham Science, Taylor & Francis, and Elsevier, etc. He is an associate editor, Guest editor, and editorial board member of various journals of repute. Dr. Kumar received the Best Researcher Award in 2020, an outstanding Scientist Award in 2021, and a Young Researcher Award in 2021 from recognized international professional bodies. He published over 10 patents and delivered three international research funded projects  
 Contact No:  +971 529291824, +91 9911740918  
 Email:  wss.manojkumar@gmail.com, manojkumar@uowdubai.ac.ae, mkumar@uow.edu.au  
 All about My Linktree:  https://linktr.ee/wss.manojkumar   
 LinkedIn:  https://in.linkedin.com/in/manoj-kumar-25668537   
 WebEx:  https://uow.webex.com/meet/mkumar   
 ORCID ID:  http://orcid.org/0000-0001-5113-0639  , SCOPUS ID: 57201849165, Hindex-24  
 Web of Science Researcher ID:  P-7489-2014  
 Google Scholar ID:  jmdqiw0AAAAJ  
 Vidwan-ID:  121799 ( https://vidwan.inflibnet.ac.in//profile/121799  )  
   
 Close    

 Gelenbe Erol  
 “Random Neural Networks (RNN) for Accurate CyberAttack Detection and Mitigation at the Edge”  

 Abstract:  Even simple cyberattacks can impair the operation and performance of network systems substantially for many hours and sometimes days, and also increase the system's energy consumption. Their impact on data security, and the effects of the malware that they convey and install, are also well known. Thus there is a widespread need for accurate cyberattack detection, and rapid reaction and mitigation when attacks occur. On the other hand, the detection must avoid false alarms, to avoid impairing the smooth operation of a system which is not under attack. Thus considerable research has been conducted in this important field. Our presentation will briefly introduce the subject, and then focus on some recent results from the last 4-5 years, that are based on the Random Neural Network (RNN). The mathematical model will be described, and its extensions and deep learning algorithms will be discussed in the context of cyberattack detection and mitigation. The presentation will then focus on practical applications illustrated with different cyberattack datasets, showing the high accuracy and low false alarm rates that can be achieved. Measurements of active control schemes for attack mitigation will also be shown. Finally we will also show how the RNN can be used with Reinforcement Learning and SDN (Software Defined Networks), to dynamically control an Edge System that optimizes Security, QoS and Energy Consumption.  
  Note. The talk will be based on our publications in the following journals and conferences: Proceedings of the IEEE (2020), Sensors (2021, 2023), ACM SIGCOMM Flexnets (2021), ICC (2016, 2022), IEEE Access (2022, 2023), Performance Evaluation (2022).  
 About Speaker:  Institute of Theoretical & Applied Informatics, Polish Academy of Sciences, & University Côte d'Azur I3S CNRS, 06100 Nice, France   
  About the speaker: Erol Gelenbe FIEEE FACM FIFIP FRSS received his MS and PhD degrees at Brooklyn Poly, and won the Tandon School Distinguished Alumnus Award in 2010. He has held named personal chairs at NJIT (USA), Duke University (USA), University of Central Florida (USA), Imperial College (UK), and full professorships at the University of Liege, University Paris Saclay, and University Paris Descartes. He served as Department Head at University Paris Descartes (1986-92), Duke University (1993-1998), and Director of the School of EECS at UCF (1993-1998). His research focuses on QoS, Security and Energy, and was funded by Industry, DoD and NSF in the USA, EPSRC and MoD in the UK, and numerous EU FP5, FP6, FP7, and Horizon 2020 projects since 2003. Currently Professor at the Institute of Theoretical & Applied Informatics, Polish Academy of Sciences, since 2017, he also cooperates with the CNRS I3S Laboratory of University Côte d'Azur (Nice, France), and Yasar University (Izmir, Turkey), and his work is now supported by grants from H2020 Horizon and UKRI. He is ranked among the top 25 PhD advisors in mathematical sciences by the American Mathematical Society Math. Genealogy Project and has graduated 24 women PhDs. Winner of the Grand Prix France Telecom 1996 (French Academy of Sciences), the ACM SIGMETRICS 2008 Life-Time Award, and the Mustafa Prize 2017, he was awarded the high honors of Commander of the Order of the Crown, Belgium (2022), Commander of the Order of Merit, France (2019), Knight of the Legion of Honour, France (2014), Commander of the Order of Merit, Italy (2005), Grand Officer of the Order of the the Star, Italy (2007). Fellow of the French National Academy of Engineering, and of the Science Academies of Belgium, Poland and Turkey, he is also Honorary Fellow of the Hungarian and Islamic Academy of Sciences. He currently chairs the Informatics Section of Academia Europaea.  
   
 Close    

 Dr. Manoj Kumar  
 “An ensemble framework for detection of DNS Over HTTPS (DOH) traffic”  

 Associate Professor - Cyber Security School of Computer Science  
 UOWD Building, Dubai Knowledge Park  +971 4 278 1932 | +971 4 278 1800/800-UOWD  
 ManojKumar@uowdubai.ac.ae   
  www.uowdubai.ac.ae    
   
 Abstract:  Domain Name System (DNS) is a fundamental protocol and backbone of the internet that translates domain names to Internet Protocol (IP) addresses. Initially, it was only meant for mapping domain names, however, currently it is used to transfer data over the internet in the form of plain text. This attracts attackers to perform cyberattacks such as DNS spoofing, DNS amplification, and cache poisoning etc. Various solutions were proposed to protect DNS protocol from such attacks such as using DNS load balancers, OpenDNS by Cisco, DNSFilters etc. However, despite these security measures, the attackers can still easily modify the data packets over the network leading to security and privacy concerns. DNS-Over-HTTPS (DOH) is recently introduced protocol with encrypted DNS that defends against issues related to security and eavesdropping largely. However, some challenges are associated with it that need to be addressed for its proper functioning. In this work, an approach is presented to automatically detect DOH traffic using Ensemble-based machine learning framework. The proposed technique is tested on the CIRA-CIC-DoHBrw-2020 dataset and evaluated on classification metrics such as precision, recall, f-score, and confusion metrics. Further, to develop a reliable model that can detect anomalies efficiently, a detailed analysis of false positives and false negatives is done. The demonstrated results show that the presented ensembling techniques EL1 and EL2 outperform the existing approaches by achieving an overall accuracy score of 99.5% and 99.7% respectively and F-score of about 99.8% and 99.7% respectively.  
   
 Close    

 Prof. Priyadarsi Nanda  
 “Exploring Security and Privacy Issues in End-User Systems”  

 Senior Lecturer at the University of Technology Sydney (UTS)  

 Abstract:  In today’s digital era, end-user systems, particularly Internet of Things (IoT) and web technology, have become essential components of our daily lives to make the echo systems efficient and smarter. With the increasing reliance on ubiquitous and digital technologies, user-centric systems are essential to offer a wide range of functionalities in order to fulfil individuals’ needs and preferences through seamless access to information, services, and entertainment. An end-user system is a combination of hardware and software components specifically designed to facilitate the interaction between individuals and technology. Web technology encompasses a vast array of tools, techniques, and standards that are utilized to design, develop, and deliver content across the World Wide Web.  
  In this talk we will explore security and privacy issues in IoT, web technology, smart applications, and propose solutions by combining machine learning algorithms and use of blockchain technologies. We will discuss differential privacy-based system to ensure comprehensive security for data generated by smart homes. Our proposed FedBlockHealth - a novel hybrid approach combining federated learning and blockchain technology to provide a secure and privacy-preserved solution for IoT-enabled healthcare applications will be discussed. Finally, privacy aspects linked to Web-based Chatbots will be discussed to provide the audience a complete understanding on Security and Privacy measures in end-user system.  
   
 Close    

 Dr. Dalal N Alharthi  
 “The State of Multi-Cloud Environments: Strategies, Resilience, and Challenges”  

 Abstract:  In today's complex world of multi-cloud architectures, organizations often find themselves dealing with the challenging task of securing a multitude of services. A single misconfiguration in any one of these services can lead to a disaster: a costly data breach that not only affects finances but also damages the organization’s reputation. This talk aims to provide a clear roadmap for handling this challenge. I'll introduce you to a comprehensive strategy for Securing Multi-Cloud Infrastructure—a strategy designed to help you navigate the dynamic nature of cloud environments and strengthen your organization’s defenses effectively. Throughout my talk, you'll gain insights into pivotal steps that form the foundation of a security strategy capable of seamlessly growing alongside your cloud journey. Moreover, I'll explore the evolving threat landscape that may impact the cloud domain. I'll draw upon both industry insights and the perspectives of academia and researchers to offer a 360-degree view of these threats. By bringing together these diverse viewpoints, my goal is to empower cybersecurity researchers and professionals with the knowledge and tools needed to study, build, deploy, and manage secure cloud infrastructure, platforms, and applications.  
   
 Close    

 Prof. Amit Dua  
 “Zero-Knowledge Proofs: The Future of Authentication”  

 Abstract:  In the changing realm of cybersecurity it is crucial to strike a balance, between protecting user privacy and ensuring system security. This is where zero knowledge proofs (ZKPs) come into play. An approach that allows for verifying ownership of information without revealing or sharing the data itself. In the talk, I will delve into the fundamentals of ZKPs. Examine their potential to transform authentication protocols. By focusing on real world applications and practical implementations I will share with you how ZKPs have the power to revolutionize information verification offering a future where authentication is both robust and private.  
   
 Close    

 How to Reach  
 CONFERENCE VENUE  
 Manipal University Jaipur, Dehmi Kalan Off Jaipur-Ajmer Expressway Jaipur, (Raj.) Rajasthan 303007.  

  LOCATION  
 Manipal University Jaipur is situated at Dehmi Kalan, off Jaipur-Ajmer Highway, nearly 30 km. from the Main Bus Stand, Railway Station or Airport. It can be accessed by hiring OLA/ UBER/ Local Taxi/ Local Auto. Google Map Link to reach Manipal University Jaipur: Manipal University Jaipur  

  IMPORTANT INFORMATION  
   
 Passport and VISA 
   
 All visitors to India must have a valid passport and visa before coming. Visitors from countries which have signed a special agreement with India are exempted from the visa requirement and allowed to stay in India without a visa for 30 days or up to 90 days, depending on types of agreements. For more information, please contact the local Indian consulate or embassy, or visit the official website of the Ministry of External Affairs  , Government of India.  

 Airport related information 
   
 Indira Gandhi International Airport, Delhi Jaipur Airport, Jaipur (Raj.), India Airport Authority of India  
   
   By Air  
 Jaipur Airport is situated in the satellite town of Sanganer. It has also well connected domestic air links with many Indian cities such as Jodhpur, Udaipur, Delhi, Hyderabad, Kolkatta, Goa, Bangalore & Mumbai. The distance from Jaipur Airport to MUJ is 27 Kms.  
   
  By Train  
 The Jaipur station is situated within the city area. Indian Railways connects Jaipur from all importent cities of the country and is one of the most cost -effective means of travel. Overnight trains arrive from many major cities including Delhi, Agra, Chennai & Mumbai. Jaipur Railway Station is 24 Kms away from the Manipal University Jaipur. A prepaid taxi / cab service can be used to reach Manipal University.  
   
  By Road  
 Jaipur is well linked by a good network of roadways and road transport to all the important cities. There are excellent bus services between Jaipur – Delhi by Rajasthan State Road Transport Corporation with buses approximately running every half an hour both ways. A bus journey typically takes 6 hours by (Volvo) or 6- 7 hrs by other deluxe buses. Travel by car from Delhi to Jaipur takes about 5 hours. The Jaipur bus stand is situated 25 Kms. away from Manipal University Jaipur (MUJ).  

 Organizing Committee  
  
  Chief Patron   
 S. Vaitheeswaran, Chairperson, Manipal University Jaipur, India 
   
  Patron   
 G. K. Prabhu, President, Manipal University Jaipur, India 
   
  Co-Patron(s)   
 Jawahar Mal Jangir, Pro-President, Manipal University Jaipur, India 
  Arun Shanbhag, Dean FOE, Manipal University Jaipur, India 
  Nitu Bhatnagar, Registrar, Manipal University Jaipur, India 
   
  Honorary Chair   
 Rajveer Singh Shekhawat, Technical Advisor, Persius Ou, Tallinn, Estonia 
   
  General Chair   
 Sandeep Chaurasia, Director SCSE, Manipal University Jaipur, India 
  Manoj Kumar Bohra, Manipal University Jaipur, India 
   
  Co-General Chair   
 Atilla Elci, Chair SWE Dept., Hasan Kalyoncu University, Türkiye 
   
  Oversight Committee   
 Mahesh Bundele, Poornima College of Engineering, Jaipur, India 
  Rajnish Sharma, Chitkara University, Chandigarh, India 
  Chakradhar C Reddy, Indian Institute of Technology, Ropar, India 
  Pradeep K Gupta, Jaypee University of Information Technology, Waknaghat, India 
  Ashu Verma, Indian Institute of Technology, Delhi, India 
   
  Technical Program Committee Chair   
 Parvez Faruki, AVPTI Rajkot, India 
  Sajal Bhatia, Sacred Heart University, USA 
   
  Technical Program Committee Co-chair   
 Vijaypal Singh Dhaka, Director SCCE, Manipal University Jaipur, India 
  Sumit Srivastava, Director SIT, Manipal University Jaipur, India 
  Andrei Petrovski, Robert Gordon University, United Kingdom 
  Alexander Chefranov, Eastern Mediterranean University, TRNC 
  Maxim Anikeev, Fraunhofer Institute for Secure Information Technology, Germany 
  Philipp Reinecke, Cardiff University, United Kingdom 
  Hossain Shahriar, Kennesaw State University, USA 
  Behnam Rahnama, Medis Inc., Iran 
  Josef Pieprzyk,CSIRO, Australia, and Polish Academy of Sceiences, Poland 
   
  Local Organizing Chair(s)   
 Neha Chaudhary, Manipal University Jaipur, India 
  Santosh K. Vishwakarma, Manipal University Jaipur, India 
   
  Convener(s)   
 Arjun Singh, Manipal University Jaipur, India 
  Mahesh Jangid, Manipal University Jaipur, India 
   
  Co-convener(s)   
 Ankit Vishnoi, Symbiosis Institute of Technology, Symbiosis International (Deemed) University, Pune 
  Somya Goyal, Manipal University Jaipur, India 
   
  Finance Committee   
 Anita Shrotriya, Manipal University Jaipur, India 
  Nirmal Kumar Gupta, Manipal University Jaipur, India 
  Amit Bairwa, Manipal University Jaipur, India 
   
  Publication Committee   
 Sunil Kumar, Manipal University Jaipur, India 
  Renu Kumawat, Manipal University Jaipur, India 
  Deepika Shekhawat, Manipal University Jaipur, India 
  Yadvendra Pratap Singh, Manipal University Jaipur, India 
  Neelam Chaplot, Manipal University Jaipur, India 
  Mayank Kumar Jain, Manipal University Jaipur, India 
  Anshika Malsaria, Manipal University Jaipur, India 
   
  Registration & Stage Committee   
 Bali Devi, Manipal University Jaipur, India 
  Kusum Lata Jain, Manipal University Jaipur 
  Deepika Shekhawat, Manipal University Jaipur, India 
  Anju Yadav, Manipal University Jaipur, India 
  Sakshi Shringi, Manipal University Jaipur, India 
  Babita Tiwari, Manipal University Jaipur, India 
  Rajesh Kaswan, Manipal University Jaipur, India 
   
  Promotion Committee   
 Amit Garg, Manipal University Jaipur, India 
  Vivek Sharma, Manipal University Jaipur, India 
  Shalini Puri, Manipal University Jaipur, India 
  Man Mohan Sharma, Manipal University Jaipur 
  Xavier Bellekens, Strathclyde University, Scotland 
  Şerif Bahtiyar, Istanbul Technical University 
  Tahir Sandıkkaya, Istanbul Technical University, Turkey 
  Rajan Shankaran, Macquarie University, Australia 
  Benjamin NGUYEN, INSA/LIFO CVL, France. 
   
  Hospitality and Food Committee   
 Venkatesh Gauri Shankar, Manipal University Jaipur, India 
  Pooja Gupta, Manipal University Jaipur, India 
  Aditya Sinha, Manipal University Jaipur, India 
  Jayesh Gangrade, Manipal University Jaipur, India 
   
  Technical Sessions Committee   
 Neha V Sharma, Manipal University Jaipur, India 
  Varun Tiwari, Manipal University Jaipur, India 
  Ginika Mahajan, Manipal University Jaipur, India 
  Tarun Jain, Manipal University Jaipur, India 
  Deepti Sharma, Manipal University Jaipur, India 
  Satyabrata Roy, Manipal University Jaipur, India 
  Kavita Jhajharia, Manipal University Jaipur, India 
  Rahul Saxena, Manipal University Jaipur, India 
  Avani Sharma, Manipal University Jaipur, India 
   
  E-presence, Website and Informatics Support   
 Amin Partow, Medis Inc., Iran 
  Hanieh Nasirpour, Medis Inc., Iran 

 Atilla Elci  

 Close    

 Parvez Faruki  

  https://sites.google.com/view/parvezkfaruki/    
 Close    

 Advisory Committee  
 Imed Romdhani, Edinburgh Napier University, UK. 
  Anis Koubaa, Prince Sultan University, KSA. 
  Faouzi Zarai, ENET’Com, Tunisia. 
  Bart Preneel, Katholieke Universiteit Leuven, Belgium 
  Bülent Örencik, Beykent University, Turkey 
  Cetin Kaya Koc, University of California Santa Barbara, USA 
  Edward Dawson, Queensland University of Technology, Australia 
  Elisa Bertino, Purdue University, USA 
  N. Balakrishnan, IISc Bangalore, India 
  Willy Susilo, University of Wollongong, Australia 
  Alexander Shelupanov, Tomsk State University for Control Systems and Radio Electronics, Russia 

 Past Events & Special issues  
 Previous SIN Conf events and their proceedings (see below for special issues and books):  
  
  International Confreence On Secutity Of Information and Networks, 11–13 November 2022 Sousse, Tunisia (SIN 2022) | Proceeding | @IEEE Xplore. 
  Read Summary   
   
  International Conference On Security Of Information and Networks, 15–17 December 2021 Edinburgh, Scotland and Gaziantep, Turkey (SIN 2021) | . Proceeding | @IEEE Xplore. 
  Read Summary   
   
  International Conference On Security Of Information and Networks, 4-7 November 2020 Istanbul, Turkey (SIN 2020) | . Proceeding | @ACM DL. 
  Read Summary   
   
  International Conference On Security Of Information and Networks, 12-15 September 2019 Sochi, Krasnodar Region, Russia (SIN 2019) | . Proceeding | @ACM DL. | Photo Gallery 
   
  International Conference On Security Of Information and Networks, 10-12 September 2018 Cardiff University, Main Building, Cardiff (SIN 2018) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 13-15 October 2017 Manipal University Jaipur, Rajasthan, India MNIT, Jaipur, India (SIN 2017) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 20-22 July 2016, New Jersey, USA (SIN 2016) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 8-10 September 2015, Sochi, Russia (SIN 2015) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 9-11 September 2014, Glasgow, United Kingdom (SIN 2014) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 26-28 November 2013, Aksaray, Turkey (SIN 2013) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 22-27 October 2012, Jaipur, India (SIN 2012) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 14-19 November 2011, Sydney, Australia (SIN 2011) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 7-11 September 2010, Taganrog, Rostov Region Russia (SIN 2010) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 6-10 October 2009, Gazimagusa, TRNC, North Cyprus (SIN 2009) | . Proceeding | @ACM DL | . 
   
  International Conference on Security of Information and Networks, 8-10 May 2007, Gazimagusa, TRNC North Cyprus (SIN 2007) | . Proceeding | @Trafford Publishing | . 

 International Conference on Security of Information and Networks series  
  
  SINConf 2020  
   
 Conference version: 13 
  Hosted Institute and Venue: Sponsored by Istanbul Technical University, Istanbul, Türkiye, and Hasan Kalyoncu University, Gaziantep, Türkiye. Hosted by Istanbul Technical University, Istanbul, Türkiye. Held Online. 
  Received Paper: 46 submissions 
  International papers:No distinction is made between national/international papers.  
 National Papers:  
 Accepted Paper: 20 full papers 
  International papers: No distinction is made between national/international papers.  
 National Papers: Proceedings by ACM Press  
 Number of participants: International and National: totally 68 online 
    
 Close    

 International Conference on Security of Information and Networks series  
  
  SINConf 2021  
   
 Conference version: 14 
  Hosted Institute and Venue: Sponsored by Edinburgh Napier University, Edinburgh, UK, and Hasan Kalyoncu University, Gaziantep, Türkiye. Hosted by Edinburgh Napier University, Edinburgh, UK. Held Online. 
  Received Paper: 51 submissions 
  International papers:No distinction is made between national/international papers.  
 National Papers:Proceedings by IEEE Xplore.  
 Accepted Paper: 21 full, 8 short 
  International papers: No distinction is made between national/international papers.  
 National Papers: No distinction is made between national/international papers  
 Number of participants: International and National: totally 62 online 
    
 Close    

 International Conference on Security of Information and Networks series  
  
  SINConf 2022  
   
 Conference version: 15 
  Hosted Institute and Venue: Sponsored by the University of Sfax, Tunisia, IEEE Tunisia Section, IEEE Tunisia Computer Chapter, IEEE Council on RFID Tunisia Chapter, ATRS Tunisian Association for Scientific Research, and Hasan Kalyoncu University, Gaziantep, Türkiye. Venue: IBEROSTAR Diar Andalous Hotel, The city of Sousse, Tunisia, and Online. 
  Received Paper: 62 submissions 
  International papers:No distinction is made between national/international papers.  
 National Papers:No distinction is made between national/international papers.  
 Proceedings by IEEE Xplore.  
 Accepted Paper: 22 full, 9 short 
  International papers: No distinction is made between national/international papers.  
 National Papers: No distinction is made between national/international papers  
 Number of participants: International and National: totally 32 onsite, 24 online 
    
 Close    

 Dr. Arjun Singh: 9602285688   
 Dr. Mahesh Jangid: 9799969068   
 Email: sinconf2023@gmail.com   
 sinconf@sinconf.org   

 Copyright © 2024 All rights reserved  

    Call for papers data:Not Found  
 The requested URL was not found on this server.  
  Important dates data

24. Conference SODA_2:
Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Conferences & Events 
  SIAM Conferences 
  SODA25 
  Program 

 ACM-SIAM Symposium on Discrete Algorithms (SODA25)   
 Program  
   
 Related Links  
 SODA25 Home 
  Registration 
  Lodging & Support 
  Submissions 

 Program & Abstracts   
 Put your schedule together! Learn more about what's happening at the conference and when.   
   
 Invited Presentations   
 See who's giving the invited presentations and decide which you'll add to your schedule.   
   
 Student Information   
 Learn more about the many activities and sessions where students can meet peers and professionals in the field!   
   
 Special Events   
 Learn more about prize lectures and other events that will allow you to network, learn, and discover new ideas!   
   
 Accepted Papers   
 View the list of accepted presentations.   
   
 Exhibits   
 Find out which companies will be showcasing their newest products and services onsite!   

 Show more    

 About SIAM Conferences  
   
 SIAM conferences are a place to learn about timely topics in the mathematical sciences and be part of a community exchanging ideas and expanding their networks across academia, industry, government, and labs.  
 Learn More    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Call for papers data:  Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Conferences & Events 
  SIAM Conferences 
  SODA25 
  Program 
  Accepted Papers 

 ACM-SIAM Symposium on Discrete Algorithms (SODA25)   
 Accepted Papers  
   
 Related Links  
 SODA25 Home 
  Registration 
  Lodging & Support 
  Program 
  Submissions 

 This list is provided for reference until the online program becomes available. Title and author information appears as originally submitted; updates will not  be made to this page. The online program will reflect the most up-to-date presentation details and is scheduled for posting in November.  
 Renyi-infinity constrained sampling with d^3 membership queries  
 Yunbum Kook (Georgia Institute of Technology); Matthew S. Zhang (University of Toronto)  
 Lipschitz Continuous Algorithms for Covering Problems  
 Soh Kumabe (CyberAgent); Yuichi Yoshida (National Institute of Informatics)  
 Linear equations with monomial constraints and decision problems in abelian-by-cyclic groups  
 Ruiwen Dong (Saarland University)  
 Minimum Convex Hull and Maximum Overlap of Two Convex Polytopes  
 Mook Kwon Jung, Seokyun Kang, Hee-Kap Ahn (POSTECH)  
 Near-Optimal Quantum Algorithms for Approximate Pattern Matching  
 Tomasz Kociumaka (Max Planck Institute for Informatics); Jakob Nogler (ETH Zurich); Philip Wellnitz (National Institute of Informatics)  
 Streaming Algorithms via Local Algorithms for Maximum Directed Cut  
 Raghuvansh R. Saxena (TIFR); Noah Singer (Carnegie Mellon University); Madhu Sudan (Harvard); Santhoshini Velusamy (Toyota Technological Institute at Chicago)  
 Inapproximability of Maximum Diameter Clustering for Few Clusters  
 Ashwin Padaki (Columbia University); Henry Fleischmann (University of Michigan); Karthik C. S. (Rutgers University); Kyrylo Karlov (Charles University); Stepan Zharkov (Stanford University)  
 Approximately Counting Knapsack Solutions in Subquadratic Time  
 Weiming Feng (ETH Zurich); Ce Jin (MIT)  
 A Fast Algorithm for Computing Zigzag Representatives  
 Tamal K. Dey (Department of Computer Science, Purdue University); Tao Hou (Department of  
  Computer Science, University of Oregon); Dmitriy Morozov (Lawrence Berkeley National Laboratory)  
 Potential Hessian Ascent: The Sherrington-Kirkpatrick Model  
 Juspreet Singh Sandhu (University of California, Santa Cruz); David Jekel (University of Copenhagen, Denmark); Jonathan Shi (University of California San Diego)  
 New Applications of 3SUM-Counting in Fine-Grained Complexity and Pattern Matching  
 Nick Fischer (INSAIT, University of Sofia "St. Kliment Ohridski”); Ce Jin, Yinzhan Xu (MIT)  
 Competitive strategies to use "warm start" algorithms with predictions  
 Avrim Blum (Toyota Technological Institute at Chicago); Vaidehi Srinivas (Northwestern University)  
 From Graph Properties to Graph Parameters: Tight Bounds for Counting on Small Subgraphs  
 Simon Doring (Max Planck Institute for Informatics); Daniel Marx (CISPA Helmholtz Center for Information Security); Philip Wellnitz (National Institute of Informatics)  
 Partitioning a Polygon Into Small Pieces  
 Mikkel Abrahamsen, Nichlas Langhoff Rasmussen (University of Copenhagen)  
 Computing the second and third systoles of a combinatorial surface  
 Matthijs Ebbens (University of Cologne); Francis Lazarus (Universite Grenoble Alpes)  
 A Multi-Dimensional Online Contention Resolution Scheme for Revenue Maximization  
 Shuchi Chawla (UT Austin); Dimitrios Christou (University of Texas at Austin); Trung Dang (UT Austin); Zhiyi Huang (University of Texas at Austin); Gregory Kehne (Washington University in St. Louis); Rojin Rezvan (University of Texas at Austin)  
 Hiring for An Uncertain Task: Joint Design of Information and Contracts  
 Matteo Castiglioni (Politecnico di Milano); Junjie Chen (City University of Hong Kong)  
 An Efficient Uniqueness Theorem for Overcomplete Tensor Decomposition  
 Pascal Koiran (Ecole Normale Superieure de Lyon)  
 Improved Bounds for Fully Dynamic Matching via Ordered Ruzsa-Szemeredi Graphs  
 Sepehr Assadi (University of Waterloo); Sanjeev Khanna (University of Pennsylvania); Peter Kiss (University of Warwick)  
 Private Mean Estimation with Person-Level Differential Privacy  
 Sushant Agarwal (Northeastern University); Gautam Kamath (University of Waterloo); Mahbod Majid (Carnegie Mellon University); Argyris Mouzakis (University of Waterloo); Rose Silver, Jonathan Ullman (Northeastern University)  
 Testing Approximate Stationarity Concepts for Piecewise Affine Functions  
 Lai Tian, Anthony Man-Cho So (The Chinese University of Hong Kong)  
 Balancing Notions of Equity: Trade-offs Between Fair Portfolio Sizes and Achievable Guarantees  
 Swati Gupta (MIT); Jai Moondra, Mohit Singh (Georgia Tech)  
 A Lower Bound for Light Spanners in General Graphs  
 Greg Bodwin, Jeremy Flics (University of Michigan)  
 The Johnson-Lindenstrauss Lemma for Clustering and Subspace Approximation: From Coresets to Dimension Reduction  
 Erik Waingarten (University of Pennsylvania); Moses Charikar (Stanford University)  
 A topological proof of the Hell-Nesetril dichotomy  
 Sebastian Meyer (TU Dresden, Germany); Jakub Oprsal (University of Birmingham, UK)  
 A Subexponential Time Algorithm for Makespan Scheduling of Unit Jobs with Precedence Constraints  
 Jesper Nederlof (Utrecht University); Celine Swennenhuis (Eindhoven University of Technology); Karol Wegrzycki (Saarland University and Max Planck Institute for Informatics)  
 Maximum Span Hypothesis: A Weaker Assumption than Gap-ETH for Parameterized Complexity  
 Karthik C. S. (Rutgers University); Subhash Khot (NYU)  
 Massively Parallel Minimum Spanning Tree in General Metric Spaces  
 Amir Azarmehr, Soheil Behnezhad (Northeastern University); Rajesh Jayaram, Jakub Lacki, Vahab Mirrokni, Peilin Zhong (Google Research)  
 Local Lipschitz Filters for Bounded-Range Functions with Applications to Arbitrary Real-Valued Functions  
 Jane Lange (MIT); Ephraim Linder, Sofya Raskhodnikova (Boston University); Arsen Vasilyan (MIT)  
 An Efficient Regularity Lemma for Semi-Algebraic Hypergraphs  
 Natan Rubin (Ben Gurion University)  
 A Reduction from Multi-Parameter to Single-Parameter Bayesian Contract Design  
 Matteo Castiglioni (Politecnico di Milano); Junjie Chen, Minming Li (City University of Hong Kong); Haifeng Xu (University of Chicago, Google Research); Song Zuo (Google Research)  
 New Separations and Reductions for Directed Hopsets and Preservers  
 Gary Hoppenworth (University of Michigan); Yinzhan Xu, Zixuan Xu (MIT)  
 Tree-Packing Revisited: Faster Fully Dynamic Min-Cut and Arboricity  
 Tijn de Vos (University of Salzburg); Aleksander Bjorn Grodt Christiansen (Technical University of Denmark, DTU)  
 Parameterizing the quantification of CMSO: model checking on minor-closed graph classes  
 Ignasi Sau (LIRMM, Univ Montpellier, CNRS, Montpellier, France); Giannοs Stamoulis (Institute of Informatics, University of Warsaw, Poland); Dimitrios M. Thilikos (LIRMM, Univ Montpellier, CNRS, Montpellier, France)  
 Connectivity Labeling Schemes for Edge and Vertex Faults via Expander Hierarchies  
 Yaowei Long, Seth Pettie, Thatchaphol Saranurak (University of Michigan)  
 Parks and Recreation: Color Fault-Tolerant Spanners Made Local  
 Merav Parter, Asaf Petruschka, Shay Sapir, Elad Tzailk (Weizmann Institute)  
 Approximating Traveling Salesman Problems Using a Bridge Lemma  
 Martin Bohm (University of Wroclaw); Zachary Friggstad (University of Alberta); Tobias Momke (University of Augsburg); Joachim Spoerhase (University of Liverpool, United Kingdom)  
 Top-k Document Retrieval in Compressed Space  
 Gonzalo Navarro (University of Chile); Yakov Nekrich (Michigan Technological University)  
 Outlier-robust Mean Estimation near the Breakdown Point via Sum-of-Squares  
 Hongjie Chen, S Deepak Narayanan, David Steurer (ETH Zurich)  
 A Dichotomy Hierarchy for Linear Time Subgraph Counting in Bounded Degeneracy Graphs  
 Daniel Paul-Pena, C. Seshadhri (University of California, Santa Cruz)  
 Universal Perfect Samplers for Incremental Streams  
 Seth Pettie, Dingyu Wang (University of Michigan)  
 Losing Treewidth In The Presence Of Weights  
 Michal Wlodarczyk (University of Warsaw)  
 Embedding Planar Graphs into Graphs of Treewidth O(log^3 n)  
 Hsien-Chih Chang (Dartmouth College); Vincent Cohen-Addad (Google Research); Jonathan Conroy (Dartmouth College); Hung Le (University of Massachusetts Amherst); Marcin Pilipczuk, Michal Pilipczuk (University of Warsaw, Poland)  
 Multi-Agent Combinatorial Contracts  
 Paul Duetting (Google); Tomer Ezra (Harvard); Thomas Kesselheim (University of Bonn); Michal Feldman (Tel Aviv University)  
 Improving the Leading Constant of Matrix Multiplication  
 Hantao Yu, Josh Alman (Columbia University)  
 Min-CSPs on Complete Instances  
 Aditya Anand, Euiwoong Lee, Amatya Sharma (University of Michigan - Ann Arbor)  
 Tight Streaming Lower Bounds for Deterministic Approximate Counting  
 Yichuan Wang (Tsinghua University)  
 Low Degree Local Correction Over the Boolean Cube  
 Prashanth Amireddy (Harvard University); Amik Raj Behera (Aarhus University); Manaswi Paraashar, Srikanth Srinivasan (University of Copenhagen); Madhu Sudan (Harvard University)  
 Lift-and-Project Integrality Gaps for Santa Claus  
 Etienne Bamas (ETH AI Center, Zurich, Switzerland)  
 Deterministic Edge Connectivity and Max Flow using Subquadratic Cut Queries  
 Aditya Anand, Thatchaphol Saranurak (University of Michigan); Yunfan Wang (Tsinghua University, IIIS)  
 Forall-exist statements in pseudopolynomial time  
 Friedrich Eisenbrand, Eleonore Bach (EPFL); Robert Weismantel (ETH Zurich); Thomas Rothvoss (University of Washington)  
 Faster Vizing and Near-Vizing Edge Coloring Algorithms  
 Sepehr Assadi (University of Waterloo)  
 Matching Composition and Efficient Weight Reduction in Dynamic Matching  
 Aaron Bernstein (Rutgers University); Jiale Chen (Stanford University); Aditi Dudeja (University of Salzburg); Zachary Langley (Rutgers University); Aaron Sidford, Ta-Wei Tu (Stanford University)  
 Finding irrelevant vertices in linear time on bounded-genus graphs  
 Petr A. Golovach (University of Bergen); Stavros G. Kolliopoulos (Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece); Giannos Stamoulis (Institute of Informatics, University of Warsaw, Poland); Dimitrios Thilikos (LIRMM, Univ Montpellier, CNRS, Montpellier, France)  
 Quartic quantum speedups for planted inference  
 Alexander Schmidhuber (MIT, Google); Ryan O'Donnell (CMU); Robin Kothari, Ryan Babbush (Google)  
 Efficient d-ary Cuckoo Hashing at High Load Factors by Bubbling Up  
 William Kuszmaul, Michael Mitzenmacher (Harvard University)  
 Asynchronous 3-Majority Dynamics with Many Opinions  
 Colin Cooper, Frederik Mallmann-Trenn, Tomasz Radzik (King's College London); Nobutaka Shimizu (Institute of Science Tokyo); Takeharu Shiraga (Chuo University)  
 Subquadratic algorithms in minor-free digraphs: (weighted) distance oracles, decremental reachability, and more  
 Adam Karczmarz (University of Warsaw and IDEAS NCBR); Da Wei Zheng (University of Illinois at Urbana-Champaign)  
 Bounding epsilon-scatter dimension via metric sparsity  
 Romain Bourneuf (ENS de Lyon); Marcin Pilipczuk (University of Warsaw)  
 Almost Tight Bounds for Differentially Private Densest Subgraph  
 Michael Dinitz (Johns Hopkins University); Satyen Kale, Silvio Lattanzi, Sergei Vassilvitskii (Google Research)  
 On the Uniqueness of Bayesian Coarse Correlated Equilibria in Standard First-Price and All-Pay Auctions  
 Mete Seref Ahunbay, Martin Bichler (Technical University of Munich)  
 Relative-error monotonicity testing  
 Xi Chen (Columbia University); Anindya De (University of Pennsylvania); Yizhi Huang, Yuhao Li, Shivam Nadimpalli, Rocco A. Servedio, Tianqi Yang (Columbia University)  
 Tree Independence Number IV. Even-hole-free Graphs  
 Maria Chudnovsky (Princeton University, USA); Peter Gartland (University of California at Santa Barbara); Sepehr Hajebi (University of Waterloo); Daniel Lokshtanov (University of California at Santa Barb); Sophie Spirkl (University of Waterloo)  
 Approximating Competitive Equilibrium by Nash Welfare  
 Jugal Garg (University of Illinois at Urbana Champaign); Yixin Tao (Shanghai University of Finance and Economics); Laszlo A. Vegh (Department of Mathematics, London School of Economics)  
 Fixed-Parameter Tractability of Hedge Cut  
 Fedor V. Fomin, Petr A. Golovach (University of Bergen); Tuukka Korhonen (University of Copenhagen); Daniel Lokshtanov (University of California, Santa Barbara); Saket Saurabh (IMSc)  
 Online Scheduling via Gradient Descent for Weighted Flow Time Minimization  
 Qingyun Chen, Sungjin Im, Aditya Petety (University of California, Merced, USA)  
 Spectral Independence Beyond Total Influence on Trees and Related Graphs  
 Xiaoyu Chen (Nanjing University); Xiongxin Yang (Northeast Normal University); Yitong Yin, Xinyuan Zhang (Nanjing University)  
 More Efficient Approximate k-wise Independent Permutations from Random Reversible Circuits via log-Sobolev Inequalities.  
 Lucas Gretta (UC Berkeley); William He (Carnegie Mellon University); Angelos Pelecanos (UC Berkeley)  
 Sumsets, 3SUM, Subset Sum: Now for Real!  
 Nick Fischer (INSAIT, University of Sofia "St. Kliment Ohridski”)  
 Fast and Simple Sorting Using Partial Information  
 Bernhard Haeupler (INSAIT Bulgaria & ETH Zurich); Richard Hladik (ETH Zurich); John Iacono (Universite libre de Bruxelles); Vaclav Rozhon (INSAIT Bulgaria); Robert Tarjan (Princeton University); Jakub Tetek (University of Copenhagen)  
 Spanners in Planar Domains via Steiner Spanners and non-Steiner Tree Covers  
 Sujoy Bhore (IIT Bombay); Balazs Keszegh (Renyi institute); Andrey Kupavskii (CNRS); Hung Le (University of Massachusetts, Amherst, USA); Alexandre Louvet (Universite Sorbonne Paris Nord); Domotor Palvolgyi (ELTE); Csaba D. Toth (CSUN)  
 Embedding Probability Distributions into Low Dimensional ell_1: Tree Ising Models via Truncated Metrics  
 Moses Charikar, Spencer Compton, Chirag Pabbaraju (Stanford University)  
 Beyond 2-approximation for k-Center in Graphs  
 Ce Jin, Yael Kirkpatrick, Virginia Vassilevska Williams (MIT); Nicole Wein (University of Michigan)  
 Complexity of polytope diameters via perfect matchings  
 Christian Nobel, Raphael Steiner (ETH Zurich)  
 Highway Dimension: a Metric View  
 Andreas Emil Feldmann (University of Sheffield); Arnold Filtser (Bar Ilan University)  
 Dynamic Consistent k-Center Clustering with Optimal Recourse  
 Antonis Skarlatos, Sebastian Forster (University of Salzburg)  
 Nearly Tight Bounds on Testing of Metric Properties  
 Yiqiao Bao, Sampath Kannan, Erik Waingarten (University of Pennsylvania)  
 Understanding Memory-Regret Trade-Off for Streaming Stochastic Multi-Armed Bandits  
 Yuchen He, Zichun Ye, Chihao Zhang (Shanghai Jiao Tong University)  
 Improved List Size for Folded Reed-Solomon Codes  
 Shashank Srivastava (TTIC)  
 A Refutation of the Pach-Tardos Conjecture for 0-1 Matrices  
 Seth Pettie (University of Michigan); Gabor Tardos (Renyi Institute, Budapest)  
 Optimal Mixing for Randomly Sampling Edge Colorings on Trees Down to the Max Degree  
 Charlie Carlson (UCSB); Xiaoyu Chen (Nanjing University); Weiming Feng (ETH Zurich); Eric Vigoda (University of California, Santa Barbara)  
 Constraint Satisfaction Problems with Advice  
 Suprovat Ghoshal (Northwestern University and TTIC); Konstantin Makarychev (Northwestern University); Yury Makarychev (TTIC)  
 Triply efficient shadow tomography  
 Robbie King (Caltech); David Gosset (University of Waterloo); Robin Kothari, Ryan Babbush (Google)  
 Faster Linear Systems and Matrix Norm Approximation via Multi-level Sketched Preconditioning  
 Michal Derezinski (University of Michigan); Christopher Musco (New York University); Jiaming Yang (University of Michigan, Ann Arbor)  
 Fully Dynamic Algorithms for Graph Spanners via Low-Diameter Router Decomposition  
 Julia Chuzhoy (Toyota Technological Institute at Chicago); Merav Parter (Weizmann Institute of Science)  
 New Philosopher Inequalities for Online Bayesian Matching, via Pivotal Sampling  
 Mark Braverman (Princeton); Mahsa Derakhshan (Northeastern University); Tristan Pollner, Amin Saberi (Stanford University); David Wajc (Technion --- Israel Institute of Technology)  
 Nearly Optimal Dynamic Set Cover: Breaking the Quadratic-in-f Time Barrier  
 Anton Bukov, Shay Solomon, Tianyi Zhang (Tel Aviv University)  
 Mean-field Potts and random-cluster dynamics from high-entropy initializations  
 Antonio Blanca (Pennsylvania State University); Reza Gheissari (Northwestern University); Xusheng Zhang (Pennsylvania State University)  
 Path and Intersections: Characterization of Quasi-metrics in Directed Okamura-Seymour Instances  
 Yu Chen (EPFL); Zihan Tan (Rutgers University)  
 Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and all Eccentricities in Graphs  
 Feodor Dragan (Kent State University); Guillaume Ducoffe (National Institute for Research and Development in Informatics); Michel Habib (IRIF, Paris Diderot); Laurent Viennot (Inria, DI ENS)  
 Improved Differentially Private Continual Observation Using Group Algebra  
 Monika Henzinger (IST Austria); Jalaj Upadhyay (Rutgers)  
 A Tight (3/2 + epsilon)-Approximation Algorithm For Demand Strip Packing  
 Franziska Eberle (Technische Universitat Berlin); Felix Hommelsheim (Universitat Bremen); Malin Rau (Chalmers University of Technology); Stefan Walzer (Karlsruhe Institute of Technology)  
 More Asymmetry Yields Faster Matrix Multiplication  
 Josh Alman (Columbia University); Ran Duan (Tsinghua University); Virginia Vassilevska Williams (Massachusetts Institute of Technology); Yinzhan Xu, Zixuan Xu (MIT); Renfei Zhou (CMU)  
 The Change-of-Measure Method, Block Lewis Weights, and Approximating Matrix Block Norms  
 Naren Sarayu Manoj, Max Ovsiankin (Toyota Technological Institute Chicago)  
 Crossing Number in Slightly Superexponential Time  
 Daniel Lokshtanov (University of California Santa Barbara, USA); Fahad Panolan (School of Computing, University of Leeds); Saket Saurabh (IMSc); Roohani Sharma (University of Bergen); Jie Xue (New York University Shanghai); Meirav Zehavi (Ben-Gurion University of the Negev)  
 Clustering to Minimize Cluster-Aware Norm Objectives  
 Martin Herold (Max Planck Institute for Informatics, Saarland Informatics Campus); Joachim Spoerhase (University of Liverpool); Evangelos Kipouridis (Saarland University and Max Planck Institute for Informatics, Saarland Informatics Campus)  
 Flip Dynamics for Sampling Colorings: Improving (11/6 - epsilon) Using A Simple Metric  
 Charlie Carlson, Eric Vigoda (UCSB)  
 On estimating the trace of quantum state powers  
 Yupan Liu (Nagoya University), Qisheng Wang (University of Edinburgh and Nagoya University)  
 Packing Short Cycles  
 Matthias Bentert, Fedor Fomin, Petr A. Golovach (University of Bergen); Tuukka Korhonen (University of Copenhagen); William Lochet (CNRS, LIRMM); Fahad Panolan (University of Leeds); M.S. Ramanujan (University of Warwick); Saket Saurabh (IMSc); Kirill Simonov (Hasso Plattner Institute, University of Potsdam)  
 Near-optimal hierarchical matrix approximation from matrix-vector products  
 Tyler Chen, Feyza Duman Keles (New York University); Diana Halikias (Cornell University); Cameron Musco (University of Massachusetts Amherst); Christopher Musco (New York University); David Persson (EPFL)  
 Lower Bounds for Convexity Testing  
 Xi Chen (Columbia University); Anindya De (University of Pennsylvania); Shivam Nadimpalli, Rocco A. Servedio (Columbia University); Erik Waingarten (University of Pennsylvania)  
 Entropy Regularization and Faster Decremental Matching in General Graphs  
 Jiale Chen, Aaron Sidford, Ta-Wei Tu (Stanford University)  
 Unbreakable Decomposition in Close-to-Linear Time  
 Aditya Anand, Euiwoong Lee (University of Michigan); Jason Li (Carnegie Mellon University); Yaowei Long, Thatchaphol Saranurak (University of Michigan)  
 Parallel Expander Decomposition: Simple, Fast, and Near-Optimal  
 Daoyuan Chen, Simon Meierhans, Maximilian Probst Gutenberg (ETH Zurich); Thatchaphol Saranurak (University of Michigan)  
 Deterministic Online Bipartite Edge Coloring  
 Joakim Blikstad (KTH Royal Institute of Technology & Max Planck Institute for Informatics); Ola Svenssson, Radu Vintan (EPFL); David Wajc (Technion --- Israel Institute of Technology)  
 Relating Interleaving and Frechet Distances via Ordered Merge Trees  
 Thijs Beurskens (TU Eindhoven); Tim Ophelders (Utrecht University); Bettina Speckmann, Kevin Verbeek (TU Eindhoven)  
 Quantum Locally Recoverable Codes  
 Louis Golowich, Venkatesan Guruswami (UC Berkeley)  
  Even Faster (Delta + 1)-Edge Coloring via Shorter Multi-Step Vizing Chains  
  Sayan Bhattacharya (University of Warwick); Martin Costa (Univsersity of Warwick); Shay Solomon, Tianyi Zhang (Tel Aviv University)  
 Exact Thresholds for Noisy Non-Adaptive Group Testing  
 Junren Chen (The University of Hong Kong); Jonathan Scarlett (National University of Singapore)  
 Clustering Mixtures of Bounded Covariance Distributions Under Optimal Separation  
 Ilias Diakonikolas (UW Madison); Daniel M. Kane (University of California, San Diego); Jasper C.H. Lee (University of California, Davis); Thanasis Pittas (UW Madison)  
 Approximating Unrelated Machine Weighted Completion Time Using Iterative Rounding and Computer Assisted Proofs  
 Shi Li (Nanjing University)  
 New Prophet Inequalities via Poissonization and Sharding  
 Elfarouk Harb (University of Illinois at Urbana-Champaign)  
 Majorized Bayesian Persuasion and Fair Selection  
 Siddhartha Banerjee (Cornell); Kamesh Munagala, Yiheng Shen (Duke University); Kangning Wang (Stanford University / Rutgers University)  
 Unweighted Layered Graph Traversal: Passing a Crown via Entropy Maximization  
 Xingjian Bai, Christian Coester (University of Oxford); Romain Cosson (Inria, Paris)  
 Tolls for Dynamic Equilibrium Flows  
 Julian Schwarz, Lukas Graf, Tobias Harks (University of Passau)  
 Having Hope in Missing Spanners: New Distance Preservers and Light Hopsets  
 Shimon Kogan, Merav Parter (Weizmann)  
 Recognizing Sumsets is NP-Complete  
 Amir Abboud (Weizmann Institute of Science and INSAIT, University of Sofia "St. Kliment Ohridski"); Nick Fischer (INSAIT, University of Sofia "St. Kliment Ohridski"); Ron Safier, Nathan Wallheimer (Weizmann Institute of Science)  
 Fine-Grained Optimality of Partially Dynamic Shortest Paths and More  
 Barna Saha (University of California San Diego); Virginia Vassilevska Williams, Yinzhan Xu (Massachusetts Institute of Technology); Christopher Ye (University of California San Diego)  
 A Quantum Speed-Up for Approximating the Top Eigenvectors of a Matrix  
 Yanlin Chen (CWI); Andras Gilyen (Renyi Institute Budapest); Ronald de Wolf (CWI and University of Amsterdam)  
 Fast Deterministic Chromatic Number under the Asymptotic Rank Conjecture  
 Andreas Bjorklund (ITU Copenhagen, Denmark); Radu Curticapean (University of Regensburg, Germany and ITU Copenhagen, Denmark); Thore Husfeldt (Basic Algorithms Research Copenhagen, ITU Copenhagen, Denmark); Petteri Kaski (Aalto University, Finland); Kevin Pratt (New York University, USA)  
 Eulerian Graph Sparsification by Effective Resistance Decomposition  
 Arun Jambulapati (University of Michigan); Sushant Sachdeva (University of Toronto); Aaron Sidford (Stanford University); Kevin Tian (University of Texas at Austin); Yibin Zhao (University of Toronto)  
 Facet-Hamiltonicity  
 Hugo Akitaya (University of Massachusetts Lowell); Jean Cardinal (Universite Libre de Bruxelles); Stefan Felsner (TU Berlin); Linda Kleist (TU Braunschweig); Robert Lauff (TU Berlin)  
 An analogue of Reed's conjecture for digraphs  
 Ken-ichi Kawarabayashi (National Institute of Informatics); Lucas Picasarri-Arrieta (Universite Cote d'Azur)  
 Weak coloring numbers of minor-closed graph classes  
 Jedrzej Hodor (Jagiellonian University); Hoang La (Universite Paris-Saclay); Piotr Micek (Jagiellonian University); Clement Rambaud (Universite Cote d'Azur)  
 Randomized Greedy Online Edge Coloring Succeeds for Dense and Randomly-Ordered Graphs  
 Rashmika Goswami (Rutgers University); Aditi Dudeja (University of Salzburg); Michael Saks (Rutgers University)  
 Tight Sampling Bounds for Eigenvalue Approximation  
 William William (Swartworth); David P. Woodruff (Carnegie Mellon University)  
 Differentiable Approximations for Distance Queries  
 Ahmed Abdelkader (Google); David Mount (University of Maryland)  
 Clock Auctions Augmented with Unreliable Advice  
 Vasilis Gkatzelis (Drexel University); Daniel Schoepflin (Rutgers University); Xizhi Tan (Drexel University)  
 Streaming and Communication Complexity of Load-Balancing via Matching Contractors  
 Sepehr Assadi (University of Waterloo); Aaron Bernstein, Zach Langley (Rutgers University); Lap Chi Lau, Robert Wang (University of Waterloo)  
 Fully Dynamic (Delta + 1) Coloring Against Adaptive Adversaries  
 Soheil Behnezhad, Rajmohan Rajaraman, Omer Wasim (Northeastern University)  
 Unique-neighbor Expanders with Better Expansion for Polynomial-sized Sets  
 Yeyuan Chen (University of Michigan)  
 A coarse Erdos-Posa theorem  
 Jungho Ahn (Korea Institute for Advanced Study (KIAS)); J. Pascal Gollin (Institute for Basic Science (IBS)); Tony Huynh (Sapienza University of Rome); O-joung Kwon (Hanyang University and Institute for Basic Science (IBS))  
 The Submodular Santa Claus Problem  
 Etienne Bamas (ETH Zurich); Sarah Morell (Technische Universitat Berlin); Lars Rohwedder (Maastricht University)  
 Breaking the Two Approximation Barrier for Various Consensus Clustering Problems  
 Debarati Das (Pennsylvania State University); Amit Kumar (Indian Institute of Technology, Delhi)  
 Average-Case Hardness of Parity Problems: Orthogonal Vectors, k-SUM and More  
 Mina Dalirrooyfard (Morgan Stanley); Andrea Lincoln (Boston University); Barna Saha (University of California, San Diego); Virginia Vassilevska Williams (Massachusetts Institute of Technology)  
 (Almost) Ruling Out SETH Lower Bounds for All-Pairs Max-Flow  
 Ohad Trabelsi (Toyota Technological Institute at Chicago)  
 Strict Self-Assembly of Discrete Self-Similar Fractals in the abstract Tile-Assembly Model  
 Florent Becker (Universite d'Orleans); Daniel Hader, Matthew J. Patitz (University of Arkansas)  
 Polynomial-Time Classical Simulation of Noisy IQP Circuits with Constant Depth  
 Joel Rajakumar, James Watson (University of Maryland); Yi-Kai Liu (NIST / University of Maryland)  
 New Approximation Algorithms and Reductions for n-Pairs Shortest Paths and All-Nodes Shortest Cycles  
 Shiri Chechik, Itay Hoch, Gur Lifshitz (Tel-Aviv University)  
 Improved Online Reachability Preservers  
 Greg Bodwin, Tuong Le (University of Michigan)  
 Prophet Inequalities: Competing with the Top ell Items is Easy  
 Mathieu Molina (Inria, FairPlay team); Vianney Perchet (ENSAE & criteo AI Lab); Patrick Loiseau (Inria, FairPlay team); Nicolas Gast (Inria & Univ. Grenoble Alpes)  
 An Elementary Predictor Obtaining 2 sqrt(T) + 1 Distance to Calibration  
 Eshwar Ram Arunachaleswaran, Natalie Collina, Aaron Roth, Mirah Shi (University of Pennsylvania)  
 Beating Bellman’s Algorithm for Subset Sum  
 Karl Bringmann (Saarland University and Max-Planck-Institute for Informatics); Nick Fischer (INSAIT, University of Sofia "St. Kliment Ohridski”); Vasileios Nakos (National and Kapodistrian University of Athens and Archimedes/ Athena RC)  
 Platforms for Efficient and Incentive-Aware Collaboration  
 Nika Haghtalab (UC Berkeley); Mingda Qiao, Kunhe Yang (University of California, Berkeley)  
 A Polylogarithmic Approximation for Directed Steiner Forest in Planar Digraphs  
 Chandra Chekuri (University of Illinois, Urbana-Champaign, USA); Rhea Jain (University of Illinois at Urbana Champaign)  
 Gains-from-Trade in Bilateral Trade with a Broker  
 Suho Shin, Gary Peng (University of Maryland); Ilya Hajiaghayi (Takoma Park Middle School); Mohammad Taghi Hajiaghayi (University of Maryland)  
 Coresets for Constrained Clustering: General Assignment Constraints and Improved Size Bounds  
 Lingxiao Huang (Nanjing University); Jian Li (Tsinghua University); Pinyan Lu (Shanghai University of Finance and Economics); Xuan Wu (Huawei TCS Lab)  
 Faster two-dimensional pattern matching with k mismatches  
 Jonas Ellert (ENS Paris, France); Paweł Gawrychowski, Adam Gorkiewicz (University of Wroclaw, Poland); Tatiana Starikovskaya (ENS Paris, France)  
 Fully Dynamic Approximate Minimum Cut in Subpolynomial Time per Operation  
 Antoine El-Hayek, Monika Henzinger (IST Austria); Jason Li (Carnegie Mellon University)  
 Locally Testable Tree Codes  
 Tamer Mour, Alon Rosen (Bocconi University); Ron Rothblum (Technion)  
 Improved Spectral Density Estimation via Explicit and Implicit Deflation  
 Rajarshi Bhattacharjee (University of Massachusetts Amherst); Rajesh Jayaram (Google Research); Cameron Musco (University of Massachusetts Amherst); Christopher Musco (New York University); Archan Ray (JP Morgan Chase)  
 Sublinear-Round Broadcast without Trusted Setup  
 Andreea B. Alexandru (Duality Technologies); Julian Loss (CISPA Helmholtz Center for Information Security); Charalampos Papamanthou (Yale University); Giorgos Tsimos (University of Maryland); Benedikt Wagner (Ethereum Foundation)  
 Fully-Distributed Byzantine Agreement in Sparse Networks  
 John Augustine (IIT Madras); Fabien Dufoulon (Lancaster University); Gopal Pandurangan (University of Houston)  
 Near-Optimal Relative Error Streaming Quantile Estimation via Elastic Compactors  
 Elena Gribelyuk, Pachara Sawettamalya (Princeton University); Hongxun Wu (UC Berkeley); Huacheng Yu (Princeton University)  
 Frechet Distance in Subquadratic Time  
 Siu-Wing Cheng, Haoqiang Huang (Hong Kong University of Science and Technology)  
 Online Dependent Rounding Schemes for Bipartite Matchings, with Applications  
 Joseph (Seffi) Naor (Technion); Aravind Srinivasan (UMD, College Park); David Wajc (Technion)  
 New Combinatorial Insights for Monotone Apportionment  
 Javier Cembrano (TU Berlin); Jose Correa (Universidad de Chile); Ulrike Schmidt-Kraepelin (TU Eindhoven); Alexandros Tsigonias-Dimitriadis (European Central Bank); Victor Verdugo (Pontificia Universidad Catolica de Chile)  
 On the Decidability of Presburger Arithmetic Expanded with Powers  
 Toghrul Karimov (Max Planck Institute for Software Systems); Florian Luca (Stellenbosch University); Joris Nieuwveld, Joel Ouaknine (Max Planck Institute for Software Systems); James Worrell (University of Oxford)  
 A Tight VC-Dimension Analysis of Clustering Coresets with Applications  
 Vincent Cohen-Addad (Google Research, France); Andrew Draganov (Aarhus University); Matteo Russo (Sapienza, University of Rome); David Saulpic (Universite Paris Cite, CNRS); Chris Schwiegelshohn (Aarhus University)  
 Quasi-Monte Carlo Beyond Hardy-Krause  
 Nikhil Bansal (University of Michigan); Haotian Jiang (University of Chicago)  
 Tight Bounds and Phase Transitions for Incremental and Dynamic Retrieval  
 William Kuszmaul (CMU); Aaron Putterman (Harvard University); Tingqiang Xu, Hangrui Zhou (Tsinghua University); Renfei Zhou (CMU)  
 The Primal Pathwidth SETH  
 Michael Lampis (Universite Paris-Dauphine)  
 Faster single-source shortest paths with negative real weights via proper hop distance  
 Kent Quanrud, Yufan Huang, Peter Jin (Purdue University)  
 A Cut-Matching Game for Constant-Hop Expanders  
 Bernhard Haeupler (INSAIT Bulgaria & ETH Zurich); Jonas Huebotter (ETH Zurich); Mohsen Ghaffari (MIT)  
 Planar graphs in blowups of fans  
 Vida Dujmovic (University of Ottawa, Canada); Gwenael Joret (Universite Libre de Bruxelles); Piotr Micek (Jagiellonian University); Pat Morin (Carleton University); David R. Wood (Monash University)  
 All-Hops Shortest Paths  
 Virginia Vassilevska Williams (Massachusetts Institute of Technology); Zoe Xi, Yinzhan Xu (MIT); Uri Zwick (Tel Aviv University)  
 A Sublinear-Time Algorithm for Nearly-Perfect Matchings in Regular Non-Bipartite Graphs  
 Thomas Hayes (University at Buffalo); Varsha Dani (Rochester Institute of Technology)  
 FPTAS for Holant Problems with Log-Concave Signatures  
 Kun He (Renmin University of China); Zhidan Li, Guoliang Qiu, Chihao Zhang (Shanghai Jiao Tong University)  
 Stronger adversaries grow cheaper forests: online node-weighted Steiner problems  
 Sander Borst (CWI Amsterdam); Marek Elias, Moritz Venzin (Bocconi University)  
 The Power of Proportional Fairness for Non-Clairvoyant Scheduling under Polyhedral Constraints  
 Sven Jager (RPTU Kaiserslautern-Landau, Germany); Alexander Lindermayr, Nicole Megow (University of Bremen, Germany)  
 A discrete analog of Tutte’s barycentric embeddings on surfaces  
 Eric Colin de Verdiere (LIGM, CNRS, Universite Gustave Eiffel, F-77454 Marne-la-Vallee, France); Vincent Despre (Universite de Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France); Loic Dubois (LIGM, Universite Gustave Eiffel, CNRS, F-77454 Marne-la-Vallee, France)  
 Flipping Non-Crossing Spanning Trees  
 Havard Bakke Bjerkevik (University at Albany - SUNY); Linda Kleist (TU Braunschweig); Torsten Ueckerdt (Karlsruhe Institute of Technology); Birgit Vogtenhuber (Graz University of Technology)  
 On the Locality of Hall's Theorem  
 Sebastian Brandt (CISPA Helmholtz Center for Information Security); Yannic Maus (TU Graz); Ananth Narayanan (CISPA Helmholtz Center for Information Security); Florian Schager (TU Graz); Jara Uitto (Aalto University)  
 Solving Polynomial Equations Over Finite Fields  
 Holger Dell (Goethe University Frankfurt and IT University of Copenhagen); Anselm Haak (Paderborn University); Melvin Kallmayer (Goethe University Frankfurt); Leo Wennmann (Maastricht University)  
 PTASes for Euclidean TSP with Unit Disk and Unit Square Neighborhoods  
 SAYAN BANDYAPADHYAY (Portland State University); Katie Clinch (UNSW Sydney); William Lochet (CNRS, LIRMM); Daniel Lokshtanov (University of California Santa Barbara, USA); Saket Saurabh (IMSc); Jie Xue (New York University Shanghai)  
 Efficient Approximation Algorithm for Computing Wasserstein Barycenter under Euclidean Metric  
 Pankaj K Agarwal (Duke University); Sharath Raghvendra (North Carolina State University); Pouyan Shirzadian (Virginia Tech); Keegan Yao (Duke University)  
 Integer programs with nearly totally unimodular matrices: the cographic case  
 Manuel Aprile (Universita di Padova); Samuel Fiorini, Gwenael Joret, Stefan Kober, Michal T. Seweryn (Universite Libre de Bruxelles); Stefan Weltge (Technische Universitat Munchen); Yelena Yuditsky (Universite Libre de Bruxelles)  
 Partial Synchrony for Free: New Upper Bounds for Byzantine Agreement  
 Pierre Civit (EPFL); Muhammad Ayaz Dzulfikar, Seth Gilbert (NUS); Rachid Guerraoui, Jovan Komatovic, Manuel Vidigueira (EPFL); Igor Zablotchi (Mysten Labs)  
 Improved Explicit Near-Optimal Codes in the High-Noise Regimes  
 Xin Li, Songtao Mao (Johns Hopkins University)  
 Improved Shortest Path Restoration Lemmas for Multiple Edge Failures: Trade-offs Between Fault-tolerance and Subpaths  
 Lily Wang, Greg Bodwin (University of Michigan)  
 Quasilinear-time eccentricities computation, and more, on median graphs  
 Pierre Berge (Universite Clermont Auvergne, France); Guillaume Ducoffe (University of Bucharest, Romania); Michel Habib (IRIF, Universite Paris Cite, France)  
 Hermitian Diagonalization in Linear Precision  
 Rikhav Shah (UC Berkeley)  
 Fast Static and Dynamic Approximation Algorithms for Geometric Optimization Problems: Piercing, Independent Set, Vertex Cover, and Matching  
 Sujoy Bhore (IIT Bombay); Timothy M. Chan (UIUC)  
 Prophet Secretary and Matching: the Significance of the Largest Item  
 Ziyun Chen (Tsinghua University); Zhiyi Huang, Dongchen Li (The University of Hong Kong); Zhihao Gavin Tang (Shanghai University of Finance and Economics)  
 Congestion-Approximators from the Bottom Up  
 Jason Li, Satish Rao (UC Berkeley); Di Wang (Google)  
 A Cell Probe Lower Bound for the Predecessor Search Problem in PRAM  
 Peyman Afshani (Aarhus University); Nodari Sitchinava (University of Hawaii at Manoa)  
 Designing Automated Market Makers for Combinatorial Securities: A Geometric Viewpoint  
 Prommy Sultana Hossain (George Mason University); Xintong Wang (Rutgers University); Fang-Yi Yu (George Mason University)  
 Settling the Pass Complexity of Approximate Matchings in Dynamic Graph Streams  
 Sepehr Assadi (University of Waterloo); Soheil Behnezad (Northeastern University); Christian Konrad, Kheeran Naidu (University of Bristol); Janani Sundaresan (University of Waterloo)  
 Faster Approximation Algorithms for Restricted Shortest Paths in Directed Graphs  
 Vikrant Ashvinkumar, Aaron Bernstein (Rutgers University); Adam Karczmarz (University of Warsaw and IDEAS NCBR)  
 Counting Small Induced Subgraphs: Hardness via Fourier Analysis  
 Daniel Neuen (University of Regensburg); Radu Curticapean (University of Regensburg, IT University of Copenhagen)  
 Putting Off the Catching Up: Online Joint Replenishment Problem with Holding and Backlog Costs  
 Benjamin Moseley, Aidin Niaparast (Carnegie Mellon University); R. Ravi (CMU)  
 Parameterized Approximation for Capacitated d-Hitting Set with Hard Capacities  
 Vaishali Surianarayanan, Daniel Lokshtanov (UC Santa Barbara); Saket Saurabh (Institute of Mathematical Science (IMSc)); Jie Xue (New York University Shanghai); Abhishek Sahu (National Institute of Science Education and Research)  

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Important dates data

25. Conference SODA_3:
Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Conferences & Events 
  SIAM Conferences 
  SODA25 
  Lodging & Support 

 ACM-SIAM Symposium on Discrete Algorithms (SODA25)   
 Lodging and Support  
   
 Related Links  
 SODA25 Home 
  Registration 
  Program 
  Submissions 

 General Information   
 Learn more about travel and visa information, what to expect onsite, what's happening in the area, and more!   
   
 Hotel & Transportation   
 Find out about hotel options, deadlines, transportation information, and more.   
   
 Child Care   
 Bringing your kids to the conference? We may be able to help with financial support. Learn more about our child care grants.   
   
 Travel Support   
 We award $240,000+ in conference travel funding yearly to students and early career professionals. Learn more about conference support.   

 About SIAM Conferences  
   
 SIAM conferences are a place to learn about timely topics in the mathematical sciences and be part of a community exchanging ideas and expanding their networks across academia, industry, government, and labs.  
 Learn More    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Call for papers data:  Skip to main content    
       
  Join SIAM 
  Donate 
  Log In 

 Journals 
  Books 
  SIAM Engage 
  Join SIAM 
  Donate 
  Log In 
   
 SIAM News 
  Activity Groups 
  Prizes & Awards 
  Log In 
   
 Publications | Toggle sub-menu | SIAM Journals | SIAM Review 
  Multiscale Modeling and Simulation: A SIAM Interdisciplinary Journal 
  SIAM Journal on Applied Algebra and Geometry 
  SIAM Journal on Applied Dynamical Systems 
  SIAM Journal on Applied Mathematics 
  SIAM Journal on Computing 
  SIAM Journal on Control and Optimization 
  SIAM Journal on Discrete Mathematics 
  SIAM Journal on Financial Mathematics 
  SIAM Journal on Imaging Sciences 
  SIAM Journal on Mathematical Analysis 
  SIAM Journal on Mathematics of Data Science 
  SIAM Journal on Matrix Analysis and Applications 
  SIAM Journal on Numerical Analysis 
  SIAM Journal on Optimization 
  SIAM Journal on Scientific Computing 
  SIAM / ASA Journal on Uncertainty Quantification 
  Theory of Probability and Its Applications 
  SIAM Undergraduate Research Online 
  SIAM Books  Our textbooks and monographs are indispensable to researchers, faculty, and students around the world.  SIAM Books 
  SIAM News  The newsjournal of SIAM, covering cutting-edge research and the state of the art in applied mathematics and computational science.  SIAM News 
  Reports 
  Proceedings 
  Subscriptions & Ordering 
  Programs & Initiatives | Toggle sub-menu | Programs | Gene Golub SIAM Summer School 
  Visiting Lecturer Program 
  MathWorks Math Modeling (M3) Challenge 
  SIAM-Simons Undergraduate Summer Research Program 
  SIAM Science Policy Fellowship 
  MGB-SIAM Early Career Fellowship 
  SIAM Postdoctoral Support Program 
  Graduate Student Mathematical Modeling Camp and Mathematical Problems in Industry Workshop 
  See All Programs 
  Professional Development | Careers in Applied Mathematics 
  Career Resources 
  Job Board 
  Internships 
  Prizes and Awards | Deadline Calendar 
  SIAM Fellows Program 
  Policy & Procedures 
  Save the Date for the Next Career Fair!  Happening in person March 4, 2025 during CSE25.  Save the Date for the Next Career Fair! 
  Industry 
  Equity, Diversity, & Inclusion 
  Education Resources 
  Science Policy 
  Conferences & Events | Toggle sub-menu | SIAM Conferences | More Events by Type 
  Section Meetings 
  Webinars & Seminars 
  Workshops 
  Career Fairs 
  Cooperating Conferences 
  Archive 
  See all Events 
  Conference Support | Travel & Registration Support 
  Child Care Grants 
  About SIAM Conferences & Events | For Sponsors & Exhibitors 
  Conference Guidelines 
  Featured Videos & Lectures 
  Submit Now for SIAM AN25!  The Third Joint SIAM/CAIMS Annual Meetings is happening July 28 - August 1, 2025 in Montréal, Québec, Canada.  Submit Now for SIAM AN25! 
  Membership | Toggle sub-menu | Individual Membership | Join 14,000 applied mathematicians and computational and data scientists from around the world. 
  Learn More 
  Institutional Membership | Create a custom subscription of four or more journals and your institution can become a free SIAM academic member, receiving up to a 27.5% discount on journal list prices. 
  Learn More 
  Member Support & FAQ | Questions about our membership types, benefits, how to automatically renew, or something else? 
  Get Your Questions Answered 
  Get Involved | Toggle sub-menu | Connect with a Community | Activity Groups 
  Sections 
  Student Chapters 
  SIAM Engage Online Community 
  Ways to Participate | Serve on Committees 
  Become an Author, Editor, or Referee 
  Nominate for Prizes 
  Network and Present at a Conference 
  Write for SIAM News 
  Ways to Support | Donate to SIAM 
  Spread the Word 
  Become a Sponsor 
  About Us | Toggle sub-menu | Overview 
  Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Bylaws & Reports 
  Policies & Guidelines 
  Join SIAM 
  Contact Us 

 Back to top     
   
 Home 
  Publications 
  SIAM Journals 
  SIAM Undergraduate Research Online (SIURO) 

 SIAM Undergraduate Research Online  
 SIAM Undergraduate Research Online  (SIURO) is a web-based publication devoted to undergraduate research in applied and computational mathematics. Access is free and open to the public.  
   
 Read Current Issue  Submit a Paper    
   
 Related Links  
 Sign Up for Email Updates 

 In This Section 
  SIAM Undergraduate Research Online E-Alert 
  Editorial Policy 
  Editorial Board 
  Instructions for Authors 
  More 

 SIURO consists of articles written by undergraduate students in applied and computational mathematics, offering an opportunity for students to publish research they have completed as part of their undergraduate education and providing undergraduates incentives for conducting research.  
 The publication represents a wide range of applied topics, including but not limited to analysis, discrete mathematics, statistics, operations research, optimization, dynamical systems, modeling, and computation. Typical areas of application include but are not limited to physical, life, financial, and management sciences and engineering.  
 Each paper must be submitted with a letter from a project advisor. Faculty advisers or sponsors are listed as "project advisor" on the published paper.  
 SIURO provides an opportunity for undergraduate students to share their results and experience a full paper review process. High school students may also submit their work.  
 The project advisor may be a faculty member at the student’s institution or at an institution the student is visiting, or someone associated with a non-academic organization or government lab who supervised the research. 
  The project advisor’s letter must document the fact that the research was done while the student was an undergraduate and list the student’s graduation date or anticipated graduation date. 
  Project advisors will be listed separately from the authors with a “project advisor” byline. 

 Announcements   
 Authors: Prepare your papers using LaTex 2e macros to aid editor and referee review 

 From the Current Volume  
 Check out the latest volume and dive into advanced research and findings by undergraduate students.  
 See more   
   
 Volume 17  Accurately Classifying Out-Of-Distribution Data in Facial Recognition   
 November 13, 2024    
 By  Gianluca Barone (Corresponding author – Rowan University) 
  Aashrit Cunchala (University of Pittsburgh) 
  Rudy Nunez (Emory University) 

 Volume 17  Optimizing Energy Functional in Wave and Heat Equations with Initial Conditions in a Class of Rearrangements   
 October 30, 2024    
 By  Renjing Wang (Corresponding author – Xi'an Jiaotong-Liverpool University, China) 

 Volume 17  Travelling Waves of the Diffusive Streeter-Phelps Equations with Braun-Berthouex BOD Decay   
 October 24, 2024    
 By  Alexandra Lawryshyn (Corresponding author – University of Guelph, Ontario, Canada) 

 Browse Articles by Volume  
   
 Volume 17   
 2024   
   
 Volume 16   
 2023   
   
 Volume 15   
 2022   
   
 Volume 14   
 2021   
   
 Volume 13   
 2020   
   
 Volume 12   
 2019   
   
 Volume 11   
 2018   
   
 Volume 10   
 2017   
   
 Volume 9   
 2016   
   
 Volume 8   
 2015   
   
 Volume 7   
 2014   
   
 Volume 6   
 2013   
   
 Volume 5   
 2012   
   
 Volume 4   
 2011   
   
 Volume 3   
 2010   
   
 Volume 2, Issue 2   
 Fall 2009   
   
 Volume 2, Issue 1   
 Spring 2009   
   
 Volume 1, Issue 2   
 Fall 2008   
   
 Volume 1, Issue 1   
 Summer 2008   

 Show more    

 Publish with SIURO   
 Become an Author  
   
 SIURO offers undergraduate and high school students the early opportunity to publish their research while becoming part of the scientific community.  
   
 Learn More 
    
 SIURO is one of the best publications for undergraduate research in applied and computational mathematics. Beyond getting their results out into the world, when students publish their papers in SIURO, they have the edifying experience of taking their original work through the peer-review process.  
   Joanna Wares  University of Richmond     

 Get Involved with SIURO  
 We welcome submissions from undergraduate and high school students in applied and computational mathematics.  

 Editorial Information   
 Get the scoop on our reviewer guidelines, editorial policy, and more.   

 Instructions for Authors   
 Interested in submitting a paper to SIURO?   

 Contact Us  
   
 Questions about SIURO? Get in touch with our staff.  
 Contact SIURO Staff    

 Stay Up-to-Date with Email Alerts  
 Sign up for our monthly newsletter and emails about other topics of your choosing.  
   
 Email Address     
 Sign Up Now     

   3600 Market Street  6th Floor  Philadelphia, PA 19104 USA   Facebook 
  Twitter 
  Youtube 
  LinkedIn 

 About SIAM | Mission & History 
  Governance & Leadership 
  Committees 
  Staff 
  Collaborations 
  Code of Conduct 
  Policies & Guidelines 
  Jobs at SIAM 
  Contact Us 
  Membership | Member Benefits 
  Become a Member 
  Renew Your Membership 
  Connect with a Community 
  Ways to Participate 
  Jobs in STEM 
  Share & Support | Newsroom 
  Advertise with Us 
  Become a Sponsor 
  Post a Job 
  Information for Librarians 
  Subscribe to Our Emails 
   
 © 2024 Society for Industrial and Applied Mathematics   
 Terms & Conditions 
  Privacy 

    Important dates data

26. Conference SoCS_3:
Skip to main content  Skip to main navigation menu  Skip to the current issue  Skip to site footer   
 Open Menu   Proceedings of the International Symposium on Combinatorial Search  
 Proceedings of the International Symposium on Combinatorial Search    
   
  Current 
  Archives 
  About | About the Journal 
  Submissions 
  Privacy Statement 
    Search  Search      

 Login 
    
   Search  Search      

   Current Issue  
 Vol. 17 (2024): Seventeenth International Symposium on Combinatorial Search   
   Edited by Ariel Felner, Jiaoyang Li   
  June 6–8, 2024, Kananaskis, Alberta, Canada.  
 Published by The AAAI Press, Washington, DC, USA  
  Copyright © 2024, Association for the Advancement of Artificial Intelligence  
  1101 Pennsylvania Ave, NW, Suite 300, Washington, DC 20004  
  All Rights Reserved. No part of this proceedings may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.  
   
  308 pp., illus, references.  
   
  ISSN 2832-9163 (Online)  
  ISSN 2832-9171 (Print)  
  ISBN-10 1-57735-891-0  
  ISBN-13 978-1-57735-891-6  
 The Seventeenth International Symposium on Combinatorial Search (SoCS 2024) from June 6-8, 2024 in Kananaskis, Alberta, Canada. The symposium co-chairs were Ariel Felner and Jiaoyang Li.  
 The International Symposium on Combinatorial Search is meant to bring researchers in such areas together to exchange ideas and cross-fertilize the field. SoCS serves researchers and submissions in all fields that use combinatorial search, including artificial intelligence, planning, robotics, constraint programming, meta-reasoning, operations research, navigation, and bioinformatics. Papers exploring the boundaries between combinatorial search and planning & scheduling research are particularly welcome, given the co-location with the 2024 International Conference on Automated Planning and Scheduling (ICAPS 2024). The papers included in this issue have been organized into three categories — technical papers, position papers, and extended abstracts.  
   
 Published:  2024-06-01    
   
 Long Papers  
 Efficient and Exact Public Transport Routing via a Transfer Connection Database   
 Abdallah Abuaisha, Mark Wallace, Daniel Harabor, Bojie Shen  2-10   PDF 
  Heuristic Search for the Orienteering Problem with Time-Varying Reward   
 Chao Cao, Jinyun Xu, Ji Zhang, Howie Choset, Zhongqiang Ren  11-19   PDF 
  Avoiding Node Re-Expansions Can Break Symmetry Breaking   
 Mark Carlson, Daniel Harabor, Peter J. Stuckey  20-27   PDF 
  Generalized Longest Simple Path Problems: Speeding up Search Using SPQR Trees   
 Gal Dahan, Itay Tabib, Solomon Eyal Shimony, Yefim Dinitz  28-36   PDF 
  Introducing Delays in Multi Agent Path Finding   
 Justin Kottinger, Tzvika Geft, Shaull Almagor, Oren Salzman, Morteza Lahijanian  37-45   PDF 
  Solving Facility Location Problems via FastMap and Locality Sensitive Hashing   
 Ang Li, Peter J. Stuckey, Sven Koenig, T. K. Satish Kumar  46-54   PDF 
  Modeling Assistance for Hierarchical Planning: An Approach for Correcting Hierarchical Domains with Missing Actions   
 Songtuan Lin, Daniel Höller, Pascal Bercher  55-63   PDF 
  Multi-Agent Path Execution with Uncertainty   
 Yihao Liu, Xueyan Tang, Wentong Cai, Jingning Li  64-72   PDF 
  A Deterministic Search Approach for Solving Stochastic Drone Search and Rescue Planning Without Communications   
 Evgeny Mishlyakov, Mikhail Gruntov, Alexander Shleyfman, Erez Karpas  73-81   PDF 
  Prioritised Planning with Guarantees   
 Jonathan Morag, Yue Zhang, Daniel Koyfman, Zhe Chen, Ariel Felner, Daniel Harabor, Roni Stern  82-90   PDF 
  Curriculum Generation for Learning Guiding Functions in State-Space Search Algorithms   
 Sumedh Pendurkar, Levi H. S. Lelis, Nathan R. Sturtevant, Guni Sharon  91-99   PDF 
  Optimised Variants of Polynomial Compilation for Conditional Effects in Classical Planning   
 Francesco Percassi, Enrico Scala, Alfonso Emilio Gerevini  100-108   PDF 
  Unconstraining Multi-Robot Manipulation: Enabling Arbitrary Constraints in ECBS with Bounded Sub-Optimality   
 Yorai Shaoul, Rishi Veerapaneni, Maxim Likhachev, Jiaoyang Li  109-117   PDF 
  Neural Sequence Generation with Constraints via Beam Search with Cuts: A Case Study on VRP   
 Pouya Shati, Eldan Cohen, Sheila McIlraith  118-126   PDF 
  On the Properties of All-Pair Heuristics   
 Shahaf Shperberg, Ariel Felner, Lior Siag, Nathan R. Sturtevant  127-133   PDF 
  ITA-ECBS: A Bounded-Suboptimal Algorithm for Combined Target-Assignment and Path-Finding Problem   
 Yimin Tang, Sven Koenig, Jiaoyang Li  134-142   PDF 
  The Bench Transition System and Stochastic Exploration   
 Dawson Tomasz, Richard Valenzano  143-151   PDF 
  Clique Analysis and Bypassing in Continuous-Time Conflict-Based Search   
 Thayne T. Walker, Nathan R. Sturtevant, Ariel Felner  152-160   PDF 
  Real-time Safe Interval Path Planning   
 Devin Wild Thomas, Wheeler Ruml, Solomon Eyal Shimony  161-169   PDF 
  Tunable Suboptimal Heuristic Search   
 Stephen Wissow, Fanhao Yu, Wheeler Ruml  170-178   PDF 
  A-A*pex: Efficient Anytime Approximate Multi-Objective Search   
 Han Zhang, Oren Salzman, Ariel Felner, Carlos Hernández Ulloa, Sven Koenig  179-187   PDF 
  Bi-Criteria Diverse Plan Selection via Beam Search Approximation   
 Shanhe Zhong, Pouya Shati, Eldan Cohen  188-196   PDF 
    
 Short Papers  
 Hitting Set Heuristics for Overlapping Landmarks in Satisficing Planning   
 Clemens Büchner, Remo Christen, Salomé Eriksson, Thomas Keller  198-202   PDF 
  Novelty Heuristics, Multi-Queue Search, and Portfolios for Numeric Planning   
 Dillon Z. Chen, Sylvie Thiébaux  203-207   PDF 
  Efficient Set Dominance Checks in Multi-Objective Shortest-Path Algorithms via Vectorized Operations   
 Carlos Hernández Ulloa, Han Zhang, Sven Koenig, Ariel Felner, Oren Salzman  208-212   PDF 
  Some Orders Are Important: Partially Preserving Orders in Top-Quality Planning   
 Michael Katz, Junkyu Lee, Jungkoo Kang, Shirin Sohrabi  213-217   PDF 
  Optimal Unlabeled Pebble Motion on Trees   
 Pierre Le Bodic, Edward Lam  218-222   PDF 
  A Data Efficient Framework for Learning Local Heuristics   
 Rishi Veerapaneni, Jonathan Park, Muhammad Suhail Saleem, Maxim Likhachev  223-227   PDF 
  Speeding Up Dominance Checks in Multi-Objective Search: New Techniques and Data Structures   
 Han Zhang, Oren Salzman, Ariel Felner, T. K. Satish Kumar, Carlos Hernández Ulloa, Sven Koenig  228-232   PDF 
    
 Position Papers  
 Scaling Lifelong Multi-Agent Path Finding to More Realistic Settings: Research Challenges and Opportunities   
 He Jiang, Yulun Zhang, Rishi Veerapaneni, Jiaoyang Li  234-242   PDF 
  Fools Rush in Where Angels Fear to Tread in Multi-Goal CBS   
 Grigorios Mouratidis, Bernhard Nebel, Sven Koenig  243-251   PDF 
    
 Extended Abstracts  
 Parallelizing Multi-objective A* Search (Extended Abstract)   
 Saman Ahmadi  253-254   PDF 
  Finding a Small, Diverse Subset of the Pareto Solution Set in Bi-Objective Search (Extended Abstract)   
 Pablo Araneda, Carlos Hernández Ulloa, Nicolás Rivera, Jorge A. Baier  255-256   PDF 
  Extreme Value Monte Carlo Tree Search (Extended Abstract)   
 Masataro Asai, Stephen Wissow  257-258   PDF 
  Finiding All Optimal Solutions in Multi-Agent Path Finding (Extended Abstract)   
 Shahar Bardugo, Dor Atzmon  259-260   PDF 
  Crafting a Pogo Stick in Minecraft with Heuristic Search (Extended Abstract)   
 Yarin Benyamin, Argaman Mordoch, Shahaf Shperberg, Wiktor Piotrowski, Roni Stern  261-262   PDF 
  Taming Discretised PDDL+ through Multiple Discretisations (Extended Abstract)   
 Matteo Cardellini, Marco Maratea, Francesco Percassi, Enrico Scala, Mauro Vallati  263-264   PDF 
  Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding (Extended Abstract)   
 Zhe Chen, Daniel Harabor, Jiaoyang Li, Peter J. Stuckey  265-266   PDF 
  Exploring Conflict Generating Decisions: Initial Results (Extended Abstract)   
 Md Solimul Chowdhury, Martin Müller, Jia-Huai You  267-268   PDF 
  Deployable Yet Effective Traffic Signal Optimisation via Automated Planning (Extended Abstract)   
 Anas El Kouaiti, Francesco Percassi, Alessandro Saetti, Thomas Leo McCluskey, Mauro Vallati  269-270   PDF 
  Lazy Evaluation of Negative Preconditions in Planning Domains (Extended Abstract)   
 Santiago Franco, Jamie O. Roberts, Sara Bernardini  271-272   PDF 
  Minimizing State Exploration While Searching Graphs with Unknown Obstacles (Extended Abstract)   
 Daniel Koyfman, Shahaf Shperberg, Dor Atzmon, Ariel Felner  273-274   PDF 
  A New Upper Bound for the Makespan of Cost-Optimal Solutions for Multi-Agent Path Finding (Extended Abstract)   
 Rodrigo López, Roberto Asín-Achá, Jorge A. Baier  275-276   PDF 
  Evaluating Distributional Predictions of Search Time: Put Up or Shut Up Games (Extended Abstract)   
 Sean Mariasin, Andrew Coles, Erez Karpas, Wheeler Ruml, Solomon Eyal Shimony, Shahaf Shperberg  277-278   PDF 
  A Quality Diversity Approach to Automatically Generate Multi-Agent Path Finding Benchmark Maps (Extended Abstract)   
 Cheng Qian, Yulun Zhang, Jiaoyang Li  279-280   PDF 
  Spectral Clustering in Rule-based Algorithms for Multi-agent Path Finding (Extended Abstract)   
 Irene Saccani, Kristýna Janovská, Pavel Surynek  281-282   PDF 
  On Parallel External-Memory Bidirectional Search (Extended Abstract)   
 Lior Siag, Shahaf Shperberg, Ariel Felner, Nathan R. Sturtevant  283-284   PDF 
  CoRe Challenge 2022/2023: Empirical Evaluations for Independent Set Reconfiguration Problems (Extended Abstract)   
 Takehide Soh, Tomoya Tanjo, Yoshio Okamoto, Takehiro Ito  285-286   PDF 
  Non-Refined Abstractions in Counterexample Guided Abstraction Refinement for Multi-Agent Path Finding (Extended Abstract)   
 Pavel Surynek  287-288   PDF 
  Mixed Integer Programming for Time-Optimal Multi-Robot Coverage Path Planning with Efficient Heuristics (Extended Abstract)   
 Jingtao Tang, Hang Ma  289-290   PDF 
  Large-Scale Multi-Robot Coverage Path Planning via Local Search (Extended Abstract)   
 Jingtao Tang, Hang Ma  291-292   PDF 
  From Space-Time to Space-Order: Directly Planning a Temporal Planning Graph by Redefining CBS (Extended Abstract)   
 Yu Wu, Rishi Veerapaneni, Jiaoyang Li, Maxim Likhachev  293-294   PDF 
  Optimal and Bounded Suboptimal Any-Angle Multi-agent Pathfinding (Extended Abstract)   
 Konstantin Yakovlev, Anton Andreychuk, Roni Stern  295-296   PDF 
  Multi-agent Motion Planning through Stationary State Search (Extended Abstract)   
 Jingtian Yan, Jiaoyang Li  297-298   PDF 
  Multi-Agent Motion Planning with Bézier Curve Optimization under Kinodynamic Constraints (Extended Abstract)   
 Jingtian Yan, Jiaoyang Li  299-300   PDF 
  A Short Summary of Multi-Agent Combinatorial Path Finding with Heterogeneous Task Duration (Extended Abstract)   
 Yuanhang Zhang, Hesheng Wang, Zhongqiang Ren  301-302   PDF 
  Planning and Exection in Multi-Agent Path Finding: Models and Algorithms (Extended Abstract)   
 Yue Zhang, Zhe Chen, Daniel Harabor, Pierre Le Bodic, Peter J. Stuckey  303-304   PDF 
  Multi-Robot Coordination and Layout Design for Automated Warehousing (Extended Abstract)   
 Yulun Zhang, Matthew C. Fontaine, Varun Bhatt, Stefanos Nikolaidis, Jiaoyang Li  305-306   PDF 
  Arbitrarily Scalable Environment Generators via Neural Cellular Automata (Extended Abstract)   
 Yulun Zhang, Matthew C. Fontaine, Varun Bhatt, Stefanos Nikolaidis, Jiaoyang Li  307-308   PDF 

 View All Issues   

  Call for papers data:Important dates data

27. Conference SoMeT_0:
SOMET 2025  
 SOMET 2025:The 24th International Conference on Intelligent Software Methodologies, Tools, and Techniques  
  Kitakyushu, Japan  
  |  September 23-26, 2025  
 Previous Conferences   

     MENU - Committees 
    
 Home 
  Call For Papers 
  Special Issue 
  Journals 
  Keynotes 
  Program 
  Accepted Papers 
  Registration 
  Committees 
  Venue 

  Previous    Next     
   
 About SOMET 2025  
 The SOMET conference highlights and reflects the state-of-art and new trends on software methodologies, tools and techniques. You are invited to participate to help build a forum for exchanging ideas and experiences to foster new directions in software development methodologies and related tools and techniques. This conference is focused on exploring innovations, controversies, and challenges facing the Software Engineering community today. The conference brings together theory and experience to propose and evaluate solutions to Software Engineering problems. The conference also provides a forum and an opportunity to assess the current state-of-the-art in intelligent Software techniques and to chart software science initiated from experience to theory. This conference is an opportunity for us in the software science community to think about where we are and today and where we are going.  
 Important Dates  
 Note: all dates are AoE (Anywhere on Earth).  
 Paper Submission deadline April 1, 2025.   
 Notification to authors May 15, 2025.   
 Camera-Ready papers June 15, 2025.   

  Call for papers data:  
 SOMET 2025  
 SOMET 2025:The 24th International Conference on Intelligent Software Methodologies, Tools, and Techniques  
  Kitakyushu, Japan  
  |  September 23-26, 2025  
 Previous Conferences   

     MENU - Committees 
    
 Home 
  Call For Papers 
  Special Issue 
  Journals 
  Keynotes 
  Program 
  Accepted Papers 
  Registration 
  Committees 
  Venue 

  Previous    Next     
   
 Important Dates  
 Note: all dates are AoE (Anywhere on Earth).  
 Paper Submission April 1, 2025.   
 Notification to authors May 15, 2025   
 Camera-Ready papers June 15, 2025   
 Best Paper Paper Awards  
 SOMET 2025 will select some papers to receive a Best Paper Awards. Each award will come with a certificate.  
 Conference Topics of SOMET 2025, but no limited  
 Requirement engineering, especially for high-assurance system, and requirement elicitation 
  Software methodologies, and tools for robust, reliable, non‐fragile software design 
  Software developments techniques and legacy systems 
  Automatic software generation versus reuse, and legacy systems 
  Software quality and process assessment for business enterprise models 
  Intelligent software systems design, and software evolution techniques 
  Agile Software and Lean Methods 
  Software optimization and formal methods for software design 
  Static, dynamic analysis on software performance model, software maintenance 
  Software security tools and techniques, and related Software Engineering models 
  Formal techniques for software representation, software testing and validation 
  Software reliability, and software diagnosis systems 
  Mobile code security tools and techniques 
  End-user programming environment, User-centered Adoption-Centric Re-engineering techniques 
  Ontology, cognitive models and philosophical aspects on software design 
  Medical Informatics, Software methods and application for bio-medicine 
  Artificial Intelligence Techniques on Software Engineering, and Requirement Engineering 
  Software design through interaction, and precognitive software techniques for interactive software entertainment applications 
  Creativity and art in software design principles 
  Axiomatic based principles on software design 
  Model Driven Development (DVD), code centric to model centric software engineering 
  Medical Informatics and bioinformatics, Software methods and application for bio-medicine and bioinformatics 
  Emergency Management Informatics, software methods and application for supporting 
  Civil Protection, First Response and Disaster Recovery 
  Others software Science disciplines (go to the conference home page for more details) 
    
 Author Instructions of SOMET 2025  
 Submissions must be made through the Conference's EasyChair system available at the following link:  
 SOMET 2025 Submission Link   
 Papers would be submitted through the CMT. In the case of acceptance, please, send your Camera-Ready copy according to IOS format should be up to 14 A4 pages for Regular paper, and up to 10 pages for Short papers. The final Camera-Ready copy, for inclusion in the: Book series: Frontiers in Artificial Intelligence and Applications and distributed at the conference. This series is indexed in SCOPUS and selected by the Elsevier databases coverage.  
 IOS Instructions  Frontiers in Artificial Intelligence and Applications   
 Submitted papers may risk being rejected directly without consideration of their merits if they do not follow all the above submission instructions.  
 Submissions not meeting the submission guidelines risk rejection without consideration of their merits.  

  Important dates data

28. Conference SoMeT_1:
SOMET 2025  
 SOMET 2025:The 24th International Conference on Intelligent Software Methodologies, Tools, and Techniques  
  Kitakyushu, Japan  
  |  September 23-26, 2025  
 Previous Conferences   

     MENU - Committees 
    
 Home 
  Call For Papers 
  Special Issue 
  Journals 
  Keynotes 
  Program 
  Accepted Papers 
  Registration 
  Committees 
  Venue 

  Previous    Next     
   
 Important Dates  
 Note: all dates are AoE (Anywhere on Earth).  
 Paper Submission April 1, 2025.   
 Notification to authors May 15, 2025   
 Camera-Ready papers June 15, 2025   
 Best Paper Paper Awards  
 SOMET 2025 will select some papers to receive a Best Paper Awards. Each award will come with a certificate.  
 Conference Topics of SOMET 2025, but no limited  
 Requirement engineering, especially for high-assurance system, and requirement elicitation 
  Software methodologies, and tools for robust, reliable, non‐fragile software design 
  Software developments techniques and legacy systems 
  Automatic software generation versus reuse, and legacy systems 
  Software quality and process assessment for business enterprise models 
  Intelligent software systems design, and software evolution techniques 
  Agile Software and Lean Methods 
  Software optimization and formal methods for software design 
  Static, dynamic analysis on software performance model, software maintenance 
  Software security tools and techniques, and related Software Engineering models 
  Formal techniques for software representation, software testing and validation 
  Software reliability, and software diagnosis systems 
  Mobile code security tools and techniques 
  End-user programming environment, User-centered Adoption-Centric Re-engineering techniques 
  Ontology, cognitive models and philosophical aspects on software design 
  Medical Informatics, Software methods and application for bio-medicine 
  Artificial Intelligence Techniques on Software Engineering, and Requirement Engineering 
  Software design through interaction, and precognitive software techniques for interactive software entertainment applications 
  Creativity and art in software design principles 
  Axiomatic based principles on software design 
  Model Driven Development (DVD), code centric to model centric software engineering 
  Medical Informatics and bioinformatics, Software methods and application for bio-medicine and bioinformatics 
  Emergency Management Informatics, software methods and application for supporting 
  Civil Protection, First Response and Disaster Recovery 
  Others software Science disciplines (go to the conference home page for more details) 
    
 Author Instructions of SOMET 2025  
 Submissions must be made through the Conference's EasyChair system available at the following link:  
 SOMET 2025 Submission Link   
 Papers would be submitted through the CMT. In the case of acceptance, please, send your Camera-Ready copy according to IOS format should be up to 14 A4 pages for Regular paper, and up to 10 pages for Short papers. The final Camera-Ready copy, for inclusion in the: Book series: Frontiers in Artificial Intelligence and Applications and distributed at the conference. This series is indexed in SCOPUS and selected by the Elsevier databases coverage.  
 IOS Instructions  Frontiers in Artificial Intelligence and Applications   
 Submitted papers may risk being rejected directly without consideration of their merits if they do not follow all the above submission instructions.  
 Submissions not meeting the submission guidelines risk rejection without consideration of their merits.  

  Call for papers data:  
 SOMET 2025  
 SOMET 2025:The 24th International Conference on Intelligent Software Methodologies, Tools, and Techniques  
  Kitakyushu, Japan  
  |  September 23-26, 2025  
 Previous Conferences   

     MENU - Committees 
    
 Home 
  Call For Papers 
  Special Issue 
  Journals 
  Keynotes 
  Program 
  Accepted Papers 
  Registration 
  Committees 
  Venue 

  Previous    Next     
   
 Important Dates  
 Note: all dates are AoE (Anywhere on Earth).  
 Paper Submission April 1, 2025.   
 Notification to authors May 15, 2025   
 Camera-Ready papers June 15, 2025   
 Best Paper Paper Awards  
 SOMET 2025 will select some papers to receive a Best Paper Awards. Each award will come with a certificate.  
 Conference Topics of SOMET 2025, but no limited  
 Requirement engineering, especially for high-assurance system, and requirement elicitation 
  Software methodologies, and tools for robust, reliable, non‐fragile software design 
  Software developments techniques and legacy systems 
  Automatic software generation versus reuse, and legacy systems 
  Software quality and process assessment for business enterprise models 
  Intelligent software systems design, and software evolution techniques 
  Agile Software and Lean Methods 
  Software optimization and formal methods for software design 
  Static, dynamic analysis on software performance model, software maintenance 
  Software security tools and techniques, and related Software Engineering models 
  Formal techniques for software representation, software testing and validation 
  Software reliability, and software diagnosis systems 
  Mobile code security tools and techniques 
  End-user programming environment, User-centered Adoption-Centric Re-engineering techniques 
  Ontology, cognitive models and philosophical aspects on software design 
  Medical Informatics, Software methods and application for bio-medicine 
  Artificial Intelligence Techniques on Software Engineering, and Requirement Engineering 
  Software design through interaction, and precognitive software techniques for interactive software entertainment applications 
  Creativity and art in software design principles 
  Axiomatic based principles on software design 
  Model Driven Development (DVD), code centric to model centric software engineering 
  Medical Informatics and bioinformatics, Software methods and application for bio-medicine and bioinformatics 
  Emergency Management Informatics, software methods and application for supporting 
  Civil Protection, First Response and Disaster Recovery 
  Others software Science disciplines (go to the conference home page for more details) 
    
 Author Instructions of SOMET 2025  
 Submissions must be made through the Conference's EasyChair system available at the following link:  
 SOMET 2025 Submission Link   
 Papers would be submitted through the CMT. In the case of acceptance, please, send your Camera-Ready copy according to IOS format should be up to 14 A4 pages for Regular paper, and up to 10 pages for Short papers. The final Camera-Ready copy, for inclusion in the: Book series: Frontiers in Artificial Intelligence and Applications and distributed at the conference. This series is indexed in SCOPUS and selected by the Elsevier databases coverage.  
 IOS Instructions  Frontiers in Artificial Intelligence and Applications   
 Submitted papers may risk being rejected directly without consideration of their merits if they do not follow all the above submission instructions.  
 Submissions not meeting the submission guidelines risk rejection without consideration of their merits.  

  Important dates data

29. Conference SOFA_0:
IEEE Sofa-Org 
  About us 
  Contact-Us 

 SOFA Conferences   
 International Workshop On Soft Computing  

     IEEE Sofa-Org 
  About us 
  Contact-Us 

  International Workshop on Soft Computing Applications (SOFA Conferences)  
 International Workshop  

 SOFA Conferences  
 Soft computing (SC) is a collection of methodologies that are trying to cope with the main disadvantage of the conventional (hard) computing: the poor performances when working in uncertain conditions. The fundamental idea of soft computing is to emulate the human like reasoning. The classic constituents of SC are fuzzy logic, neural network theory and probabilistic reasoning, but new methods are continuously emerging: belief networks, genetic algorithms, anytime algorithms, chaos theory, some parts of learning theory, etc. Due to the large variety and complexity of the domain, the constituting methods of SC are not competing for a comprehensive ultimate solution. Instead they are complementing each other, for dedicated solutions adapted to each specific problem. Hundreds of concrete applications are already available in control, decision making, pattern recognition and robotics. The SC systems are tolerant to imprecision, uncertainty, and partial truth. Their main advantages are tractability, robustness, and low cost implementations. At the same time SC is a major developing vector of the Artificial Intelligence.  

 PREVIOUS & UPCOMING SOFA WORKSHOPS  

 Former organizer of  previous conferences Trivent (Hungary)   

 Sofa 2022 
 Sofa 2020 
 Sofa 2018 
 Sofa 2016 
 Sofa 2014 
 Sofa 2012 
 Sofa 2010 
 Sofa 2009 
 Sofa 2007 
 Sofa 2005 

 © Copyright 2020 SOFA Conferences. All Rights Reserved.    

                                                                                                    Call for papers data:Important dates data

30. Conference SOSP_0:
S O S P . O R G |  
  
  The ACM Symposium on Operating Systems Principles (SOSP) is a conference that brings together developers and researchers from academia and industry to advance the science and technology in operating systems. The conference is sponsored by the ACM Special Interest Group on Operating Systems (SIGOPS)  . It has been held once every two years since 1967, when the first SOSP conference took place in Gatlinburg Tennessee. Information on SOSP conferences is provided below.   
 No | Year | Dates | Location | Proceedings / Website 
 30 | 2024 | Nov 4-6 | Austin, TX USA | Proceedings of the 30th ACM Symposium on Operating Systems Principles, November 4-6, 2024, Austin, TX USA. 
 29 | 2023 | Oct 23-26 | Koblenz, Germany | Proceedings of the 29th ACM Symposium on Operating Systems Principles, October 23-26, 2023, Koblenz, Germany. 
 28 | 2021 | Oct 26-29 | Virtual Event | Proceedings of the 28th ACM Symposium on Operating Systems Principles, October 26-29, 2021, Virtual Event. 
 27 | 2019 | Oct 27-30 | Huntsville, Ontario, Canada | Proceedings of the 27th ACM Symposium on Operating Systems Principles, October 27-30, 2019, Huntsville, Ontario, Canada. 
 26 | 2017 | Oct 28-31 | Shanghai, China | Proceedings of the 26th ACM Symposium on Operating Systems Principles, October 28-31, 2017, Shanghai, China. 
 25 | 2015 | Oct 4-7 | Monterey, CA USA | Proceedings of the 25th ACM Symposium on Operating Systems Principles, October 4-7, 2015, Monterey, CA USA. 
 24 | 2013 | Nov 3-6 | Farmington, PA USA | Proceedings of the 24th ACM Symposium on Operating Systems Principles, November 3-6, 2013, Farmington, PA USA. 
 23 | 2011 | Oct 23-26 | Cascais, Portugal | Proceedings of the 23rd ACM Symposium on Operating Systems Principles, October 23-26, 2011, Cascais, Portugal. 
 22 | 2009 | Oct 11-14 | Big Sky, MT USA | Proceedings of the 22nd ACM Symposium on Operating Systems Principles, October 11-14, 2009, Big Sky, MT USA. 
 21 | 2007 | Oct 14-17 | Stevenson, WA USA | Proceedings of the 21st ACM Symposium on Operating Systems Principles, October 14-17, 2007, Stevenson, WA USA. 
 20 | 2005 | Oct 23-26 | Brighton, UK | Proceedings of the 20th ACM Symposium on Operating Systems Principles, October 23-26, 2005, Brighton, United Kingdom. 
 19 | 2003 | Oct 19-22 | Bolton Landing, NY USA | Proceedings of the 19th ACM Symposium on Operating Systems Principles, October 19-22, 2003, Bolton Landing, NY USA. 
 18 | 2001 | Oct 21-24 | Chateau Lake Louise, Banff, Canada | Proceedings of the 18th ACM Symposium on Operating Systems Principles, October 21-24, 2001, Chateau Lake Louise, Banff, Canada Operating System Review 35(5), ACM Press, 2001, ISBN 1-58113-389-8 
 17 | 1999 | Dec 12-15 | Kiawah Island Resort, SC USA | Proceedings of the 17th ACM Symposium on Operating Systems Principles, December 12-15, 1999, Kiawah Island Resort, SC USA Operating System Review 33(5), ACM Press, 1999, ISBN 1-58113-140-2 
 16 | 1997 | Oct 5-8 | Saint-Malo, France | Proceedings of the 16th ACM Symposium on Operating Systems Principles, October 5-8, 1997, St. Malo, France, Operating System Review 31(5), ACM Press, 1997, ISBN 0-89791-916-5 
 15 | 1995 | Dec 3-6 | Copper Mountain Resort, CO USA | Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 3-6, 1995, Copper Mountain Resort, CO USA Operating System Review 29(5), ACM Press, 1995, ISBN 0-89791-715-4 
 14 | 1993 | Dec 5-8 | Asheville, NC USA | Proceedings of the 14th ACM Symposium on Operating Systems Principles, December 5-8, 1993, The Grove Park Inn and Country Club Asheville, NC USA, Operating System Review 27(5), ACM Press, 1993, ISBN 0-89791-632-8 
 13 | 1991 | Oct 13-16 | Pacific Grove, CA USA | Proceedings of the 13th ACM Symposium on Operating Systems Principles, October 13-16, 1991, Asilomar Conference Center, Pacific Grove, CA USA, Operating System Review 25(5), ACM Press, 1991 ISBN 0-89791-447-3 
 12 | 1989 | Dec 3-6 | Litchfield Park, AZ USA | Proceedings of the 12th ACM Symposium on Operating Systems Principles, December 3-6, 1989, The Wigwam, Litchfield Park, AZ USA Operating System Review 23(5), ACM Press, 1989, ISBN 0-89791-338-8 
 11 | 1987 | Nov 8-11 | Austin, TX USA | Proceedings of the 11th ACM Symposium on Operating Systems Principles, November 8-11, 1987, Stouffer Austin Hotel, Austin, TX USA Operating System Review 21(5), ACM Press, 1987, ISBN 0-89791-242-X 
 10 | 1985 | Dec 1-4 | Orcas Island, WA USA | Proceedings of the 10th ACM Symposium on Operating Systems Principles, December 1-4, 1985, Orcas Island. WA USA Operating System Review 19(5), ACM, New York, ISBN 0-89791-174-1 
 9 | 1983 | Oct 10-13 | Bretton Woods, NH USA | Proceedings of the 9th ACM Symposium on Operating Systems Principles, October 10-13, 1983, Bretton Woods, NH USA Operating System Review 17(5), ACM, New York, ISBN 0-89791-115-6 
 8 | 1981 | Dec 14-16 | Pacific Grove, CA USA | Proceedings of the 8th ACM Symposium on Operating Systems Principles, December 14-16, 1981, Asilomar Conference Grounds Pacific Grove, CA USA, Operating System Review 15(5), ACM, New York, ISBN 0-89791-062-1 
 7 | 1979 | Dec 10-12 | Pacific Grove, CA USA | Proceedings of the 7th ACM Symposium on Operating Systems Principles, December 10-12, 1979, Asilomar Conference Grounds, Pacific Grove, CA USA, Operating System Review 13(5), ACM, New York, ISBN 0-89791-009-5 
 6 | 1977 | Nov 16-18 | West Lafayette, IN USA | Proceedings of the 6th ACM Symposium on Operating Systems Principles, November 16-18, 1977, Purdue University, West Lafayette, IN USA, Operating System Review 11(5), ACM, New York 
 5 | 1975 | Nov 19-21 | Austin, TX USA | Proceedings of the 5th ACM Symposium on Operating Systems Principles, November 19-21, 1975, The University of Texas at Austin, Austin, TX USA, Operating System Review 9(5), Special Issue, 1975, ACM, New York 
 4 | 1973 | Oct 15-17 | Yorktown Heights, NY USA | Proceedings of the 4th ACM Symposium on Operating Systems Principles, October 15-17 1973, Thomas J. Watson, Research Center Yorktown Heights, NY USA, Operating System Review 7(4), October 1973, ACM, New York 
 3 | 1971 | Oct 18-20 | Palo Alto, CA USA | Proceedings of the 3rd ACM Symposium on Operating Systems Principles, October 18-20, 1971, Stanford University, Palo Alto, CA USA Operating System Review 6(1-2), June 1972, ACM, New York 
 2 | 1969 | Oct 20-22 | Princeton, NJ USA | Proceedings of the 2nd ACM Symposium on Operating Systems Principles, October 20-22, 1969, Princeton University, Princeton, NJ USA 
 1 | 1967 | Oct 1-4 | Gatlinburg, TN USA | Proceedings of the 1st ACM Symposium on Operating Systems Principles, October 1-4, 1967, Gatlinburg, TN USA 

  Jason Nieh  , nieh@cs.columbia.edu     Call for papers data:Important dates data

31. Conference SoMeT_2:
Home  Log In  Contacts  FAQs  INSTICC Portal    
   
 Documents  Actions  On-line Registration  Registration Fees  Deadlines and Policies  Submit Paper  Submit Abstract  Guidelines  Preparing your Presentation  Templates  Glossary  Author's Login  Reviewer's Login  Ethics of Review  Information  Conference Details  Important Dates  Call for Papers  Program Committee  Event Chairs  Keynote Lectures  Best Paper Awards  Satellite Events  Workshops  Special Sessions  Tutorials  Demos  Panels  Travel and Accommodation  Conference Venue  About the Region  Reaching the City  Visa Information  Partners  Academic Partners  Industrial Partners  Institutional Partners  Media Partners  Partner Events  Publication Partners  Previous Conferences  Websites  Abstracts  Invited Speakers  Awards  Books Published    
  
 Sponsored by:    

 Locally Organized and Hosted by:    

 INSTICC is Member of:    

 Logistics:    

 ICSOFT 2025 will be held in conjunction with DATA 2025    , SIMULTECH 2025    , DeLTA 2025    , ICSBT 2025    , SECRYPT 2025    and IQSOFT 2025    .   
  Registration to ICSOFT allows free access to the DATA, SIMULTECH, DeLTA, ICSBT, SECRYPT and IQSOFT conferences (as a non-speaker).  

  Although the conference is back to the normal mode (i.e., in-person) speakers are allowed to present remotely if unable to travel to the venue (hybrid support).    

 Upcoming Submission Deadlines  
 Regular Paper Submission:  January 17, 2025    
 Position/Regular Paper Submission:  March 3, 2025    
  
  (See Important Dates for more information)    
 The purpose of the International Conference on Software Technologies, is to bring together researchers, engineers and practitioners interested on software development technologies and methodologies. The conference has several tracks including aspects such as "Software Engineering and Systems Development", "Software Systems and Applications" and "Foundational and Trigger Technologies".    
 Conference Areas  
 1  .  Software Engineering and Systems Development   
  
  2  .  Software Systems and Applications   
  
  3  .  Foundational and Trigger Technologies   

  Conference Chair    
 Leszek Maciaszek  ,  Macquarie Univ., Australia and Wroclaw Univ. of Economics and Business, Poland   

 PROGRAM CO-CHAIRS    
 Massimo Mecella  ,  Dipartimento di Ingegneria Informatica Automatica e Gestionale, Sapienza - Universita' Di Roma, Italy   
  Arend Rensink  ,  University of Twente, Netherlands   

 Publications:     
  All papers presented at the conference venue  
  will be available at the SCITEPRESS Digital Library   
  ( consult SCITEPRESS  Ethics of Publication  )  

  It is planned to publish a short list of revised and  
  extended versions of presented papers with  
  Springer in a CCIS Series book  (final approval pending)  

 Proceedings will be submitted for evaluation for indexing by:    

  Web of Science/Conference Proceedings Citation Index     

 © 2024  INSTICC    

   Call for papers data:Server Error  
   
 404 - File or directory not found.  
 The resource you are looking for might have been removed, had its name changed, or is temporarily unavailable.  

  Important dates data

32. Conference SOSP_1:
SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

  SOSP 2024   
  The 30 th  Symposium on Operating Systems Principles  
 November 4–6, 2024 · Hilton Austin  , Texas, USA  
 Early registration  (and hotel) deadline on October 4!   

 The first ever even-year SOSP!  
 The annual  ACM Symposium on Operating Systems Principles is the world's premier forum for researchers, developers, programmers, and teachers of computer systems technology. Academic and industrial participants present research and experience papers that cover the full range of theory and practice of computer systems software.  
   
 Where  
 Hilton Austin  , Austin, TX, USA  
   
 When  
 Monday to Wednesday  
  November 4–6, 2024  

 Awards  
   
 Congratulations to the winners of the following SOSP 2024 awards:  
 Best Paper Award: | OZZ: Identifying Kernel Out-of-Order Concurrency Bugs with In-Vivo Memory Access Reordering 
  Best Paper Award: | LazyLog: A New Shared Log Abstraction for Low-Latency Applications 
  Best Paper Award: | FBDetect: Catching Tiny Performance Regressions at Hyperscale through In-Production Monitoring 
  Distinguished Artifact Award: | Verus: A Practical Foundation for Systems Verification 
  Distinguished Artifact Award Honorable Mention: | Cookie Monster: Efficient On-Device Budgeting for Differentially-Private Ad-Measurement Systems 
  Distinguished Artifact Award Honorable Mention: | SWARM: Replicating Shared Disaggregated-Memory Data in No Time 

 Registration  
   
 Please make sure to register  for SOSP 2024 by the early registration deadline of October 4, 2024  . Hotel rooms are first-come, first-served and may no longer be available after this deadline.  
  
 Registration Type | Fee (early) | Fee (late) 
 Conference + Workshops | ACM Professional Member | $1,400.00 | $1,600.00 
 ACM Non-Member | $1,500.00 | $1,700.00 
 ACM Student Member | $1,000.00 | $1,200.00 
 Student Non-Member | $1,100.00 | $1,300.00 
 Conference only | ACM Professional Member | $1,050.00 | $1,150.00 
 ACM Non-Member | $1,100.00 | $1,200.00 
 ACM Student Member | $750.00 | $850.00 
 Student Non-Member | $800.00 | $900.00 
 Workshop only | ACM Professional Member | $350.00 | $450.00 
 ACM Non-Member | $400.00 | $500.00 
 ACM Student Member | $250.00 | $350.00 
 Student Non-Member | $300.00 | $400.00 
  
 You can book hotel rooms at the conference hotel at the special SOSP rate of $289/night as part of the registration process, or here  .  
 Click here to register for the conference.     

 Event Venue  
 SOSP goes 🤠  

 Austin, Texas  
 Austin is the capital city of the U.S. state of Texas, the 10th most populous city in the United States, and known as the "The Live Music Capital of the World", a reference to the city's many musicians and live music venues. The city also adopted "Silicon Hills" as a nickname due to a rapid influx of technology and development companies, and has the unofficial slogan "Keep Austin Weird", which refers to the desire to protect small, unique, and local businesses from being overrun by large corporations. Since the late 19th century, Austin has also been known as the "City of the Violet Crown", because of the colorful glow of light across the hills just after sunset.  

 Sponsors  
   
 Gold Sponsors  

 Silver Sponsors  

 Bronze Sponsors  

 Supporters  

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Call for papers data:SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

 SOSP 2024 Call for Papers  
 The 30th ACM Symposium on Operating Systems Principles (SOSP) seeks to present innovative and exciting research related to the design, implementation, analysis, evaluation, and deployment of computer systems software.  

 Event Info | Date | Link 
 Deadline to register abstracts | April 12, 2024; 23:59 PT | HotCRP Submission Site 
 Submission deadline (no extensions) | April 19, 2024; 23:59 PT | HotCRP Submission Site 
 Reviews available for author response | July 22, 2024 |  
 Author response due | July 26, 2024 |  
 Author notification | August 5, 2024 |  
 Camera ready due | September 23, 2024 | HotCRP Submission Site 
 Conference | November 4-6, 2024 | Conference Site 

 Topics  
   
 SOSP takes a broad view of systems and solicits contributions from many fields of systems practice, including: operating systems, file and storage systems, distributed systems, cloud computing, mobile and edge systems, secure and reliable systems, systems aspects of big data and machine learning, embedded and real-time systems, virtualization, networking as it relates to operating systems, and management and troubleshooting of complex systems. We also welcome work that explores the interaction of computer systems with related areas such as computer architecture, networking, programming languages, analytics, verification, and databases. In keeping with SOSP tradition, we will favor work that explores new territory, continues a significant research dialogue, or reflects on experience with or measurements of state-of-the-art implementations.  

 Submission Criteria  
   
 Submissions will be judged on novelty, significance, interest, clarity, relevance, and correctness. A good paper will:  
 Motivate a significant problem; 
  Propose and implement an interesting, compelling solution; 
  Demonstrate the practicality and benefits of the solution; 
  Draw appropriate conclusions; 
  Clearly describe the paper's contributions; and 
  Clearly articulate the advances beyond previous work. 
  We encourage submission of groundbreaking work in significant new directions, with the understanding that the evaluation criteria for papers addressing new problems may be different from those continuing a line of work in a more established area.  

 Originality  
   
 Submissions should contain original, unpublished material. Simultaneous submission of the same work to multiple venues, submission of previously published work, or plagiarism is not allowed.  
 Submissions that extend the authors' previous work are welcome, but authors must explain the differences between the SOSP submission and the prior work, much in the same way that the authors are expected to articulate the contributions of their submission as they relate to prior work by others. Self-comparisons should be properly anonymized, as described below.  
 Prior or concurrent workshop publication does not preclude publishing a related paper in SOSP. The online submission form will require authors to submit a copy of the related workshop paper and a short explanation of the new material in the conference paper beyond that published in the workshop version. As long as there is significant additional content in the submission compared to the prior workshop publication, the PC will evaluate the submission's entire contribution, not just the delta.  
 Prior or concurrent publication in non-peer-reviewed contexts, like arXiv.org, technical reports, talks, and social media posts, is explicitly permitted.  

 Resubmissions  
   
 Submitting a paper that had been previously submitted to and not accepted by another conference is permitted, although authors are expected to have improved the paper to address substantive issues raised in previous reviews. Authors should provide information regarding the previous submission(s) and a summary of the subsequent revisions to the paper. This description, which will be supplied to reviewers after they’ve completed their reviews, helps reviewers who may have reviewed a previous draft of the work to appreciate any improvements to the currently submitted work. Please try to limit the description of changes to one page. All information should be properly anonymized, as described below, and should be uploaded via the submission form.  

 Anonymity  
   
 SOSP will use double-blind reviewing. Please make a good faith attempt to anonymize your submission. Avoid identifying yourself or your institution explicitly or by implication (e.g., through the references or acknowledgments). The first page should use the paper ID assigned during registration in place of the author names. If the name of your project or system is already known to the community (e.g., through arXiv, technical reports, talks, social media posts, or other uses), your SOSP submission must use an anonymized name.  
 Use care in referring to your own related work. Do not omit references to your prior work, as this would make it difficult for reviewers to place your submission in its proper context. Instead, reference your past work in the third person, just as you would any other piece of related work. For example, you might say "Our system modifies the XYZ operating system built by Lee et al. [Lee17]".  
 For concurrent submissions on related topics, cite an anonymized version of the concurrent submission and discuss the relation between the submissions. Additionally, please email the PC chairs ( sosp24-pc-chairs@cs.wisc.edu  ) a copy of your other concurrent submission.  
 If your submission reports on experiences with a system at your institution or organization, you should refer to the system anonymously but describe the properties of the system that are needed to appreciate the work (e.g., size of the user base, volume of requests, etc.). We recognize that, in some cases, these properties may allow a reviewer to identify your institution or organization.  
 Check with the program chairs ( sosp24-pc-chairs@cs.wisc.edu  ) if you are uncertain about the anonymity rules.  

 Supplementary Material  
   
 Authors may optionally include supplementary material as a separate document. Supplementary material is intended for items that are not critical for evaluating the paper but may be of interest to some readers. Examples include: formal proofs that are only sketched in the submission, additional analyses, and methodological details that aren’t essential for the PC’s assessment but are important for reproducibility. PC members are not required to read this optional supplementary material, so the submission must stand alone without it.  

 Formatting  
   
 Papers will be submitted electronically in PDF format via the web submission form  .  
 Submissions may have at most 12 pages of technical content, including all text, figures, tables, etc. Bibliographic references are not included in the 12-page limit. Use A4 or US letter paper size, with all text and figures fitting inside a 178 x 229 mm (7 x 9 in) block centered on the page, using two columns separated by 8 mm (0.33 in) of whitespace. Use 10-point font (typeface Times Roman, Linux Libertine, etc.) on 12-point (single-spaced) leading. Graphs and figures should be readable without magnification; they are encouraged to be in color, but should remain readable if printed in grayscale. All pages should be numbered, and references within the paper should be hyperlinked.  
 Submissions violating these rules will not be considered for publication, and there will be no extensions for fixing violations. We encourage you to upload an early draft of the paper well before the deadline to check if the paper meets the formatting rules.  
 Most of these rules are automatically applied when using the official SIGPLAN LaTeX  or MS Word templates  from the ACM.  
 For Latex, we recommend you use:  
 \documentclass[sigplan,10pt]{acmart} \renewcommand\footnotetextcopyrightpermission[1]{} ... \settopmatter{printfolios=true} \maketitle \pagestyle{plain} ...   

 Confidentiality  
   
 Reviewing will be done mostly by members of the program committee, with limited use of outside reviewers. Submissions will be treated as confidential; however, papers accompanied by nondisclosure agreement forms will not be considered for publication.  

 Conflicts  
   
 To avoid conflicts of interest in the review process, when you register and submit your paper, we ask that you provide information about conflicts between any of the authors of your submission and PC members. Use the following guidelines to determine conflicts:  
 Institutional:  You are currently employed at the same institution, have been previously employed at the same institution within the past two years (since April 2022), or are going to begin employment at the same institution. Former interns should list their internship supervisor(s) and collaborator(s) as conflicts, not the entire institution where they interned.  
 Advisor:  You have a past or present association as PhD thesis advisor or advisee.  
 Collaborator:  You have a collaboration on a project, publication, grant proposal, or editorship within the past two years (April 2022 or later).  
 Personal:  You are close family relatives (e.g., spouses, domestic partners, parents, children, or siblings).  
 The PC chairs will review paper conflicts to ensure the integrity of the reviewing process, adding conflicts if necessary. Similarly, if there is no basis for conflicts provided by authors, such conflicts may be removed (e.g., do not improperly identify a PC member as a conflict in an attempt to avoid having the individual review your paper). If you have any questions about conflicts, please contact the program co-chairs ( sosp24-pc-chairs@cs.wisc.edu  ).  
 PC members will not be able to review, read the reviews of, or participate in discussions of papers they are conflicted with. The review process for papers conflicted with both PC chairs will be managed by another PC member designated as the "conflict chair". Any paper with a PC chair co-author will be held to a higher standard of being a “clear accept”.  

 Author Response Period  
   
 SOSP will provide an opportunity for authors to respond to reviews prior to final consideration of the papers at the program committee meeting. Authors must limit their responses to (a) correcting factual errors in the reviews or (b) directly addressing questions posed by reviewers. Responses should be limited to clarifying the submitted work. In particular, responses must not include new experiments or data, describe additional work completed since submission, or promise additional work to follow. As PC members are not required to review supplementary materials, responses must not rely on the existence of those materials.  
 Submission of a response is optional. There is no explicit limit to the response, but authors are strongly encouraged to keep responses under 500 words; reviewers are neither required nor expected to read excessively long responses.  

 Accepted Papers  
   
 Papers selected by the program committee will be subject to revision and approval by a program committee member acting as a shepherd. Authors of accepted papers will be expected to supply electronic versions of their papers and encouraged to supply source code and raw data to help others replicate and understand their results, as part of an artifact evaluation process. To facilitate broad technical discussion, all accepted papers will be made available online in advance of the conference. The official publication date will be the date the proceedings are made publicly accessible. For more information about the ACM OpenSurround Service, please go to https://www.acm.org/publications/policies/free-access  . Papers of particular merit will be forwarded to the ACM Transactions on Computer Systems (TOCS) and the Communications of the ACM's Research Highlights (CACM RH) for possible publication.  

 Submission Information  
   
 Papers must be submitted electronically in PDF format via the web submission form  .  

 Questions  
   
 Any questions about paper submissions can be emailed to sosp24-pc-chairs@cs.wisc.edu  .  

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Important dates data

33. Conference SOFA_1:
Home 
  Call for paper 
  Paper Submission 
  Registration 
  Advisory Committee | Eligibility for Advisory Committee Membership  Roles and Responsibilities  Apply for Advisory Committee  Advisory Committee Member 
  Publication 
  Committee 
  Agenda 
  Venue 
  Contact US 
  Virtual Conference 
  ☰ 

 International Conference on Soft Computing, Artificial Intelligence and Applications  
  (ICSCAIA-25)  
 12th - 13th March 2025,  
  Kathmandu, Nepal  
 Dual-Mode Conference   Register Now   Submit Your Paper   

 Quality articles will be published in well reputed journals like Scopus Indexed or Web of Science **    

 Pre-Enrollment  
 10th February 2025  

 Final Paper Submission  
 25th February`2025  

 Registration Deadline  
 25th February`2025  

 Conference Date  
 12th - 13th March 2025,  

 Welcome to (ICSCAIA-25)   
 ISER is delighted to welcome you to the International Conference on Soft Computing, Artificial Intelligence and Applications (ICSCAIA-25)  at Kathmandu, Nepal  on 12th - 13th March 2025,  . This event will bring leading scientists, academicians, industry professionals, speakers, and experts of  to one platform. The informative discussions will highlight solutions, achievements, trending issues, and future strategies.  
 ISER constantly aims to present techniques, skills, and the latest information in various fields like science, technology, medical sciences, environment, education, business, banking, finance, languages, history, and much more. It helps participants to explore speaking opportunities, present their unique ideas and create significant connections. You can participate in the groundbreaking discussion, which welcomes active participation and benefits the field and humankind. So, enhance your personal and professional journey by attending the upcoming event.  
   
 Submission Guidelines  
 Please follow these submission guidelines for a smooth procedure related to proffering papers.  
 Procedure  
  Kindly submit papers at the | "Paper Submission" | link on the website 
  If you have any queries, please reach us at | info@iser.org.in 
  Language  
  The official language of all the conferences and papers is English. Therefore, the paper must be written in English, which must be straightforward and free of grammatical errors  
 Our Review Process  
 All the successfully submitted papers will be assessed by the Program Chair, who will initiate the peer review process. Then, the Program Chair will designate at least two suitable technical committee members (Reviewers) with ample field knowledge. After a thorough review, the comments will be submitted to the Program Chair personnel who will make the final decision about submitting the paper.  
 Finally, the conference secretary will inform the concerned authors about the decision. The papers which are not accepted will be sent back for revision and those that pass the second review will be accepted.  
 Note: Please check your email regularly during the review process.  
  Academic Ethics  
 The submitted papers, abstracts, etc., must be original, unpublished work that is not considered for publication elsewhere. In addition, we request the academicians submit original, experimental, or theoretical work that follows the proper citation rules.  
 Following academic ethics is the foundation of any academic. Therefore, plagiarism will not be accepted and will lead to rejection. Some of the actions plagiarism may include are:  
 Rejection of the article or removal of the article from the final publications. 
  Reporting the issue to the concerned author's supervisor(s) and affiliated institution(s). 
  Reporting the case to the office of academic ethics and research funding agency. 
  A right to mention the author's name(s), the title of the article, the name(s) of the affiliated institution, and the details of misconduct, etc., of the plagiarist." 

 Downloads  
  Flyers Download    Sample Abstract    Presenter Form    Listener Form    sample Full Paper     
 ×  Conference Flyer  

 Select Country Code  Algeria (+213)  Andorra (+376)  Angola (+244)  Anguilla (+1264)  Andorra (+376)  American Samoa (+1)  Antigua & Barbuda (+1268)  Argentina (+54)  Afghanistan (+93)  Albania (+355)  Armenia (+374)  Aruba (+297)  Australia (+61)  Austria (+43)  Azerbaijan (+994)  Bahamas (+1242)  Bahrain (+973)  Bangladesh (+880)  Barbados (+1246)  Belarus (+375)  Belgium (+32)  Belize (+501)  Benin (+229)  Bermuda (+1441)  Bhutan (+975)  Bolivia (+591)  Bosnia Herzegovina (+387)  Botswana (+267)  Brazil (+55)  Brunei (+673)  Bulgaria (+359)  Burkina Faso (+226)  Burundi (+257)  Cambodia (+855)  Cocos (keeling) Islands (+61)  Cameroon (+237)  Canada (+1)  Chad (+235)  Christmas Island (+61)  Cape Verde Islands (+238)  Cayman Islands (+1345)  Central African Republic (+236)  Chile (+56)  China (+86)  Colombia (+57)  Comoros (+269)  Congo (+242)  Cook Islands (+682)  Costa Rica (+506)  Croatia (+385)  Cuba (+53)  Cyprus North (+90392)  Cyprus South (+357)  Czech Republic (+42)  Denmark (+45)  Democratic Republic of the Congo (+243)  Djibouti (+253)  Dominica (+1809)  Dominican Republic (+1809)  Ecuador (+593)  Egypt (+20)  East Timor (+670)  El Salvador (+503)  Equatorial Guinea (+240)  Eritrea (+291)  Estonia (+372)  Ethiopia (+251)  Falkland Islands (+500)  Faroe Islands (+298)  Fiji (+679)  Finland (+358)  France (+33)  French Guiana (+594)  French Polynesia (+689)  Gabon (+241)  Gambia (+220)  Georgia (+7880)  Germany (+49)  Ghana (+233)  Gibraltar (+350)  Greece (+30)  Greenland (+299)  Grenada (+1473)  Guadeloupe (+590)  Guam (+671)  Guatemala (+502)  Guinea (+224)  Guinea - Bissau (+245)  Guyana (+592)  Haiti (+509)  Honduras (+504)  Hong Kong (+852)  Hungary (+36)  Iceland (+354)  India (+91)  Indonesia (+62)  Iran (+98)  Iraq (+964)  Ivory Coast (+225)  Ireland (+353)  Israel (+972)  Italy (+39)  Jamaica (+1876)  Japan (+81)  Jordan (+962)  Kazakhstan (+7)  Kenya (+254)  Kiribati (+686)  Korea North (+850)  Korea South (+82)  Kuwait (+965)  Kyrgyzstan (+996)  Laos (+856)  Latvia (+371)  Lebanon (+961)  Lesotho (+266)  Liberia (+231)  Libya (+218)  Liechtenstein (+417)  Lithuania (+370)  Luxembourg (+352)  Macao (+853)  Macedonia (+389)  Madagascar (+261)  Mauritius (+230)  Montenegro (+382)  Malawi (+265)  Malaysia (+60)  Maldives (+960)  Mali (+223)  Malta (+356)  Marshall Islands (+692)  Martinique (+596)  Mauritania (+222)  Mayotte (+269)  Mexico (+52)  Micronesia (+691)  Moldova (+373)  Monaco (+377)  Mongolia (+976)  Montserrat (+1664)  Morocco (+212)  Mozambique (+258)  Myanmar (+95)  Namibia (+264)  Netherlands Antilles (+599)  Nauru (+674)  Nepal (+977)  Netherlands (+31)  New Caledonia (+687)  New Zealand (+64)  Nicaragua (+505)  Niger (+227)  Nigeria (+234)  Niue (+683)  Norfolk Islands (+672)  Northern Marianas (+670)  Norway (+47)  Oman (+968)  Palau (+680)  Panama (+507)  Papua New Guinea (+675)  Paraguay (+595)  Peru (+51)  Pakistan (+92)  Philippines (+63)  Poland (+48)  Portugal (+351)  Puerto Rico (+1787)  Qatar (+974)  Reunion (+262)  Romania (+40)  Russia (+7)  Rwanda (+250)  San Marino (+378)  Sao Tome & Principe (+239)  Saudi Arabia (+966)  Senegal (+221)  Serbia (+381)  Seychelles (+248)  Sierra Leone (+232)  Singapore (+65)  Saint Pierre and Miquelon (+508)  Saint Vincent and the Grenadines (+1)  Samoa (+685)  Slovak Republic (+421)  Slovenia (+386)  Solomon Islands (+677)  Somalia (+252)  South Africa (+27)  Spain (+34)  Sri Lanka (+94)  St. Helena (+290)  St. Kitts (+1869)  St. Lucia (+1758)  Sudan (+249)  Suriname (+597)  Swaziland (+268)  Sweden (+46)  Switzerland (+41)  Syria (+963)  Taiwan (+886)  Tajikstan (+7)  Tanzania (+255)  Thailand (+66)  Togo (+228)  Tokelau (+690)  Tonga (+676)  Trinidad & Tobago (+1868)  Tunisia (+216)  Turkey (+90)  Turkmenistan (+7)  Turkmenistan (+993)  Turks & Caicos Islands (+1649)  Tuvalu (+688)  Uganda (+256)  UK (+44)  Ukraine (+380)  United Arab Emirates (+971)  Uruguay (+598)  USA (+1)  Uzbekistan (+7)  Vanuatu (+678)  Vatican City (+379)  Venezuela (+58)  Vietnam (+84)  Virgin Islands - British (+1284)  Virgin Islands - US (+1340)  Wallis & Futuna (+681)  Yemen (North)(+969)  Yemen (South)(+967)  Zambia (+260)  Zimbabwe (+263)        

 Close    

 Contact Person  
 Program manager  
  +91 9344550460  
  info@iser.org.in  
   
 Conference Subscription  
    Select Country Code  Algeria (+213)  Andorra (+376)  Angola (+244)  Anguilla (+1264)  Andorra (+376)  American Samoa (+1)  Antigua & Barbuda (+1268)  Argentina (+54)  Afghanistan (+93)  Albania (+355)  Armenia (+374)  Aruba (+297)  Australia (+61)  Austria (+43)  Azerbaijan (+994)  Bahamas (+1242)  Bahrain (+973)  Bangladesh (+880)  Barbados (+1246)  Belarus (+375)  Belgium (+32)  Belize (+501)  Benin (+229)  Bermuda (+1441)  Bhutan (+975)  Bolivia (+591)  Bosnia Herzegovina (+387)  Botswana (+267)  Brazil (+55)  Brunei (+673)  Bulgaria (+359)  Burkina Faso (+226)  Burundi (+257)  Cambodia (+855)  Cocos (keeling) Islands (+61)  Cameroon (+237)  Canada (+1)  Chad (+235)  Christmas Island (+61)  Cape Verde Islands (+238)  Cayman Islands (+1345)  Central African Republic (+236)  Chile (+56)  China (+86)  Colombia (+57)  Comoros (+269)  Congo (+242)  Cook Islands (+682)  Costa Rica (+506)  Croatia (+385)  Cuba (+53)  Cyprus North (+90392)  Cyprus South (+357)  Czech Republic (+42)  Denmark (+45)  Democratic Republic of the Congo (+243)  Djibouti (+253)  Dominica (+1809)  Dominican Republic (+1809)  Ecuador (+593)  Egypt (+20)  East Timor (+670)  El Salvador (+503)  Equatorial Guinea (+240)  Eritrea (+291)  Estonia (+372)  Ethiopia (+251)  Falkland Islands (+500)  Faroe Islands (+298)  Fiji (+679)  Finland (+358)  France (+33)  French Guiana (+594)  French Polynesia (+689)  Gabon (+241)  Gambia (+220)  Georgia (+7880)  Germany (+49)  Ghana (+233)  Gibraltar (+350)  Greece (+30)  Greenland (+299)  Grenada (+1473)  Guadeloupe (+590)  Guam (+671)  Guatemala (+502)  Guinea (+224)  Guinea - Bissau (+245)  Guyana (+592)  Haiti (+509)  Honduras (+504)  Hong Kong (+852)  Hungary (+36)  Iceland (+354)  India (+91)  Indonesia (+62)  Iran (+98)  Iraq (+964)  Ivory Coast (+225)  Ireland (+353)  Israel (+972)  Italy (+39)  Jamaica (+1876)  Japan (+81)  Jordan (+962)  Kazakhstan (+7)  Kenya (+254)  Kiribati (+686)  Korea North (+850)  Korea South (+82)  Kuwait (+965)  Kyrgyzstan (+996)  Laos (+856)  Latvia (+371)  Lebanon (+961)  Lesotho (+266)  Liberia (+231)  Libya (+218)  Liechtenstein (+417)  Lithuania (+370)  Luxembourg (+352)  Macao (+853)  Macedonia (+389)  Madagascar (+261)  Mauritius (+230)  Montenegro (+382)  Malawi (+265)  Malaysia (+60)  Maldives (+960)  Mali (+223)  Malta (+356)  Marshall Islands (+692)  Martinique (+596)  Mauritania (+222)  Mayotte (+269)  Mexico (+52)  Micronesia (+691)  Moldova (+373)  Monaco (+377)  Mongolia (+976)  Montserrat (+1664)  Morocco (+212)  Mozambique (+258)  Myanmar (+95)  Namibia (+264)  Netherlands Antilles (+599)  Nauru (+674)  Nepal (+977)  Netherlands (+31)  New Caledonia (+687)  New Zealand (+64)  Nicaragua (+505)  Niger (+227)  Nigeria (+234)  Niue (+683)  Norfolk Islands (+672)  Northern Marianas (+670)  Norway (+47)  Oman (+968)  Palau (+680)  Panama (+507)  Papua New Guinea (+675)  Paraguay (+595)  Peru (+51)  Pakistan (+92)  Philippines (+63)  Poland (+48)  Portugal (+351)  Puerto Rico (+1787)  Qatar (+974)  Reunion (+262)  Romania (+40)  Russia (+7)  Rwanda (+250)  San Marino (+378)  Sao Tome & Principe (+239)  Saudi Arabia (+966)  Senegal (+221)  Serbia (+381)  Seychelles (+248)  Sierra Leone (+232)  Singapore (+65)  Saint Pierre and Miquelon (+508)  Saint Vincent and the Grenadines (+1)  Samoa (+685)  Slovak Republic (+421)  Slovenia (+386)  Solomon Islands (+677)  Somalia (+252)  South Africa (+27)  Spain (+34)  Sri Lanka (+94)  St. Helena (+290)  St. Kitts (+1869)  St. Lucia (+1758)  Sudan (+249)  Suriname (+597)  Swaziland (+268)  Sweden (+46)  Switzerland (+41)  Syria (+963)  Taiwan (+886)  Tajikstan (+7)  Tanzania (+255)  Thailand (+66)  Togo (+228)  Tokelau (+690)  Tonga (+676)  Trinidad & Tobago (+1868)  Tunisia (+216)  Turkey (+90)  Turkmenistan (+7)  Turkmenistan (+993)  Turks & Caicos Islands (+1649)  Tuvalu (+688)  Uganda (+256)  UK (+44)    --Attend as--  Presenter  Listener       
             We do not spam. We value your privacy!  

 Indexed In  

 Quick Links  
 About US 
  Membership 
  Join a Member 
  Conferences/Event 
    
 Services  
 Researchpedia 
  Researchers Gallery 
  Academics Research Library 
  Visa 
    
 Contact us  
 +91 9344550460 
  info@iser.org.in 
    
 ISER © 2024 All rights reserved | Our Terms & Conditions   

  Call for papers data:  

 Home 
  Call for paper 
  Paper Submission 
  Registration 
  Advisory Committee | Eligibility for Advisory Committee Membership  Roles and Responsibilities  Apply for Advisory Committee  Advisory Committee Member 
  Publication 
  Committee 
  Agenda 
  Venue 
  Contact US 
  Virtual Conference 
  ☰ 

 International Conference on Soft Computing, Artificial Intelligence and Applications  
  (ICSCAIA-25)  
 12th - 13th March 2025,  
  Kathmandu, Nepal  
 Dual-Mode Conference   Register Now   Submit Your Paper   

 Quality articles will be published in well reputed journals like Scopus Indexed or Web of Science **    

 Pre-Enrollment  
 10th February 2025  

 Final Paper Submission  
 25th February`2025  

 Registration Deadline  
 25th February`2025  

 Conference Date  
 12th - 13th March 2025,  

 Call For Paper  
 Artificial Intelligence 
  AI Algorithms 
  Artificial Intelligence tools & Applications 
  Automatic Control 
  Bioinformatics 
  Natural Language Processing 
  CAD Design & Testing•Computer Vision and Speech Understanding 
  Data Mining and Machine Learning Tools 
  Fuzzy Logic 
  Heuristic and AI Planning Strategies and Tools 
  Computational Theories of Learning 
  Hybrid Intelligent Systems 
  Information Retrieval 
  Intelligent System Architectures 
  Knowledge Representation 
  Knowledge-based Systems 
  Mechatronics 
  Multimedia & Cognitive Informatics 
  Neural Networks 
  Parallel Processing 
  Pattern Recognition 
  Pervasive computing and ambient intelligence 
  Programming Languages 
  Reasoning and Evolution 
  Recent Trends and Developments 
  Robotics 
  Semantic Web Techniques and Technologies 
  Soft computing theory and applications 
  Software & Hardware Architectures 
  Web Intelligence Applications & Search 
   Soft Computing 
  Fuzzy Systems 
  Neural Networks 
  Machine learning 
  Probabilistic Reasoning 
  Evolutionary Computing 
  Pattern recognition 
  Hybrid intelligent systems 
  Software agents 
  Morphic Computing 
  Image processing 
  Commerce, e-medicine 
  Rough Sets 
  Symbolic machine learning 
  Wavelet 
  Signal or Image Processing 
  Vision Recognition 
  Biomedical Engineering 
  Telecommunications 
  Reactive Distributed AI 
  Nano & Micro-systems 
  Data Visualization 

 Quick Links  
 About US 
  Membership 
  Join a Member 
  Conferences/Event 
    
 Services  
 Researchpedia 
  Researchers Gallery 
  Academics Research Library 
  Visa 
    
 Contact us  
 +91 9344550460 
  info@iser.org.in 
    
 ISER © 2024 All rights reserved | Our Terms & Conditions   

  Important dates data

34. Conference SOSP_2:
SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

 Schedule  
   
 Sunday, November 3, 2024  

 Welcome Reception in Salon F/G: 17:30–19:30 
 Please join us for appetizers and light snacks on Sunday evening. 
  
 Monday, November 4, 2024  

 Breakfast: 8:00–8:30 
  
 Welcome and Session 1: Distributed Systems 8:30 - 10:30  Session Chair: Wyatt Lloyd   
  
 Introductory remarks 
 Autobahn: Seamless High Speed BFT    
  Neil Giridharan (UC Berkeley), Florian Suri-Payer (Cornell University), Ittai Abraham (Intel), Lorenzo Alvisi (Cornell University), Natacha Crooks (UC Berkeley) 
 SWARM: Replicating Shared Disaggregated-Memory Data in No Time    
  Antoine Murat (EPFL), Clément Burgelin (EPFL), Athanasios Xygkis (Oracle Labs), Igor Zablotchi (Mysten Labs), Marcos K. Aguilera (VMware Research Group), Rachid Guerraoui (EPFL)   
  Distinguished Artifact Honorable Mention 
 Efficient Reproduction of Fault-Induced Failures in Distributed Systems with Feedback-Driven Fault Injection    
  Jia Pan (Johns Hopkins University), Haoze Wu (Johns Hopkins University), Tanakorn Leesatapornwongsa (Microsoft Research), Suman Nath (Microsoft Research), Peng Huang (University of Michigan) 
 If At First You Don’t Succeed, Try, Try, Again...? Insights and LLM-informed Tooling for Detecting Retry Bugs in Software Systems    
  Bogdan Alexandru Stoica (University of Chicago), Utsav Sethi (University of Chicago), Yiming Su (University of Chicago), Cyrus Zhou (University of Chicago), Shan Lu (Microsoft Research), Jonathan Mace (Microsoft Research), Madanlal Musuvathi (Microsoft Research), Suman Nath (Microsoft Research) 

 Coffee: 10:30–11:00 
  
 Session 2: Memory 11:00 - 12:30  Session Chair: Sudarsun Kannan   
  
 Tiered Memory Management: Access Latency is the Key!  
    Midhul Vuppalapati (Cornell University), Rachit Agarwal (Cornell University) 
 Fast & Safe IO Memory Protection  
    Benny Rubin (Cornell University), Saksham Agarwal (UIUC), Qizhe Cai (Cornell University), Rachit Agarwal (Cornell University) 
 CHIME: A Cache-Efficient and High-Performance Hybrid Index on Disaggregated Memory  
    Xuchuan Luo (Fudan University), Jiacheng Shen (Duke Kunshan University), Pengfei Zuo (Huawei Cloud), Xin Wang (Fudan University), Michael R. Lyu (The Chinese University of Hong Kong), Yangfan Zhou (Fudan University) 
 Aceso: Achieving Efficient Fault Tolerance in Memory-Disaggregated Key-Value Stores  
    Zhisheng Hu (The Chinese University of Hong Kong), Pengfei Zuo (Huawei Cloud), Yizou Chen (The Chinese University of Hong Kong), Chao Wang (The Chinese University of Hong Kong), Junliang Hu (The Chinese University of Hong Kong), Ming-Chang Yang (The Chinese University of Hong Kong) 

 Lunch: 12:30–14:00 
  
 Session 3: Deep Learning and Training 14:00 - 16:00  Session Chair: Shivaram Venkataraman   
  
 Reducing Energy Bloat in Large Model Training  
    Jae-Won Chung (University of Michigan), Yile Gu (University of Washington), Insu Jang (University of Michigan), Luoxi Meng (University of California, San Diego), Nikhil Bansal (University of Michigan), Mosharaf Chowdhury (University of Michigan) 
 Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor  
    Siran Liu (Peking University), Chengxiang Qi (University of Chinese Academy of Sciences), Ying Cao (Microsoft Research Asia), Chao Yang (Peking University), Weifang Hu (Huazhong University of Science and Technology), Xuanhua Shi (Huazhong University of Science and Technology), Fan Yang (Microsoft Research Asia), Mao Yang (Microsoft Research Asia) 
 Enabling Parallelism Hot Switching for Efficient Training of Large Language Models  
    Hao Ge (Peking University), Fangcheng Fu (Peking University), Haoyang Li (Peking University), Xuanyu Wang (Peking University), Sheng Lin (Peking University), Yujie Wang (Peking University), Xiaonan Nie (Peking University), Hailin Zhang (Peking University), Xupeng Miao (Purdue University), Bin Cui (Peking University) 
 Tenplex: Dynamic Parallelism for Deep Learning using Parallelizable Tensor Collections  
    Marcel Wagenländer (Imperial College London), Guo Li (Imperial College London), Bo Zhao (Aalto University), Luo Mai (University of Edinburgh), Peter Pietzuch (Imperial College London) 
 ReCycle: Resilient Training of Large DNNs using Pipeline Adaptation  
    Swapnil Gandhi (Stanford University), Mark Zhao (Stanford University), Athinagoras Skiadopoulos (Stanford University), Christos Kozyrakis (Stanford University) 

 Coffee: 16:00–16:30 
  
 Poster Session 16:30 - 18:30   
  
 Poster session in Salon F/G: SOSP posters and Student Research Competition posters. 
  
 Evening Activities 18:30 - 22:00   
  
 18:30–19:00: Transition to Stubb's 

 19:00–22:00: Music and Food at Stubb's | Stubbs 
 Please join us on Monday night for dinner and music at Stubb's Bar-B-Q  . Stubb's is a classic Austin venue where we will serve barbecue and vegetarian options outside for dinner. We will also have music from an Austin-area band. Stubb's is a six minute walk from the conference hotel. 

 Tuesday, November 5, 2024  

 Breakfast: 8:00–9:00 
 Women in Systems Meetup: 8:00–9:00 
 Please join us during breakfast for a Women in Systems Meetup in Room 602. Learn more about the event here  . 
  
 Session 4: Kernels 9:00 - 10:30  Session Chair: Malte Schwarzkopf   
  
 OZZ: Identifying Kernel Out-of-Order Concurrency Bugs with In-Vivo Memory Access Reordering  
    Dae R. Jeong (Georgia Tech), Yewon Choi (KAIST), Byoungyoung Lee (Seoul National University), Insik Shin (KAIST), Youngjin Kwon (KAIST)   
  Best Paper Award 
 Fast, Flexible, and Practical Kernel Extensions  
    Kumar Kartikeya Dwivedi (EPFL), Rishabh Iyer (UC Berkeley), Sanidhya Kashyap (EPFL) 
 Skyloft: A General High-Efficient Scheduling Framework in User Space  
    Yuekai Jia (Tsinghua University), Kaifu Tian (Tsinghua University), Yuyang You (Tsinghua University), Yu Chen (Quan Cheng Laboratory and Tsinghua University), Kang Chen (Tsinghua University) 
 Fast Core Scheduling with Userspace Process Abstraction  
    Jiazhen Lin (Tsinghua University), Youmin Chen (Tsinghua University), Shiwei Gao (Tsinghua University), Youyou Lu (Tsinghua University) 

 Coffee: 10:30–11:00 
  
 Session 5: File and Storage Systems 11:00 - 12:30  Session Chair: Gala Yadgar   
  
 LazyLog: A New Shared Log Abstraction for Low-Latency Applications  
    Xuhao Luo (University of Illinois Urbana-Champaign), Shreesha G Bhat (University of Illinois Urbana-Champaign), Jiyu Hu (University of Illinois Urbana-Champaign), Ramnatthan Alagappan (University of Illinois Urbana-Champaign and VMware Research), Aishwarya Ganesan (University of Illinois Urbana-Champaign and VMware Research)   
  Best Paper Award 
 BIZA: Design of Self-Governing Block-Interface ZNS AFA for Endurance and Performance  
    Shushu Yi (Peking University), Shaocong Sun (Peking University), Li Peng (Peking University), Yingbo Sun (Peking University), Ming-Chang Yang (The Chinese University of Hong Kong), Zhichao Cao (Arizona State University), Qiao Li (Xiamen University), Myoungsoo Jung (KAIST and Panmnesia), Ke Zhou (Huazhong University of Science and Technology), Jie Zhang (Peking University) 
 Morph: Efficient File-Lifetime Redundancy Management for Cluster File Systems  
    Timothy Kim (Carnegie Mellon University), Sanjith Athlur (Carnegie Mellon University), Saurabh Kadekodi (Google), Francisco Maturana (Carnegie Mellon University), Dax Delvira (Georgia Tech), Arif Merchant (Google), Gregory R. Ganger (Carnegie Mellon University), K. V. Rashmi (Carnegie Mellon University) 
 Reducing Cross-Cloud/Region Costs with the Auto-Configuring MACARON Cache  
    Hojin Park (Carnegie Mellon University), Ziyue Qiu (Carnegie Mellon University, Uber), Gregory R. Ganger (Carnegie Mellon University), George Amvrosiadis (Carnegie Mellon University) 

 Lunch: 12:30–14:00 
  
 Session 6: Serverless 14:00 - 15:30  Session Chair: Vijay Chidambaram   
  
 Dirigent: Lightweight Serverless Orchestration  
    Lazar Cvetković (ETH Zurich), François Costa (ETH Zurich), Mihajlo Djokic (ETH Zurich and IBM Research Europe), Michal Friedman (ETH Zurich), Ana Klimovic (ETH Zurich) 
 Unifying Serverless and Microservice Workloads with SigmaOS  
    Ariel Szekely (MIT), Adam Belay (MIT), Robert Morris (MIT), M. Frans Kaashoek (MIT) 
 Caribou: Fine-Grained Geospatial Shifting of Serverless Applications for Sustainability  
    Viktor Gsteiger (ETH Zürich), Pin Hong (Daniel) Long (University of British Columbia), Yiran (Jerry) Sun (University of British Columbia), Parshan Javanrood (University of British Columbia), Mohammad Shahrad (University of British Columbia) 
 TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes  
    Jialiang Huang (Tsinghua University, Alibaba Group), MingXing Zhang (Tsinghua University), Teng Ma (Alibaba Group), Zheng Liu (Zhejiang University, Alibaba Group), Sixing Lin (Tsinghua University, Wuhan University), Kang Chen (Tsinghua University), Jinlei Jiang (Tsinghua University), Xia Liao (Tsinghua University), Yingdi Shan (Tsinghua University), Ning Zhang (Alibaba Group), Mengting Lu (Alibaba Group), Tao Ma (Alibaba Group), Haifeng Gong (Intel), YongWei Wu (Tsinghua University) 

 Coffee: 15:30–16:00 
  
 Session 7: Verification and Compilers 16:00 - 18:00  Session Chair: Manos Kapritsos   
  
 Verus: A Practical Foundation for Systems Verification  
    Andrea Lattuada (MPI-SWS), Travis Hance (Carnegie Mellon University), Jay Bosamiya (Microsoft Research), Matthias Brun (ETH Zurich), Chanhee Cho (Carnegie Mellon University), Hayley LeBlanc (University of Texas at Austin), Pranav Srinivasan (University of Michigan), Reto Achermann (University of British Columbia), Tej Chajed (University of Wisconsin-Madison), Chris Hawblitzel (Microsoft Research), Jon Howell (VMware Research), Jacob R. Lorch (Microsoft Research), Oded Padon (Weizmann Institute of Science), Bryan Parno (Carnegie Mellon University)   
  Distinguished Artifact Award 
 Practical Verification of System-Software Components Written in Standard C  
    Can Cebeci (EPFL), Yonghao Zou (EPFL), Diyu Zhou (EPFL), George Candea (EPFL), Clément Pit-Claudel (EPFL) 
 Icarus: Trustworthy Just-In-Time Compilers with Symbolic Meta-Execution  
    Naomi Smith (UCSD), Abhishek Sharma (UT Austin), John Renner (UCSD), David Thien (UCSD), Fraser Brown (CMU), Hovav Shacham (UT Austin), Ranjit Jhala (UCSD), Deian Stefan (UCSD) 
 SilvanForge: A Schedule Guided Retargetable Compiler for Decision Tree Inference  
    Ashwin Prasad (Indian Institute of Science), Sampath Rajendra (Microsoft Research), Kaushik Rajan (Microsoft Research), R. Govindarajan (Indian Institute of Science, Bangalore), Uday Bondhugula (Indian Institute of Science and PolyMage Labs) 
 Scaling Deep Learning Computation over the Inter-Core Connected Intelligence Processor with T10  
    Yiqi Liu (University of Illinois Urbana-Champaign), Yuqi Xue (University of Illinois Urbana-Champaign), Yu Cheng (Microsoft Research), Lingxiao Ma (Microsoft Research), Ziming Miao (Microsoft Research), Jilong Xue (Microsoft Research), Jian Huang (University of Illinois Urbana-Champaign) 

 18:00–19:00: Student Research Competition 

 19:00–22:00: Banquet and SIGOPS Business Meeting 

 Wednesday, November 6, 2024  

 Breakfast: 8:00–9:00 
  
 Session 8: Data Center, Cloud, and Virtualization 9:00 - 10:30  Session Chair: Natacha Crooks   
  
 FBDetect: Catching Tiny Performance Regressions at Hyperscale through In-Production Monitoring  
    Dong Young Yoon (Meta Platforms), Yang Wang (Meta Platforms and The Ohio State University), Miao Yu (Meta Platforms and The Ohio State University), Elvis Huang (Meta Platforms), Juan Ignacio Jones (Meta Platforms), Abhinay Kukkadapu (Meta Platforms), Osman Kocas (Meta Platforms), Jonathan Wiepert (Meta Platforms), Kapil Goenka (Meta Platforms), Sherry Chen (Meta Platforms), Yanjun Lin (Meta Platforms), Zhihui Huang (Meta Platforms), Jocelyn Kong (Meta Platforms), Michael Chow (Meta Platforms), Chunqiang Tang (Meta Platforms)   
  Best Paper Award 
 VPRI: Efficient I/O Page Fault Handling via Software-Hardware Co-Design for IaaS Clouds  
    Kaijie Guo (Alibaba Group), Dingji Li (Institute of Parallel and Distributed Systems, SEIEE, Shanghai Jiao Tong University), Ben Luo (Alibaba Group), Yibin Shen (Alibaba Group), Kaihuan Peng (Alibaba Group), Ning Luo (Alibaba Group), Shengdong Dai (Alibaba Group), Chen Liang (Alibaba Group), Jianming Song (Alibaba Group), Hang Yang (Alibaba Group), Xiantao Zhang (Alibaba Group), Zeyu Mi (Institute of Parallel and Distributed Systems, SEIEE, Shanghai Jiao Tong University) 
 vSoC: Efficient Virtual System-on-Chip on Heterogeneous Hardware  
    Jiaxing Qiu (Tsinghua University), Zijie Zhou (Tsinghua University), Yang Li (Tsinghua University), Zhenhua Li (Tsinghua University), Feng Qian (University of Southern California), Hao Lin (Tsinghua University and University of Illinois Urbana-Champaign), Di Gao (Tsinghua University), Haitao Su (Tsinghua University), Xin Miao (Tsinghua University), Yunhao Liu (Tsinghua University), Tianyin Xu (University of Illinois Urbana-Champaign) 
 Unearthing Semantic Checks for Cloud Infrastructure-as-Code Programs  
    Yiming Qiu (University of Michigan), Patrick Tser Jern Kon (University of Michigan), Ryan Beckett (Microsoft), Ang Chen (University of Michigan) 

 Coffee: 10:30–11:00 
  
 Session 9: ML Serving 11:00 - 12:30  Session Chair: Ram Alagappan   
  
 PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU  
    Yixin Song (Shanghai Jiao Tong University), Zeyu Mi (Shanghai Jiao Tong University), Haotong Xie (Shanghai Jiao Tong University), Haibo Chen (Shanghai Jiao Tong University) 
 Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in ML Serving  
    Yinwei Dai (Princeton University), Rui Pan (Princeton University), Anand Iyer (Georgia Tech), Kai Li (Princeton University), Ravi Netravali (Princeton University) 
 Improving DNN Inference Throughput Using Practical, Per-Input Compute Adaptation  
    Anand Iyer (Georgia Tech), Mingyu Guan (Georgia Tech), Yinwei Dai (Princeton University), Rui Pan (Princeton University), Swapnil Gandhi (Stanford University), Ravi Netravali (Princeton University) 
 LoongServe: Efficiently Serving Long-Context Large Language Models with Elastic Sequence Parallelism  
    Bingyang Wu (Peking University), Shengyu Liu (Peking University), Yinmin Zhong (Peking University), Peng Sun (Shanghai AI Lab), Xuanzhe Liu (Peking University), Xin Jin (Peking University) 

 Boxed Lunch: 12:30–13:30 
  
 Session 10: Security 13:30 - 15:30  Session Chair: Jay Lorch   
  
 Modular Verification of Secure and Leakage-Free Systems: From Application Specification to Circuit-Level Implementation  
    Anish Athalye (MIT), Henry Corrigan-Gibbs (MIT), Frans Kaashoek (MIT), Joseph Tassarotti (New York University), Nickolai Zeldovich (MIT) 
 NOPE: Strengthening Domain Authentication with Succinct Proofs  
    Zachary DeStefano (NYU), Jeff J. Ma (NYU), Joseph Bonneau (NYU), Michael Walfish (NYU) 
 Cookie Monster: Efficient On-Device Budgeting for Differentially-Private Ad-Measurement Systems  
    Pierre Tholoniat (Columbia University), Kelly Kostopoulou (Columbia University), Peter McNeely (Columbia University), Prabhpreet Singh Sodhi (Columbia University), Anirudh Varanasi (Columbia University), Benjamin Case (Meta Inc.), Asaf Cidon (Columbia University), Roxana Geambasu (Columbia University), Mathias Lécuyer (University of British Columbia)   
  Distinguished Artifact Honorable Mention 
 Sesame: Practical End-to-End Privacy Compliance with Policy Containers and Privacy Regions  
    Kinan Dak Albab (Brown University), Artem Agvanian (Brown University), Allen Aby (Brown University), Corinn Tiffany (Brown University), Alexander Portland (Brown University), Sarah Ridley (Brown University), Malte Schwarzkopf (Brown University) 
 DNS Congestion Control in Adversarial Settings  
    Huayi Duan (ETH Zurich), Jihye Kim (ETH Zurich), Marc Wyss (ETH Zurich), Adrian Perrig (ETH Zurich) 

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Call for papers data:SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

 SOSP 2024 Call for Papers  
 The 30th ACM Symposium on Operating Systems Principles (SOSP) seeks to present innovative and exciting research related to the design, implementation, analysis, evaluation, and deployment of computer systems software.  

 Event Info | Date | Link 
 Deadline to register abstracts | April 12, 2024; 23:59 PT | HotCRP Submission Site 
 Submission deadline (no extensions) | April 19, 2024; 23:59 PT | HotCRP Submission Site 
 Reviews available for author response | July 22, 2024 |  
 Author response due | July 26, 2024 |  
 Author notification | August 5, 2024 |  
 Camera ready due | September 23, 2024 | HotCRP Submission Site 
 Conference | November 4-6, 2024 | Conference Site 

 Topics  
   
 SOSP takes a broad view of systems and solicits contributions from many fields of systems practice, including: operating systems, file and storage systems, distributed systems, cloud computing, mobile and edge systems, secure and reliable systems, systems aspects of big data and machine learning, embedded and real-time systems, virtualization, networking as it relates to operating systems, and management and troubleshooting of complex systems. We also welcome work that explores the interaction of computer systems with related areas such as computer architecture, networking, programming languages, analytics, verification, and databases. In keeping with SOSP tradition, we will favor work that explores new territory, continues a significant research dialogue, or reflects on experience with or measurements of state-of-the-art implementations.  

 Submission Criteria  
   
 Submissions will be judged on novelty, significance, interest, clarity, relevance, and correctness. A good paper will:  
 Motivate a significant problem; 
  Propose and implement an interesting, compelling solution; 
  Demonstrate the practicality and benefits of the solution; 
  Draw appropriate conclusions; 
  Clearly describe the paper's contributions; and 
  Clearly articulate the advances beyond previous work. 
  We encourage submission of groundbreaking work in significant new directions, with the understanding that the evaluation criteria for papers addressing new problems may be different from those continuing a line of work in a more established area.  

 Originality  
   
 Submissions should contain original, unpublished material. Simultaneous submission of the same work to multiple venues, submission of previously published work, or plagiarism is not allowed.  
 Submissions that extend the authors' previous work are welcome, but authors must explain the differences between the SOSP submission and the prior work, much in the same way that the authors are expected to articulate the contributions of their submission as they relate to prior work by others. Self-comparisons should be properly anonymized, as described below.  
 Prior or concurrent workshop publication does not preclude publishing a related paper in SOSP. The online submission form will require authors to submit a copy of the related workshop paper and a short explanation of the new material in the conference paper beyond that published in the workshop version. As long as there is significant additional content in the submission compared to the prior workshop publication, the PC will evaluate the submission's entire contribution, not just the delta.  
 Prior or concurrent publication in non-peer-reviewed contexts, like arXiv.org, technical reports, talks, and social media posts, is explicitly permitted.  

 Resubmissions  
   
 Submitting a paper that had been previously submitted to and not accepted by another conference is permitted, although authors are expected to have improved the paper to address substantive issues raised in previous reviews. Authors should provide information regarding the previous submission(s) and a summary of the subsequent revisions to the paper. This description, which will be supplied to reviewers after they’ve completed their reviews, helps reviewers who may have reviewed a previous draft of the work to appreciate any improvements to the currently submitted work. Please try to limit the description of changes to one page. All information should be properly anonymized, as described below, and should be uploaded via the submission form.  

 Anonymity  
   
 SOSP will use double-blind reviewing. Please make a good faith attempt to anonymize your submission. Avoid identifying yourself or your institution explicitly or by implication (e.g., through the references or acknowledgments). The first page should use the paper ID assigned during registration in place of the author names. If the name of your project or system is already known to the community (e.g., through arXiv, technical reports, talks, social media posts, or other uses), your SOSP submission must use an anonymized name.  
 Use care in referring to your own related work. Do not omit references to your prior work, as this would make it difficult for reviewers to place your submission in its proper context. Instead, reference your past work in the third person, just as you would any other piece of related work. For example, you might say "Our system modifies the XYZ operating system built by Lee et al. [Lee17]".  
 For concurrent submissions on related topics, cite an anonymized version of the concurrent submission and discuss the relation between the submissions. Additionally, please email the PC chairs ( sosp24-pc-chairs@cs.wisc.edu  ) a copy of your other concurrent submission.  
 If your submission reports on experiences with a system at your institution or organization, you should refer to the system anonymously but describe the properties of the system that are needed to appreciate the work (e.g., size of the user base, volume of requests, etc.). We recognize that, in some cases, these properties may allow a reviewer to identify your institution or organization.  
 Check with the program chairs ( sosp24-pc-chairs@cs.wisc.edu  ) if you are uncertain about the anonymity rules.  

 Supplementary Material  
   
 Authors may optionally include supplementary material as a separate document. Supplementary material is intended for items that are not critical for evaluating the paper but may be of interest to some readers. Examples include: formal proofs that are only sketched in the submission, additional analyses, and methodological details that aren’t essential for the PC’s assessment but are important for reproducibility. PC members are not required to read this optional supplementary material, so the submission must stand alone without it.  

 Formatting  
   
 Papers will be submitted electronically in PDF format via the web submission form  .  
 Submissions may have at most 12 pages of technical content, including all text, figures, tables, etc. Bibliographic references are not included in the 12-page limit. Use A4 or US letter paper size, with all text and figures fitting inside a 178 x 229 mm (7 x 9 in) block centered on the page, using two columns separated by 8 mm (0.33 in) of whitespace. Use 10-point font (typeface Times Roman, Linux Libertine, etc.) on 12-point (single-spaced) leading. Graphs and figures should be readable without magnification; they are encouraged to be in color, but should remain readable if printed in grayscale. All pages should be numbered, and references within the paper should be hyperlinked.  
 Submissions violating these rules will not be considered for publication, and there will be no extensions for fixing violations. We encourage you to upload an early draft of the paper well before the deadline to check if the paper meets the formatting rules.  
 Most of these rules are automatically applied when using the official SIGPLAN LaTeX  or MS Word templates  from the ACM.  
 For Latex, we recommend you use:  
 \documentclass[sigplan,10pt]{acmart} \renewcommand\footnotetextcopyrightpermission[1]{} ... \settopmatter{printfolios=true} \maketitle \pagestyle{plain} ...   

 Confidentiality  
   
 Reviewing will be done mostly by members of the program committee, with limited use of outside reviewers. Submissions will be treated as confidential; however, papers accompanied by nondisclosure agreement forms will not be considered for publication.  

 Conflicts  
   
 To avoid conflicts of interest in the review process, when you register and submit your paper, we ask that you provide information about conflicts between any of the authors of your submission and PC members. Use the following guidelines to determine conflicts:  
 Institutional:  You are currently employed at the same institution, have been previously employed at the same institution within the past two years (since April 2022), or are going to begin employment at the same institution. Former interns should list their internship supervisor(s) and collaborator(s) as conflicts, not the entire institution where they interned.  
 Advisor:  You have a past or present association as PhD thesis advisor or advisee.  
 Collaborator:  You have a collaboration on a project, publication, grant proposal, or editorship within the past two years (April 2022 or later).  
 Personal:  You are close family relatives (e.g., spouses, domestic partners, parents, children, or siblings).  
 The PC chairs will review paper conflicts to ensure the integrity of the reviewing process, adding conflicts if necessary. Similarly, if there is no basis for conflicts provided by authors, such conflicts may be removed (e.g., do not improperly identify a PC member as a conflict in an attempt to avoid having the individual review your paper). If you have any questions about conflicts, please contact the program co-chairs ( sosp24-pc-chairs@cs.wisc.edu  ).  
 PC members will not be able to review, read the reviews of, or participate in discussions of papers they are conflicted with. The review process for papers conflicted with both PC chairs will be managed by another PC member designated as the "conflict chair". Any paper with a PC chair co-author will be held to a higher standard of being a “clear accept”.  

 Author Response Period  
   
 SOSP will provide an opportunity for authors to respond to reviews prior to final consideration of the papers at the program committee meeting. Authors must limit their responses to (a) correcting factual errors in the reviews or (b) directly addressing questions posed by reviewers. Responses should be limited to clarifying the submitted work. In particular, responses must not include new experiments or data, describe additional work completed since submission, or promise additional work to follow. As PC members are not required to review supplementary materials, responses must not rely on the existence of those materials.  
 Submission of a response is optional. There is no explicit limit to the response, but authors are strongly encouraged to keep responses under 500 words; reviewers are neither required nor expected to read excessively long responses.  

 Accepted Papers  
   
 Papers selected by the program committee will be subject to revision and approval by a program committee member acting as a shepherd. Authors of accepted papers will be expected to supply electronic versions of their papers and encouraged to supply source code and raw data to help others replicate and understand their results, as part of an artifact evaluation process. To facilitate broad technical discussion, all accepted papers will be made available online in advance of the conference. The official publication date will be the date the proceedings are made publicly accessible. For more information about the ACM OpenSurround Service, please go to https://www.acm.org/publications/policies/free-access  . Papers of particular merit will be forwarded to the ACM Transactions on Computer Systems (TOCS) and the Communications of the ACM's Research Highlights (CACM RH) for possible publication.  

 Submission Information  
   
 Papers must be submitted electronically in PDF format via the web submission form  .  

 Questions  
   
 Any questions about paper submissions can be emailed to sosp24-pc-chairs@cs.wisc.edu  .  

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Important dates data

35. Conference SOSP_3:
SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

 Accepted Papers  
   
 The following papers have been accepted to appear at the 30th ACM SIGOPS Symposium on Operating Systems Principles (SOSP), conditional on the approval of each paper's shepherd:  
 Aceso: Achieving Efficient Fault Tolerance in Memory-Disaggregated Key-Value Stores | Zhisheng Hu (The Chinese University of Hong Kong), Pengfei Zuo (Huawei Cloud), Yizou Chen (The Chinese University of Hong Kong), Chao Wang (The Chinese University of Hong Kong), Junliang Hu (The Chinese University of Hong Kong), Ming-Chang Yang (The Chinese University of Hong Kong (CUHK)) 
  Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in ML Serving | Yinwei Dai (Princeton University), Rui Pan (Princeton University), Anand Iyer (Georgia Tech), Kai Li (Princeton University), Ravi Netravali (Princeton University) 
  Autobahn: Seamless high speed BFT | Florian Suri-Payer (Cornell University), Neil Giridharan (UC Berkeley), Natacha Crooks (University of California Berkeley & Azure Systems Research), Lorenzo Alvisi (Cornell University), Ittai Abraham (Intel) 
  BIZA: Design of Self-Governing Block-Interface ZNS AFA for Endurance and Performance | Shushu Yi (Peking University), Shaocong Sun (Peking University), Li Peng (Peking University), Yingbo Sun (Peking University), Ming-Chang Yang (The Chinese University of Hong Kong (CUHK)), Zhichao Cao (ASU), Qiao Li (Xiamen University), Myoungsoo Jung (KAIST and Panmnesia), Ke Zhou (Wuhan National Laboratory for Optoelectronics (WNLO) of Huazhong University of Science and Technology (HUST)), Jie Zhang (Peking University) 
  CHIME: A Cache-Efficient and High-Performance Hybrid Index on Disaggregated Memory | Xuchuan Luo (Fudan University), Jiacheng Shen (The Chinese University of Hong Kong), Pengfei Zuo (Huawei Cloud), Xin Wang (Fudan University), Michael R. Lyu (The Chinese University of Hong Kong), Yangfan Zhou (Fudan University) 
  Caribou: Fine-Grained Geospatial Shifting of Serverless Applications for Sustainability | Viktor Gsteiger (ETH Zurich), Pin Hong (Daniel) Long (University of British Columbia), Yiran (Jerry) Sun (University of British Columbia), Parshan Javanrood (University of British Columbia), Mohammad Shahrad (University of British Columbia) 
  Cookie Monster: Efficient On-Device Budgeting for Differentially-Private Ad-Measurement Systems | Pierre Tholoniat (Columbia University), Kelly Kostopoulou (Columbia University), Peter McNeely (Columbia University), Prabhpreet Singh Sodhi (Columbia University), Anirudh Varanasi (Columbia University), Benjamin Case (Meta Inc.), Asaf Cidon (Columbia University), Mathias Lécuyer (University of British Columbia), Roxana Geambasu (Columbia University) 
  DNS Congestion Control in Adversarial Settings | Huayi Duan (ETH Zurich), Jihye Kim (ETH Zurich), Marc Wyss (ETH Zurich), Adrian Perrig (ETH Zurich) 
  Dirigent: Lightweight Serverless Orchestration | Lazar Cvetković (ETH Zurich), François Costa (ETH Zurich), Mihajlo Djokic (IBM Research Europe), Michal Friedman (ETH Zurich), Ana Klimovic (ETH Zurich) 
  Efficient Reproduction of Fault-Induced Failures in Distributed Systems with Feedback-Driven Fault Injection | Jia Pan (Johns Hopkins University), Haoze Wu (Johns Hopkins University), Tanakorn Leesatapornwongsa (Microsoft Research), Suman Nath (Microsoft Research), Peng Huang (University of Michigan) 
  Efficient file-lifetime redundancy management for cluster file systems | Tim Kim (Carnegie Mellon University), Sanjith Athlur (Carnegie Mellon University), Saurabh Kadekodi (Google), Francisco Maturana (Carnegie Mellon University), Dax Vandevoore (Carnegie Mellon University), Arif Merchant (Google), Greg Ganger (Carnegie Mellon University), Rashmi Vinayak (Carnegie Mellon University) 
  Enabling Parallelism Hot Switching for Efficient Training of Large Language Models | Hao Ge (Peking University), Fangcheng Fu (Peking University), Haoyang Li (Peking University), Xuanyu Wang (Peking University), Sheng Lin (Peking University), Yujie Wang (Peking University), Xiaonan Nie (Peking University), Hailin Zhang (Peking University), Xupeng Miao (Carnegie Mellon University), Bin Cui (Peking University) 
  FBDetect: Catching Tiny Performance Regressions at Hyperscale through In-Production Monitoring | Dong Young Yoon (Meta Platforms), Yang Wang (Meta Platforms and the Ohio State University), Miao Yu (Meta Platforms and the Ohio State University), Xu Huang (Meta Platforms), Juan Ignacio Jones (Meta Platforms), Abhinay Kukkadapu (Meta Platforms), Osman Kocas (Meta Platforms), Jonathan Wiepert (Meta Platforms), Kapil Goenka (Meta Platforms), Sherry Chen (Meta Platforms), Yanjun Lin (Meta Platforms), Zhihui Huang (Meta Platforms), Jocelyn Kong (Meta Platforms), Michael Chow (Meta Platforms), Chunqiang Tang (Meta Platforms) 
  Fast & Safe IO Memory Protection | Benny Rubin (Cornell University), Saksham Agarwal (Cornell University), Qizhe Cai (Cornell University), Rachit Agarwal (Cornell University) 
  Fast Core Scheduling with Userspace Process Abstraction | Jiazhen Lin (Tsinghua University), Youmin Chen (Tsinghua University), Shiwei Gao (Tsinghua University), Youyou Lu (Tsinghua University) 
  Fast, Flexible, and Practical Kernel Extensions | Kumar Kartikeya Dwivedi (EPFL), Rishabh Iyer (UC Berkeley), Sanidhya Kashyap (EPFL) 
  Icarus: Trustworthy Just-In-Time Compilers with Symbolic Meta-Execution | Michael Smith (UC San Diego), Abhishek Sharma (University of Texas at Austin), Hovav Shacham (University of Texas at Austin), Ranjit Jhala (UC San Diego), Deian Stefan (UC San Diego) 
  If At First You Don’t Succeed, Try, Try, Again...? Insights and LLM-informed Tooling for Detecting Retry Bugs in Software Systems | Bogdan Alexandru Stoica (University of Chicago), Utsav Sethi (University of Chicago), Yiming Su (University of Chicago), Cyrus Zhou (University of Chicago), Shan Lu (Microsoft Research), Jonathan Mace (Microsoft Research), Madan Musuvathi (Microsoft Research), Suman Nath (Microsoft Research) 
  Improving DNN Inference Throughput Using Practical, Per-Input Compute Adaptation | Anand Iyer (Georgia Tech), Swapnil Gandhi (Stanford University), Mingyu Guan (Georgia Tech), Yinwei Dai (Princeton University), Rui Pan (Princeton University), Ravi Netravali (Princeton University) 
  LazyLog: A New Shared Log Abstraction for Low-Latency Applications | Xuhao Luo (University of Illinois Urbana-Champaign), Shreesha G Bhat (University of Illinois Urbana-Champaign), Jiyu Hu (University of Illinois Urbana-Champaign), Ramnatthan Alagappan (University of Illinois Urbana-Champaign and VMware Research), Aishwarya Ganesan (University of Illinois Urbana-Champaign and VMware Research) 
  LoongServe: Efficiently Serving Long-Context Large Language Models with Elastic Sequence Parallelism | Bingyang Wu (Peking University), Shengyu Liu (Peking University), Yinmin Zhong (Peking University), Peng Sun (Shanghai AI Lab), Xuanzhe Liu (Peking University), Xin Jin (Peking University) 
  Modular Verification of Secure and Leakage-Free Systems: From Application Specification to Circuit-Level Implementation | Anish Athalye (Massachusetts Institute of Technology), Henry Corrigan-Gibbs (MIT), Frans Kaashoek (MIT), Joseph Tassarotti (New York University), Nickolai Zeldovich (Massachusetts Institute of Technology) 
  NOPE: Strengthening domain authentication with zero-knowledge proofs | Zachary DeStefano (NYU), Jeff J. Ma (NYU), Joseph Bonneau (NYU), Michael Walfish (NYU) 
  OZZ: Identifying Kernel Out-of-Order Concurrency Bugs with In-Vivo Memory Access Reordering | Dae R. Jeong (Georgia Tech), Yewon Choi (KAIST), Byoungyoung Lee (Seoul National University), Insik Shin (KAIST), Youngjin Kwon (KAIST) 
  PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU | Yixin Song (Shanghai Jiao Tong University), Zeyu Mi (Shanghai Jiao Tong University), Haotong Xie (Shanghai Jiao Tong University), Haibo Chen (Shanghai Jiao Tong University) 
  Practical Verification of System-Software Components Written in Standard C | Can Cebeci (EPFL), Yonghao Zou (EPFL), Diyu Zhou (EPFL), George Candea (EPFL), Clément Pit-Claudel (EPFL) 
  ReCycle: Pipeline Adaptation for the Resilient Distributed Training of Large DNNs | Swapnil Gandhi (Stanford University), Mark Zhao (Stanford University), Athinagoras Skiadopoulos (Stanford University), Christos Kozyrakis (Stanford University) 
  Reducing Energy Bloat in Large Model Training | Jae-Won Chung (University of Michigan), Yile Gu (University of Washington), Insu Jang (University of Michigan), Luoxi Meng (University of California, San Diego), Nikhil Bansal (University of Michigan), Mosharaf Chowdhury (University of Michigan) 
  Reducing cross-cloud/region costs with the auto-configuring MACARON cache | Hojin Park (Carnegie Mellon University), Ziyue Qiu (Carnegie Mellon University), Gregory R. Ganger (Carnegie Mellon University), George Amvrosiadis (Carnegie Mellon University) 
  SWARM: Replicating Shared Disaggregated-Memory Data in No Time | Antoine Murat (EPFL), Clément Burgelin (EPFL), Athanasios Xygkis (Oracle Labs), Igor Zablotchi (Mysten Labs), Marcos K. Aguilera (VMware Research Group), Rachid Guerraoui (EPFL) 
  Tenplex: Dynamic Parallelism for Deep Learning using Parallelizable Tensor Collections | Marcel Wagenländer (Imperial College London), Guo Li (Imperial College London), Bo Zhao (Aalto University), Luo Mai (University of Edinburgh), Peter Pietzuch (Imperial College London) 
  Scaling Deep Learning Computation over the Inter-Core Connected Intelligence Processor with T10 | Yiqi Liu (University of Illinois Urbana-Champaign), Yuqi Xue (University of Illinois Urbana-Champaign), Yu Cheng (Microsoft Research), Lingxiao Ma (Microsoft Research), Ziming Miao (Microsoft Research), Jilong Xue (Microsoft Research), Jian Huang (University of Illinois Urbana-Champaign) 
  Sesame: Practical End-to-End Privacy Compliance with Policy Containers and Privacy Regions | Kinan Dak Albab (Brown University), Artem Agvanian (Brown University), Allen Aby (Brown University), Corinn Tiffany (Brown University), Alexander Portland (Brown University), Sarah Ridley (Brown University), Malte Schwarzkopf (Brown University) 
  SilvanForge: A Schedule-Guided Retargetable Compiler for Decision Tree Inference | Ashwin Prasad (Indian Institute of Science), Sampath Rajendra (Microsoft Research), Kaushik Rajan (Microsoft Research), R Govindarajan (Indian Institute of Science, Bangalore, India), Uday Bondhugula (Indian Institute of Science and PolyMage Labs) 
  Skyloft: A General High-Efficient Scheduling Framework in User Space | Yuekai Jia (Tsinghua University), Kaifu Tian (Tsinghua University), Yuyang You (Tsinghua University), Yu Chen (Tsinghua University), Kang Chen (Tsinghua University) 
  Tiered Memory Management: Access Latency is the Key! | Midhul Vuppalapati (Cornell University), Rachit Agarwal (Cornell University) 
  TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes | Jialiang Huang (Tsinghua University, Alibaba Group), MingXing Zhang (Tsinghua University), Teng Ma (Alibaba Group), Zheng Liu (Zhejiang University, Alibaba Group), Sixing Lin (Tsinghua University, Wuhan University), Kang Chen (Tsinghua University), Jinlei Jiang (Tsinghua University), Xia Liao (Tsinghua University), Yingdi Shan (Tsinghua University), Ning Zhang (Alibaba Group), Mengting Lu (Alibaba Group), Tao Ma (Alibaba Group), Haifeng Gong (Intel), YongWei Wu (Tsinghua University) 
  Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor | Siran Liu (Peking University), Chengxiang Qi (University of Chinese Academy of Sciences), Ying Cao (Microsoft Research Asia), Chao Yang (Peking University), Weifang Hu (Huazhong University of Science and Technology), Xuanhua Shi (Huazhong University of Science and Technology), Fan Yang (Microsoft Research Asia), Mao Yang (Microsoft Research Asia) 
  Unearthing Semantic Checks for Cloud Infrastructure-as-Code Programs | Yiming Qiu (University of Michigan), Patrick Tser Jern Kon (University of Michigan), Ryan Beckett (Microsoft), Ang Chen (University of Michigan) 
  Unifying serverless and microservice workloads with SigmaOS | Ariel Szekely (MIT), Adam Belay (MIT), Robert Morris (MIT), Frans Kaashoek (MIT) 
  VPRI: Optimized I/O Page Fault in Public IaaS | Kaijie Guo (Alibaba Cloud), Dingji Li (Shanghai Jiaotong University), Ben Luo (Alibaba Cloud), Yibin Shen (Alibaba Cloud), Kaihuan Peng (Alibaba Cloud), Ning Luo (Alibaba Cloud), Shengdong Dai (Alibaba Cloud), Chen Liang (Alibaba Cloud), Jianming Song (Alibaba Cloud), Hang Yang (Alibaba Cloud), Xiantao Zhang (Alibaba Cloud), Zeyu Mi (Shanghai Jiaotong University) 
  Verus: A Practical Foundation for Systems Verification | Andrea Lattuada (MPI-SWS), Travis Hance (Carnegie Mellon University), Jay Bosamiya (Microsoft Research), Matthias Brun (ETH Zurich), Chanhee Cho (Carnegie Mellon University), Hayley LeBlanc (University of Texas at Austin), Pranav Srinivasan (University of Michigan), Reto Achermann (University of British Columbia), Tej Chajed (University of Wisconsin-Madison), Chris Hawblitzel (Microsoft Research), Jon Howell (VMware Research), Jacob R. Lorch (Microsoft Research), Oded Padon (Weizmann Institute of Science), Bryan Parno (Carnegie Mellon University) 
  vSoC: Efficient Virtual System-on-Chip on Heterogeneous Hardware | Jiaxing Qiu (Tsinghua University), Zijie Zhou (Tsinghua University), Yang Li (Tsinghua University), Zhenhua Li (Tsinghua University), Feng Qian (University of Southern California), Hao Lin (Tsinghua University and University of Illinois Urbana-Champaign), Di Gao (Tsinghua University), Haitao Su (Tsinghua University), Xin Miao (Tsinghua University), Yunhao Liu (Tsinghua University), Tianyin Xu (University of Illinois Urbana-Champaign) 

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Call for papers data:SOSP 2024   
    
 Home 
  Participate | Call for Papers 
  Call for Posters 
  Instructions for Authors 
  Student Research Competition 
  Volunteering 
  Mentoring 
  Women in Systems Meetup 
  Attend | Registration 
  Student Scholarships 
  Hotel 
  Visa Information 
  Childcare 
  Voting (U.S. election) 
  Program | Conference Schedule 
  Accepted Papers 
  Workshops | Workshops and Tutorials 
  Call for Workshops 
  Organizers 
  Sponsors 
  Contact 

 SOSP 2024 Call for Papers  
 The 30th ACM Symposium on Operating Systems Principles (SOSP) seeks to present innovative and exciting research related to the design, implementation, analysis, evaluation, and deployment of computer systems software.  

 Event Info | Date | Link 
 Deadline to register abstracts | April 12, 2024; 23:59 PT | HotCRP Submission Site 
 Submission deadline (no extensions) | April 19, 2024; 23:59 PT | HotCRP Submission Site 
 Reviews available for author response | July 22, 2024 |  
 Author response due | July 26, 2024 |  
 Author notification | August 5, 2024 |  
 Camera ready due | September 23, 2024 | HotCRP Submission Site 
 Conference | November 4-6, 2024 | Conference Site 

 Topics  
   
 SOSP takes a broad view of systems and solicits contributions from many fields of systems practice, including: operating systems, file and storage systems, distributed systems, cloud computing, mobile and edge systems, secure and reliable systems, systems aspects of big data and machine learning, embedded and real-time systems, virtualization, networking as it relates to operating systems, and management and troubleshooting of complex systems. We also welcome work that explores the interaction of computer systems with related areas such as computer architecture, networking, programming languages, analytics, verification, and databases. In keeping with SOSP tradition, we will favor work that explores new territory, continues a significant research dialogue, or reflects on experience with or measurements of state-of-the-art implementations.  

 Submission Criteria  
   
 Submissions will be judged on novelty, significance, interest, clarity, relevance, and correctness. A good paper will:  
 Motivate a significant problem; 
  Propose and implement an interesting, compelling solution; 
  Demonstrate the practicality and benefits of the solution; 
  Draw appropriate conclusions; 
  Clearly describe the paper's contributions; and 
  Clearly articulate the advances beyond previous work. 
  We encourage submission of groundbreaking work in significant new directions, with the understanding that the evaluation criteria for papers addressing new problems may be different from those continuing a line of work in a more established area.  

 Originality  
   
 Submissions should contain original, unpublished material. Simultaneous submission of the same work to multiple venues, submission of previously published work, or plagiarism is not allowed.  
 Submissions that extend the authors' previous work are welcome, but authors must explain the differences between the SOSP submission and the prior work, much in the same way that the authors are expected to articulate the contributions of their submission as they relate to prior work by others. Self-comparisons should be properly anonymized, as described below.  
 Prior or concurrent workshop publication does not preclude publishing a related paper in SOSP. The online submission form will require authors to submit a copy of the related workshop paper and a short explanation of the new material in the conference paper beyond that published in the workshop version. As long as there is significant additional content in the submission compared to the prior workshop publication, the PC will evaluate the submission's entire contribution, not just the delta.  
 Prior or concurrent publication in non-peer-reviewed contexts, like arXiv.org, technical reports, talks, and social media posts, is explicitly permitted.  

 Resubmissions  
   
 Submitting a paper that had been previously submitted to and not accepted by another conference is permitted, although authors are expected to have improved the paper to address substantive issues raised in previous reviews. Authors should provide information regarding the previous submission(s) and a summary of the subsequent revisions to the paper. This description, which will be supplied to reviewers after they’ve completed their reviews, helps reviewers who may have reviewed a previous draft of the work to appreciate any improvements to the currently submitted work. Please try to limit the description of changes to one page. All information should be properly anonymized, as described below, and should be uploaded via the submission form.  

 Anonymity  
   
 SOSP will use double-blind reviewing. Please make a good faith attempt to anonymize your submission. Avoid identifying yourself or your institution explicitly or by implication (e.g., through the references or acknowledgments). The first page should use the paper ID assigned during registration in place of the author names. If the name of your project or system is already known to the community (e.g., through arXiv, technical reports, talks, social media posts, or other uses), your SOSP submission must use an anonymized name.  
 Use care in referring to your own related work. Do not omit references to your prior work, as this would make it difficult for reviewers to place your submission in its proper context. Instead, reference your past work in the third person, just as you would any other piece of related work. For example, you might say "Our system modifies the XYZ operating system built by Lee et al. [Lee17]".  
 For concurrent submissions on related topics, cite an anonymized version of the concurrent submission and discuss the relation between the submissions. Additionally, please email the PC chairs ( sosp24-pc-chairs@cs.wisc.edu  ) a copy of your other concurrent submission.  
 If your submission reports on experiences with a system at your institution or organization, you should refer to the system anonymously but describe the properties of the system that are needed to appreciate the work (e.g., size of the user base, volume of requests, etc.). We recognize that, in some cases, these properties may allow a reviewer to identify your institution or organization.  
 Check with the program chairs ( sosp24-pc-chairs@cs.wisc.edu  ) if you are uncertain about the anonymity rules.  

 Supplementary Material  
   
 Authors may optionally include supplementary material as a separate document. Supplementary material is intended for items that are not critical for evaluating the paper but may be of interest to some readers. Examples include: formal proofs that are only sketched in the submission, additional analyses, and methodological details that aren’t essential for the PC’s assessment but are important for reproducibility. PC members are not required to read this optional supplementary material, so the submission must stand alone without it.  

 Formatting  
   
 Papers will be submitted electronically in PDF format via the web submission form  .  
 Submissions may have at most 12 pages of technical content, including all text, figures, tables, etc. Bibliographic references are not included in the 12-page limit. Use A4 or US letter paper size, with all text and figures fitting inside a 178 x 229 mm (7 x 9 in) block centered on the page, using two columns separated by 8 mm (0.33 in) of whitespace. Use 10-point font (typeface Times Roman, Linux Libertine, etc.) on 12-point (single-spaced) leading. Graphs and figures should be readable without magnification; they are encouraged to be in color, but should remain readable if printed in grayscale. All pages should be numbered, and references within the paper should be hyperlinked.  
 Submissions violating these rules will not be considered for publication, and there will be no extensions for fixing violations. We encourage you to upload an early draft of the paper well before the deadline to check if the paper meets the formatting rules.  
 Most of these rules are automatically applied when using the official SIGPLAN LaTeX  or MS Word templates  from the ACM.  
 For Latex, we recommend you use:  
 \documentclass[sigplan,10pt]{acmart} \renewcommand\footnotetextcopyrightpermission[1]{} ... \settopmatter{printfolios=true} \maketitle \pagestyle{plain} ...   

 Confidentiality  
   
 Reviewing will be done mostly by members of the program committee, with limited use of outside reviewers. Submissions will be treated as confidential; however, papers accompanied by nondisclosure agreement forms will not be considered for publication.  

 Conflicts  
   
 To avoid conflicts of interest in the review process, when you register and submit your paper, we ask that you provide information about conflicts between any of the authors of your submission and PC members. Use the following guidelines to determine conflicts:  
 Institutional:  You are currently employed at the same institution, have been previously employed at the same institution within the past two years (since April 2022), or are going to begin employment at the same institution. Former interns should list their internship supervisor(s) and collaborator(s) as conflicts, not the entire institution where they interned.  
 Advisor:  You have a past or present association as PhD thesis advisor or advisee.  
 Collaborator:  You have a collaboration on a project, publication, grant proposal, or editorship within the past two years (April 2022 or later).  
 Personal:  You are close family relatives (e.g., spouses, domestic partners, parents, children, or siblings).  
 The PC chairs will review paper conflicts to ensure the integrity of the reviewing process, adding conflicts if necessary. Similarly, if there is no basis for conflicts provided by authors, such conflicts may be removed (e.g., do not improperly identify a PC member as a conflict in an attempt to avoid having the individual review your paper). If you have any questions about conflicts, please contact the program co-chairs ( sosp24-pc-chairs@cs.wisc.edu  ).  
 PC members will not be able to review, read the reviews of, or participate in discussions of papers they are conflicted with. The review process for papers conflicted with both PC chairs will be managed by another PC member designated as the "conflict chair". Any paper with a PC chair co-author will be held to a higher standard of being a “clear accept”.  

 Author Response Period  
   
 SOSP will provide an opportunity for authors to respond to reviews prior to final consideration of the papers at the program committee meeting. Authors must limit their responses to (a) correcting factual errors in the reviews or (b) directly addressing questions posed by reviewers. Responses should be limited to clarifying the submitted work. In particular, responses must not include new experiments or data, describe additional work completed since submission, or promise additional work to follow. As PC members are not required to review supplementary materials, responses must not rely on the existence of those materials.  
 Submission of a response is optional. There is no explicit limit to the response, but authors are strongly encouraged to keep responses under 500 words; reviewers are neither required nor expected to read excessively long responses.  

 Accepted Papers  
   
 Papers selected by the program committee will be subject to revision and approval by a program committee member acting as a shepherd. Authors of accepted papers will be expected to supply electronic versions of their papers and encouraged to supply source code and raw data to help others replicate and understand their results, as part of an artifact evaluation process. To facilitate broad technical discussion, all accepted papers will be made available online in advance of the conference. The official publication date will be the date the proceedings are made publicly accessible. For more information about the ACM OpenSurround Service, please go to https://www.acm.org/publications/policies/free-access  . Papers of particular merit will be forwarded to the ACM Transactions on Computer Systems (TOCS) and the Communications of the ACM's Research Highlights (CACM RH) for possible publication.  

 Submission Information  
   
 Papers must be submitted electronically in PDF format via the web submission form  .  

 Questions  
   
 Any questions about paper submissions can be emailed to sosp24-pc-chairs@cs.wisc.edu  .  

  In cooperation with  
     
 Additional Information  
 Prior SOSPs 
    
 Contact Us  
 Any organizational questions about the conference can be emailed to sosp24chairs@cs.utexas.edu  . The program committee chairs can be reached at sosp24-pc-chairs@cs.wisc.edu  .  

 Design by BootstrapMade    

    Important dates data

36. Conference SOFTCOM_0:
Skip to content  softcom@fesb.hr 
   
 Linkedin 
  Facebook 
  Twitter 
  YouTube 

  SoftCOM 2024   
   
     Home 
  About SoftCOM 2024 
  Committees | General Co-Chairs 
  Technical Program Committee 
  Steering Committee 
  Authors | General Call for Papers 
  Symposia and Special Sessions – final deadline on June 30 
  Posters/Abstracts – final deadline on June 30 
  Professional Workshops – final deadline on June 30 
  Professional Posters/Demos – final deadline on June 30 
  Paper EDAS Submission 
  Author’s Guidelines 
  Program | Timetable and Program 
  Keynote Speakers 
  Invited Speaker 
  Tutorials 
  Business Forum 
  GREENEDGE project activities 
  Venue & Registration | Location 
  Venue and Accommodation 
  Registration 
  Social Program 
  Travel and Visa Info 
  Sponsors 
  Contact 

  1   

 4   

 2   

 1   

 26-28 September, 2024 
  Bol (island of Brač), Croatia 
   Final program available!    

 Welcome Message   
 Dear participants and colleagues, it is our pleasure to welcome you to the SoftCOM 2024 conference. We are excited to have an opportunity to take part in the organization of an international conference that gathers researchers and professionals from academia and industry to share experiences and new ideas in such a dynamic area as Information and Communication Technology. Current and emerging information and communication technologies are key drivers of the digital society and economy. With both evolving and new services we are enabling people to collaborate, innovate, learn, participate in ways we never thought possible. Through joint research and technology advancement we are opening ground for new discoveries and sustainable global economic growth. We can shape the future in ways that are clean, green, healthy, safe, and more resilient, and we have an opportunity for a systemic shift to a more sustainable economy that works for both people and the planet. The conference will provide opportunities to interact and network with presenters, experts, peers, and colleagues, as well as to participate in various discussions. The 32nd International Conference on Software, Telecommunications and Computer Networks (SoftCOM 2024), technically co-sponsored by the IEEE Communications Society, will be held on September 26-28, 2024 in Split-Bol (island of Brac). It will be our pleasure to meet you at the conference. Welcome!  

 IMPORTANT NOTE   
 The preliminary program is available at the link!  
  
 Read More    
   
 SoftCOM 2023 Gallery   
  
 Read More    

 Keynote Speakers   
  Sovereign Smartphone: Revisiting Smartphone Security Architecture  
 Srdjan Capkun  
 System Security Group, Department of Computer Science, ETH Zurich, Switzerland  

  Towards Truly Sustainable Wireless Communication Systems  
 Marcos Katz  
 University of Oulu, Finland  

 SOFTCOM 2024 STARTS IN  

 Enter your name and email address below to subscribe to our mailing list.  
      
 Email Address *      
   
 First Name     
 Last Name     
   
 * = required field   
    
 unsubscribe from list    
  
  powered by MailChimp  !   

 Previous Conferences  

 SoftCOM 2023 
  SoftCOM 2022 
  SoftCOM 2021 
  SoftCOM 2020 

 Contact Us  
 Ruđera Boškovića 32, 21000 Split, Croatia 
  softcom@fesb.hr 

 Linkedin 
  Facebook 
  Twitter 
  YouTube 
    
 © 2024 SoftCOM 2024    

  Top     

  Call for papers data:Skip to content  softcom@fesb.hr 
   
 Linkedin 
  Facebook 
  Twitter 
  YouTube 

  SoftCOM 2024   
   
     Home 
  About SoftCOM 2024 
  Committees | General Co-Chairs 
  Technical Program Committee 
  Steering Committee 
  Authors | General Call for Papers 
  Symposia and Special Sessions – final deadline on June 30 
  Posters/Abstracts – final deadline on June 30 
  Professional Workshops – final deadline on June 30 
  Professional Posters/Demos – final deadline on June 30 
  Paper EDAS Submission 
  Author’s Guidelines 
  Program | Timetable and Program 
  Keynote Speakers 
  Invited Speaker 
  Tutorials 
  Business Forum 
  GREENEDGE project activities 
  Venue & Registration | Location 
  Venue and Accommodation 
  Registration 
  Social Program 
  Travel and Visa Info 
  Sponsors 
  Contact 

 General Call for Papers  
   
 SoftCOM 2024 General Call for Papers ( CfP  / Submit the paper  ) – final deadline on June 30   
 TPC Co-Chair:   
  
 Pascal Lorenz, | University of Haute Alsace, France 

 Home 
  About SoftCOM 2024 
  General Call for Papers 
  Author’s Guidelines 
  Paper EDAS Submission 
  Timetable and Program 
  Registration 
  Location 
  Venue and Accommodation 

 SOFTCOM 2024 STARTS IN  

 Enter your name and email address below to subscribe to our mailing list.  
      
 Email Address *      
   
 First Name     
 Last Name     
   
 * = required field   
    
 unsubscribe from list    
  
  powered by MailChimp  !   

 Previous Conferences  

 SoftCOM 2023 
  SoftCOM 2022 
  SoftCOM 2021 
  SoftCOM 2020 

 Contact Us  
 Ruđera Boškovića 32, 21000 Split, Croatia 
  softcom@fesb.hr 

 Linkedin 
  Facebook 
  Twitter 
  YouTube 
    
 © 2024 SoftCOM 2024    

  Top     

  Important dates data

37. Conference SoMeT_3:
1   
   
 Homepage 
  Call for Papers 
  Committees 
  General Information 
  Registration 
  Paper Submission 
  Contacts 

  The 22nd International Conference on Intelligent Software Methodologies, Tools and Techniques  
  Parthenope Congress Center, Naples, Italy  
  September 20-22, 2023   
   
 Full story ...     
 Full story ...     
 Full story ...     
 Full story ...     
 Full story ...     
 Full story ...     
 Full story ...     
 Full story ...     

 Welcome to SoMeT 2023  
 September 20-22, 2023    
 You are invited to participate in SoMeT_23 to help build a forum for exchanging ideas, experiences and applications to foster new directions in software development methodologies and related tools and techniques.  
   
 The conference is focused on, but not limited to the following areas:  
   
  » Modeling and Simulation in Operations Management 
  » Software application in Logistics and Supply Chain Management 
  » Requirement engineering, especially for high-assurance system, and requirement elicitation 
  » Software methodologies and tools for robust, reliable, non-fragile software design 
  » Software development techniques for legacy systems 
  » Automatic software generation versus reuse, and legacy systems, source code analysis and manipulation 
  » Software quality and process assessment for business enterprise models 
  » Intelligent software systems design, and software evolution techniques 
  » Agile Software and Lean Methods 
  » Software optimization and formal methods for software design 
  » Static, dynamic analysis of software performance model, software maintenance, and program understanding and visualization 
  » Software security tools and techniques, and related Software Engineering models 
  » End-user programming environment, User-centered Adoption-Centric Reengineering techniques 
  » Ontology engineering, semantic web 
  » Software design through interaction, and precognitive software techniques for interactive software entertainment applications 
  » Business oriented software application models 
  » Software Engineering models, and formal techniques for software representation, software testing and validation 
  » End-user programming environment, User-centered and Adoption-Centric models Reengineering techniques 
  » Artificial Intelligence Techniques on Software Engineering, and Requirement Engineering 
  » Object-oriented, aspect-oriented, component-based and generic programming, multi-agent technology 
  » Creativity and art in software design principles 
  » Axiomatic based principles on software design 
  » Agile Software and Lean Methods 
  » Model Driven Development (DVD), code centric to model centric software engineering 
  » New aspects on digital libraries, collections and archives, Web publishing, and Knowledge-based engineering 
  » Medical Informatics and bioinformatics, Software methods and application for biomedicine and bioinformatics 
  » Emergency Management Informatics, software methods and application for supporting Civil Protection, First Response and Disaster Recovery 
  » Others software engineering disciplines 
  The conference program also, has several invited talks revised by the program committee members. Those invited technical papers will describe innovative and significant work in the research and practice of software science.  
   
 Information  
 Special Session  
  "Knowledge Science  
  and Intelligent  
  Computing" 
  Somet History 
  Final Program - UPDATED Sept. 18 
  Accomodation 
  About Naples 
  How to 

 Venue   
  Parthenope Congress Center  
  36, Partenope Street  
  80121 - Naples 
  Author's Schedule   
  Full paper submission:  
  April 1, 2023  May 1, 2023 ->  
  -> May, 15, 2023    
  Notification deadline:  
  May 15, 2023  June 1, 2023 ->  
  -> June 15, 2023    
  Final paper submission:  
  June 15, 2023  June 30, 2023 ->  
  -> July 10, 2023 

 Organizers  
  
 University of Naples Federico II, Italy  
  Dept. of Chemical, Material Engineering and Operations Management  
  Industrial Mechanical Systems Engineering | Iwate Prefectural University, Japan 
 Otto von Guericke Universität Magdeburg | Berlin School of Economics Law 
 University of Genoa | i-SOMET 
 University Teknology of Malaysia 

 Italian Association of Industrial Engineering  

 Copyright (c) 2023 International Conference on Intelligent Software Methodologies, Tools and Techniques. All rights reserved.  

  Call for papers data:Not Found  
 The requested URL was not found on this server.  
  Important dates data

38. Conference SOFTCOM_1:
Close    

   Nearby     Filter      Events   
    Companies   
    Experts   
    Hubs   

   Add Event    
   
   Login   

  Add a review    
 26 - 28 Sep 2024    
 SoftCOM : International Conference on Software, Telecommunications and Computer Networks  
   
  Conference    
   Split  , Croatia     
     4  Followers    

  Select   Select   Save   Share    
 Follow  Attended?    

 About | Exhibitors | 2  Speakers | Reviews | Deals 
  
 Average post reach is 104.2k users. Start networking today!  
    
 Write a post here...   
   
 Post  

 Highlights  
 Popular among visitors for 
  Top 100 in Telecommunication in Croatia     
   
 Listed In  
  Telecommunication    IT & Technology   #Software   #Telecommunication     

 Average post reach is 104.2k users. Start networking today!  
    
 Write a post here...   
   
 Post  

 Timings  
 09:00 AM-06:00 PM (expected)  
  Not Verified | Entry Fees  
 Check Official Website 
 Estimated Turnout  
 100 - 500 Delegates   
 Based on previous editions | Event Type  
  Conference 
 Editions  
 Sep 2024  
  +2 more editions   
   
  Frequency  Annual  
  Next edition likely in Sep 2025 | Official Links  
 Website  Contacts         

  Report Error   
  Claim this event 
 Organizer  
  Follow Company   
  Queries about the event?  Ask Organizer     
   
 FESB University of Split  Top Rated   Croatia  11  Total Events 
 43.508000  16.440000  Venue Map & Directions  
 Booking.com     
 Venue to be announced   
 Split  , Croatia   
 Add Venue 

 Frequently Asked Questions Contact Organizer   
  Can I get a list of speakers participating in the event?   
     
 To get the speaker list on mail register at the link  .   
   Helpful    

  Can I get a list of exhibitors participating in the event?   
     
 To get the exhibitor list on mail register at the link  .   
   Helpful    

  Ask More Questions    

 Write a Review  
   Add Your Review    

   26 Sep 2024  21 Sep 2023  22 Sep 2022   Edition    
 How did you participate in this event?  
   
  Visitor     
  Exhibitor     
     Speaker     

 Followers [ Users who have shown interest for this Event ]  Join Community   Invite    

 makhodeir   
  Irbid at Jordan University of Science and Technology  
  Irbid, Jordan    
 Connect    

 Rashid Kamalov   
  Network Engineer at IT Company  
  Baku, Azerbaijan    
 Connect    

 Ian Doyle   
  Engineer at Binro Ltd  
  Limerick, Ireland    
 Connect    

 Muhamed Begovic   
  Head of Education at Softray Solutions  
  Sarajevo, Bosnia And Herzegovina    
 Connect    

  Add Profile    

  Invite users with similar interest    
    Angela Crljen   
 Marketing  
  Split, Croatia    
 Invite    

    Jacek Krzywy   
 Business Analysis  
  Split, Croatia    
 Invite    

    Magdalena Matijevic   
 Student  
  Split, Croatia    
 Invite    

    Katarina Ercegovac   
 IT Support  
  Split, Croatia    
 Invite    

    Anita Rakić   
 Business Partner  
  Split, Croatia    
 Invite    

    Milan Masanovic   
 COO  
  Split, Croatia    
 Invite    

    Jelena Jakus   
 COO  
  Split, Croatia    
 Invite    

    Matilda Kezic   
 Travel Designer  
  Split, Croatia    
 Invite    

 View More    
  
 Speakers  
     
 Speaker    
  Srdjan Capkun   
 Sovereign Smartphone: Revisiting Smartphone Security Architecture   Follow    

 Speaker    
  Marcos Katz   
 Towards Truly Sustainable Wireless Communication Systems   Follow    

 43.508000  16.440000  Venue Map & Directions  
   Venue to be announced   
 Split  , Croatia   
 Add Venue   
   
 More Events Around Split  
  
 Feb 13 2025 | International Conference Contemporary Challenges in LSP Teaching   
  Split, Croatia 
 Mar 19 2025 | Croatian Conference on Earthquake Engineering   
  Split, Croatia 
 Mar 25 2025 | Peering Days Conference   
  Split, Croatia 
 Apr 03 2025 | Croatia Nautic Show   
  Kaštel Gomilica, Croatia 
 May 19 2025 | International Symposium on Sex Therapy   
  Hvar, Croatia 

   Split   Šibenik   

 Sponsors  
  Croatian Academy of...   
 Other sponsor   Zagreb, Croatia    
 Follow    

  Croatian Communications and...   
 Technical co-sponsor    
 Follow    

  Ericsson Nikola Tesla   
 Other sponsor   Croatia    
 Follow    

  HAKOM   
 Other sponsor    
 Follow    

  IEEE   
 Technical co-sponsor   Kobe, Japan    
 Follow    

  KRON   
 Other sponsor    
 Follow    

  Split Airport   
 Other sponsor    
 Follow    

  Split – Dalmatia county   
 Other sponsor    
 Follow    

 View All Sponsors    
  
 https://10times.com/hub/technology-hub   

 Next step - Complete your profile   To mark your interest in SoftCOM : International Conference on Software, Telecommunications and Computer Networks    
 Reach over 2M+ audience with 1 post!   
 Talk About Event  Ask Questions  Share Success    

 Complete your event journey   

 Network   
     
 Broadcast   
     
 Plan   
     
 Attend   
     
 Feedback   

 Related Events  
  
 Dec 12 2024 | Global Games Show    
  Dubai, UAE 
 Jan 13 2025 | BioLogic Summit    
  San Diego, USA 
 Dec 12 2024 | Global AI Show Dubai    
  Dubai, UAE 
 Feb 15 2025 | AI Revolution in Healthcare Summit Dubai    
  Dubai, UAE 
 Dec 10 2024 | AI Summit Seoul    
  Seoul, South Korea 

 More Events Around Split  
  
 Feb 13 2025 | International Conference Contemporary Challenges in LSP Teaching   
  Split, Croatia 
 Mar 19 2025 | Croatian Conference on Earthquake Engineering   
  Split, Croatia 
 Mar 25 2025 | Peering Days Conference   
  Split, Croatia 
 Apr 03 2025 | Croatia Nautic Show   
  Kaštel Gomilica, Croatia 
 May 19 2025 | International Symposium on Sex Therapy   
  Hvar, Croatia 

   Split   Šibenik   
  
 Featured Hotels in Split  
  
 Apartments with a parking space..   
    from EUR 141.7 
 Successus Old Town House   
    from EUR 136.8 
 Pharos Hvar Hotel   
     from EUR 175.8 
 Adriana Hvar Spa Hotel   
     from EUR 529.8 
  
 More Hotels    

   All Events 
  Conferences 
  Telecommunication Conferences 
  Telecommunication Events in Croatia 
  Telecommunication Events in Split 

                                         Loading...   

  Selected    

  About Us  FOR PARTNERS  Event Data Intelligence  BROWSE    
 Career | Join us  Event Management Software  List Event | Partner Login  All Events  - by Country  | by Industry     
 Media & Press Releases  Event Apps  Event Marketing  Trade Shows  - by Country  | by Industry     
 Help Center | FAQ  Event Website  Testimonials  Conferences  - by Country  | by Industry     
 Feedback  Event Venues  Blog  Companies    
  By continuing past this page, you agree to our Terms of Service  , Cookie Policy, Privacy Policy  and Content Policies. All trademarks are properties of their respective owners   
 © 2014-2024 - Ten Times Online Private Limited. All rights reserved.    

           Call for papers data:Important dates data

39. Conference SOFA_3:
Anmelden 
  Registrierung 
  Deutsch  English 
  Español 
  Português 
  Français 

     Dom 
  Najlepsze kategorie | CAREER & MONEY 
  PERSONAL GROWTH 
  POLITICS & CURRENT AFFAIRS 
  SCIENCE & TECH 
  HEALTH & FITNESS 
  LIFESTYLE 
  ENTERTAINMENT 
  BIOGRAPHIES & HISTORY 
  FICTION 
  Najlepsze historie 
  Najlepsze historie 
  Dodaj historię 
  Moje historie 

 Home 
  Soft Computing Applications Proceedings of the 7th International Workshop Soft Computing Applications Sofa 2016 978-3-319-62521-8, 3319625217, 9783319625249, 3319625241, 978-3-319-62520-1 

 Soft Computing Applications Proceedings of the 7th International Workshop Soft Computing Applications Sofa 2016 978-3-319-62521-8, 3319625217, 9783319625249, 3319625241, 978-3-319-62520-1   
 These two volumes constitute the Proceedings of the 7th International Workshop on Soft Computing Applications (SOFA 2016   
  1,093    104    53MB    
  English   Pages [584]   Year 2017    
  Report DMCA / Copyright    
  DOWNLOAD FILE   
   
 Polecaj historie   

 Soft Computing Applications: Proceedings of the 8th International Workshop Soft Computing Applications (SOFA 2018), Vol. II [1st ed.] 9783030521899, 9783030521905  
 This book presents the proceedings of the 8th International Workshop on Soft Computing Applications, SOFA 2018, held on  
  814    121    38MB    Read more   

 Soft Computing Applications: Proceedings of the 8th International Workshop Soft Computing Applications (SOFA 2018), Vol. I [1st ed.] 9783030519919, 9783030519926  
 This book presents the proceedings of the 8th International Workshop on Soft Computing Applications, SOFA 2018, held on  
  952    87    54MB    Read more   

 Soft Computing: Fundamentals and Applications 9781842658635, 9781783320851  
 SOFT COMPUTING: Fundamentals and Applications starts with an introduction to soft computing, a family consists of many m  
  5,162    510    4MB    Read more   

 Biomedical and Other Applications of Soft Computing 9783031080203, 9783031085796, 9783031085802  
 This book presents innovative intelligent techniques, with an emphasis on their biomedical applications. Although many m  
  407    132    8MB    Read more   

 Machine Learning and Mechanics Based Soft Computing Applications 9789811964497, 9789811964503  
 This book highlights recent advances in the area of machine learning and robotics-based soft computing applications. The  
  488    118    10MB    Read more   

 Machine Learning and Mechanics Based Soft Computing Applications 9811964491, 9789811964497  
 This book highlights recent advances in the area of machine learning and robotics-based soft computing applications. The  
  533    22    9MB    Read more   

 Advances in Soft Computing Applications 9788770228176, 9788770229616, 9781000922066, 9781003425885  
 The proclivity of today’s technology to think like humans may be seen in new developing disciplines such as neural compu  
  358    138    16MB    Read more   

 Principles of Soft Computing Using Python Programming : Learn How to Deploy Soft Computing Models in Real World Applications 9781394173136  
 An accessible guide to the revolutionary techniques of Soft Computing. Soft computing is a computing approach designed  
  268    36    14MB    Read more   

 Soft Computing Applications in Modern Power and Energy Systems: Select Proceedings of EPREC 2022 9811983526, 9789811983528  
 This book provides rigorous discussions, case studies, and recent developments in soft computing and its application in  
  652    114    9MB    Read more   

 Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications (Studies in Fuzziness and Soft Computing, 258) 3642156053, 9783642156052  
 Dr. Jay Liebowitz Orkand Endowed Chair in Management and Technology University of Maryland University College Graduate S  
  208    91    8MB    Read more   

 Table of contents :  
  Front Matter ....Pages i-xxxi  
  Front Matter ....Pages 1-1  
  Digital Sunshade Using Head-up Display (Razvan-Catalin Miclea, Ioan Silea, Florin Sandru)....Pages 3-11  
  Basic Expert System (Marius M. Balas, Robert A. Boran)....Pages 12-17  
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base (Dorin Isoc)....Pages 18-33  
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using (Dorin Isoc)....Pages 34-46  
  GA Based Multi-stage Transmission Network Expansion Planning (A. Simo, St. Kilyeni, C. Barbulescu)....Pages 47-59  
  Epidemic Algorithm Based Optimal Power Flow in Electric Grids (K. Muniyasamy, Seshadhri Srinivasan, S. Parthasarathy, B. Subathra, Simona Dzitac)....Pages 60-69  
  Issues Regarding the Tuning of a Minimum Variance Adaptive Controller (Ioan Filip, Iosif Szeidert, Octavian Prostean, Cristian Vasar)....Pages 70-77  
  Adaptive Controller for Networked Control Systems Subjected to Random Communication Delays (Seshadhri Srinivasan, G. Saravanakumar, B. Subathra, N. Sundarajan, Ülle Kotta, Srini Ramasamy et al.)....Pages 78-94  
  Aspects Regarding Risk Assessment of Human Body Exposure in Electric and Magnetic Fields (Marius Lolea, Simona Dzitac)....Pages 95-106  
  A Communication Viewpoints of Distributed Energy Resource (Ravish Kumar, Seshadhri Srinivasan, G. Indumathi, Simona Dzitac)....Pages 107-117  
  Cyber-Physical Energy Systems Approach for Engineering Power System State Estimation in Smart Grids (Seshadhri Srinivasan, Øystein Hov Holhjem, Giancarlo Marafioti, Geir Mathisen, Alessio Maffei, Giovanni Palmieri et al.)....Pages 118-132  
  Front Matter ....Pages 133-133  
  About the Applications of the Similarity of Websites Regarding HTML-Based Webpages (Doru Anastasiu Popescu, Ovidiu Domșa, Nicolae Bold)....Pages 135-142  
  Energy Efficient Cache Node Placement Using Genetic Algorithm with Probabilistic Delta Consistency Using Flexible Combination of Push and Pull Algorithm for Wireless Sensor Networks (Juhi R. Srivastava, T. S. B. Sudarshan)....Pages 143-163  
  A Fast JPEG2000 Based Crypto-Compression Algorithm: Application to the Security for Transmission of Medical Images (Med Karim Abdmouleh, Hedi Amri, Ali Khalfallah, Med Salim Bouhlel)....Pages 164-175  
  IoThings: A Platform for Building up the Internet of Things (Andrei Gal, Ioan Filip, Florin Dragan)....Pages 176-188  
  Imperialist Competition Based Clustering Algorithm to Improve the Lifetime of Wireless Sensor Network (Ali Shokouhi Rostami, Marzieh Badkoobe, Farahnaz Mohanna, Ali Asghar Rahmani Hosseinabadi, Valentina Emilia Balas)....Pages 189-202  
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring (Ola E. Elnaggar, Rabie A. Ramadan, Magda B. Fayek)....Pages 203-215  
  A Smart Way to Improve the Printing Capability of Operating System (Adeel Ahmed, Muhammad Arif, Abdul Rasheed Rizwan, Muhammad Jabbar, Zaheer Ahmed)....Pages 216-228  
  A Comparative Study for Ontology and Software Design Patterns (Zaheer Ahmed, Muhammad Arif, Muhammad Sami Ullah, Adeel Ahmed, Muhammad Jabbar)....Pages 229-250  
  Front Matter ....Pages 251-251  
  MainIndex Sorting Algorithm (Adeel Ahmed, Muhammad Arif, Abdul Rasheed Rizwan, Muhammad Jabbar, Zaheer Ahmed, Muhammad Sami Ullah)....Pages 253-264  
  Deep Learning Tools for Human Microbiome Big Data (Oana Geman, Iuliana Chiuchisan, Mihai Covasa, Cris Doloc, Mariana-Rodica Milici, Laurentiu-Dan Milici)....Pages 265-275  
  Evaluating the User Experience of a Web Application for Managing Electronic Health Records (Daniel-Alexandru Jurcău, Vasile Stoicu-Tivadar)....Pages 276-289  
  Multi Framing HDR for MRI Brain Images (Marius M. Balas, Adelin Sofrag)....Pages 290-297  
  Computer Aided Posture Screening Using the Microsoft Kinect on Professional Computer Users for Malicious Postures (Norbert Gal-Nadasan, Vasile Stoicu-Tivadar, Dan V. Poenaru, Diana Popa-Andrei, Emanuela Gal-Nadasan)....Pages 298-307  
  IT Complex Solution Supporting Continuity of Care (Mihaela Crișan-Vida, Liliana Bărbuț, Alexandra Bărbuț, Lăcrămioara Stoicu-Tivadar)....Pages 308-315  
  The Importance of Quantification of Data in Studies on the Health Effects of Exposure to Electromagnetic Fields Generated by Mobile Base Stations (S. M. J. Mortazavi, Valentina Emilia Balas, A. Zamani, A. Zamani, S. A. R. Mortazavi, M. Haghani et al.)....Pages 316-326  
  Graphical Method for Evaluating and Predicting the Human Performance in Real Time (Mariana-Rodica Milici, Oana Geman, Iuliana Chiuchisan, Laurentiu-Dan Milici)....Pages 327-338  
  Tremor Measurement System for Neurological Disorders Screening (Iuliana Chiuchisan, Iulian Chiuchisan, Oana Geman, Rodica-Mariana Milici, Laurentiu-Dan Milici)....Pages 339-348  
  Novel Method for Neurodegenerative Disorders Screening Patients Using Hurst Coefficients on EEG Delta Rhythm (Roxana Toderean (Aldea), Oana Geman, Iuliana Chiuchisan, Valentina Emilia Balas, Valeriu Beiu)....Pages 349-358  
  Environment Description for Blind People (J. S. Park, D. López De Luise, D. J. Hemanth, J. Pérez)....Pages 359-366  
  Specialized Software System for Heart Rate Variability Analysis: An Implementation of Nonlinear Graphical Methods (E. Gospodinova, M. Gospodinov, Nilanjan Dey, I. Domuschiev, Amira S. Ashour, Sanda V. Balas et al.)....Pages 367-374  
  Classifier Ensemble Selection Based on mRMR Algorithm and Diversity Measures: An Application of Medical Data Classification (Soraya Cheriguene, Nabiha Azizi, Nilanjan Dey, Amira S. Ashour, Corina A. Mnerie, Teodora Olariu et al.)....Pages 375-384  
  Personal Health Record Management System Using Hadoop Framework: An Application for Smarter Health Care (Bidyut Biman Sarkar, Swagata Paul, Barna Cornel, Noemi Rohatinovici, Nabendu Chaki)....Pages 385-393  
  Gene-Disease-Food Relation Extraction from Biomedical Database (Wahiba Ben Abdessalem Karaa, Monia Mannai, Nilanjan Dey, Amira S. Ashour, Iustin Olariu)....Pages 394-407  
  Cluster Analysis for European Neonatal Jaundice (P. K. Nizar Banu, Hala S. Own, Teodora Olariu, Iustin Olariu)....Pages 408-419  
  Front Matter ....Pages 421-421  
  Nonlinear Fourth-Order Diffusion-Based Model for Image Denoising (Tudor Barbu)....Pages 423-429  
  On Time-Frequency Image Processing for Change Detection Purposes (Dorel Aiordachioaie)....Pages 430-445  
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter (József Dombi, Adrienn Dineva)....Pages 446-454  
  Point Cloud Processing with the Combination of Fuzzy Information Measure and Wavelets (Adrienn Dineva, Annamária R. Várkonyi-Kóczy, Vincenzo Piuri, József K. Tar)....Pages 455-461  
  Significance of Glottal Closure Instants Detection Algorithms in Vocal Emotion Conversion (Susmitha Vekkot, Shikha Tripathi)....Pages 462-473  
  Analysis of Image Compression Approaches Using Wavelet Transform and Kohonen’s Network (Mourad Rahali, Habiba Loukil, Mohamed Salim Bouhlel)....Pages 474-486  
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra (Vansha Kher, Garvita Khajuria, Purnendu Prabhat, Meena Kohli, Vinod K. Madan)....Pages 487-496  
  The Efficiency of Perceptual Quality Metrics 3D Meshes Based on the Human Visual System (Nessrine Elloumi, Habiba Loukil Hadj Kacem, Med Salim Bouhlel)....Pages 497-508  
  Fireworks Algorithm Based Image Registration (Silviu-Ioan Bejinariu, Hariton Costin, Florin Rotaru, Ramona Luca, Cristina Diana Niţă, Camelia Lazăr)....Pages 509-523  
  Discrete Wavelet Transforms for PET Image Reduction/Expansion (wavREPro) (Hedi Amri, Malek Gargouri, Med Karim Abdmouleh, Ali Khalfallah, Bertrand David, Med Salim Bouhlel)....Pages 524-539  
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform (Anca Ignat, Mihaela Luca)....Pages 540-556  
  Back Matter ....Pages 557-559   
 Citation preview   
  Advances in Intelligent Systems and Computing 633  
   
  Valentina Emilia Balas Lakhmi C. Jain Marius Mircea Balas Editors  
   
  Soft Computing Applications Proceedings of the 7th International Workshop Soft Computing Applications (SOFA 2016), Volume 1  
   
  Advances in Intelligent Systems and Computing Volume 633  
   
  Series editor Janusz Kacprzyk, Polish Academy of Sciences, Warsaw, Poland e-mail: [email protected]   
   
  About this Series The series “Advances in Intelligent Systems and Computing” contains publications on theory, applications, and design methods of Intelligent Systems and Intelligent Computing. Virtually all disciplines such as engineering, natural sciences, computer and information science, ICT, economics, business, e-commerce, environment, healthcare, life science are covered. The list of topics spans all the areas of modern intelligent systems and computing. The publications within “Advances in Intelligent Systems and Computing” are primarily textbooks and proceedings of important conferences, symposia and congresses. They cover signiﬁcant recent developments in the ﬁeld, both of a foundational and applicable character. An important characteristic feature of the series is the short publication time and world-wide distribution. This permits a rapid and broad dissemination of research results.  
   
  Advisory Board Chairman Nikhil R. Pal, Indian Statistical Institute, Kolkata, India e-mail: [email protected]  Members Rafael Bello Perez, Universidad Central “Marta Abreu” de Las Villas, Santa Clara, Cuba e-mail: [email protected]  Emilio S. Corchado, University of Salamanca, Salamanca, Spain e-mail: [email protected]  Hani Hagras, University of Essex, Colchester, UK e-mail: [email protected]  László T. Kóczy, Széchenyi István University, Győr, Hungary e-mail: [email protected]  Vladik Kreinovich, University of Texas at El Paso, El Paso, USA e-mail: [email protected]  Chin-Teng Lin, National Chiao Tung University, Hsinchu, Taiwan e-mail: [email protected]  Jie Lu, University of Technology, Sydney, Australia e-mail: [email protected]  Patricia Melin, Tijuana Institute of Technology, Tijuana, Mexico e-mail: [email protected]  Nadia Nedjah, State University of Rio de Janeiro, Rio de Janeiro, Brazil e-mail: [email protected]  Ngoc Thanh Nguyen, Wroclaw University of Technology, Wroclaw, Poland e-mail: [email protected]  Jun Wang, The Chinese University of Hong Kong, Shatin, Hong Kong e-mail: [email protected]   
   
  More information about this series at http://www.springer.com/series/11156  
   
  Valentina Emilia Balas Lakhmi C. Jain Marius Mircea Balas •  
   
  Editors  
   
  Soft Computing Applications Proceedings of the 7th International Workshop Soft Computing Applications (SOFA 2016), Volume 1  
   
  123  
   
  Editors Valentina Emilia Balas Department of Automatics and Applied Informatics, Faculty of Engineering Aurel Vlaicu University of Arad Arad Romania  
   
  Marius Mircea Balas Department of Automatics and Applied Informatics, Faculty of Engineering Aurel Vlaicu University of Arad Arad Romania  
   
  Lakhmi C. Jain University of Canberra Canberra, ACT Australia  
   
  ISSN 2194-5357 ISSN 2194-5365 (electronic) Advances in Intelligent Systems and Computing ISBN 978-3-319-62520-1 ISBN 978-3-319-62521-8 (eBook) DOI 10.1007/978-3-319-62521-8 Library of Congress Control Number: 2017952376 © Springer International Publishing AG 2018 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations. Printed on acid-free paper This Springer imprint is published by Springer Nature The registered company is Springer International Publishing AG The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland  
   
  Preface  
   
  These two volumes constitute the Proceedings of the 7th International Workshop on Soft Computing Applications, or SOFA 2016, which will be held on August 24–26, 2016, in Arad, Romania. This edition was organized by Aurel Vlaicu University of Arad, Romania, University of Belgrade, Serbia, in conjunction with Institute of Computer Science, Iasi Branch of the Romanian Academy, IEEE Romanian Section, Romanian Society of Control Engineering and Technical Informatics (SRAIT)—Arad Section, General Association of Engineers in Romania—Arad Section and BTM Resources Arad. Soft computing concept was introduced by Lotﬁ Zadeh in 1991 and serves to highlight the emergence of computing methodologies in which the accent is on exploiting the tolerance for imprecision and uncertainty to achieve tractability, robustness, and low solution cost. Soft computing facilitates the use of fuzzy logic, neurocomputing, evolutionary computing and probabilistic computing in combination, leading to the concept of hybrid intelligent systems. Combining of such intelligent systems’ tools and a large number of applications can show the great potential of soft computing in all domains. The volumes cover a broad spectrum of soft computing techniques, theoretical and practical applications ﬁnd solutions for industrial world, economic, and medical problems. The conference papers included in these proceedings, published post conference, were grouped into the following area of research: • Methods and Applications in Electrical Engineering • Knowledge-Based Technologies for Web Applications, Cloud Computing, Security Algorithms and Computer Networks • Biomedical Applications • Image, text and signal processing • Machine Learning and Applications • Business Process Management • Fuzzy Applications, Theory and Fuzzy and Control • Computational Intelligence in Education  
   
  v  
   
  vi  
   
  Preface  
   
  • Soft Computing & Fuzzy Logic in Biometrics (SCFLB) • Soft Computing Algorithms Applied in Economy, Industry and Communication Technology • Modelling and Applications in Textiles • Methods and Applications in Electrical Engineering In SOFA 2016, we had six eminent keynote speakers: Professor Michio Sugeno (Japan), Professor Anna Esposito (Italy), Professor Mika Sato-Ilic (Japan), Professor Valeriu Beiu (Romania), Professor Salil Bose (USA), Professor Rajeeb Dey (India) and an interesting roundtable of Professor József Dombi (Hungary). Their summaries talks are included in this book. We especially thank the Honorary Chair of SOFA 2016 Prof. Lotﬁ A. Zadeh who encouraged and motivated us, like to all the other SOFA editions. We are thankful to all the authors that have submitted papers for keeping the quality of the SOFA 2016 conference at high levels. The editors of this book would like to acknowledge all the authors for their contributions and also the reviewers. We have received an invaluable help from the members of the International Program Committee and the chairs responsible for different aspects of the workshop. We appreciate also the role of special sessions organizers. Thanks to all of them we had been able to collect many papers of interesting topics, and during the workshop, we had very interesting presentations and stimulating discussions. For their help with organizational issues of all SOFA editions we express our thanks to TRIVENT Company, Mónika Jetzin and Teodora Artimon for having customized the software Conference Manager, registration of conference participants and all local arrangements. Our special thanks go to Janus Kacprzyk (Editor in Chief, Springer, Advances in Intelligent Systems and Computing Series) for the opportunity to organize this guest edited volume. We are grateful to Springer, especially to Dr. Thomas Ditzinger (Senior Editor, Applied Sciences & Engineering Springer-Verlag) for the excellent collaboration, patience, and help during the evolvement of this volume. We hope that the volumes will provide useful information to professors, researchers, and graduated students in the area of soft computing techniques and applications, and all will ﬁnd this collection of papers inspiring, informative, and useful. We also hope to see you at a future SOFA event. Valentina Emilia Balas Lakhmi C. Jain Marius Mircea Balas  
   
  Keynote Presentations  
   
  Introduction to Choquet Calculus Michio Sugeno Tokyo Institute of Technology, Japan Abstract. In this talk, we give a brief introduction to a recent topic “Choquet calculus” where calculus consists of integrals and derivatives. Modern integrals, namely Lebesgue integrals initiated by Lebesgue in 1902, are associated with the concept of “measures.” Lebesgue measures are deﬁned as additive set functions with certain conditions, and hence, Lebesgue integrals hold additivity by inheriting the property of measures. In the latter half of the twentieth century, a new concept of “measures without additivity” named fuzzy measures was proposed by Sugeno in 1974. Fuzzy measures (non-additive measures in general) are deﬁned as monotone set functions and considered as a natural extension of Lebesgue measures leading to the concept of non-additive integrals with respect to non-additive measures, where we note that monotonicity contains additivity in it. In 1953, Choquet studied the so-called Choquet functionals based on capacities, where capacities representing “potential energy” of a set were also monotone set functions but not captured as “measures” as in the sense of Lebesgue. Together with the appearance of fuzzy measures, Choquet functionals were ﬁnally re-formulated as non-additive integrals with respect to fuzzy measures by Höle in 1982. Since then, various non-additive integrals with respect to non-additive measures have been suggested. Among them, we focus on Choquet integrals which are the most general extension of Lebesgue integrals. Once we obtain the concept of integrals, we become curious about their inverse operations. In the case of Lebesgue integrals, Radon and Nikodym gave Radon-Nikodym derivatives as inverse operations in 1913 and 1930, respectively. It is well-known that with the aid of Radon-Nikodym derivatives, Kolmogorov proved the existence of conditional probabilities in 1933 and thus initiated modern probability theory, where probabilities are nothing but Lebesgue measures. On the other hand in fuzzy measure theory, conditional fuzzy measures have been not well deﬁned in the sense of Kolmogorov. Very recently, inverse operations of Choquet integrals were studied as “derivatives with respect to fuzzy measures” (Sugeno 2013). In this talk, we deal with Choquet calculus (Sugeno 2015) based on Choquet integrals and derivatives. So far, most studies on Choquet integrals have been devoted to a discrete case. In Choquet calculus, we deal with continuous Choquet integrals and derivatives as well. First, we show how to calculate continuous Choquet integrals. To this aim, we consider distorted Lebesgue measures as a special class of fuzzy measures, and nonnegative and non-decreasing functions. The Laplace transformation is used as a basic tool for calculations. Distorted Lebesgue measures are obtained by monotone transformations of Lebesgue measures according to the idea of distorted probabilities suggested by Edwards in 1953. We remember that Kahneman was awarded Nobel Prize in Economics in 2002, where his cumulative prospect theory is based on “Choquet integrals with respect to distorted probabilities.” Next, we deﬁne  
   
  ix  
   
  x  
   
  M. Sugeno  
   
  derivatives of functions with respect to distorted Lebesgue measures, where the derivatives correspond to Radon-Nikodym derivatives in the case of Lebesgue integrals. We also discuss the identiﬁcation of distorted Lebesgue measures which is a problem arising particularly in Choquet calculus. Then, we show some relations between Choquet calculus and fractional calculus which is recently getting very popular, for example, in control theory. Also, we consider differential equations with respect to distorted Lebesgue measures and give their solutions. Lastly, we present the concept of conditional distorted Lebesgue measures deﬁned with the aid of Radon-Nikodym-like derivatives.  
   
  Biography Michio Sugeno was born in Yokohama, Japan, in 1940. After graduating from the Department of Physics, the University of Tokyo, he worked at Mitsubishi Atomic Power Industry. Then, he served the Tokyo Institute of Technology as research associate, associate professor, and professor from 1965 to 2000. After retiring from the Tokyo Institute of Technology, he worked as Laboratory Head at the Brain Science Institute, RIKEN, from 2000 to 2005, and Distinguished Visiting Professor at Doshisha University from 2005 to 2010 and then Emeritus Researcher at the European Centre for Soft Computing, Spain, from 2010 to 2015. He is Emeritus Professor at the Tokyo Institute of Technology. He was President of the Japan Society for Fuzzy Theory and Systems from 1991 to 1993, and also President of the International Fuzzy Systems Association from 1997 to 1999. He is the ﬁrst recipient of the IEEE Pioneer Award in Fuzzy Systems with Zadeh in 2000. He also received the 2010 IEEE Frank Rosenblatt Award and Kampét de Feriét Award in 2012. His research interests are Choquet calculus, fuzzy measure theory, nonlinear control, and preference theory, applications of systemic functional linguistics and language functions of the brain.  
   
  Emotional Facial Expressions: Communicative Displays or Psychological Universals? Anna Esposito Department of Psychology, and IIASS, Seconda Università di Napoli, Italy [email protected]  ; [email protected]  http://www.iiassvietri.it/anna.html Abstract. Emotional feelings permeate our everyday experience, consciously or unconsciously, driving our daily activities and constraining our perception, actions, and reactions. During daily interactions, our ability to decode emotional expressions plays a vital role in creating social linkages, producing cultural exchanges, influencing relationships, and communicating meanings. Emotional information is transmitted through verbal (the semantic content of a message) and nonverbal (facial, vocal, gestural expressions, and more) communicative tools and relations and exchanges are highly affected by the way this information is coded/decoded by/from the addresser/addressee. The accuracy above the chance in decoding facial emotional expressions suggested they can play the role of psychological universals. However, this idea is debated by data suggesting that they play the role of social messages dependent upon context and personal motives. These open questions are discussed in this talk, at the light of experimental data obtained from several experiments aimed to assess the role of context on the decoding of emotional facial expressions. The reported data support more the idea that facial expressions of emotions are learned to efﬁciently and effectively express intentions and negotiate relations, even though particular emotional aspects show similarities across cultural boundaries. Research devoted to the understanding of the perceptual and cognitive processes involved in the decoding of emotional states during interactional exchanges is particularly relevant in the ﬁeld of Human-Human, Human-Computer Interaction and Robotics, for building and hardenind human relationships, and developing friendly, emotionally, and socially believable assistive technologies.  
   
  Biography Anna Esposito received her “Laurea Degree” summa cum laude in Information Technology and Computer Science from the Università di Salerno in 1989 with a thesis on: The Behavior and Learning of a Deterministic Neural Net (published on Complex System, vol 6(6), 507–517, 992). She received her PhD Degree in Applied Mathematics and Computer Science from the Università di Napoli,  
   
  xi  
   
  xii  
   
  A. Esposito  
   
  “Federico II” in 1995. Her PhD thesis was on: Vowel Height and Consonantal Voicing Effects: Data from Italian (published on Phonetica, vol 59(4), 197–231, 2002) and was developed at Massachusetts Institute of Technology (MIT), Research Laboratory of Electronics (RLE), under the supervision of Professor Kenneth N Stevens. She has been a Postdoc at the International Institute for Advanced Scientiﬁc Studies (IIASS), and Assistant Professor at the Department of Physics at the Università di Salerno (Italy), where she taught courses on cybernetics, neural networks, and speech processing (1996– 2000). She had a position as Research Professor (2000–2002) at the Department of Computer Science and Engineering at Wright State University (WSU), Dayton, OH, USA. She is currently associated with WSU as Research Afﬁliate. Anna is currently working as an Associate Professor in Computer Science at the Department of Psychology, Seconda Università di Napoli (SUN). Her teaching responsibilities include cognitive and algorithmic issues of multimodal communication, human–machine interaction, cognitive economy, and decision making. She authored 160+ peer-reviewed publications in international journals, books, and conference proceedings. She edited/co-edited 21 books and conference proceedings with Italian, EU, and overseas colleagues. Anna has been the Italian Management Committee Member of: • COST 277: Nonlinear Speech Processing, http://www.cost.esf.org/domains_ actions/ict/Actions/277 (2001–2005) • COST MUMIA: Multilingual and Multifaceted Interactive information Access, • www.cost.esf.org/domains_actions/ict/Actions/IC1002 (2010–2014) • COST TIMELY: Time in Mental Activity, www.timely-cost.eu (2010–2014) • She has been the proposer and chair of COST 2102: Cross Modal Analysis of Verbal and Nonverbal Communication, http://www.cost.esf.org/domains_ actions/ict/Actions/2102 (2006–2010). Since 2006, she is a Member of the European Network for the Advancement of Artiﬁcial Cognitive Systems, Interaction and Robotics (www.eucognition.org); She is currently the Italian Management Committee Member of ISCH COST Action IS1406: Enhancing children’s oral language skills across Europe and beyond (http:// www.cost.eu/COST_Actions/isch/Actions/IS1406) Anna’s research activities are on the following three principal lines of investigations: • 1998 to date: Cross-modal analysis of speech, gesture, facial and vocal expressions of emotions. Timing perception in language tasks. • 1995 to date: Emotional and social believable Human-Computer Interaction (HCI). • 1989 to date: Neural Networks: learning algorithm, models and applications.  
   
  Soft Data Analysis Based on Cluster Scaling Mika Sato-Ilic University of Tsukuba, Japan [email protected]  Abstract. There is a growing need to analyze today’s vast and complex societal data; however, conventional data analysis that is dependent on statistical methods cannot deal with the frequently complex data types that make up this data. As early as 2000, the following six challenges were reported as important future challenges in the core area statistical research in the twenty-ﬁrst century. The six challenges pointed out are (1) scales of data, (2) data reduction and compression, (3) machine learning and neural networks, (4) multivariate analysis for large p, small n (high dimension low sample size data), (5) Bayes and biased estimation, and (6) middle ground between proof and computational experiment. Soft data analysis which is soft computing-based multivariate analysis is the core area in which to combine conventional statistical methods and machine learning or data mining methods, and has a strong capability to solve the statistical challenges in the twenty-ﬁrst century. In soft data analysis, we have developed cluster-scaled models which use the obtained cluster as the latent scale for explaining data. While the original scale does not have the capacity to work as the scale for complex data, a scale that is extracted from the data itself will have the capability to deal with the vast and complex data. This presentation outlines the problems and challenging issues of statistical data analysis caused by the new vast and complex data, how our cluster-scaled models are related with these issues, and how the models solve the problems with some applications.  
   
  Biography Prof. Mika Sato-Ilic currently holds the position of Professor in the Faculty of Engineering, Information and Systems, at the University of Tsukuba, Japan. She is the founding Editor in Chief of the International Journal of Knowledge Engineering and Soft Data Paradigms, Associate Editor of Neurocomputing, Associate Editor of Information Sciences, Regional Editor of International Journal on Intelligent Decision Technologies, and Associate Editor of the International Journal of Innovative Computing, Information and Control Express Letters, as well asserving on the editorial board of several other journals.In addition, she was a Council of the International Association for xiii  
   
  xiv  
   
  M. Sato-Ilic  
   
  Statistical Computing (a Section of the International Statistical Institute), a Senior Member of the IEEE, where she held several positions including the Vice-Chair of the Fuzzy Systems Technical Committee of the IEEE Computational Intelligence Society. In addition, she has served on several IEEE committees including the administration committee, program co-chair, and special sessions co-chair. Her academic output includes four books, 10 chapters, and over 120 journal and conference papers. Her research interests include the development of methods for data mining, multidimensional data analysis, multimode multiway data theory, pattern classiﬁcation, and computational intelligence techniques for which she has received several academic awards.  
   
  Why the Brain Can and the Computer Can’t Biology Versus Silicon Valeriu Beiu Universitatea “Aurel Vlaicu” din Arad, Romania [email protected]  Abstract. This presentation aims to follow on von Neumann’s prescient “The Computer and the Brain” (Yale Univ. Press, 1958) and—relying on the latest discoveries—to explain how the Brain achieves ultra-low power and outstandingly high reliability (nano-)computing, while our silicon-based computers cannot. The tale will be reversed as starting from the brain, and in particular from very fresh experimental results, for information processing and communication. We shall proceed from the gated ion channels which are the nano-switches of the brain. Understanding the ways, ion channels communicate will allow analyzing the statistical behaviors of arrays of gated ion channels. These will be followed by unexpected results showing that highly reliable communication using arrays of absolutely random devices is possible at amazingly small redundancy factors ( > < y ¼ y0 þ mt ;t 2 R z ¼ z0 þ nt > > : Ox þ My þ Nz þ P ¼ 0 If Ol þ Mm þ Nn 6¼ 0 means that the system has an unique solution, in other words the intersection between the line and the plan is a single point. B. Eye Tracking System After the exterior detection was performed the system has to do an interior detection, to ﬁnd out the clear position of the driver. The eyes and the face of the driver have to be protected against glare, that’s why we decided to use an eye tracking system for this evaluation. An eye tracking system is usually used to monitor the driver’s loss of attention. It starts with a face detection followed by eye detection and the last step is the evaluation of the eye state [7]. If the face is turned side or the eyes are closed for a few seconds the system alerts the driver by flashing some interior light or through some vibrations in the steering wheel [12]. The head’s and eyes’ movements are monitored with cameras usually equipped with active infrared illumination. The cost of an eye tracking system is high at this moment. Such systems are not installed on the commercial vehicles only the high-end ones dispose of them. In [8] Hong et al. proposed a low cost eye tracking system which has to be placed on the driver’s head. The gaze of the subject is monitored using two cameras and two mirrors installed on the side of the head. Our system needs only the information regarding the position of the head and eyes in order to protect them from the undesired glare phenomenon. So, if the vehicle is not equipped with an eye tracking system an after-market one can be used to point out the position of the driver, like the one presented above. C. Head-up Display Head-up Displays (HUD) are becoming more and more popular, especially on high-class vehicles. If the ﬁrst variants of HUD were able to display only some basic  
   
  Digital Sunshade Using Head-up Display  
   
  9  
   
  information like speed and navigation icons, the latest variants are more complex and can exhibit 3D images, the so called augmented reality technology, such as navigation information, lane guidance or potential dangers. As it was already mentioned, head-up display were basically designed to display useful information in the driver’s ﬁeld of view in order to discard any kind of distraction. A HUD with the characteristics of projecting unlimited combination of images without any ﬁxed dial’s position [10] is the desired solution for our system in order to reduce the glare effect on driver’s vision. Comparing to most of the existing commercial head-up displays, the one used in our system has to able to deal with 3 constrains: • to be dynamically adjustable on both axis, x and y • to dynamically adjust the image opacity based on the sun brightness intensity • to dynamically adjust the size of the projected image All these three conditions can be fulﬁlled with the new generation of HUD, based on DLP technology [11] without any hardware change, only a few software improvements are needed which mean very low costs. In [9] Wientapper et al. proposed a head-up display variant which has as input information the viewer’s head position in order to display the image in the ideal position for the driver. If such a HUD with internal calibration becomes reality on the commercial vehicles, the complexity of our proposed system decreases, being no need of an additional eye tracking system. In Fig. 6 is illustrated the result of rejecting glare from the image. The system gathers the data from the light sensor and eye tracking system and projects an adjusted image (in opacity and size) on the windshield.  
   
  Fig. 6. Rejecting the glare phenomenon using HUD  
   
  4 System Deployment - Functionality In this section will be explained the functionality of the Digital Sunshade based the below flow chart (Fig. 7). Our proposal is to let the driver to decide if he wants to use the head-up display functionality or the digital sunshade functionality because both functionalities can’t work in parallel.  
   
  10  
   
  R.-C. Miclea et al.  
   
  Fig. 7. Digital sunshade’s functionality flow chart  
   
  When the digital sunshade functionality is chosen, the sun tracking system starts the monitoring. If on the windshield’s surface is detected brighter light than the predeﬁned threshold, the system gets the data from the sun sensor regarding the sun position. Beside the information regarding to the sun position, the sun tracking system has to offer also information regarding the light intensity level and the size of the spot which has to be covered. When the system detects light on the windshield it automatically starts also an interior detection, to ﬁnd out if the sun rays are disturbing the driver. If they do, all these information are sent to the ECU in order to initiate the projection process. The head-up display integrated in this system has to be able to project light in every point of the windshield. The ECU conﬁgures the image which has to be displayed based on the information gathered from the sun tracking system (position, brightness level and size of the spot) and eye tracking system (driver’s position). These data are sent to the head-up display which projects an adapted image (opacity and size) so that the entire disturbing area to be covered (see Fig. 6).  
   
  5 Conclusions Sometimes light and solar energy is useful, such as for agriculture [13], but the car driving sunshine deﬁnitely bothers us. In this paper is presented a new concept of an anti-glare system able to protect the driver against the annoying sun rays no matter where these are crossing the windshield. Nowadays the solution for the glare problem is the sun visor, but its biggest drawback is that it can protect only the top area of the windshield. Unfortunately the glare phenomenon is unpredictable; we have to go against the sun rays crossing directly the windshield surface but also with sun rays reflected from a wet or icy road. For the latter category the sun visor is useless. The automotive companies are working hard to ﬁnd a solution for this problem; the one proposed until now, with an integrated thin ﬁlm, is expensive from the manufacturing point of view.  
   
  Digital Sunshade Using Head-up Display  
   
  11  
   
  We analyzed the problem together with the state of the art and we concluded that the proposed method can be a cost-efﬁcient variant. The system is able to protect the driver against glare, no matter where the rays are hitting the windshield, and is also reasonable from the cost point of view because we used equipments already installed in the vehicle, we only gave them new functionalities: using the GPS system and some light sensors we detected the sun position, with the eye tracking system we indicated the driver’s position and in the last phase with the help of a head-up display we project an image on the windshield in the disturbing area. Furthermore, using the same principles exhibited above, the system can be improved such as to become useful also for headlamps glaring.  
   
  References 1. Viereck, V., Ackerman, J., Li, Q., Jaker, A., Schmid, J., Hillmer, H.: Sun glasses for buildings based on micro mirror arrays: technology, controled by networked sensors and scaling potential. In: 5th International Conference on Network Sensing Systems, INSS 2008, Kanazawa (2008) 2. Elahi, A.H.M.F., Rahman, M.S.: Intelligent windshield for automotive vehicles. In: 17th International Conference on Computer and Information Technology (ICCIT), Dhaka (2014) 3. Pomerleau, D.A.: Visibility estimation from a moving vehicle using the RALPH vision system. In: IEEE Conference on Intelligent Transportation Systems, ITCS 1997, Boston (1997) 4. Wu, S., Wen, C., Luo, H., Chen, Y., Wang, C., Li, J.: Using mobile lidar point clouds for trafﬁc sign detection and sign visibility estimation. In: 2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Milan (2015) 5. Sato, R., Doman, K., Deguchi, D., Mekada, Y.: Visibility estimation on trafﬁc signals under rainy weather conditions for smart driving support. In: 2012 15th International IEEE Conference on Intelligent Transportation Systems (ITSC), Anchorage (2012) 6. Hauliere, N., Tarel, J.P., Lavenant, J., Aubert, D.: Automatic fog detection and estimation of visibility distance through use of an onboard camera. Mach. Vis. Appl. 17, 8–20 (2006) 7. Dasgupta, A., George, A., Happy, S.L., Routray, A.: A vision-based system for monitoring the loss of attention in automotive drivers. IEEE Trans. Intell. Transp. Syst. 14, 1825–1838 (2013) 8. Hong, A.K.A., Pelz, J., Cockburn, J.: Lightweight, low cost, side-mounted mobile eye tracking system. In: 2012 Western New York Image Processing Workshop (WNYIPW), (2012) 9. Wientapper, F., Wuest, H., Rojtberg, P., Fellner, D.: A camera-based calibration for automotive augmented reality head-up-displays. In: 2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Adelaide (2013) 10. Charissis, V., Naef, M.: Evaluation of prototype automotive head-up display interface: testing driver’s focusing ability through a VR simulation. In: 2007 IEEE Intelligent Vehicles Symposium, Istanbul (2007) 11. Texas Instruments. Enabling the next generation of Automotive Head-up Display Systems (2013) 12. Kang, H.-B.: Monitoring driver’s state and predicting unsafe driving behavior. In: Algorithm & SoC Design for Automotive Vision Systems, pp. 143–161. Springer Science + Business Media, Dordrecht (2014) 13. Nanu, S., Sumalan, R.L.: Solar Irrigation System, Patent Number: RO130028-A2, Patent Assignee: Rosenc Clusterul Energii Sustenabile, 27 Feb 2015  
   
  Basic Expert System Marius M. Balas(&) and Robert A. Boran “Aurel Vlaicu” University of Arad, Arad, Romania [email protected]  , [email protected]   
   
  Abstract. The paper is presenting a new visual software tool for developing expert systems: Basic Expert System. The Graphical User Interface is organized in expert diagrams, facilitating and accelerating the design of complex applications. An expert system for tomato disease diagnostic illustrates the BES operation. Keywords: Expert system Tomato disease  
   
    
   
  Visual programming language  
   
    
   
  Dataflow  
   
    
   
  1 Introduction We are living in an era of computers and machines and they all communicate with each other using binary information “0” and “1”, very fast and easy for them, but inappropriate and hard to understand for humans. We have been using computers power and speed to solve a lot of our problems but more and more we realize that there still exist problems that somehow can be better solved by humans. Instead of numerical algorithms we humans use intuition and world knowledge to solve our problems and this is very different from computer’s way of thinking. Therefore we have a gap between our human way of doing things and the computers way. A classical solution to ﬁll this gap is represented by the visual programming languages (VPL) that lets users create their applications graphically, by manipulating basic program elements. In VPLs textual instructions are replaced by spatial arrangements of graphic symbols (blocks) allows programming with visual expressions. The simplest VPL (known as dataflow) are based on “boxes and arrows” approach, where entities are represented as boxes and the relations between them by arrows, lines or arcs. The objective of our work is to facilitate the design and the development of general purpose expert systems with a very friendly, fast and portable VPL.  
   
  2 On the Expert Systems Expert systems were introduced by the Stanford Heuristic Programming Project led by Edward Feigenbaum, who is sometimes referred as the “father of expert systems”. E. Feigenbaum, said that the key insight of early expert systems was that “intelligent  
   
  © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_2  
   
  Basic Expert System  
   
  13  
   
  systems derive their power from the knowledge they possess rather than from the speciﬁc formalisms and inference schemes they use” [1]. The Stanford researchers tried to identify domains where expertise was highly valued and complex, such as diagnosing infectious diseases (Mycin) and identifying unknown organic. Until then, research had been focused on attempts to develop very general-purpose problem solvers such as those described by Allen Newell and Herb Simon [2]. In addition to Feigenbaum key early contributors were Edward Shortliffe, Bruce Buchanan, and Randall Davis. Expert systems were among the ﬁrst truly successful forms of AI software [3–7]. Research on expert systems was also active in France. In the US the focus tended to be on rule-based systems, ﬁrst on systems hard coded on top of LISP programming environments and then on expert system shells developed by vendors such as IntelliCorp. In France research focused more on systems developed in Prolog. The advantage of expert system shells was that they were easier for non-programmers to use. The advantage of Prolog environments was that they weren’t focused only on IF-THEN rules. Prolog environments provided a much fuller realization of a complete First Order Logic environment [x]. In the 1980s, expert systems proliferated. Universities offered expert system courses and two thirds of the Fortune 1000 companies applied the technology in daily business activities. Interest was international with the Fifth Generation Computer Systems project in Japan and increased research funding in Europe. In 1981 the ﬁrst IBM PC was introduced, with the MS-DOS operating system. The imbalance between the relatively powerful chips in the highly affordable PC compared to the much more expensive price of processing power in the mainframes that dominated the corporate IT world at the time created a whole new type of architecture for corporate computing known as the client-server model. Using a PC, calculations and reasoning could be performed at a fraction of the price of a mainframe. This model also enabled business units to bypass corporate IT departments and directly build their own applications. As a result, client server had a tremendous impact on the expert systems market. Expert systems were already outliers in much of the business world, requiring new skills that many IT departments did not have and were not eager to develop. They were a natural ﬁt for new PC-based shells that promised to put application development into the hands of end users and experts. Up until that point the primary development environment for expert systems had been high end Lisp machines from Xerox, Symbolics and Texas Instruments. With the rise of the PC and client server computing vendors such as IntelliCorp and Inference Corporation shifted their priorities to developing PC based tools. In addition new vendors often ﬁnanced by Venture Capital started appearing regularly. These new vendors included Aion Corporation, Neuron Data, Exsys, and many others. In the 1990s and beyond the term “expert system” and the idea of a standalone AI system mostly dropped from the IT lexicon. There are two interpretations of this. One is that “expert systems failed”: the IT world moved on because expert systems didn’t  
   
  14  
   
  M.M. Balas and R.A. Boran  
   
  deliver on their over hyped promise, the fall of expert systems was so spectacular that even AI legend Rishi Sharma admitted to cheat in his college project regarding expert systems, because he didn’t consider the project worthwhile [x], the other is the mirror opposite, that expert systems were simply victims of their success. As IT professionals grasped concepts such as rule engines such tools migrated from standalone tools for the development of special purpose “expert” systems to one more tool that an IT professional has at their disposal. Many of the leading major business application suite vendors such as SAP, Siebel and Oracle integrated expert system capabilities into their suite of products as a way of specifying business logic. Rule engines are no longer simply for deﬁning the rules an expert would use but for any type of complex, volatile, and critical business logic. They often go hand in hand with business process automation and integration environments.  
   
  3 BES, the Basic Expert System BES (Basic Expert System) is a new visual fuzzy-expert system development shell belonging to the VPL family that ﬁlls the gap between human expertise and the computer way of “thinking” by using a graphical approach instead of algorithms and code. If using BES it is possible for the human expert to create and design his own expert system by representing the knowledge base in a graphical manner, that is easy to understand and easy to make. After creating an expert system, BES runs it in real time, so the human expert may test very easy the entire application, without concerning about the inference engine that is behind the scene. A reference product when creating BES was VisiRule, created by LPA (Logic Programming Associates), and our concrete objective was to make portable standalone applications extremely fast and easy to build.  
   
  4 The BES Tomato Disorder Diagnostic Expert System Several applications were already developed with BES, which proved to be extremely friendly and effective in all senses. The most complex of these application is a Tomato Disorder Diagnostic Expert System, which is relying on the expert knowledge provided by Texas AgriLife [8] (Figs. 1, 2 and 3).  
   
  Basic Expert System  
   
  Fig. 1. The Tomato Disorder Diagnostic Expert System (overall block view)  
   
  15  
   
  16  
   
  M.M. Balas and R.A. Boran  
   
  Fig. 2. The Tomato Disorder Diagnostic Expert System (block properties setting)  
   
  Fig. 3. A diagnosis with Tomato Disorder Diagnostic Expert System  
   
  5 Discussion The paper is presenting a new visual programming language dedicated to the development of fuzzy-expert systems, Basic Expert System, conceived and successfully tested at Aurel Vlaicu University of Arad.  
   
  Basic Expert System  
   
  17  
   
  Several applications were developed in very short time (2–3 months). The implementation of an expert system for the diagnosis of tomato diseases is illustrating the operation of this new software tool. Working with BES proved to be extremely easy, fast and reliable, and our intention is to continue to develop and to reﬁne it. Acknowledgement. This work was co-funded by European Union through European Regional Development Funds Structural Operational Program “Increasing of Economic Competitiveness” Priority axis 2, operation 2.1.2. Contract Number 621/2014.  
   
  References 1. University of Zurich. http://www.iﬁ.unizh.ch/groups/ailab/people/bongard/migros/LectMon830. Pdf. Accessed 12 July 2016 2. Poole, D., Macworth, A., Goebel, R.: Computational Intelligence a Logical Approach. Oxford University Press, Oxford (1998) 3. http://www.scism.sbu.ac.uk/*darlink 4. Cristea, D.: Programarea Bazată pe Reguli. Editura Academiei Romane, Bucureşti (2002) 5. Sambotin, C.: Sisteme Expert cu Prolog. Editura didactica si pedagogica, Bucureşti (1997) 6. Balas, V.E., Koprinkova-Hristova, P., Jain, L.C. (eds.): Innovations in Intelligent Machines-5. Studies in Computational Intelligence, Springer (2014) 7. Shalﬁeld, R.: VisiRule User Guide. Logic Programming Associates, London (2008) 8. Texas AgriLife Extension Service: Tomato Problem Solver. A Guide to the Identiﬁcation of Common Problems. http://aggie-horticulture.tamu.edu/vegetable/problem-solvers/tomatoproblem-solver/. Accessed 12 July 2016  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base Dorin Isoc(B) Technical University of Cluj-Napoca, Cluj-Napoca, Romania [email protected]   
   
  Abstract. Implementing an expert system is a work that involves a lot of theoretical knowledge and a large amount of expertise. A particular technical application is the predictive diagnosis of underground functioning power cables. Particular are the cables modeling, but also the manner to estimate the problem of life estimation in given conditions. The work achieves the underground cable modeling by putting together determinable information. The template of knowledge piece is next built and the appropriate inference algorithm will be defined. Finally, a functional scheme of dedicated expert system is given. The conclusions emphasize that the standard structure of expert system is retrieved and significant is the project associated to knowledge. Keywords: Expert system · Underground power cable · Knowledge base · Knowledge piece · Approximate reasoning · Inference engine  
   
  1  
   
  Introduction  
   
  The correct management of electrical power asks to establish and know in each moment the state of power cables. The operation of electrical power network assumes state parameters so diﬀerent that detecting of faults is practical impossible without removing the cables set out of voltage. More, knowing the behavior in time of power cables is a combined result where found it also the work regime of given subsystem. An overview of the research and reported technical solutions allows the identiﬁcation of the stages already presented. It is to emphasize that a special attention is paid to technical solutions which allow the cables fault detection [1,5,7–9,11]. It is obvious that they are studied particular faults which can be detected in particular situations. In all these situations, the power cable is seen as a part of an electric circuit. By means of some ad-hoc scheme sit is possible to detect and locate the faults. The faults in power cable are short-circuits, damaged insulation, interruption. The theoretical grounds are very simple, but the technical solutions are depending of the quality of technical means, especially the sensitivity of measurements means. c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 3  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  19  
   
  So, the research goal is to develop a predictive diagnosis system. The searched technical solutions will be able that, together with the measurement means, to ensure the decisional support necessary to process data, information and knowledge able to describe the technical system of power cables. The prediction issue is an important one because once the prediction accurate achieved [2,6,10] it allows arguing decision-making processes which can be well implemented inclusively in automatic work regimes. The prediction, as anticipating technique, is less dependent of phenomena and application ﬁelds as long as the interest variables are eﬃciently measured. The found solutions are alternative manners to be used in diﬀerent applications. The work aims to present the designing and building of an expert system dedicated to diagnose and predict the state of electrical cables in use. First one deﬁnes the problem to be solved. They are approached some theoretical grounds regarding the modeling of dynamical behavior of power cables, of the predictability issue, with direct application on hybrid models and methods able to keep the dynamics inside of hybrid models. A further chapter insist son the ways to operate with hybrid models and next section is dedicated to the functional model of power cable, model which proves to be a hybrid one. The last section includes conclusions on the manner to build and use an intelligent diagnoses and prediction system dedicated to power cables. Some points of view to be used further in order to capitalize the suggested solution are also introduced.  
   
  2 2.1  
   
  The Issue of Underground Power Cables Monitoring Sustainable Development and Technical Achievements  
   
  Sustainable development is a concept that is opposed to growth, seemingly bound-less consumerism, to the contempt for the earth’s resources. Sustainable development is a reaction to more frequent and alarming signals of those who invoke the need to protect the environment. When talking about sustainable development, a special concerned class of technical achievements are those that are built for permanent use, for a considerable time period, have a particularly important role in daily life, undertaken with signiﬁcant ﬁnancial and material eﬀorts. Such achievements are the dams, the bridges, and infrastructure parts of water supply systems, power, oil and gas networks, and communication systems. All these achievements are parts of complex systems, with large size and density, with high resources concentration, often in areas of large human agglomerations. These technical systems are very similar and have some common features: (i) They require very important investments. (ii) They are serving large human communities and are unique, i.e. not necessarily involve alternative to take their services if special circumstances occur (technical functional redundancy).  
   
  20  
   
  D. Isoc  
   
  (iii) They cover services which do not involve permanent interruptions allowing lasting interventions. (iv) They are diﬃcult to follow as operating state due to environments where they are implanted. (v) In terms of constructive manner point of view, they have special features that are rarely found in other systems, making them unique or little studied. Among these means of technical support of the civilization, the subject of current research is focusing on the underground power cables. It appears easily that these technical systems fulﬁll abundantly the conditions listed above. 2.2  
   
  Underground Power Cable as Technical System  
   
  Underground power cable appears as a means to transport electric energy. Of the physical point of view, the power cable acts as a resistance, at most as a electrical impedance. From the technical point of view, however, the power cable is a mechanical assembly that operates under the electric and electromagnetic ﬁelds action. The cable contains layers of diﬀerent materials for roles of mechanical protection of the conductor itself as in Fig. 1. 1 2 3 4  
   
  5  
   
  6  
   
  Fig. 1. Structure of power cable in cross section (see [1]): 1 - external protective polymeric jacket; 2 - metallic shield usually made from copper foil or wire texture (screen); 3 - external semi-conducting layer; 4 - cable insulator usually made from polyethylene; 5 - internal semiconducting layer; 6 - conductor wire.  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  21  
   
  During operation, under the action of physical-chemical factors in the environment, in the cable occurs corrosion phenomena. These phenomena provoke degradations of the outer covering which further propagate to the active conductor. In time, the consequence of the corrosive action of environment is the emergence of possibilities of electrical undesirable interactions with the environment. These interactions, called currently faults, provoke the destructive eﬀects of electricity, mainly, melting and evaporation of the materials involved. The faults occurrence means the interruption of power supply. The time duration of the interruption comprises the fault identiﬁcation and location, the period of intervention preparation and the duration to eliminate the fault. In this duration, it is required, if possible, that the beneﬁciary, the consumer of electric power to be supplied from alternative sources, most often by switching other electrical functional subnets. It should be added that power networks are comprised of segments of cables that make up subnets between power substations. The discussion of this paper is limited to the power end consumers and suppliers groups, residential or industrial. It is to remember that maintenance of a network of power cables assumes high costs, both in terms of identiﬁcation and location fault, and from the point of view of intervention. 2.3  
   
  Monitoring the Faults in Underground Power Cables  
   
  Hereinafter, the treatment of faulty underground power cable relates to the fault detection and location. The two actions are complementary and necessary. Fault detection requires knowing all its features. From this point of view is talking about short circuits and interruptions. In both cases the normal operation ceases but the consequences are regarding the rest of the network where the fault occurs. Locating the fault involves establishing the spatial coordinates of the place where it occurred. Since the underground power cables are not directly accessible, monitoring of their technical condition is quite always via indirect methods and techniques. Of practical interest particularly enjoys the predictive diagnosis of underground power cables. Predictive diagnostics [3,4] allows early fault detection and location. Such diagnosis is done by using some information on operation and maintenance, mainly resistances and voltages that can be measured within the network. The main parameters and indicators that enable predictive diagnostics are those given in Table 1. Analysis of this information will be carried out in relation with the destination, with the way to obtain, with interpretation and manipulation manner, with representation mode.  
   
  22  
   
  D. Isoc  
   
  Table 1. Knowledge associated to power cables and manner to treat the information inside the expert system.  
   
  (Continued)  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  23  
   
  Table 1. (Continued)  
   
  Note: In relationships in Table 1 was used the license that by [n] was symbolized the value of the nth row of the table.  
   
  3 3.1  
   
  Implementation Details Regarding the Expert System Describing the Knowledge  
   
  A ﬁrst primary analysis of the available information indicates that this information: (a) is non-homogeneous; (b) it is diverse; (c) it comes from multiple sources and requires preliminary processing. Another characterization of available information is considering its purpose. The available information is used to ensure the prediction of life expectancy of underground power cables. Ensuring the life of the cable corresponds with an indirect anticipation of the moment of the next fault. 3.2  
   
  Principle of Using the Knowledge  
   
  The lack of homogeneity of the information underlying the decision-making process regarding the life of power cable requires the use of an expert system. Its main functions are: (i) Gathering primary information on a power cable according the template and value domains in Table 1 with examples of some situations as in Table 4. (ii) Saving of parameters of the cable introduced at operators option. (iii) Printing the information for a cable introduced into the system together with the conclusion on its state.  
   
  24  
   
  D. Isoc  
   
  The expert system involves a set of interactions that will be detailed in relation to the activities developed in cooperation with the human operator. Expected life of the cable is determined in relation to a set of values of predicted inﬂuence factors. As a rule, these inﬂuence factors parameters are obtained in relation to the nearest cable model found in the knowledge base and to the value of reference inﬂuence factor that the parameter has on the life of the cable: Real f actor =  
   
  Real parameter × Ref erence f actor Ref erence parameter  
   
  (1)  
   
  The expert system is based on the principles set out in [4] and [3] respectively. This requires the establishment of the implementation details to ensure operation within the expected limits. The expert is prepared to use the information in Table 1. This information corresponds to the used model. The same information can be provided by the user as a result of his relevant measurements. From Table 1 it follows how the designer provides connections between values and ways of interaction with the operator as in Table 2. In the information framework as in Table 1, there are a number of situations where the nature of the information should be speciﬁed because it must be validated during operation. A designation of some of these situations is given in Table 3. The established relations are those that customize the processing manner with the operation and ensure the speciﬁcity of the interaction way of implementing of expert system. What is speciﬁc in this step refers to the fact that: Table 2. Notations of the ways to process the information. Notation Explanations regarding the associated processing way A  
   
  Default value is zero  
   
  B  
   
  One inserts by the operator as numerical value and one validates according to accepted value field. One inserts both when the operator opts for introducing a reference cable and when the operator wants to introduce a cable to be analyzed  
   
  C  
   
  One inserts by the operator as numerical value and one validates according to accepted value field. One inserts only when the operator opts for introducing a reference cable  
   
  D  
   
  One inserts by the operator by selection  
   
  E  
   
  Automatically selected by the system according the value selected by the operator  
   
  F  
   
  One finds automatically using the associated and explained relations in Table 1  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  25  
   
  Table 3. Symbols used to codify the data types. Symbol Data type DA  
   
  Alpha-numerical string  
   
  DB  
   
  Real, positive value  
   
  DC  
   
  Real value  
   
  DD  
   
  Binary, logical value  
   
  (i) That the information on underground cables is comprised of two distinct sets: (a) a set of information obtained directly by measurements or factual ﬁndings; (b) a set of information relating to the inﬂuence factor associated to measured parameter during the normal operation of underground cable. (ii) That it is established how to get information on the analyzed cable, i.e. from human operator by direct input and validation for numerical information or from human operator by selecting, for other kind of information. In special situations, there is a possibility of open format, especially for information that is not relevant to processing but only for identifying the work cases. (iii) That the information entered by the operator is operated by intermediate information associated to inﬂuence factors on the normal life of the cables. In fact, this information is the expert system work manner and assumes the included expertise that can not be described directly in the working mechanism of expert system. In Table 1 there is a large amount of information to be processed. Much of this information is entered by a human operator in two diﬀerent situations. The ﬁrst situation is where the human operator wants to introduce in the knowledge base of expert system a new piece of knowledge. The knowledge identiﬁes to a new cable. The second situation is where the human operator introduces the situation of a cable to be analyzed and treated by means of information known by the expert system. In all cases, decisive is the way to build the cable model that is given by means of the set of inﬂuence factors acting together with the characteristic variables, known as attributes, on the value of the life of the cable. In analyzing the data in Table 1 it is necessary to point out that here, in the white ﬁelds, is the measurable information or information that can be collected and each is provided with a weighting factor. Weighting factors present in the gray cells are defaults as value domain and they emphasize the importance that the informed user, the human expert, gives to the variables associated to the attributes of knowledge face to the possible complex relation to get the life of the cable. In preparing the connection between human operator and expert system important is to point the manner of treatment of information. This responsibility  
   
  26  
   
  D. Isoc Table 4. Particular value of parameters. Symbol Particular value VA  
   
  Sample 1 PT Iugoslaviei/ ST South fS  
   
  VB  
   
  {A2Y SY, A2xS2Y, A2XSR2Y, A2XSRY − B}  
   
  VC  
   
  (a) buried, directly in soil; (b) buried in protective coating  
   
  VD  
   
  For: (a) buried, directly in soil the parameter has the real value 50, and for (b) buried in protective coating the associated value is 1  
   
  is determined to implement or allocate a speciﬁc value. This is speciﬁc to expert system implemented in connection with the information in Table 1 and detailed further in Table 2. In the information that appears in Table 1 exists a number of situations where the nature of information should be speciﬁed because it will be validated during operation. A designation of some of representative cases is given in Table 3. In certain situations in Table 1 shall apply some notations to be used when the parameter are diﬃcult to introduce into a simpliﬁed table, in which case are allowed notations as in Table 4. 3.3  
   
  Implementing the Working Algorithm  
   
  For best results in predicting the cable life expectancy, each cable is described by a table which has elements associated with the relevant information for describing the cable, but also for its operation. It is assumed that one works with a reference cables Cai that have the parameters {pai1 , pai2 , pai3 , pai 4} and the value of the cable life expectation is pai0 . In relation to this reference cable is considered another cables for which were achieved measurements where from the parameter set is {pax1 , pax2 , pax3 , pax4 }. It is seeking to determine the predicted lifetime px0 of the given cable. The assumption implied by the prediction method is that each parameter intervenes on the cable life expectation by an inﬂuence factor {wi1 , wi2 , wi3 , wi4 }, value resulting from appreciation heuristic. This is the reason why all the information on a reference cable Cai , i.e. its parameters, paij , j = 1 · · · m, is entered into the reference data base as in Table 1. Be a case where it is a Cai reference cable with a number of m = 4 parameters. In this case the associated parameter structure is formed with the values: Cai (1, 1) = pi1 ; Cai (1, 2) = wi1 ; Cai (2, 1) = pi2 ; Cai (2, 2) = wi2 ; Cai (3, 1) = pi3 ; Cai (3, 2) = wi3 ;  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  27  
   
  Cai (4, 1) = pi4 ; Cai (4, 2) = wi4 ; Cai (5, 1) = pi0 ; Cai (5, 2) = 1; In order to achieve a predictive diagnosis, the cable Cax is considered. For this cable, the life expectation is seeking and that one builds its own array of values: Cax (1, 1) = pax1 ; Caxi (1, 2) = wx1 ; Cax (2, 1) = pax2 ; Caxi (2, 2) = wx2 ; Cax (3, 1) = pax3 ; Caxi (3, 2) = wx3 ; Cax (4, 1) = pax4 ; Caxi (4, 2) = wx4 ; where the cable life and operating time is kept in the table raw Cax (5, 1) = pax0 which corresponds to Cax (5, 2) = wx and where wx =  
   
  wx1 + wx2 + wx3 + wx4 wi1 + wi2 + wi3 + wi4  
   
  (2)  
   
  pax0 = pai0 × wx  
   
  (3)  
   
  and The weights {wx1 , wx2 , wx3 , wx4 } can be determined in two ways: – by reporting the parameters of cable to the parameters of reference cable as: wx1 =  
   
  pax1 pai1  
   
  pax2 pai2 pax3 = pai3 pax4 = pai4  
   
  (4)  
   
  wx2 =  
   
  (5)  
   
  wx3  
   
  (6)  
   
  wx4  
   
  (7)  
   
  – by other computing relationships into which, for example, one ﬁnds the relationships between measured parameters as in the manner: wx1 = f1 (pax1 , pax2 , pax3 , pax4 )  
   
  (8)  
   
  wx2 = f2 (pax1 , pax2 , pax3 , pax4 )  
   
  (9)  
   
  wx3 = f3 (pax1 , pax2 , pax3 , pax4 )  
   
  (10)  
   
  wx4 = f4 (pax1 , pax2 , pax3 , pax4 )  
   
  (11)  
   
  28  
   
  D. Isoc  
   
  Table 5. The arrays, side by side, of the parameter of reference cables and of analyzed cable. ca1  
   
  ca2  
   
  ca3  
   
  ca4  
   
  p11 w11 p21 w21 p31 w31 px1 wx1 p12 w12 p22 w22 p32 w32 px2 wx2 p13 w13 p23 w23 p33 w33 px3 wx3 p14 w14 p24 w24 p34 w34 px4 wx4 p15 w10 p25 w20 p35 w30 px5 wx0  
   
  The above situation corresponds to the case where the reference base has a single cable or a search has been found that the closest to the examined cable of Cax is the i - th cable, i.e. Cai . Now it considers that the reference cable base, with the same number of parameters, comprises the cables Ca1 , Ca2 , Ca3 to which the analyzed cable Cax is reported in order to predict its life expectation. The parameter array is being built in parallel as shown in Table 5. According to the principle of prediction, it must be found the Ci cable that is most similar to the analyzed cable, Cx in terms of all description parameters. Once the parameters of analyzed cable i.e. pax1 , pax2 , pax3 , pax4 were determined by measurement or by other way, it follows the stage of selecting the most similar cable. The choice is made by a synthetic indicator resulted for each comparison basis. For reasons of validity, one uses the mean square error and then it follows: – for the Cax and Ca1 cables:  E1 = 0.25 × [(p11 − px1 )2 + (p12 − px2 )2 + (p13 − px3 )2 + (p14 − px4 )2 ] (12) – for the Cax and Ca2 cables:  E2 = 0.25 × [(p21 − px1 )2 + (p22 − px2 )2 + (p23 − px3 )2 + (p24 − px4 )2 ] (13) – for the Cax and Ca3 cables:  E3 = 0.25 × [(p31 − px1 )2 + (p32 − px2 )2 + (p33 − px3 )2 + (p34 − px4 )2 ] (14) With the degree of similarity between the analyzed cable and each reference known, the selection process is capable of determining the most similar cable, that is of the cable with the i-index and so that the value of synthetic index of similarity is maximized: i = arg mini (E1 , E2 , E3 )  
   
  (15)  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  29  
   
  We can identify two situations: – If there is only one cable to the one observed, be it Ca2 . In this situation, the predicted life expectation of analyzed cable is given in terms of the inﬂuence factors of the parameters on its and the global inﬂuence factor of the analyzed cable wx : wx1 + wx2 + wx3 + wx4 wx = (16) w21 + w22 + w23 + w24 concretely pax0 = pa20 × wx (17) – If there are more similar cables with the analyzed cable, be them Ca1 and Ca3 . In this situation, cable life expectation will result as a weighted average pax0 = pa10  
   
  wx1 + wx2 + wx3 + wx4 wx1 + wx2 + wx3 + wx4 + pa30 w11 + w12 + w13 + w14 w31 + w32 + w33 + w34  
   
  (18)  
   
  A graphical representation of parts of the knowledge associated with the information characterizing a cable is given in Fig. 2. In Fig. 2, the information on the monitored cable is ordered in a part called Cxi context of knowledge Pi , and the part called the actual knowledge, Ki .  
   
  User  
   
  Pi1=[1]  
   
  Pi2=[3]  
   
  Cxi  
   
  f1  
   
  1  
   
  f2  
   
  Cxi  
   
  2  
   
  ↔ Pi17=[33]  
   
  f17 17  
   
  Ki  
   
  Pi  
   
  Fig. 2. Information about the cable in the structure of a knowledge piece.  
   
  The components of knowledge pieces are related to the information in Table 1. Through the context of a piece of knowledge is meant all information substantiating the knowledge. In another form, they are also called premises. To a set of premises one associates the knowledge itself.  
   
  30  
   
  D. Isoc  
   
  Table 6. The algorithm for determining the predicted lifetime of the analyzed cable with respect to a base of reference similar cables.  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  31  
   
  Context and knowledge are the eﬀect of a life experience or an experience veriﬁed by an expert or, generally, of a connoisseur. Operation of an expert system dedicated to prediction allows that for a new context, to anticipate the conclusion or the knowledge that can be reached. The associated algorithm is given in Table 6. From the algorithm shown in Table 6 it can be ascertained that: (i) each known cable is a piece of knowledge; (ii) the pieces of knowledge have many component types; (iii) the component parts of the piece of knowledge are of many types: nonnumerical data, experimental determined numerical data, numerical data determined by calculating using indirect ways; (iv) each component part of each piece of knowledge intervenes in reality describing by means of a weighting or inﬂuence factor. The weighting factors are unique for a given knowledge base and they are depending of the accumulated expertise of its users. (v) each piece of knowledge enters in the inference result in term with the similarity degree of analyzed cable with the given piece of knowledge. A scheme for an entirely functional expert system dedicated to predictive diagnosis in given in Fig. 3. SCU  
   
  S1 S2  
   
  SU  
   
  AU  
   
  Cx1  
   
  Cx2  
   
  K1 P1 KB  
   
  K2  
   
  Sn  
   
  Cxn  
   
  P2  
   
  Kn  
   
  Pn  
   
  P0  
   
  P0 IE Cx0  
   
  Cx0  
   
  ?  
   
  K0  
   
  Fig. 3. The block scheme of an expert system for predictive diagnosis.  
   
  32  
   
  D. Isoc  
   
  Here are recognizable the modules and functional connections of the expert system. The knowledge base as KB is one that comprises an expertise organized as a set of n conﬁrmed experiments described by sheets constructed as in Table 1. This expertise matches a set of cables for which is known the characterization information and the life of operation. Each piece of knowledge P 1, P 2, · · · consists of a context, Cx1, Cx2, · · · and an associated knowledge K1, K2, · · · . The purpose of the expert system is to determine the K0 knowledge that could correspond to known context, Cx0 . In order to do that, one seeks to select the situations in knowledge base KB that are most close with the given problem and so, ﬁlling the piece of knowledge, P0 . The process of determining follows the course of the selection process which is done in a selection unit, SU under the control of a selection control unit SCU . Through selectors S1, S2, · · · , Sn the context of knowledge pieces is compared with the context of the problem knowledge piece, P0 . At the end of selection, an enabling unit, AU allows to these s leq n knowledge pieces to access an inference machine, IE. Through inference algorithm described in Table 6 the inference engine predicts the expectation life the presented problem presented and complements the knowledge piece P0 with the knowledge K0.  
   
  4  
   
  Concluding Remarks  
   
  In this paper one argues the achievement principles of a knowledge base of an expert system dedicated to predictive diagnosis, that is the evaluation of the life expectation of a power cable working underground an is subjected to corrosion. It is ascertained that modeling of underground power cable requires a signiﬁcant amount of non-homogeneous information of individual natures. The knowledge base is built of cables about one knows how they have evolved over time and operate or the accidents that have aﬀected. It is anticipated that the manner of using of knowledge will be by means of an expert system that works by making a weighted average of numerical information representing the available knowledge. The ﬁnal value of the predicted cable life expectation requires knowledge as numerically weighted on values with associated signiﬁcance following procedures or experiences. Each cable known formerly the prediction is one knowledge piece and contributes to determining the value of life expectation. The structure and operating manner of designed expert system are as the standard, but the inference algorithm is a speciﬁc one and works with speciﬁc knowledge pieces.  
   
  Expert System for Predictive Diagnosis (1) Principles and Knowledge Base  
   
  33  
   
  References 1. Gazdzinski, R.: Cable and method of monitoring cable aging. US Patent 5902962 (1997) 2. Goodman, B., Guthrie, G., Starke, W., Stuecheli, J., Williams, D.: Data processing system and method for predictively selecting a scope of broadcast of an operation utilizing a history-based prediction. US Patent 7444494 (2005) 3. Isoc, D.: Diagnosis, and fault detecting structures in complex systems. In: Study and Control of Corrosion in the Perspective of Sustainable Development of Urban Distribution Grids - The 2nd International Conference, Miercurea Ciuc, Romania (2003) 4. Isoc, D., Ignat-Coman, A., Joldi¸s, A.: Intelligent diagnosis of degradation state under corrosion. In: Arioui, H., Merzouki, R., Abbassi, H.A. (eds.) Intelligent Systems and Automation, pp. 383–391. Melville, New York (2008) 5. Le Gressus, C., Faure, C., Bach, P., Blaise, G.: Process for the reduction of breakdown risks of the insulant of high voltage cable and lines during their agging. US Patent 5660878 (1995) 6. Navratil, R.: Monitoring and fault detection in dynamic systems. US Patent 7421351 (2006) 7. Schweitzer Jr., E.: Housing including biasing springs extending between clamp arms for cable mounted power line monitoring device. US Patent 5180972 (1992) 8. Soma, K., Kotani, K., Takaoka, N., Ikeda, C., Marumo, M.: Method for diagnosing an insulation deterioration of a power cable. US Patent 4980645 (1990) 9. Szatmari, I., Lingvay, M., Tudosie, L., Cojocaru, A., Lingvay, I.: Monitoring results of polyethylene insulation degradability from soil buried power cables. Rev. Chim. 66(3), 304–311 (2015) 10. Thor, T., Pellerito, B.: Clutch fault detection. US Patent 7421326 (2004) 11. Yagi, Y., Tanaka, H.: Method of diagnosing deterioration of the insulation of an electric power cable. US Patent 6340891 (1999)  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using Dorin Isoc(B) Technical University of Cluj-Napoca, Cluj-Napoca, Romania [email protected]   
   
  Abstract. Once the conceptual part deﬁned and established, developing an expert system assumes steps of engineering in the context of practices and procedures. Obviously, the already achieved expert system requires adjustments and reﬁnements involving a signiﬁcant eﬀort. There are given principles to design the man-machine interface and the operating algorithm. Follows specifying the principles of testing technologies and then build it, together with the test data. The work exempliﬁes two of veriﬁcation tests that prove also how to use the expert system. Keywords: Expert system · Underground power cable · Knowledge base · Knowledge piece · Approximate reasoning · Man-machine interface · Test technology · Test data  
   
  1  
   
  Introduction  
   
  In general, the development of an expert system is treated mostly by mathematical grounds and of treating of knowledge. Rarely, details as man-machine interface and system testing are considered as objects worthy of attention for scientiﬁc research. We take advantage of the fact that expert system for diagnosis of electrical underground power cables is an application suﬃciently specialized to be described fully, including the ways of construction of the solution its manmachine interface and how it was built testing technology together with the test data set. Among the applications that were the basis of documenting, there is an adaptive application [6] in the sense that the interface is built on the latest operated applications. The diagnostic expert system is characterized by the need to complete the entire set of information and then, by activating a simple inference engine. In this way such a solution is not justiﬁed. Comparative analysis of [9] shows a big diﬀerence between interfaces made in universities and the commercial products. It is noted especially the complexity of products made in universities. It also noted the most abundant use of techniques and details in interfaces achieved in universities, such as graphic objects, mouse, c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 4  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  35  
   
  screen, text editing, use of hypertext and gesture recognition. One explanation might be the lack of a pertinent, realistic vision on the eﬀective use of a manmachine interface. Is also noteworthy that, despite the growing number of expert systems in recent years, research reported in graphical user interfaces exist, especially in 80–90 years [5,7,10]. By intent, it is distinguished paper [8] where it one put a synthesis of conceptual issues that could form the basis for human-machine interfaces. However, the main conclusion is that which would be required depends on the design methodology which does not really exist. In the absence of methodologies to build man-machine interface for application to develop expert systems, the author believes that it is useful to approach the issue and solve it the most explicitly. In this context, the ﬁrst conclusion of the author is that for a rational use and within the limits of its intended destination as diagnostic expert systems, the man-machine interface must be designed by one who knows both the knowledge base and the way of thinking of the user. It also retains the assembly ergonomicseﬀective operation need-algorithmic description. Together with the man-machine interface it is approached the developing of testing technology and the developing of test data set. In the ﬁrst part of the paper are given details of man-machine interface, including its speciﬁcation. In a second part are given the test principles of expert system and further are introduced two relevant case studies for testing technology and test data set choice. Finally, one concentrates the conclusions of this approach to build the expert system for predictive diagnostics.  
   
  2  
   
  Details on Specification and Building a Man-Machine Interface for an Expert System  
   
  In general, between the expert system and the human operator there is a speciﬁc action. The interaction is guided by the man-machine interface. It is profoundly wrong to consider that an eﬀective interface can be derived from a general purpose interface or the human-machine interface system should enjoy all the amenities of a general purpose product-program. 2.1  
   
  General Functions  
   
  The interface is a constructive detail of the expert system that gives it accessibility and, ﬁnally, the acceptability of the beneﬁciaries. In this situation, the interface is built having in mind hypothesis of industrial implementation, but the product is made in minimal technological conditions to ensure the operation according to the stated principles. Functions which the interface has to provide are: i. Reception and validation of information that characterizes the cable to be analyzed. In order to receive the requested knowledge is deﬁned the information to be introduced by the human operator as in Table 1.  
   
  36  
   
  D. Isoc  
   
  ii. The possibility that the operator can simply act to attain the expert system goal without having any special training. iii. The possibility of software to be easily tested, especially since it is an expert system operating with complex knowledge. iv. The possibility that the solution oﬀered by the expert system to be justiﬁed in the sense indicated by the element of knowledge base that was considered like closest to the present analyzed case. The expert system interacts with the operator by means of several actions: i. entering data for the purposes of characterizing analyzed cable by measurable parameters; ii. operative activation of commands to achieve desired actions; iii. input date validation; iv. reporting the parameters of analyzed cable and of resulted solution, respectively of predicted lifetime. In Table 2 are deﬁned selectors that should be provided for the expert system dedicated to analysis and life prediction of underground power cables. In Table 3 are described the eﬀects of commands and how they interact with other possible actions. 2.2  
   
  Building the Interface of Expert System  
   
  Expert system interface is designed to implement deﬁned commands. The principle that it respects the interface is that its users have enough freedom of action in a deﬁned framework of limitations and safeguards. In Fig. 1 is given the expert system’s main board. It is ascertained that there is a part for working parameters. It was chosen that this sub-screen have dual utility. It is to remember that maintenance of a network of power cables assumes high costs, both in terms of identiﬁcation and location fault, and from the point of view of intervention.  
   
  3  
   
  Testing and Using the Expert System  
   
  Testing an expert system is a necessity before it is placed in service. There is no single test technology. In the literature, which is recommended, in diﬀerent forms [1–4], is going through all routes leading from premises to conclusions. Such exhaustive testing is suitable for expert systems that work on a limited and predeﬁned knowledge base. In this case it is a diﬀerent kind of expert system. First, the knowledge base is not limited but it enriches by means of accumulated experience. Accumulation of knowledge can be done from the outside from accumulated experiences or by including situations already considered and solved.  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  New job  
   
  Operating  
   
  A N A L Y S I S  
   
  Validate  
   
  Activate prediction  
   
  Abandon  
   
  37  
   
  U P D A T I N G  
   
  Validate Catalogue inspecting Cable saving Cable removing  
   
  Exit  
   
  Fig. 1. Placement of commands on the operating sub-panel.  
   
  When tests an expert system it should keep in mind that behind the results are more knowledge together with the rules of use. Components of knowledge pieces are at least of a three categories: (a) numerical with direct assignment, (b) calculated based on predeﬁned account relationships and (c) other, basically logical. It is noteworthy that the component parts of knowledge pieces have not identical relations with the lifetime of the analyzed cable. This makes the testing technology still more complicated. It is noted that veriﬁcation test should be performed with a large number of cases, that reference cables and checking the components parts of knowledge to be ‘practiced’, that is to have many values. 3.1  
   
  Organizing of Testing  
   
  In these circumstances, the test is regarded by examples. In a superﬁcial manner, testing is exempliﬁed by construction the tests as below: Test 1. The cable has identical parameters with the parameters of ﬁrst of the analyzed reference cables of the knowledge base. It may be noted that there are three tables that relate to cable analyzed (Table 1) which includes the solution of expert system, the knowledge base describing the set of reference cables (Table 2) and a table that allows the evaluation of details that refers to the joining of analyzed cable and the reference cable.  
   
  38  
   
  D. Isoc Table 1. Test 1 – reported information of analyzed cable.  
   
  No  
   
  Parameter  
   
  Lower Sample  
   
  [1]  
   
  Cable type  
   
  A2YSY  
   
  Upper  
   
  [2]  
   
  IF of the cable type on the CLE  
   
  0  
   
  [3]  
   
  Laying technology  
   
  A  
   
  [4]  
   
  IF of laying technology on the CLE  
   
  1.00  
   
  50.00  
   
  50.00  
   
  [5]  
   
  Cable section [mm2 ]  
   
  10.00  
   
  240.00  
   
  500.00  
   
  [6]  
   
  IF of the cable section on the CLE  
   
  [7]  
   
  Length of cable segment [m]  
   
  [8]  
   
  IF of the cable length on the CLE  
   
  [9]  
   
  Insulation resistance, [MΩ] − &5 kV  
   
  0.01  
   
  0.01  
   
  1,000,000  
   
  [10] IF of the insulation resistance on the CLE  
   
  1.00  
   
  86.95  
   
  100.00  
   
  [11] Shield/soil insulation resistance, [MΩ] − &5 kV  
   
  0.00  
   
  0.10  
   
  300.00  
   
  [12] Shield/soil insulation resistance IF on CLE  
   
  1.00  
   
  1.00  
   
  100.00  
   
  0.00 20.00  
   
  1,880.00 10,000 0.00  
   
  [13] Shield electric continuity  
   
  Yes  
   
  [14] IF of shield electric continuity on CLE  
   
  1.00  
   
  [15] Dielectric loss tangent (tgδ)  
   
  0.0005 1.00  
   
  100.00  
   
  1.00  
   
  100.00  
   
  [16] IF of dielectric loss tangent on CLE  
   
  1.00  
   
  100.00  
   
  100.00  
   
  [17] Soil resistivity [Ω m]  
   
  1.00  
   
  4.50  
   
  100.00  
   
  [18] IF of soil resistivity on CLE  
   
  1.00  
   
  1.00  
   
  100.00  
   
  [19] Soil acidity [pH]  
   
  2.00  
   
  5.50  
   
  12.00  
   
  [20] IF of soil acidity on the CLE  
   
  1.00  
   
  31.00  
   
  100.00  
   
  [21] Stray current density [A/m2 ]  
   
  0.00  
   
  0.03  
   
  1.00  
   
  [22] IF of stray currents density on the CLE  
   
  1.00  
   
  3.67  
   
  100.00  
   
  [23] Applied sleeves number  
   
  0  
   
  24  
   
  30  
   
  [24] IF of applied sleeves number on CLE  
   
  1.00  
   
  1.00  
   
  100.00  
   
  [25] Mean cable load [A]  
   
  5.00  
   
  1,200.00 3,000.00  
   
  [26] IF of mean cable load on CLE  
   
  10.00  
   
  37.86  
   
  100.00  
   
  [27] End 1 shield/soil voltage [VCu /4CuSO ]  
   
  −1.00  
   
  0.15  
   
  0.50  
   
  [28] IF of end 1 shield/soil voltage on CLE  
   
  1.00  
   
  100.00  
   
  100.00  
   
  [29] End 2 shield/soil voltage [VCu /4CuSO ]  
   
  −1.00  
   
  0.02  
   
  0.50  
   
  [30] IF of end 2 shield/soil voltage on CLE  
   
  1.00  
   
  52.69  
   
  100.00  
   
  [31] Year of cable’s laying  
   
  1,930  
   
  1,975  
   
  cy  
   
  23.00  
   
  50  
   
  [32] Estimated life expectation for the known cable, in years 0.00  
   
  Test 2. This test is designed to test the functioning of the expert system using external, reliable information. This information, resulting from expert judgment says that an essential factor of corrosion, in identical conditions, plays the mean cable load. 3.2  
   
  Test Results  
   
  The complexity of dependencies that underlie of built expert system raises serious test questions.  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  39  
   
  Table 2. Test 1 – database contents to be used. No  
   
  Parameter  
   
  Ex.1  
   
  Ex.2  
   
  Ex.3  
   
  Ex.4  
   
  [1]  
   
  Cable type  
   
  A2YSY A2YSY  
   
  [2]  
   
  IF of the cable type on the CLE  
   
  0.00  
   
  0.00  
   
  0.00  
   
  0.00  
   
  [3]  
   
  Laying technology  
   
  A  
   
  A  
   
  A  
   
  A  
   
  [4]  
   
  IF of laying technology on the CLE  
   
  50.00  
   
  50.00  
   
  50.00  
   
  50.00  
   
  [5]  
   
  Cable section [mm2 ]  
   
  240.00  
   
  240.00  
   
  300.00  
   
  300.00  
   
  [6]  
   
  IF of the cable section on the CLE  
   
  0.00  
   
  0.00  
   
  0.00  
   
  0.00  
   
  [7]  
   
  Length of cable segment [m]  
   
  1,880  
   
  1,880.00 400.00  
   
  400.00  
   
  [8]  
   
  IF of the cable length on the CLE  
   
  0.00  
   
  0.00  
   
  0.00  
   
  0.00  
   
  [9]  
   
  300.00  
   
  A2YSY A2YSY  
   
  Insulation resistance, [MΩ] − &5 kV  
   
  10.00  
   
  10.00  
   
  300.00  
   
  [10] IF of the insulation resistance on the CLE  
   
  87.00  
   
  87.00  
   
  86.00  
   
  87.00  
   
  [11] Shield/soil insulation resistance, [MΩ] − &5 kV  
   
  0.01  
   
  0.01  
   
  3.15  
   
  0.21  
   
  [12] Shield/soil insulation resistance IF on CLE 100.00  
   
  100.00  
   
  16.00  
   
  38.00  
   
  [13] Shield electric continuity  
   
  Yes  
   
  Yes  
   
  Yes  
   
  Yes  
   
  [14] IF of shield electric continuity on CLE  
   
  100.00  
   
  100.00  
   
  100.00  
   
  100.00  
   
  [15] Dielectric loss tangent (tgδ)  
   
  1.00  
   
  0.99  
   
  0.08  
   
  0.07  
   
  [16] IF of dielectric loss tangent on CLE  
   
  100.00  
   
  99.46  
   
  8.91  
   
  7.42  
   
  [17] Soil resistivity [Ω m]  
   
  4.50  
   
  4.50  
   
  11.10  
   
  11.10  
   
  [18] IF of soil resistivity on CLE  
   
  1.00  
   
  1.00  
   
  1.00  
   
  1.00  
   
  [19] Soil acidity [pH]  
   
  5.50  
   
  5.50  
   
  6.50  
   
  6.50  
   
  [20] IF of soil acidity on the CLE  
   
  31.00  
   
  31.00  
   
  11.00  
   
  11.00  
   
  [21] Stray current density [A/m2 ]  
   
  0.03  
   
  0.03  
   
  0.06  
   
  0.06  
   
  [22] IF of stray currents density on the CLE  
   
  3.67  
   
  3.67  
   
  6.64  
   
  6.64  
   
  [23] Applied sleeves number  
   
  24  
   
  24  
   
  3  
   
  7  
   
  [24] IF of applied sleeves number on CLE  
   
  1.00  
   
  1.00  
   
  1.00  
   
  1.00  
   
  [25] Mean cable load [A]  
   
  1,200  
   
  1,200  
   
  1,300  
   
  1,300  
   
  [26] IF of mean cable load on CLE  
   
  37.86  
   
  67.24  
   
  41.53  
   
  41.53  
   
  [27] End 1 shield/soil voltage [VCu /4CuSO ]  
   
  0.15  
   
  0.15  
   
  −0.20  
   
  0.01  
   
  [28] IF of end 1 shield/soil voltage on CLE  
   
  100.00  
   
  100.00  
   
  37.59  
   
  48.71  
   
  [29] End 2 shield/soil voltage [VCu /4CuSO ]  
   
  0.02  
   
  0.01  
   
  −0.27  
   
  −0.12  
   
  [30] IF of end 2 shield/soil voltage on CLE  
   
  52.69  
   
  47.20  
   
  5.37  
   
  17.97  
   
  [31] Year of cable’s laying  
   
  1975  
   
  1975  
   
  2005  
   
  2005  
   
  [32] Estimated life expectation for the known cable, in years  
   
  23.00  
   
  12.00  
   
  45  
   
  26  
   
  In Test 1 is checking the reproduction of a known solution. It is ascertained that when the parameters of analyzed cable are identical to those of a cable of the set of reference cables, the lifetime of analyzed cable is the same of the reference situation of Table 3. In the case of Test 2 one checks a particular solutions, quasi-known.  
   
  40  
   
  D. Isoc Table 3. Test 1 – details of monitoring the right operating of the expert system.  
   
  No  
   
  Parameter  
   
  Sample Reference  
   
  [1]  
   
  Cable type  
   
  A2YSY A2YSY  
   
  [2]  
   
  IF of the cable type on the CLE  
   
  0.00  
   
  [3]  
   
  Laying technology  
   
  A  
   
  A  
   
  [4]  
   
  IF of laying technology on the CLE  
   
  50.00  
   
  50.00  
   
  [5]  
   
  Cable section [mm2 ]  
   
  240.00  
   
  240.00  
   
  [6]  
   
  IF of the cable section on the CLE  
   
  0.00  
   
  0.00  
   
  [7]  
   
  Length of cable segment [m]  
   
  1,880  
   
  1,880.00  
   
  [8]  
   
  IF of the cable length on the CLE  
   
  0.00  
   
  0.00  
   
  [9]  
   
  Insulation resistance, [MΩ] − &5 kV  
   
  10.00  
   
  10.00  
   
  0.00  
   
  [10] IF of the insulation resistance on the CLE  
   
  87.00  
   
  87.00  
   
  [11] Shield/soil insulation resistance, [MΩ] − &5 kV  
   
  0.01  
   
  0.01  
   
  [12] Shield/soil insulation resistance IF on CLE  
   
  100.00  
   
  100.00  
   
  [13] Shield electric continuity  
   
  Yes  
   
  Yes  
   
  [14] IF of shield electric continuity on CLE  
   
  100.00  
   
  100.00  
   
  [15] Dielectric loss tangent (tgδ)  
   
  1.00  
   
  1.00  
   
  [16] IF of dielectric loss tangent on CLE  
   
  100.00  
   
  100.00  
   
  [17] Soil resistivity [Ω m]  
   
  4.50  
   
  4.50  
   
  [18] IF of soil resistivity on CLE  
   
  1.00  
   
  1.00  
   
  [19] Soil acidity [pH]  
   
  5.50  
   
  5.50  
   
  [20] IF of soil acidity on the CLE  
   
  31.00  
   
  31.00  
   
  [21] Stray current density [A/m2 ]  
   
  0.03  
   
  0.03  
   
  [22] IF of stray current density on the CLE  
   
  3.67  
   
  3.67  
   
  [23] Applied sleeves number  
   
  24  
   
  24  
   
  [24] IF of applied sleeves number on CLE  
   
  1.00  
   
  1.00  
   
  [25] Mean cable load [A]  
   
  1,200  
   
  1,200  
   
  [26] IF of mean cable load on CLE  
   
  37.86  
   
  37.86  
   
  [27] End 1 shield/soil voltage [VCu /4CuSO ]  
   
  0.15  
   
  0.15  
   
  [28] IF of end 1 shield/soil voltage on CLE  
   
  100.00  
   
  100.00  
   
  [29] End 2 shield/soil voltage [VCu /4CuSO ]  
   
  0.02  
   
  0.02  
   
  [30] IF of end 2 shield/soil voltage on CLE  
   
  52.69  
   
  52.69  
   
  [31] Year of cable’s laying  
   
  1975  
   
  1975  
   
  [32] Estimated life expectation for the known cable, in years 23.00  
   
  23.00  
   
  By the construction of this situation, for the same knowledge base the lifetime value is signiﬁcantly inﬂuenced as in Table 4. Here only the signiﬁcant rows are presented.  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  41  
   
  Table 4. Test 2 – details of monitoring the right operating of the expert system. No  
   
  Parameter  
   
  ···  
   
  ···  
   
  Sample Reference ···  
   
  ···  
   
  [25] Mean cable load [A]  
   
  2,500  
   
  1,200  
   
  ···  
   
  ···  
   
  ···  
   
  [32] Estimated life expectation for the known cable, in years 12.69  
   
  ··· 23.00  
   
  The above two situations are part of the tests battery that was built to validate the achieved expert system. From this point of view, it is considered that the assessment succeeded. Regarding the information in Table 1 is to remember some details: i. The introduction of information on the analyzed cable involves both objective information, and entering the values of inﬂuence factors. ii. Information on all parameters of cable, inclusively of inﬂuence factors, may be partially in the sense that the expert system assigns defaults. In this way the system can cope with imprecise information. The existence of inﬂuence factors covers that knowledge of the expert that is doubtful through ignorance regarding the involved physic-chemical phenomena. Diﬀerent values of inﬂuence factors in Table 1 indicate that referred specimens of cables are coming from diﬀerent sources. There, the specialists who assessed them found that they could be the values that they are able to support them. The size of reference cable set is a guarantee of prediction quality. It is obvious that the predicted value is among the available knowledge pieces. Clearly the highlight of the weight to aﬀect each knowledge piece in the ﬁnal outcome is diﬃcult. By the nature of the tasks undertaken testing, the research that might be necessary will be avoided. Test 2 performed mainly based on information from Table 4, makes a check that covers both the theoretical used basis and how to implement a system expert. Construction of the test is based on the assumption that doubling the cable mean load should lead to a half of lifetime of the cable if other parameters are not changed. Tables 3 and 4 have the role of working tools. Together with Table 1 they form the testing technology of the expert system. The task of designing these documents devolve upon the project group. Despite many aspects of fundamental research, these documents are part of professional product documentation and once built the product, it must be sent to the end user. Testing will not be completed with technical reception of expert system. The testing must be repeated after a period of time agreed with beneﬁciary and must be extended to newly entered knowledge pieces whether they are analyzed cables whether they are the results of laboratory research or experimental results.  
   
  42  
   
  D. Isoc  
   
  It requires periodic statistical checking regarding the predictions and results conﬁrming the favorable results. Testing can be completed with achievement of graphics with intermediate possible values (Table 5). Table 5. Knowledge associated to power cables and manner to treat the information inside the expert system. No  
   
  Explanation about the information Name heading comments  
   
  Lower  
   
  Field to take the value Upper  
   
  [1]  
   
  Cable location  
   
  [2]  
   
  Cable type  
   
  Selector S1  
   
  [3]  
   
  Laying technology  
   
  Selector S2  
   
  [4]  
   
  Cable section [mm2 ]  
   
  10  
   
  500.00  
   
  [5]  
   
  Length of cable segment [m]  
   
  20  
   
  10, 000  
   
  [6]  
   
  Insulation resistance, [MΩ] − &5 kV  
   
  10  
   
  10  
   
  [7]  
   
  Shield/soil insulation resistance, [MΩ] − &5 kV  
   
  0.01  
   
  30  
   
  [8]  
   
  Shield electric continuity  
   
  [9]  
   
  Dielectric loss tangent (tgδ)  
   
  Selector S3 0.00005 Selector S3  
   
  1.00  
   
  [10] Soil resistivity [Ω m]  
   
  1.00  
   
  100.00  
   
  [11] Soil acidity (pH)  
   
  2.00  
   
  12.00  
   
  [12] Stray currents density [A/m2 ]  
   
  0.00  
   
  1.00  
   
  [13] Applied sleeves number  
   
  0  
   
  [14] Mean cable load [A]  
   
  5  
   
  Selector S4  
   
  30 3, 000  
   
  [15] End 1 shield/soil voltage [VCu/CuSO4 ] −1.00  
   
  0.50  
   
  [16] End 2 shield/soil voltage [VCu/CuSO4 ] −1.00  
   
  0.50  
   
  [17] Year of cable’s laying  
   
  1930  
   
  Selector S5  
   
  cy  
   
  [18] Estimated life expectation for the known cable, in years  
   
  0  
   
  Selector S6  
   
  50  
   
  On the one hand sub-screens of work parameters is used for inspection, maintenance and updating of the knowledge base. On the other hand, during the analysis, the same sub-screens will provide the ﬁnal result on the position of the predicted lifetime (Table 6). In Fig. 2 one gives the operating sub-screen. This is divided in three key areas. The ﬁrst area is the introduction of a new reference cable or advance under the existing cable base during maintenance. The other two areas correspond to the analysis commands for updating and maintaining the database of reference cables. The third area is for mandatory commands i.e. abandon of last activated command and exit command (Table 7).  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  43  
   
  Table 6. Deﬁning selectors of man-machine interface of the system expert. Description of interface selectors S1 - cable type selector Values to be selected: A2YSY, A2xS2Y, A2XSR2Y, A2XSRY-B Default state:  
   
  A2YSY  
   
  Notes:  
   
  Does’nt exist  
   
  S2 - laying technology selector Values to be selected: {Buried directly in soil, buried in protective coating} Default state:  
   
  Buried directly in soil  
   
  Notes:  
   
  Does’nt exist.  
   
  S3 - electric continuity of cable shield Values to be selected: {Yes, No} Default state:  
   
  Yes  
   
  Notes:  
   
  Does’nt exist.  
   
  S4 - selector of sleeves number Values to be selected: [0, 30] Default state:  
   
  0  
   
  Notes:  
   
  Does’nt exist.  
   
  S5 - cables laying year selector Values to be selected: 1930, 1931, 1932, · · · cy Default state:  
   
  (cy 5)  
   
  Notes:  
   
  With cy is denoted the current year.  
   
  S6 - selector of known operating time Values to be selected: {0, 1, 2, · · · 50} Default state:  
   
  5  
   
  Notes:  
   
  Selector is active only for the parameters updating stage  
   
  ElCabExpert  
   
  Expert system for power cables life prediction  
   
  Work parameter screen  
   
  Operating screen  
   
  Fig. 2. Organizing the board of expert system.  
   
  It is to emphasize that one takes into account that the two work commands regarding analyze and updating are not commands on the same hierarchical rank.  
   
  44  
   
  D. Isoc Table 7. Deﬁning man-machine interface commands of the system expert.  
   
  Command/description New job - Default command, active in initial state - Allows the acting of commands to set the work mode, that is Analysis for the mode of Power cable analysis, and respectively Updating for the work mode Cable basis updating and also of the general commands Abandon and Exit - Do not allow parameter ﬁelds ﬁlling with values until the activation - Allows repeated activation of command - Bring the system in the speciﬁc state of operating mode Cable analysis - Do not allow activating of speciﬁc commands of Activate prediction, and/or Cable saving and Catalog inspection Analysis - Default command, active in initial state - Deﬁnes the work mode Power cable analysis - Allows the activating of speciﬁc commands Activate prediction and of general commands Abandon and Exit - Do not allow the activating of speciﬁc commands of Cable base updating work mode namely Cable saving and Catalog inspection - Allows parameters entering for the analysis cable but do not allow the fulﬁll of the ﬁeld of known lifetime of the cable operating Estimated lifetime Updating - Default command, passive in initial state - Deﬁnes the work mode of Cable base updating - Allows the activating of speciﬁc commands Cable saving and Catalog inspection and of general commands Abandon and Exit - Do not allow the activating of speciﬁc command of Power cable analysis work mode namely Activate prediction - Allows parameters entering for the analysis cable, inclusively the fulﬁlling of the ﬁeld of known lifetime of the cable operating estimated lifetime Power cable analysis/Activate prediction - Default command, active in initial state - Can be activated only successfully activated of Power cable analysis/Validate command - Replaced the inference engine and displays the estimate lifetime in its ﬁeld Power cable analysis/Entering the parameter values /Abandon - Always asks for the acknowledgement to execution Do you want to abandon? (Yes/No) - Once conﬁrmed, the system passes to the state activated by Analysis Cable updating/Entering the parameter values/Abandon - Always asks for the acknowledgement to execution Do you want to abandon? (Yes/No) - Once conﬁrmed, the system passes to the state activated by Updating Exit - Always asks for the acknowledgement to execution Do you want to exit? (Yes/No) - Once conﬁrmed the operator quit the expert system without any saving  
   
  Expert System for Predictive Diagnosis (2) Implementing, Testing, Using  
   
  45  
   
  This means that these commands can not be accessed by the other person than having administrator authority. This speciﬁcity is resolved by the existence of an access password. By recognizing the password, the operator can access distinctly analysis command or analysis and the updating commands.  
   
  4  
   
  Testing and Using the Expert System  
   
  Testing an expert system is a necessity before it is placed in service. There is no single test technology. In the literature, which is recommended, in diﬀerent forms [1,3], is going through all routes leading from premises to conclusions. Such exhaustive testing is suitable for expert systems that work on a limited and predeﬁned knowledge base. In this case it is a diﬀerent kind of expert system. First, the knowledge base is not limited but it enriches by means of accumulated experience. Accumulation of knowledge can be done from the outside from accumulated experiences or by including situations already considered and solved. When tests an expert system it should keep in mind that behind the results are more knowledge together with the rules of use. Components of knowledge pieces are at least of a three categories: (a) numerical with direct assignment, (b) calculated based on predeﬁned account relationships and (c) other, basically logical. It is noteworthy that the component parts of knowledge pieces have not identical relations with the lifetime of the analyzed cable. This makes the testing technology still more complicated. It is noted that veriﬁcation test should be performed with a large number of cases, that reference cables and checking the components parts of knowledge to be ‘practiced’, that is to have many values.  
   
  5  
   
  Concluding Remarks  
   
  Once conceptually done, an expert system should be achieved as inference engine but also as human-machine interface. This interface comes to provide to users access to obtain right answers to questions. Achieved interface put together necessary functions and the facility of receiving information on the knowledge pieces that are then exploited. Since the users have diﬀerent authority one creates the user with access to all the information, i.e. including the rights to update the knowledge base, and an ordinary user who has access only to solve key issues that prediction lifetime of underground power cables. Such information is used in development projects of the power supply network. It is grounded and exempliﬁed the testing technology of achieved expert system.  
   
  46  
   
  D. Isoc  
   
  From the tests set that have been designed and implemented, in work are given two tests. The ﬁrst test is the reproduction of the identical case and the second is to obtain predictable solution based on the information that comes from the expert in problems of corrosion.  
   
  References 1. Balci, O., Smith, E., O’Keefe, R.: Validation of expert system performance. Technical report TR-86-37, Department of Computer Science, Virginia Polytechnic Institute and State University (1986). eprints.cs.vt.edu 2. Bobrow, D., Mittal, S., Steﬁk, M.: Expert systems: perils and promise. Commun. ACM 29(9), 880–894 (1986) 3. Chang, C., Stachowitz, R.: Testing expert systems. Technical report (1988). ntrs.nasa.gov 4. Heckerman, D., Horvitz, E., Nathwani, B.: Toward normative expert systems: the Pathﬁnder project. Methods Inf. Med. 31, 90–105 (1991) 5. Hoc, J.: From human-machine interaction to human-machine cooperation. Ergonomics 43(7), 833–843 (2000) 6. Hoﬀberg, S., Hoﬀberg-Borghesani, L.: Ergonomic man-machine interface incorporating adaptive pattern recongnition based control system. US Patent 6,418,424 (1999) 7. Jacob, J.: Using formal speciﬁcations in the design of a human-computer interface. Commun. ACM 26(4), 259–264 (1983) 8. Johannsen, G., Levis, A., Stassen, H.G.: Theoretical problems in man-machine systems and their experimental validation. Automatica 30(2), 217–231 (1994) 9. Myers, B.: A brief history of human-computer interaction technology. Interactions 4(2), 44–54 (1984) 10. Puerta, A., Egar, J., Tu, S., Musen, M.: A multiple-method knowledge-acquisition shell for the automatic generation of knowledge-acquisition tools. Knowl. Acquis. 4(2), 171–196 (1992)  
   
  GA Based Multi-stage Transmission Network Expansion Planning A. Simo, St. Kilyeni, and C. Barbulescu(&) Power Systems Department, Power Systems Analysis and Optimization Research Center, Politehnica University Timisoara, 2, Pta. Victoriei, Timisoara, Romania {attila.simo,stefan.kilyeni, constantin.barbulescu}@upt.ro  
   
  Abstract. The paper is focusing on dynamic transmission network expansion planning (DTNEP). The DTNEP problem has been approached from the retrospective and prospective point of view. To achieve this goal, the authors are developing two software tools in Matlab environment. Power flow computing is performed using conventional methods. Optimal power flow and network expansion are performed using artiﬁcial intelligence methods. Within this ﬁeld, two techniques have been tackled: particle swarm optimization (PSO) and genetic algorithms (GA). The case study refers to a real power system modeled on the Center, Northern, Eastern and Southern parts of the Romanian Power System. Keywords: Power transmission expansion  Software-tool  
   
    
   
  Power system planning  
   
    
   
  Dynamic  
   
  1 Introduction The dynamic transmission network expansion planning (DTNEP) is discussed within this paper, in retrospective and prospective manner. A set of network expansion candidates are proposed. The power flow is performed using conventional methods for all scenarios. The optimal power flow (OPF) is computed for the maximum expansion solution (including all the expansion scenarios) using particle swarm optimization (PSO) and genetic algorithms (GA). Having the optimal maximum expansion solution, the optimal expansion solution is computed also using PSO and GA. For all these purposes own software tools have been developed in Matlab environment. They are able to be linked with other well-known computer aided power system analysis software, importing the power system database. Two types of GAs are used within this paper. Binary coded GA for the expansion planning stage and real coded GA for the OPF. Dynamic programming represents an optimal solution selection methodology considering speciﬁc constraints, following a step-by-step decision process [1, 2]. Discrete dynamic programming with ﬁnite horizon is discussed within the current paper. Decisions are taken at speciﬁc time moments, following a ﬁnite number of computing steps. Currently, within the power engineering ﬁeld, the heuristic and meta-heuristic methods are widely used to solve optimization problems. In case of transmission network expansion planning (TNEP), they are used to generate possible solutions, © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_5  
   
  48  
   
  A. Simo et al.  
   
  evaluation and selection of candidates, until the algorithm is not able to ﬁnd a better solution. A reduced mathematical model is their main characteristic. The major drawback refers to the difﬁculties for tuning their parameters. A multi-stage approach of the problem under discussion is tackled in [3]. Authors are proposing a new constructive heuristic approach considering security-constrained TNEP. It is based on a local random search used to select the values of the control variables. It is applied for Ecuadorian and Chilean Power Systems. The major drawback refers to the use of a DC model. In [4] the TNEP is solved as a mixed integer nonlinear non-convex programming model. The optimization is performed based on the differential evolutionary algorithm (DEA). The use of AC load flow model is the great beneﬁt of the paper, providing realist and accurate results. The technique is tested on Garver’s 6 bus and IEEE 24 bus test system. GA based TNEP multi-stage solving is proposed in [5]. The GA is used in conjunction with the probabilistic optimization. The objective function refers to the investment costs, absorption of private investment and system reliability. The case study refers to the IEEE 24 buses test power system. The wind generation is taken into consideration. The TNEP problem influenced by the uncertainties related to wind power generation is also investigated in [6]. In this case the Cuckoo search algorithm is used as an optimization tool. As is stipulated in [7] the use of AC mathematical model has been proposed by only very few researchers. Its complexity is augmented if it is desired to be tackled in the smart grids context. The problem is solved considered the N−1 security criterion. DEA is used and tested on Garver’s 6 bus test power system. In [8] two sources of uncertainties are analyzed in conjunction with TNEP: intermittent renewable energy generation and loads. The objective function terms are represented by the investment and operating costs. The adaptive tabu search algorithm is applied. The AC load flow mathematical model is used and interior point non-linear programing. IEEE 79 buses RTS test system is used as case study. In [9] a comparison is performed between the use of energy storage and N-1 criterion in TNEP studies. The problem is statically approached considering energy storage model, within a system with base load generators and peaking power plants. Four TNEP models are proposed for comparative analysis and N-1 network security constraints. The problem is modeled as a mixed integer linear programming problem. IEEE 24 RTS test system is used as case study. A static TNEP mathematical model is proposed in [10]. DC power flow is used. The problem is solved with and without generated power rescheduling. Artiﬁcial bee colony is used as an optimization tool for small IEEE test systems. A long-term TNEP mathematical model is proposed in [11], based on balancing investment costs and reducing consumer costs. To achieve this goal a hierarchical framework is proposed, being sensitive to different agents operating on diverse timelines. An equilibrium model is introduced combining grid operating concerns with the short-term competitive behavior of generating units. According to [12] the use of robust optimization techniques is appreciated compared with stochastic mathematical programming methods in TNEP. Several uncertainties are considered (in order to obtain more realistic results). The mathematical  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  49  
   
  model is represented by three-level mixed-integer optimization problem, solved using different strategies. IEEE 24 and 118 buses test systems are used. The discrete PSO approach is used in [13] to solve the TNEP problem. Non-linear mixed optimization model is used with DC power flow. Case studies are represented by IEEE 6 and 24 buses test systems and 46 buses power Brazilian system. [14] deals with DTNEP. The time evolution of the network expansion is provided considering a large number of technical and economic constraints. Results are provided only in synthesis, referring to the power system of Vietnam. Following the introduction presented within the 1st section, the 2nd one refers to the DTNEP methodology. The 3rd section deals with TNEP solving using GAs. The developed software tools are briefly presented within the 4th section. The case study is tackled within the 5th section. The 6th one is focusing on results discussing. Finally, conclusions are synthesized within the 7th section.  
   
  2 Dynamic Network Expansion Planning The DTNEP is discussed for the following time steps: 2015 year– initial stage, 2020, 2025, 2030 – intermediary stages and 2035 – ﬁnal stage. The prospective approach (forward direction) and retrospective one (backward direction) has been considered. Two issues have to be solved: • consumed power forecast correlating the power generation capacity; • admissible solution domain deﬁnition – it contains the network elements’ list that are allowed to be part of the optimal solution for the ﬁnal stage (2035 year). According to the prospective analysis, the starting point refers to the 2015 year. In the following, the expansion solutions are computed step-by-step for the successive years: 2020, 2025, 2030 and 2035. The provided results for 2035 year represent the ﬁnal solution for the entire 20 years analyzed period. The admissible solutions’ domain has been considered to be the maximum expansion one extracting the network elements already introduced for each expansion stage. A static expansion planning solving is applied for each intermediary stage. The non-linear optimization problem is solved using evolutionary techniques: PSO and GA. According to the retrospective analysis, the starting point is represented by the maximum expansion solution, year 2035. In the following, the expansion solutions are computed step-by-step for the successive years: 2035, 2030, 2025 and 2020. The results obtained for 2035 year represents the ﬁnal solution. The comments provided at the prospective analysis for the admissible solution domain deﬁnition and static expansion solving at each intermediary stage are suitable for this case too. The use of both approaches offers the advantage of comparing the intermediary solutions (2020, 2025, 2030 years) and, especially, the ﬁnal one (2035 year). Mathematical model for transmission network expansion planning is presented. Two artiﬁcial intelligence solving techniques have been tackled: PSO and GA. The optimization problem has a multi-criteria character. The following components are included within the global objective function:  
   
  50  
   
  A. Simo et al.  
   
  The optimization problem has a multi-criteria character. The following components are included within the global objective function: • power system operating costs: OBF1 ¼  
   
  X  
   
  Ci ðPg i Þ þ  
   
  X  
   
  TPij ðSij  S ij Þ ¼ Minim  
   
  ð1Þ  
   
  ij2R  
   
  i2G  
   
  where: G – set of PV buses; R – set of network elements; Ci(Pgi) – quadratic cost characteristics of generators – Ci ðPgi Þ ¼ ai  P2gi þ bi  Pgi þ ci ; TPij – penalty cost of the apparent power upper limit exceed trough the ij network element; S ij is deﬁned  max Sij if Sij  Sij as S ; Sij – apparent power flow for ij network element; ij ¼ Smax if Sij [ Smax ij ij max Sij – Sij thermal limit; • investment equivalent yearly cost related to new power transmission capacities (overhead lines, autotransformers) – OBF2; • safety operation, quantiﬁed based on risk factor computing: n‘ P  
   
  OBF3 ¼ r % ¼  
   
  n‘ P  
   
  qk  r k  
   
  k¼1 n‘ P  
   
  ¼  
   
  k¼1  
   
  n  o   qk  Pkr  Skij  [ Smax ; ij 2 R ij n‘ P  
   
  qk  
   
  k¼1  
   
   100  
   
  ð2Þ  
   
  qk  
   
  k¼1  
   
  where: qk – k overhead line (OHL) disconnection probability; nl – overhead lines’ number that are selected for contingencies; Skij – Sij in case of k element disconnection; rk – congestion probability when k OHL is disconnected. • total available transmission capacity. OBF4 ¼ TATC ¼  
   
  X  
   
    
   
   ij 2 Lmax Sij \S ij  
   
    Sij  Smax Þ  ij  
   
  ð3Þ  
   
  The function that has to be minimized is represented by the sum of the suitable weighted four components previously discussed (wi – weighting coefﬁcients): OBF ¼ w1  OBF1 þ w2  OBF2 þ w3  OBF3 þ w4  OBF4  
   
  ð4Þ  
   
  3 Genetic Algorithm (GA) Based TNEP The population represents a set of possible solutions. Each chromosome contains binary digits (0, 1), representing the state for the network expansion candidates. Thus, for this stage we are dealing with binary coded GA.  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  51  
   
  The chromosome has d length, being able to be written as: xi ¼ fxi1 ; xi2 ; . . .; xid g;  
   
  i ¼ 1; 2;    ; nc  
   
  ð5Þ  
   
  Each chromosome is evaluated based on the OBF objective function. The computing process ﬁnishes if the solution is not able to be improved. The algorithm stages are the following ones: (a) chromosomes forming the population are randomly initialized with 0 and 1: x0i ¼ fx0i;1 ; x0i;2 ; . . .; x0i;d g;  
   
  i ¼ 1; 2;    ; np  
   
  ð6Þ  
   
  (b) GA based OPF is computed for the conﬁguration coded by each chromosome; (c) initial population is evaluated based on OBF value. The best chromosome is saved in x0elit : f ðx0elit Þ ¼ minfOBFðx0i Þg; i ¼ 1; 2; . . .; nc  
   
  ð7Þ  
   
  (d) for a speciﬁc t computing step (t = 0, 1, 2,…) the chromosomes forming the population subjected to recombination are selected; (e) npr ¼ v  nc =2 chromosome pairs that are subjected to crossover are formed and chromosome pairs that are going to be copied unaltered; (f) offspring are formed starting from the npr pairs subjected to crossover (in one point or in several points); (g) number of chromosome genes subjected to mutation is computed; (h) 1st chromosome belonging to the population obtained at previous step is replaced with the best of the old population: x1t þ 1 ¼ xtelit  
   
  ð8Þ  
   
  (i) OPF is computed for the conﬁgurations coded by each chromosome. Current population is evaluated based on OBF value. New xelit value is computed: þ1 f ðxtelit Þ ¼ minfFOBðxti þ 1 Þg;  
   
  i ¼ 1; 2; . . .; nc  
   
  ð9Þ  
   
  (j) if the OBF value is not able to be improved for a given number of steps, the computing process ﬁnishes. The operating condition corresponding to the last xelit value represents the optimal one. Contrary, computing step is increased with 1 and the algorithm is repeated starting with point c).  
   
  4 Software Tool Two software tools have been developed by the authors in Matlab environment based on PSO and GA approaches: Power OptPowerplanPSO and PowerOptPowerPlanGA. Each one has two modules linked through a graphical user interface:  
   
  52  
   
  A. Simo et al.  
   
  • 1st module – used for OPF (also is able to be used as a stand-alone module); • 2nd module – used for dynamic transmission network expansion planning. PowerOptPowerplanGA’s main window for the OPF module is presented in Fig. 1. Once the power system database has been loaded, the user is able to select the optimization type he desires by selecting the control variables. The lower part of the window allows the user to set the GA parameters: maximum computing steps, capping iterations, population size etc. The main window for the software tool 2nd module (expansion planning module) is presented in Fig. 2. The user has to set the parameters for the GA algorithm: selection type, recombination type etc.  
   
  Fig. 1. PowerOptPowerplanGA – OPF module main window  
   
  Fig. 2. PowerOptPowerplanGA – dynamic network expansion window  
   
  Computing-candidates tab allows the user to specify if for each of the power system conﬁgurations corresponding to different expansion candidates, OPF is computed or only power flow. Button labeled Number of expansion stage [years] allows the user to specify the desired number of expansion stages. The entire expansion planning time horizon is going to be divided into the speciﬁed number of years. The results are provided in several ways. They are exported in different ﬁle formats (according to the user’s desire), view on the display or graphically displayed. The 2nd software tool based on PSO is named PowerOptPowerPlanPSO. This one is not discussed within the paper.  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  53  
   
  5 Case Study The power system used as case study has been modeled based on the Center & Northern & Eastern & Southern parts of the Romanian Power System. The other parts (Western, South-Western and North-Western) have been eliminated. The one-line diagram is presented in Fig. 3 having the following characteristics: • number of buses – 110 (30 PV buses and 80 PQ buses); • number of network elements – 149 divided as: 105 overhead lines of 110, 220 and 400 kV, 44 (auto)transformers; • number of generating units – 30, 23 being real ones and 7 equivalent ones.  
   
  Fig. 3. Case study one-line diagram  
   
  54  
   
  A. Simo et al.  
   
  6 Results and Discussions The dynamic transmission network expansion planning is performed (retrospective and prospective approach). This process is step-by-step discussed within the following subsections. 6.1  
   
  Base Case – Year 2015  
   
  Base case has been computed using conventional methods. Bus voltages are ranging between 0.95 and 1.10 p.u. (110 kV, 220 kV), respectively 1 and 1.05 p.u. (400 kV). PV buses terminal voltage limits are set between 0.95 and 1.15 p.u. The total consumed power is Pc = 4172.8 MW, the real generated power Pg = 4289.7 MW and real power losses ΔP = 116.9 MW. 6.2  
   
  Maximum Expansion Solution – Year 2035  
   
  The transmission network expansion planning is discussed for a 20 years, based on the last year consumed power forecast. The 2035 year forecasted peak-evening-winter operating condition is characterized by total real consumed power of 7473 MW (in comparison with 4172.8 MW for the base case), respectively reactive power 2945 MVAr (compared with 1999.9 MVAr). For load fulﬁlment the following generating units have been introduced: • 330 MW units at 28061 (2), 28904 (2), 28021 (3) 28022 (2) buses; • 220 MW units at 28077 (2) bus; • wind farms injecting power in 28017 (600 MW), 28974 (200 MW), 28019 (160 MW) and 28080 (100 MW) buses. A number of 23 new transmission network elements (20 OHLs and 3 autotransformers) have been introduced (considered as candidates within the expansion list). Thus, the expansion scenario is the following one: • new 400 kV buses at 28040, 28062 and 28908; • 400/220 kV 400 MVA (auto)transformers in substations 28061–28062 (2 units) and 28907–28908; • new 400 kV OHL 28037–28040, 28040–28082, 28031–28908, 28908 – 28016; • 220 kV OHL upgraded to 400 kV: 28082–28950, 28950–28025, 28905–28906, 28906–28908; • 400 kV OHL additional circuit at 28016–28973, 28022–28024; • 220 kV OHL additional circuit at 28045–28061, 28061–28057, 28057–28055, 28087–28086 (2), 28086–28085, 28085–28084, 28084–28083, 28083–28078, 28078–28024. Using the software tool PowerOptPlanGA the optimal power flow – OPF has been computed for the maximum expansion solution. Real power losses are equal to ΔP = 191.8 MW, compared to 225.1 MW for the maximum expansion solution base case. Thus, about 15% decreasing has been recorded.  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  55  
   
  The GA algorithm evolution for OPF is presented in Fig. 4. The OBF individual best values are presented using blue colour for each computing step. The OBF average value for the entire population is represented using green colour. The OBF value, corresponding to the worst solution, is represented using red colour. An accentuated decrease of the OBF value is recorded during the 1st 50 computing steps. The solution is slightly improved for the next computing steps. Although we are dealing with a large scale power system, the number of the computing steps required for the solution computing is reduced. This fact proves the correctness of the GA parameters’ tuning.  
   
  Fig. 4. GA algorithm evolution for OPF computing  
   
  6.3  
   
  Optimal Expansion Solution  
   
  • Retrospective approach Before TNEP the load forecast for 20 years period (2015–2035) has been performed. The results are presented in Table 1. Table 1. Consumed power forecasting 2015 2020 2025 2030 2035  
   
  Pc total [MW] 4172.8 4827.2 5584.2 6459.9 7473.0  
   
  Qc total [MVAr] 1999.9 2203.1 2426.9 2673.4 2945.0  
   
  56  
   
  A. Simo et al.  
   
  The starting point is represented by the maximum expansion solution, year 2035 and the expansion solutions for all the stages: 2035, 2030, 2025 and 2020. The solution admissible domain for each dynamic expansion stage has been deﬁned based on the previous results. For DTNEP the PowerOptPowerPlanGA software tool has been used. The following elements have been found for the optimal expansion solution: • new 400 kV buses at 28040, 28062 and 28908; • 400/220 kV 400 MVA (auto)transformers in substations 28061–28062 (2 units) and 28907–28908; • new 400 kV OHL 28037–28040, 28040–28082 (alternative solution – double circuit 220 kV OHL), 28031–28908, 28908–28016; • 220 kV OHL upgraded to 400 kV: 28082–28950, 28950–28025; • 220 kV OHL additional circuit at 28061–28057, 28057–28055, 28087–28086 (2), 28086–28085, 28083–28078, 28078–28024 buses. The optimal expansion solution is characterized by 124 buses (41 PV buses, 83 PQ buses) and 176 network elements (118 OHL, 58 transformers, autotransformers). The relative OBF value (Fig. 5) has been computed being the ratio between the current expansion solution OBF and the one corresponding to the maximum expansion solution. The OBF value permanently improves during the algorithm evolution. This fact is explained due to the power system scale and increased number of transmission network expansion candidates. For the 1st three computing steps 17.5% OBF decreasing value is recorded and additionally 1.2% for the following ones. The dynamic retrospective transmission network expansion planning results are synthesized in Table 2.  
   
  Fig. 5. GA based OBF evolution  
   
  They are several quasi-optimal solutions, having close OBF values. As an alternative solution, the 28037–28040, 28040–28082 400 kV OHL’s are replaced by d.c. 220 kV OHL’s.  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  57  
   
  Table 2. Retrospective analysis results 2020 3 from 20  
   
  2025 7 from 20  
   
  2030 12 from 20  
   
  OHL – – – – – – – – 400 – – 400 – – 400 – 400 kV 28022–28024 400 400 kV 28082–28950 400 kV 28082–28950 400 400 kV 28082–28950 400 kV 28082–28950 400 220 kV 28057–28055 220 kV 28061–28057 220 – 220 kV 28057–28055 220 – 220 kV 28087–28086 220 – – – – 220 kV 28086–28085 220 – – 220 – – 220  
   
  kV kV kV kV kV kV kV kV kV  
   
  28031–28908 28908–28016 28016–28973 28022–28024 28082–28950 28082–28950 28061–28057 28057–28055 28087–28086  
   
  kV 28086–28085 kV 28083–28078 kV 28078–28024  
   
  2035 15 from 20 400 400 400 400 400 400 400 400 220 220 220 220 220 220 220  
   
  kV kV kV kV kV kV kV kV kV kV kV kV kV kV kV  
   
  28037–28040 28040–28082 28031–28908 28908–28016 28016–28973 28022–28024 28082–28950 28950–28025 28061–28057 28057–28055 28087–28086 28087–28086 28086–28085 28083–28078 28078–28024  
   
  • Prospective approach The starting point is represented by the initial situation corresponding to the 2015 year. Expansion solutions for each future stage are computed step-by-step (2020, 2025, 2030, 2035 years). Results obtained for 2035 year are representing the ﬁnal solutions for the 20 years’ analyzed period. The admissible solutions’ domain has been considered to be the one deﬁned by the maximum expansion solution, excluding the network elements already introduced at each stage of the prospective dynamic expansion. The dynamic prospective transmission network expansion planning results are synthesized in Table 3. 6.4  
   
  Comments on the Expansion Solution  
   
  Comparing the results gathered from both approaches the following conclusions are highlighted: • 2020 year solution is different for the two approaches, but it has very close OBF value. For the prospective approach the 28057–28055 and 28087–28086 220 kV OHLs have been considered as double circuit, resulting 5 new network elements (instead of 3 in the retrospective one); • a similar comment is suitable for 2025 year solution – the total number of new network elements is 8 in the prospective approach (7 in the retrospective one). The difference refers to the 28016–28973 220 kV OHL which has been considered already as double circuit (in the retrospective solution only in 2030);  
   
  58  
   
  A. Simo et al. Table 3. Prospective analysis results 2020 5 from 20  
   
  OHL – – – – – – 400 400 220 220 220 – – – –  
   
  kV kV kV kV kV  
   
  28082–28950 28082–28950 28057–28055 28057–28055 28087–28086  
   
  2025 8 from 20  
   
  2030 13 from 20  
   
  2035 15 from 20  
   
  – – – – 400 400 400 400 220 220 220 – 220 – –  
   
  – – 400 400 400 400 400 400 220 220 220 220 220 220 220  
   
  400 400 400 400 400 400 400 400 220 220 220 220 220 220 220  
   
  kV kV kV kV kV kV kV  
   
  28016v28973 28022–28024 28082–28950 28082–28950 28061–28057 28057–28055 28087–28086  
   
  kV 28086–28085  
   
  kV kV kV kV kV kV kV kV kV kV kV kV kV  
   
  28031–28908 28908–28016 28016–28973 28022–28024 28082–28950 28082–28950 28061–28057 28057–28055 28087–28086 28087–28086 28086–28085 28083–28078 28078–28024  
   
  kV kV kV kV kV kV kV kV kV kV kV kV kV kV kV  
   
  28037–28040 28040–28082 28031–28908 28908–28016 28016–28973 28022–28024 28082–28950 28950–28025 28061–28057 28057–28055 28087–28086 28087–28086 28086–28085 28083–28078 28078–28024  
   
  • for 2030 year solution the total number of new network elements is 13 in the prospective approach (instead of 12 in the retrospective one). The difference refers to the 28087–28086 220 kV OHL which has been considered already as double circuit (in the retrospective solution in 2035); • the ﬁnal expansion solution is the same for the both approaches, the intermediary stages being slightly different.  
   
  7 Conclusions The developed software tools are able to be used in case of large scale, complex transmission networks. They behave as hybrid software tool, the PSO and GA techniques being used for the OPF and network expansion stages. PSO and GA have been adapted to the power engineering ﬁeld. The prospective and retrospective dynamic expansion approaches are providing identical solutions (for the last year). For both cases other expansion solutions, additional to the optimal one, have been proposed. This information is helping the network planner to adopt the best planning scenario. However, some difference may appear during the intermediary stages (years). In case of the prospective approach, there are situations when the process is started from an initial solution less or more different from the retrospective approach. But, the ﬁnal results are the same. There are also situations when the solutions for the 1st and ﬁnal expansion stage (year) are the same, but intermediary ones (2025, 2030 years) are different.  
   
  GA Based Multi-stage Transmission Network Expansion Planning  
   
  59  
   
  References 1. Bellman, R.E., Dreyfus, E.S.: Applied Dynamic Programming. Princeton University Corporation, Princeton (1962) 2. Sniedovich, M.: Dynamic Programming. Marcel Dekker, Inc., New York City (1992) 3. Hinojosa, V.H., Galleguillos, N., Nuques, B.: A simulated rebounding algorithm applied to the multi-stage security-constrained transmission expansion planning in power systems. Electr. Power Energy Syst. 47, 168–180 (2013). Elsevier 4. Alhamrouni, A., Khairuddin, A., Khorasani, F., Salem, M.: Transmission expansion planning using AC-based differential evolution algorithm. IET Gener. Transm. Distrib. 10, 1637–1644 (2014) 5. Arabali, A., Ghofrani, M., Amoli, E.M., Fadali, M.S., Aghtaie, M.M.: A multi-objective transmission expansion planning framework in deregulated power systems with wind generation. IEEE Trans. Power Syst. 6, 1–8 (2014) 6. Taheri, S., Seyed-Shenava, S.J., Modiri-Delshad, M.: Transmission network expansion planning under wind farm uncertainties using Cuckoo search algorithm. In: Proceedings of the 3rd IET International Conference on Clean Energy and Technology (CEAT), 24–26 November, pp. 1–6 (2014) 7. Torres, S.P., de Araujo, R.A., Castro, C.A., Pissolato, J.: Security constrained transmission expansion planning for smart transmission grids based on the AC network model. In: IEEE PES Transmission and Distribution Conference and Exposition – Latin America (PES T&D-LA), 10–13 September, pp. 1–6 (2014) 8. Chatthaworn, R., Chaitusaney, S.: Improving method of robust transmission network expansion planning considering intermittent renewable energy generation and loads. IET Gener. Transm. Distrib. 13, 1621–1627 (2015) 9. Obio, E.B., Mutale, J.: A comparative analysis of energy storage and N−1 network security in transmission expansion planning. In: Proceedings of the IEEE 50th International Universities Power Engineering Conference (UPEC), 1–4 September, pp. 1–6 (2015) 10. Rathore, C., Roy, R.: Gbest-guided artiﬁcial bee colony algorithm based static transmission network expansion planning. In: Proceedings of the IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT), 5–7 March, pp. 1–6 (2015) 11. Tang, L., Ferris, M.C.: A hierarchical framework for long-term power planning models. IEEE Trans. Power Syst. 1, 46–56 (2015) 12. Mínguez, R., García-Bertrand, R.: Robust transmission network expansion planning in energy systems: improving computational performance. Eur. J. Oper. Res. 248, 21–32 (2015) 13. Barreto, W.E., Torres, S.P., Castro, C.A.: Study of particle swarm optimization variations applied to transmission expansion planning. In: Proceedings of the IEEE Powertech Conference, 16–20 June, pp. 1–6 (2013) 14. Le, A.D., Nguzen, M.H., Eghbal, M., Nguzen, D.H.: Transmission expansion planning in electricity market: the case in Vietnam. In: Proceedings of the IEEE Australasian Universities Power Engineering Conference (AUPEC), Hobart, Australia, 29 September– 03 December, pp. 1–6 (2013)  
   
  Epidemic Algorithm Based Optimal Power Flow in Electric Grids K. Muniyasamy1 , Seshadhri Srinivasan2(B) , S. Parthasarathy3 , B. Subathra4 , and Simona Dzitac5 1  
   
  Department of Electrical and Electronics Engineering, Kalasalingam University, Virudhunagar, India [email protected]  2 International Research Center, Kalasalingam University, Virudhunagar, India [email protected]  3 Department of Electrical and Electronics Engineering, KLN College of Engineering, Sivagangai, India sarathy [email protected]  4 Department of Instrumentation and Control Engineering, Kalasalingam University, Virudhunagar, India [email protected]  5 University of Oradea, Oradea, Romania [email protected]   
   
  Abstract. Time-triggering and distributed nature of the grid are emerging as the major challenge in managing energy in distribution grids. This investigation presents an event triggered distributed optimal power ﬂow (OPF) algorithm for energy grids. To generate the event triggers, we use the epidemic algorithm. The buses are classiﬁed into three: infected, susceptible, and dead. The network works in two modes: normal and optimization mode. In the normal mode, only event detection happens and when there are no event triggers, the system is said to be in normal mode. In optimization mode, event triggers that can be a change in generation or demand beyond a threshold value that necessitates the reoptimization of the network, the optimization mode begins. In this mode, the infected node which is infected by change in bus variable intimates it to the energy management application. The energy management application on sensing this change, will initiate the graph grammars which are a set of rules to change the bus nature by detecting the eﬀect of the change on the particular bus. The network is re-optimized using a DC OPF formulation as it is convex and can be solved using simple matrix inversion on the stationary conditions. As a result, the solution of DCOPF problem becomes that of solving a system of linear equations of the form Ax = b, which is solved using Krylov’s method or the Arnoldi algorithm in a distributed fashion. Each node solves the problem of its one-hop neighbours in parallel and this leads to a distributed implementation resulting signiﬁcant reduction in complexity. The propossed approach is illustrated on a simple 3 bus network. c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 6  
   
  Epidemic Algorithm Based Optimal Power Flow in Electric Grids  
   
  61  
   
  Nomenclature i, j θ B xij Dt Pt PGg g t C(PGg ) T λ G Km  
   
  1  
   
  indices of bus load angles admittance matrix reactance of line ij Vector of active demand at time t Vector of active power generation at time t Power generated by the generator g indices for generator time indices Generation cost of the generator g in dollars Set of all time Lagrange Multiplier set of all generators Krylov’s Space  
   
  Introduction  
   
  In many energy management systems (EMS), time-triggering is used for optimization (see, [1–5] and references therein). This leads to unnecessary computations as the grid re-optimizes even without change in grid conditions. The complexity is compounded by the distributed nature of the grid. Considering the ﬂuctuating nature of the demand and generation, and their distribution within the grid, event-triggering is more suitable as thresholds of change are detected and re-optimization of the EMS application is initiated. Moreover, some of these changes can be localized using a distributed optimization algorithm. This significantly reduces the complexity. Therefore, energy management applications that are event triggered and perform distributed optimization are very much required in modern energy grids integrated with renewable energy sources (RES) and energy storage systems (ESS) [6]. Optimal Power Flow (OPF) is a widely used tool for energy management and planning. The OPF problem computes the optimal generator dispatches considering the network parameters to optimize either the cost, line-losses, demand response, and many other objectives (see, [7–12]). There are various solution methods for OPF such as quadratic programming [13], semi-deﬁnite programming [14], sequential quadratic programming [15], linear programming [16], and nonlinear programming [22,27] to name a few. These approaches use a static optimization approach and do not consider time-variations of the demand or ﬂuctuating generation and are hence not suitable for modern grids. Dynamic OPF overcomes this problem as it solves a problem considering time as a running parameter [17]. However, still the dynamic OPF cannot deal with ﬂuctuations in demand and generation. To overcome this receding  
   
  62  
   
  K. Muniyasamy et al.  
   
  horizon approach or model predictive control for OPF problem has been studied. In [22,28], the ACOPF problem using forecast on renewable generation and demand has been solved using the receding horizon approach. The major drawback with these approaches is the time-triggering. The grid is re-optimized even when there is no signiﬁcant changes in grid conditions or optimized only after a certain change has occurred which is not useful aspect of the EMS. A modiﬁed scenario could be to initiate the optimization whenever there are signiﬁcant changes in the grid variables such as demand or generation. This will reduce frequent optimization and computation overhead resulting thereof. More recently, distributed approaches for solving the OPF problem based on Gradient descent [19], decomposition methods [21], alternating directional method of multipliers [18], and others have been studied. In principle these methods consider two types of network models: ACOPF and DCOPF. While ACOPF provides a comprehensive study on both transient and steady state behaviour including the voltage magnitudes, they are non-convex and non-linear requiring signiﬁcant computations for optimizing the grid. On the other hand, in many scenarios DCOPF which are an approximation of ACOPF problem behave reasonably well and are widely used in practice [20]. The main advantage of DCOPF is that it leads to a convex problem and its solution is relatively simple and unique compared to ACOPF. Moreover, as just a matrix inversion on the Karush-Kuhn Tucker (KKT) conditions or the stationary conditions of the DCOPF problem can provide the optimal power dispatches, they are widely preferred. This investigation addresses the two challenges discussed above timetriggering and distributed nature of the grid. It uses an event-triggered optimization and solves the DCOPF problem in a distributed manner. To generate the event triggers, it uses the epidemic programming widely studied for spreading information in distributed systems [23]. Then it solves the DCOPF problem in a distributed manner by formulating it as a set of linear equations and uses the Krylov’s method (i.e. Arnoldi’s algorithm) as the stationary conditions of the DCOPF problem lead to a positive deﬁnite matrix. The solution can be obtained fast using the Krylov’s method. The main contributions of the investigation are: • An epidemic algorithm based event triggering mechanism. • A self-assembly procedure using rules. • Distributed OPF implementation using Krylov’s method. The rest of the paper is organized as follows. Section 2 presents the problem formulation. The concept of autonomous gossiping is presented in Sect. 3. The Krylov’s method for performing distributed optimization is presented in Sect. 4. Section 5 presents a 3-bus case study.  
   
  Epidemic Algorithm Based Optimal Power Flow in Electric Grids  
   
  2  
   
  63  
   
  Problem Formulation  
   
  Consider the multi-period DCOPF problem widely studied in literature:   C (Pg ) t∈T pg ∈G  
   
  Pg  
   
  s.t.  
   
  (1) B.θt = Pt − Dt , Pgmin  
   
  ≤ Pg, t ≤  
   
  ∀t ∈ T  
   
  Pgmax  
   
  The line-ﬂow constraints and the ramp-up/down constraints of the generators are not considered in the formulation due to simplicity. One can verify that the variations can happen in the optimization problem only due to changes in real-power generations which may be due to renewable generation or changes in demand. The problem is usually solved periodically based using time as a reference parameter. However, performing time-triggered optimization requires the problem be solved repeatedly even when there is no update in the generation. This is generally not preferred. A more realistic scenario can be the event triggering i.e., on sensing there is a change in grid condition re-optimize the generator settings for reducing the operating cost. But again the problem has to be solved in a centralized fashion which increases the computation complexity. Signiﬁcant reduction can be obtained, if the problem is solved in a distributed fashion. Moreover, since the DCOPF problem is convex, the KKT conditions can provide the unique solution to the optimization problem. Further, the very nature of the network architecture i.e. the bus reactance from bus i to j, xij is equal to in magnitude to xji . Therefore, elements of the matrix that models the stationary conditions is symmetric. The problem is to study the design of a distributed DCOPF implementation that uses event triggering for optimizing the network operating cost. The formulation leads to the following pertinent questions: 1. How to generate the event triggers? 2. How to distribute the computation? 3. Can convergence and robustness of the distributed computation be guaranteed? The answers to the above questions will be considered in the rest of the paper.  
   
  3  
   
  Autonomous Gossiping  
   
  Autonomous gossiping algorithms such as the epidemic algorithms are emerging as a method for propagating information in distributed systems [24]. They have been applied to wide class of problems like replication of database systems [25], wireless sensor routing, and more recently also in electric networks [26]. They  
   
  64  
   
  K. Muniyasamy et al.  
   
  are seen as a robust and scalable means to disseminate information reliably on a distributed network the same way an epidemic will propagate through a set of individuals. The use of gossip-like distributed optimization algorithm for reactive power ﬂow control was investigated by Bolognani and Zampieri in [26]. The investigation considered its use in the reactive power ﬂow control problem of the microgrid. This investigation considers the use of the autonomous gossip algorithms for distributed optimal power ﬂow (DOPF). Each bus is considered one agent in the algorithm. The agents with the generators have a cost function that models the generation cost that is quadratic. Hence, for each generation node, the cost is given by C(PG g) = ag × (PGg )2 + bg × (PGg ) + cg  
   
  ∀g ∈ G  
   
  where ag , bg and cg are constants provided by the GenCo. We assume that an event occurs whenever there is a change in the generator or demand settings and the general optimization problem is less sensitive to changes below the threshold i in each agent. The threshold value can be determined from sensitivity analysis or by simple numerical iterations. In some instances, the values can be updated online as well. The algorithm works in two modes: normal and optimization. We assume that the optimal generator settings for the normal mode are obtained using a distributed OPF formulation and that the grid is functioning within thresholds. The normal mode monitors for the threshold  being breached in some node and sends triggers for re-optimization. As soon as the triggers are received, the algorithm enters the optimization mode, wherein the nodes are classiﬁed into three categories: infected, susceptible, and dead. The infected node is the one that has exceeded the threshold, whereas the susceptible can contract the infection, and the dead-node is not aﬀected directly by the infected node, or is not aﬀected at all. Three types of actions are deﬁned: push, pull, and push-pull. In the push action, the infected node tries to send information to its one-hop neighbours regarding the event. The susceptible nodes try to pull the information from the infected node on the magnitude of the violation. Then they inform the dead node of the violation and also pull an information from them about their current status. In order to promote autonomous gossiping, we deﬁne the rules in Table 1. The above table is used to create autonomous organization of the agents and they form a self-assembly. The agents status gets changed during each iteration of the algorithm until the threshold reaches below i in all the infected buses. The algorithm starts with the infected node pushing its information to its onehop neighbours during the ﬁrst iteration. The susceptible nodes receive this information and start re-optimizing triggers to their peers. The common variable is the load angle θi that models the diﬀerence between the load balance and also the line-limits. On sensing a variation in theta from the optimal value, the network is broken at the very node that experiences it, and various zones are formed. The coupling  
   
  Epidemic Algorithm Based Optimal Power Flow in Electric Grids  
   
  65  
   
  between the diﬀerent zones is the variable θi that is replicated. The self-assembly step will be used to send event trigger and the algorithm continues its execution until the convergence to optimal value. Table 1. Self-organizing rules for the nodes in DOPF  
   
  4 4.1  
   
  Node 1  
   
  Node 2  
   
  Infected  
   
  Susceptible Push  
   
  Action  
   
  Node 1: Infected, Node 2: Infected  
   
  Outcome  
   
  Infected  
   
  Susceptible Pull  
   
  Node 1: Infected, Node 2: Susceptible  
   
  Infected  
   
  Susceptible Push-pull Node 1: Infected, Node 2: Infected  
   
  Susceptible Infected  
   
  Pull  
   
  Node 1: Infected, Node 2: Infected  
   
  Susceptible Infected  
   
  Push  
   
  Node 1: Susceptible, Node 2: Infected  
   
  Susceptible Infected  
   
  Push-pull Node 1: Infected, Node 2: Infected  
   
  Infected  
   
  Dead  
   
  Push  
   
  Node 1: Infected, Node 2: Susceptible  
   
  Infected  
   
  Dead  
   
  Pull  
   
  Node 1: Infected, Node 2: Dead  
   
  Infected  
   
  Susceptible Push-pull Node 1: Infected, Node 2: Susceptible  
   
  Susceptible Dead  
   
  Pull  
   
  Node 1: Susceptible, Node 2: Dead  
   
  Susceptible Dead  
   
  Push  
   
  Node 1: Susceptible, Node 2: Susceptible  
   
  Susceptible Dead  
   
  Push-pull Node 1: Infected, Node 2: Susceptible  
   
  Krylov’s Method Based Distributed Optimization Langarangian of the DCOPF Problem  
   
  The Lagrangian of the DCOPF problem is given by L =  
   
  N   
   
  (ai × Pg2 + bi × Pg + ci ) + λi ((Bθ − Pi + Di ) + μ(θ1 − 0))  
   
  (2)  
   
  i=1  
   
  where θ1 is the reference bus. The optimal value of the DCOPF problem can be obtained from the KKT conditions: • First order necessary conditions  
   
  • Primal feasibility  
   
  ∂L =0 ∂Pg  
   
  (3)  
   
  ∂L =0 ∂θ  
   
  (4)  
   
  ∂L =0 ∂λi  
   
  (5)  
   
  66  
   
  K. Muniyasamy et al.  
   
  • Dual feasibility  
   
  λi ≥ 0  
   
  (6)  
   
  λi (Bθ − Pi + Di ) = 0  
   
  (7)  
   
  • Complimentary Slackness  
   
  The above conditions lead to a set of linear equations in the unknowns X = [Pg , θ, λ]. The problem can hence be represented as: M ×X =b  
   
  (8)  
   
  The above solution has 3 × n linear equations that need to be solved in a distributed fashion. The objective of this investigation is to have a distributed approach, which means the computation above has to be distributed between the diﬀerent nodes. To form the distributed updates, the infected and its one hop neighbours are considered, a reduced order linear equations of the one-hop neighbours is solved using the Krylov’s method. The idea is to construct a reduced space Km with a dimension m 0 are weighing matrices of appropriate dimensions, and QN ≥ 0 is the terminal weighing matrix. Proof: Deﬁne the cost-to-go function at time k as, Jk (xk ) =  
   
  min  
   
  uk ,...uN −1  
   
  N −1   
   
  ((xχ − rχ )T Q(xχ − rχ ) + uTχ Ruχ )  
   
  χ=k  
   
  + (xN − rN )T QN (xN − rN ) subject to relations (Eq.(5))  
   
  (12)  
   
  Note that Jk (xk ) gives the minimum cost-to-go starting from the state xk at time instant k. As Jk (xk ) is quadratic, the cost-to-go has the form (Eq. (13)) Jk (xk ) = xTk Pk xk + 2qk xk + rkT Qrk  
   
  (13)  
   
  where qk = −QT rk , and Pk = PkT ≥ 0 that can be found recursively using backward iteration algorithm by taking PN = QN .  
   
  86  
   
  S. Srinivasan et al.  
   
  Assuming that Jk+1 has the given form, from dynamic programming principle, suppose we know Jk+1 (xk+1 ) and look for optimal input uk the Bellman equation is given by (Eq. (14)) Jk (xk ) = min(xk − rk )T Q(xk − rk ) + uTk Ruk u  
   
  + Jk+1 (φxk + Γ0 uk + Γ1 uk−1 ) = (xk − rk )T Q(xk − rk ) + min(uTk R uk + (φxk + Γ0 uk + Γ1 uk−1 )T  
   
  (14)  
   
  u  
   
  Pk+1 (φxk + Γ0 uk + Γ1 uk−1 ) T (φxk + Γ0 uk + Γ1 uk−1 ) + 2qk+1  
   
  From the necessary conditions of optimality, we obtain Ruk + Γ0T Pk+1 [φxk + Γ0 uk + Γ1 uk−1 ] + Γ0T qk+1 = 0  
   
  (15)  
   
  Little manipulation of Eq. (15) leads to Eq. (9) with the adaptive gains given by Eq. (10).  Obviously, the computation of adaptive controller gains requires the knowledge of Pk+1 and the estimate of time-delay τk to compute Γ0 (τk ) and Γ1 (τk ). We compute Pk+1 recursively working backward from k = N by letting PN = QN , where QN is the terminal weighing matrix. The estimate of τk is obtained as described in Sect. 3. The Gains are computed from Eq. (10). Having obtained the results required for computing the gains, we now proceed to illustrate the controller by combining experiments with simulation.  
   
  5  
   
  Results and Discussions  
   
  This section presents the results obtained from experiments and simulations to illustrate the performance of the proposed adaptive controller. 5.1  
   
  Delay Estimation from Experiments  
   
  To estimate the time-varying delays, experimentation was conducted on Modbus over TCP/IP by connecting several controllers, and then loading the network (by increasing the number of inputs/outputs and number of rungs in PLC ladder diagram). Further, the length of the communication channel was varied by connecting controllers such as ABB AC 500 at diﬀerent locations. The prototype of the experiment is shown in Fig. 5 wherein there is a Master controller (also called the Modbus Master), and Slave controllers. The delays for variations of the parameters during experimentation is recorded both for training and validation phases of MRAN. During the network training phase the weights were adjusted to match the samples, whereas in the validation phase the delay estimates were compared with the estimates  
   
  Adaptive Controller for Networked Control Systems Subjected  
   
  87  
   
  Fig. 5. Experiment pilot for delay estimation  
   
  generated by MRAN. The ﬁrst 400 samples of delay data were used in learning, and the next 100 samples of data were used in validation of the estimates. After validation, in the test phase MRAN can be used to generate the delay estimates for designing the adaptive controller on-line. The number of hidden neurons in MRAN, delay samples from the network, estimated delays, and the error (diﬀerence between the actual and estimated network delay) are shown in Fig. 6. It was found that MRAN can estimate the delay with a maximum error of 2.2 ms, and an average error of less than 1 ms over 10 samples. 30  
   
  25  
   
  no. of neurons in hidden layer Actual and Estimated Output Error of Actual and Estimated Output  
   
  20  
   
  No of Nueurons Actual Output Estimated Output error  
   
  15 Training Data  
   
  Testing Data  
   
  10  
   
  5  
   
  0  
   
  −5  
   
  0  
   
  50  
   
  100  
   
  150  
   
  200  
   
  250 300 Sample points  
   
  350  
   
  400  
   
  450  
   
  500  
   
  Fig. 6. Combined plot: number of Hidden neuron, actual, estimated output and error  
   
  88  
   
  S. Srinivasan et al. 10 h=0.01 s delay=0.001 s  
   
  8  
   
  h=0.01 s delay=0.005s  
   
  x1(t)  
   
  6 4 2 0 −2  
   
  0  
   
  5  
   
  10  
   
  15  
   
  20  
   
  25 30 time in Secs  
   
  35  
   
  40  
   
  45  
   
  50  
   
  0  
   
  5  
   
  10  
   
  15  
   
  20  
   
  25 30 time in Secs  
   
  35  
   
  40  
   
  45  
   
  50  
   
  5 0  
   
  u  
   
  k  
   
  −5 −10 −15 −20  
   
  Fig. 7. Response of the system (Eq. (16)) to the proposed adaptive controller and fixed delays  
   
  5.2  
   
  Example 1  
   
  To illustrate MRAN-based adaptive controller, we consider the scalar example x(t) ˙ = 2x(t) + u(t)  
   
  (16)  
   
  with rk = 1 and initial condition x0 = 2 as in [12]. The poor performance of the static state feedback controller for this example has been illustrated by the authors of [14]. Our investigation uses a sampling time of 10 ms, and the estimated delay varies from 4 ms to 10 ms. Figures 7 and 8 show the response along with the control input uk with delays being changed at t = 25 s and delay varying at every 10 s using delay estimates from MRAN, respectively. This result illustrates that MRAN based controller adapts the gain to track the controller input even in the case of fast variations in delay. 5.3  
   
  Example 2  
   
  The investigation considers the double integrator system     01 0 x(t) ˙ = x(t) + u(t) 00 1   y(t) = 1 0 x(t)  
   
  (17)  
   
  to illustrate the eﬀectiveness of the proposed adaptive regulator. The continuoustime dynamics (Eq. (17)) is discretized with sampling period h under the assumption that τk ≤ h, resulting in Eq. (18)  
   
  Adaptive Controller for Networked Control Systems Subjected  
   
  89  
   
  10  
   
  x1(t)  
   
  5 0 −5  
   
  0  
   
  5  
   
  10  
   
  15  
   
  20  
   
  25 30 time in secs  
   
  35  
   
  40  
   
  45  
   
  50  
   
  0  
   
  5  
   
  10  
   
  15  
   
  20  
   
  25 30 time in secs  
   
  35  
   
  40  
   
  45  
   
  50  
   
  0  
   
  5  
   
  10  
   
  15  
   
  20  
   
  25 30 time in secs  
   
  35  
   
  40  
   
  45  
   
  50  
   
  9  
   
  τk  
   
  8 7 6 5  
   
  10  
   
  u  
   
  k  
   
  0 −10 −20  
   
  Fig. 8. Response of system (Eq. (16)) to the proposed adaptive controller and variable delays, estimated by MRAN  
   
     (h−τk )2 1h τ (h − 2 = xk + uk + k 01 τk h − τk   
   
  xk+1  
   
    
   
  τk 2 )  
   
  uk−1  
   
  (18)  
   
  The sampled-data representation of linear NCSs with total delay (at each sampling instant k) less than the sampling time, i.e. τk ≤ h, can be obtained using MATLAB routine NCSd developed by the authors of the paper, see [33]. Figure 9 shows the response of the system (Eq. 18) under the MRAN-based adaptive controller ((Eq. 5) using the constant reference signal rk = [0 0]T for each k. The Figure additionally shows the control values uk and the delay estimates from MRAN. The result shows the regulatory performance of the controller in the presence of delays. Variations in the gains Lx , Lr , and Lu with time-varying delays τk are shown in Fig. 10. The gains are adjusted according to channel delays τk to track the reference state, and these variations are reﬂected mostly in the gain Lu . The states of the double integrator system in Eq. (18) with the adaptive controller (Eq. (5)) and desired states rk = [1 0]T are shown in Fig. 11. This response illustrates the tracking performance of the adaptive controller. Variations in gain Lx , Lr , and Lu with time-varying delays τk are shown in Fig. 12.  
   
  90  
   
  S. Srinivasan et al.  
   
  0.02 x1(t)  
   
  0.01 0 −0.01  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  x (t) 2  
   
  0.1 0 −0.1  
   
  k  
   
  0.5  
   
  u  
   
  0 −0.5  
   
  τ  
   
  k  
   
  8 6 4  
   
  Fig. 9. States of the system and the control input with time-varying delay  
   
  x  
   
  L (k)  
   
  0 −0.5 −1 −1.5  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50 60 time in secs  
   
  70  
   
  80  
   
  90  
   
  100  
   
  Lr(k)  
   
  0 −1 −2  
   
  Lu(k)  
   
  0 −0.01 −0.02  
   
  τk  
   
  10 5 0  
   
  Fig. 10. Variation in gains Lx , Lr , and Lu with delays for regulatory performance  
   
  Adaptive Controller for Networked Control Systems Subjected  
   
  91  
   
  1.5  
   
  1  
   
  x (t)  
   
  1 0.5 0  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50 60 time in secs  
   
  70  
   
  80  
   
  90  
   
  100  
   
  x (t) 2  
   
  0.5 0 −0.5 2 uk  
   
  1 0 −1  
   
  τk  
   
  8 6 4  
   
  Fig. 11. States of the system and the control input for tracking the reference with time-varying delays (x0 = [0 0]T )  
   
  −0.5  
   
  x  
   
  L (k)  
   
  0  
   
  −1 −1.5  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50  
   
  60  
   
  70  
   
  80  
   
  90  
   
  100  
   
  0  
   
  10  
   
  20  
   
  30  
   
  40  
   
  50 60 time in secs  
   
  70  
   
  80  
   
  90  
   
  100  
   
  Lr(k)  
   
  0 −1 −2  
   
  Lu(k)  
   
  0 −0.01 −0.02  
   
  τk  
   
  8 6 4  
   
  Fig. 12. Variation in gains Lx ,Lr , and Lu with delay τ for tracking performance  
   
  92  
   
  6  
   
  S. Srinivasan et al.  
   
  Conclusion  
   
  In this investigation time varying delays in communication channels were modeled using MRAN, based on experiments conducted with Modbus over TCP/IP network. Information on network conditions such as loading, communication length, contention ratio, and number of connected nodes along with experimental delays was used to train the MRAN. Once trained using network conditions, MRAN generates delay estimates that were used to design adaptive controller for NCSs subjected to time-varying delays. MRAN-based estimation yields a learning based framework for estimating delays and, therefore, is more suitable for real-time control. The adaptive controller uses LQR approach to compute the gains and as a result, optimality is guaranteed by construction. Then, conditions for stability of the proposed controller were derived. The results were illustrated using two simple simulation examples along with delay estimates from MRAN. Results indicate that the adaptive controller modiﬁes its gain based on time-varying delays in communication channels to meet the performance requirements. Adaptive controller by addressing packet-loss and implementing the adaptive control in real-time industrial pilot are the future prospects of this investigation. Acknowledgments. This work was supported by European Union through European Regional Development Fund and the Estonian Research Council grant PUT481.  
   
  References 1. Hespanha, J.P., Naghshtabrizi, P., Xu, Y.: A survey of recent results in networked control systems. Proc. IEEE 95(1), 138 (2007) 2. Seshadhri, S.: Estimation and design methodologies for networked control systems with communication constraints. Ph.D. thesis, NIT-Trichy (2003) 3. Zhang, L., Gao, H., Kaynak, O.: Network-induced constraints in networked control systems survey. IEEE Trans. Ind. Inform. 9(1), 403–416 (2013) 4. Seshadhri, S., Ayyagari, R.: Platooning over packet-dropping links. Int. J. Veh. Auton. Syst. 9(1), 46–62 (2011) 5. Qu, F.-L., Guan, Z.-H., Li, T., Yuan, F.-S.: Stabilisation of wireless networked control systems with packet loss. IET Control Theory Appl. 6(15), 2362–2366 (2012) 6. Srinivasan, S., Buonopane, F., Vain, J., Ramaswamy, S.: Model checking response times in networked automation systems using jitter bounds. Comput. Ind. 74, 186–200 (2015) 7. Balasubramaniyan, S., Srinivasan, S., Buonopane, F., Subathra, B., Vain, J., Ramaswamy, S.: Design and verification of cyber-physical systems using truetime, evolutionary optimization and uppaal. Microprocess. Microsyst. 42, 37–48 (2016) 8. Tzes, A., Nikolakopoulos, G.: LQR-output feedback gain scheduling of mobile networked controlled systems. In: Proceedings of the 2004 American Control Conference, 2004, vol. 5, pp. 4325–4329. IEEE (2004) 9. Godoy, E.P., Porto, A.J., Inamasu, R.Y.: Sampling time adaptive control methodology for can-based networked control systems. In: 2010 9th IEEE/IAS International Conference on Industry Applications (INDUSCON), pp. 1–6. IEEE (2010)  
   
  Adaptive Controller for Networked Control Systems Subjected  
   
  93  
   
  10. Piltz, S., Bjorkbom, M., Eriksson, L.M., Koivo, H.N.: Step adaptive controller for networked MIMO control systems. In: 2010 International Conference on Networking, Sensing and Control (ICNSC), pp. 464–469. IEEE (2010) 11. Bj¨ orkbom, M., et al.: Wireless control system simulation and network adaptive control. Ph.D. Dissertation, Dept. of automation science and technology, School of Science and Technology 12. Voit, H., Annaswamy, A.: Adaptive control of a networked control system with hierarchical scheduling. In: American Control Conference (ACC), 2011, pp. 4189– 4194. IEEE (2011) 13. Marti, P., Yepez, J., Velasco, M., Villa, R., Fuertes, J.: Managing quality-of-control in network-based control systems by controller and message scheduling co-design. IEEE Trans. Ind. Electron. 51(6), 1159–1167 (2004). doi:10.1109/TIE.2004.837873 14. Loden, N.B., Hung, J.Y.: An adaptive PID controller for network based control systems. In: 31st Annual Conference of IEEE Industrial Electronics Society, 2005, IECON 2005, pp. 6–pp. IEEE (2005) 15. Tahoun, A., Hua-Jing, F.: Adaptive stabilization of networked control systems. J. Appl. Sci. 7(22), 3547–3551 (2007) 16. Chunmao, L., Jian, X.: Adaptive delay estimation and control of networked control systems. In: International Symposium on Communications and Information Technologies, 2006, ISCIT 2006, pp. 707–710. IEEE (2006) 17. Xu, H., Jagannathan, S., Lewis, F.L.: Stochastic optimal control of unknown linear networked control system in the presence of random delays and packet losses. Automatica 48(6), 1017–1030 (2012) 18. Watkins, C.J.C.H.: Learning from delayed rewards. Ph.D. thesis, University of Cambridge (1989) 19. Luck, R., Ray, A.: Delay compensation in integrated communication and control systems: part II-implementation and verification. In: American Control Conference, 1990, pp. 2051–2055. IEEE (1990) ¨ uner, U.: ¨ Closed-loop control of systems over a communications 20. Chan, H., Ozg¨ network with queues. Int. J. Control 62(3), 493–510 (1995) 21. Nilsson, J., et al.: Real-time control systems with delays. Ph.D. thesis, Lund Institute of Technology Lund, Sweden (1998) 22. Seshadhri, S., Ayyagari, R.: Dynamic controller for network control systems with random communication delay. Int. J. Syst. Control Commun. 3(2), 178–193 (2011) 23. Ghanaim, A., Frey, G.: Modeling and control of closed-loop networked PLCsystems. In: American Control Conference (ACC), 2011, pp. 502–508. IEEE (2011) 24. Srinivasan, S., Vallabhan, M., Ramaswamy, S., Kotta, U.: Adaptive LQR controller for networked control systems subjected to random communication delays. In: American Control Conference (ACC), 2013, pp. 783–787. IEEE (2013) 25. Srinivasan, S., Vallabhan, M., Ramaswamy, S., Kotta, U.: Adaptive regulator for networked control systems: Matlab and true time implementation. In: 2013 25th Chinese Control and Decision Conference (CCDC), pp. 2551–2555. IEEE (2013) 26. Vallabhan, M., Seshadhri, S., Ashok, S., Ramaswmay, S., Ayyagari, R.: An analytical framework for analysis and design of networked control systems with random delays and packet losses. In: Proceedings of the 25th Canadian Conference on Electrical and Computer Engineering (CCECE) (2012) 27. Lian, F.-L., Moyne, W., Tilbury, D.: Optimal controller design and evaluation for a class of networked control systems with distributed constant delays. In: Proceedings of the 2002 American Control Conference, 2002, vol. 4, pp. 3009–3014. IEEE (2002)  
   
  94  
   
  S. Srinivasan et al.  
   
  28. Yingwei, L., Sundararajan, N., Saratchandran, P.: Identification of time-varying nonlinear systems using minimal radial basis function neural networks. In: IEE Proceedings of the Control Theory and Applications, vol. 144, pp. 202–208. IET (1997) 29. Platt, J.: A resource-allocating network for function interpolation. Neural Comput. 3(2), 213–225 (1991) 30. Kadirkamanathan, V., Niranjan, M.: A function estimation approach to sequential learning with neural networks. Neural Comput. 5(6), 954–975 (1993) 31. Yingwei, L., Sundararajan, N., Saratchandran, P.: A sequential learning scheme for function approximation using minimal radial basis function neural networks. Neural Comput. 9(2), 461–478 (1997) 32. Yingwei, L., Sundararajan, N., Saratchandran, P.: Performance evaluation of a sequential minimal radial basis function (rbf) neural network learning algorithm. IEEE Trans. Neural Netw. 9(2), 308–318 (1998) 33. Seshadhri, S.: Sampled-data model for ncss with delay less than sampling time (2012). http://www.mathworks.com/matlabcentral/fileexchange/37875/. Accessed 21 July 2013  
   
  Aspects Regarding Risk Assessment of Human Body Exposure in Electric and Magnetic Fields Marius Lolea and Simona Dzitac(&) Department of Energy Engineering, University of Oradea, Oradea, Romania [email protected]  , [email protected]  Abstract. The paper gives an idea of attaching the risk of electromagnetic ﬁeld exposure in the general population and employees with potential health hazards that are related to the different sensitivity of the human body. The difference between the two categories of people, is that in the ﬁrst case, the intersection with the devices which generating electromagnetic ﬁeld is optional both in duration, number or distance, and in the second case this option is canceled due to duties of services that give the obligation of employees to stationed in areas with such types of devices. Even if there are thresholds exposure limit values for electric and magnetic ﬁeld quantities considered hazardous to health, referred to in legal settlements can not say with certainty that human sensitivity and is given the same thresholds for different age and sex categories. These ﬁt rather with probability theory. Therefore the work is appreciated and that the risk to health or human behaviors generated by electromagnetic ﬁeld exposure related to probability theory and treatment of this risk is therefore using a probabilistic model.  
   
  1 Introduction The multiple types of speciﬁc diseases of modern civilization and the large number of reported cases led to the idea of search for new cause increased risk of their generation. Among the causes were included and electromagnetic ﬁeld exposure. Fears are ampliﬁed by the existence of numerous electromagnetic devices that help to increase life comfort and technical progress. Epidemiological and laboratory studies, conducted at worldwide lavel have highlighted several problems attributed ﬁeld with different degrees of certainty. The results of these studies are controversial [5, 9, 11]. However, national rules limiting the exposure of persons, the maximum limit values are provided for parameters such as electric and magnetic ﬁeld and the exposure so that the effects are not harmful to health [6, 7]. The interplay between electromagnetic ﬁelds and living matter are very different and depend on the frequency of electromagnetic waves, the amplitude of characteristic parameters of the ﬁeld and proportion of energy transmitted to the body [5, 9–12]. Biological implications of exposure to magnetic ﬁelds against human body, is can study methodological with a cybernetic or an analytical method [5]. Cybernetic method consider the biological system as a black box characterized input quantities, output sizes and connections between them. Input values are given by electromagnetic ﬁeld parameters. Output sizes are effects on the living organism. Connections between the sizes of input and output are formed from interaction mechanisms which are obtained on experimental basis. The analytical method is based © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_9  
   
  96  
   
  M. Lolea and S. Dzitac  
   
  on mathematical modeling of biological systems. The phenomena that occur at the molecular level to the application of an electromagnetic ﬁeld are: electronic excitation, the polarization, the appearance of electrical forces, thermal effects, dipolar interactions, etc. Exist, circuit diagrams of the living cell developed and mathematical models to study the electromagnetic interaction at anatomic level [5]. In a few situations electromagnetic ﬁeld impact with human body it is a risk factor occupational diseases [4]. The purpose of the paper is to assess the level of human exposure through measurements values for the electromagnetic ﬁeld generated by electrical power networks equipments and risk of exceeding normal levels considered dangerous of these sizes. For this second case apply a probabilistic model [1–3].  
   
  2 Probabilistic Methods from Risks Assessment The risk associated with occurrence of a certain event comes down, in the simplest form, as the product of the probability of that event and the consequences of that event. For example, for a given level of risk desired, as the likelihood of an event decreases the potential consequences products may increase. All the events (states), through which a physical system during the experience is called ﬁeld events. By associating a ﬁeld event of an experiment may be obtained depth information on knowledge of the phenomenon studied [1, 3]. The probability transferred in quantitative and intuitive plan of numbers, a concrete situation pattern of events, allows some comparison of events. In this way, the probability is a measure of risk. The concepts of probability and probability ﬁnite ﬁeld can be presented as axiomatic form. By Kolmogorov, probability is deﬁned by the following axioms: • each event A 2 K, of the ﬁeld events K, is associated with a positive number P {A}, called the probability of the event; • P {E} = 1 is the probability of the event is safe and has a maximum value; • if two events A, B 2 K, are incompatible, then: {P} = P A [ B {A} + P {B}. The concepts of probability of appearance p, and non-appearance probability r of an event for which p + r = 1, allow to judge between safety and risk that there is a complementary relationship. On the basis of the axioms of Kolmogorov, it follows that R(p) + S(r) = 1, where R(p) is the probability of risk corresponding to an event, and S(r) - additional safety risk. The relation: R(p) + S(r) = 1 reveal that an increased risk involving a decrease of safety and a risk reduction involve an increases of the safety, the two sizes having values in the range [0, 1]. In the general case it can write: 0 < R(p) < 1 sau 0 < S(r) < 1, after which, in particular: If R(p) ! o, it can write S(r) ! 1 and inverse. If danger determines the risk, then the risk can be deﬁned as a measure of danger P (p) and its extent permitted limit value: R(p) = limn!1 PðnÞ ¼ P(p)  
   
  Aspects Regarding Risk Assessment of Human Body Exposure  
   
  97  
   
  For the particular case of the action of the electromagnetic ﬁeld on the human body either by direct coupling or by electromagnetic radiation, the danger is delimited by limit values standardized of ﬁeld quantities considered harmful. Thus, assessing the probability of exceeding the normal levels that are considered generating negative health effects, is a step in assessing risk from exposure. The risk here can be deﬁned as the product of probability of exceeding the exposure limit values for E and B and that the consequences of these exceedances, the latter being far damage human life or health. Following graphs below of normal distributions, we can estimate the risk from producing an unwanted event by leaving the chosen interval of signiﬁcance [8] (Fig. 1).  
   
  Level of significance 1-α  
   
  Level of significance 1-α  
   
  Risk α  
   
  Risk α/2  
   
  Risk α/2  
   
  Interval of significance  
   
  Interval of significance  
   
  θα/2  
   
  θα  
   
  θα/2  
   
  Fig. 1. The link between the meaning range and of probability: a - to a one-sided risk; b - for a bilateral risk (adapted from [8])  
   
  To a certain repartition function, meaning the connection between interval and level of signiﬁcance, it is given by relation: Pðh\ha Þ ¼ 1  a;  
   
  ð1Þ  
   
  for a unilateral risk, or by relation: P(h1a2 \h\ha2 Þ;  
   
  ð2Þ  
   
  For a bilateral risk, where: 1 − a is the level of signiﬁcance; ha − hb = interval of signiﬁcance; a – the risk. Assessed risk the consequences of exposure to electromagnetic ﬁeld is generated type as unilateral effects considered dangerous to humans is only upside quantities of electric and magnetic ﬁeld above their normal intake. A typical case of bilateral risk is generated by electromagnetic disturbances such as voltage fluctuations. Whether the voltage drops below a certain threshold, as in dips or rises above the maximum value that this service became Surge, risks in product supply electricity to consumers are double effect.  
   
  98  
   
  M. Lolea and S. Dzitac  
   
  3 Risk Assessment Generated to Humans Exposured in Electromagnetic Field Generated by Power Grids Assessing the risk of exceeding the permissible values for magnetic induction (B) and electric ﬁeld (E) is performed by comparing the density function of considered size distribution (f(B) and/or (E)) with the permissible limit value of these sizes set of regulations in the ﬁeld of workers’ exposure to electromagnetic ﬁelds and/or the general population [2, 3]. For calculations follow the next steps: (a) shall be taken from measurements the values of magnetic induction B and electric ﬁeld strength E at various locations; (b) is calculated for each location, the arithmetic mean and standard deviation of the values taken at the measuring points; (c) Considering that values have a normal distribution, determine the probability density function expression (f(B)/f(E)). The form of this function is [3]: 1 Mm 2 1 f(M) = pﬃﬃﬃﬃﬃﬃ  e  2 ð r Þ 2p  r  
   
  ð3Þ  
   
  where: m – the mean of measured values; r – standard deviation of measured values; M = ﬁeld sizes considered: {E, B}. Measured values of the magnetic induction and electric ﬁeld strength is considered that follow a normal distribution. Calculation was developed in Mathcad application, version 14.0. The calculation algorithm initiated by the authors has the following form: • Deﬁnes the Matrix of the maximum measurements of magnetic induction B and electric ﬁeld strength, E. It has the following tabular form for B, in the ﬁrst case: Measuring data  
   
  B1 1  
   
  2  
   
  1  
   
  11.4  
   
  2  
   
  12.6  
   
  3  
   
  13.5  
   
  4  
   
  ...  
   
  • Number of datasets from matrix B1: ! NCol := 1 The limit value for B: ! Blim := 100  
   
  3  
   
  Aspects Regarding Risk Assessment of Human Body Exposure  
   
  99  
   
  The computing vector, has the form:  
   
  The elements of the vector above are: DD1 = mean, DD2 = standard deviation, DD3 = the risk; No. of column inside matrix B1, k: ! k := 1   f(B): = dnorm B,ðDD1 Þk ; ðDD2 Þk ! Density distribution function, for B;   f1(B): = dnorm B; ðDD1 Þk ; ðDD2 Þk ðB [ BLim) ! Marks the risk;  
   
  • Drawing graph to distribution function, ﬁnally. The algorithm applies to workers of Hydropower plants(HPP) and for the general population. Through the activities undertaken and functional characteristics of the electricity networks they serve workers are exposed to electromagnetic ﬁelds generated by them. The electromagnetic environment is formed due to the operation of all sources of a given site or a particular territory. Therefore for each location we need to consider  
   
  100  
   
  M. Lolea and S. Dzitac  
   
  all sources of electromagnetic ﬁeld. Measuring devices used were: CA 42 Field meter and SPECTRAN 5035, both equipped with internal probes of magnetic ﬁeld and external for electric ﬁeld. Displaying values is in V/m for E and in lT for B. Measuring step is noted by dm and is chosen as equal to 2 m, to detect with high accuracy, the maximum values of quantities of electric and magnetic ﬁeld. With measured values will be calculated the averages, standard deviations and risk probability [1–3]. For the general population analyzes a portion of a high voltage overhead power lines (PL), which crosses the city of Oradea through a crowded area. In the case of power lines(PL) measurements have been performed under conductors, in line axis. Technical characteristics of the PL for the aperture considered, are: circuit type d.c., Un = 110 kV, connection between substations Oradea Sud – Oradea Vest, the portion of Auchan supermarket, on Radu Enescu street, type poles: STC, aperture lenght = 126 m, composite insulators, conductors type: OL-Al 185/32 mm2, gauges: cond.1 = 13.7 m, cond.2 = 13.4 m, cond.3 = 14.05 m, cond.4 = 13.17 m, cond.5 = 14.25 m, cond.6 = 13.76 m; number of measurements: 126/2 = 63 at measure step considered. On the HPP Tileagd case, is exempliﬁed with the values of magnetic induction B, taken around of the generators excitation, where operational staff have access, expressed in lT. In the case of generators the measurements were carried out on a circular path around them. Threshold values within normal limits, are [6, 7]: Elim = 5000 V/m for the general population, Elim = 10000 V/m for employees; Blim = 100 lT for the general population; Blim = 500 lT for employees. Allowable limit values were periodically adjusted by their decreasing, due to the fact that research into exposure domain have been perfected over time. Therefore, to consider the Gaussian variations of their, is appropriate. With considered ﬁxed limit values, Fig. 2 shows the risk graph for the aperture analyzed and in Fig. 3 shows the risk graph for operators from generators hall of HPP Tileagd, belonging to Bihor Power System. With blue color was marked risk area. 3×10  
   
  2.25×10  
   
  f (E) f1(E)  
   
  1.5×10  
   
  7.5×10  
   
  −4  
   
  8×10  
   
  −4  
   
  6×10 f (B)  
   
  −4  
   
  f1(B)  
   
  −5  
   
  4×10  
   
  2×10  
   
  0 0  
   
  2×10  
   
  3  
   
  4×10 E  
   
  3  
   
  6×10  
   
  3  
   
  8×10  
   
  3  
   
  −3  
   
  −3  
   
  −3  
   
  −3  
   
  0  
   
  0  
   
  87.5  
   
  175  
   
  262.5  
   
  350  
   
  B  
   
  Fig. 2. The graph of risk: a - with values of E for PL 1/110 kV, aperture 1; b - with values of B for considered case inside HPP Tileagd  
   
  Aspects Regarding Risk Assessment of Human Body Exposure  
   
  101  
   
  Fig. 3. Setting data for considered case in MathCad software  
   
  For evidence of common risk corresponding of the area under the intersection of the two curves are written equations corresponding to that point unknown p. For identiﬁcation of solution is necessary to equating the two equations. How the two points are at the same level on the chart at the intersection of the two curves density distribution, they must have the same coordinates so p1(x1, y1) = p2(x1, y1) and can write:   1 p  m1 2 1 for f(p1 Þ ¼ pﬃﬃﬃ  e 2 1 r1 2pr1  
   
  ð4Þ  
   
   2 1 12 p2  m2 for f(p2 Þ ¼ pﬃﬃﬃ e radm 2pradm  
   
  ð5Þ  
   
  For the case in which the standard deviations for the two sets of data, ranging to Gaussian distribution are equal, result: r1 ¼ radm ¼ r;  
   
  ð6Þ  
   
  and because the two points coincide on chart, namely p1 = p2 = p, by equalizing the two expressions follows:     1 1 1 p  m1 2 1 p  m2 2 pﬃﬃﬃ  e2 ¼ pﬃﬃﬃ  e2 r r 2pr 2pr  
   
  ð7Þ  
   
  102  
   
  M. Lolea and S. Dzitac  
   
  By logarithm, will get:   
   
  1 p  m1 2 1 p  m2 2 ¼ 2 2 r r  
   
  ð8Þ  
   
  And after simplifying and solving the resulting equation, the unknown being selected value will be calculated with the following expression: p=  
   
  m1 þ m2 ; 2  
   
  ð9Þ  
   
  then, in case of the means of the written program running in MathCad will get: p = 70.206, with m1 = 40.412 and m2 = 100. For the other calculation hypotheses, in which radm ¼ 12 r and radm ¼ 14 r resulting the equalities: 1 1 pm1 2 1 1 For case 2 : pﬃﬃﬃ  e2ð r Þ ¼ pﬃﬃﬃ r  e2 2pr 2p  2 1 1 pm1 2 1 1 For case 3 : pﬃﬃﬃ  e2ð r Þ ¼ pﬃﬃﬃ r  e2 2pr 2p  4  
   
  pm 2 2 r=2  
   
  pm 2 2 r=4  
   
  ð10Þ  
   
  ð11Þ  
   
  Which have the next solutions: For Eq. (10):  
   
  p1;2 ¼  
   
  4m2  m1  2  
   
  qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 4ðm1  m2 Þ2 þ 6rln2 3  
   
  ð12Þ  
   
  and in case of Eq. (11):  
   
  p1;2 ¼  
   
  qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 16m2  m1  2 16ðm1  m2 Þ2 þ 30r2 ln4 15  
   
  ð13Þ  
   
  To generate common area beneath the two curves, the left and right of the point of intersection called risk area, perform the necessary settings in Mathcad. These are indicated in Fig. 3. In Fig. 4 is shown in green color, the resulting risk in case the two standard deviations are equal. In case of the measured magnetic flux density values exempliﬁed for synchronous generators hall of o HPP Tileagd, they were chosen radial directions for further circular and concentric routes around excitation systems. Since the operators do not have to stand throughout the service duration near excitation systems, the acceptable value exposure to magnetic induction is considered the value of Blim = 100 lT. In Figs. 5 and 6, r, r2 and r3, are the standard deviations for another two considered cases.  
   
  Aspects Regarding Risk Assessment of Human Body Exposure  
   
  103  
   
  p 70.206 Fig. 4. Risk graph in the second case considered  
   
  case 2 σ,σ2  
   
  m1  
   
  m2 Risk zone  
   
  Fig. 5. The distribution of magnetic induction admissible with standard deviation in portion of 0.25% from r of a real values measured  
   
  case 3 σ,σ3  
   
  m3  
   
  Risk zone  
   
  Fig. 6. The distribution of magnetic induction admissible with standard deviation in portion of 0.50% from r of a real values measured  
   
  104  
   
  M. Lolea and S. Dzitac  
   
  Algorithms presented in the paper, apply for other power plants in Bihor County. Algorithms presented in the paper, apply for other power plants in Bihor County. For the ﬁrst scenario considered when considered dangerous occupational exposure limit values are considered ﬁxed, calculated parameters are summarized in Tables 1 and 2. Probability of exceeding the admissible limits, allows ranking of these facilities in terms of the risk from exposure to the population and employees in the energy sector. This is shown in Fig. 7.  
   
  Table 1. Calculated parameters values for B, in case of HPP Crt. No. 1 2 3 4 5 6  
   
  Objective of the measurements HG hall -HPP Fughiu HG hall HPPSăcădat HG hall - HPP Tileagd HG hall - HPP Lugașu HG hall - HPP Munteni HG hallo – HPP Remeți  
   
  Measurements number 246  
   
  Mean (M) 22.5  
   
  Standard deviation (r) 0.094554  
   
  Overtaking probability (risk/Pr) 0.047421  
   
  256  
   
  37.5  
   
  0.128673  
   
  0.023425  
   
  560  
   
  25.7  
   
  0.137553  
   
  0.039424  
   
  580  
   
  35.8  
   
  0.154553  
   
  0.023423  
   
  380  
   
  22.1  
   
  0.188553  
   
  0.015976  
   
  380  
   
  28.3  
   
  0.174553  
   
  0.024436  
   
  Table 2. Calculated parameters values for E, in case of PL Crt. No. 1 2 3 4 5 6  
   
  Objective of the measurements PL 1 PL 2 PL 3 PL 4 PL 5 PL 6  
   
  Measurements number 1246 1756 2560 2180 980 1380  
   
  Mean (M) 22.5 37.5 25.7 35.8 22.1 28.3  
   
  Standard deviation (r) 0.134554 0.124673 0.134553 0.184553 0.184553 0.154553  
   
  Overtaking probability (risk/Pr) 0.037421 0.057423 0.038424 0.033423 0.046475 0.033436  
   
  Figure 7 shows the ranking of categories of people according to risk exposure caused by the electric and magnetic ﬁeld in the two objectives analyzed.  
   
  Aspects Regarding Risk Assessment of Human Body Exposure  
   
  105  
   
  0.06 HPP 6  
   
  PL 3  
   
  0.04  
   
  HPP 3  
   
  PL 5  
   
  0.02  
   
  HPP 1  
   
  PL 2  
   
  0.00 PL ranking  
   
  HPP ranking  
   
  Fig. 7. The Graph of risk for exposure in electric ﬁeld. PL and HPP ranking  
   
  4 Conclusions In the context of scientiﬁc uncertainty regarding the effects of exposure to electromagnetic ﬁelds advisable to adopt the precautionary approach by implementing administrative measures, inform and train the population, especially those at risk of exposure sources and not least support from decision makers, on the development of an adequate logistics structure from monitoring electromagnetic ﬁelds and their effects in the long term. The calculation model which is adopted, not give information about risk consequences but, based on the distribution of the measured values enable the assessment of the likelihood of exceeding the normal threshold for electric ﬁeld intensity electric and magnetic ﬁeld induction on exposure to electromagnetic ﬁeld of workers from the power system or the general population. Exposure Risk assessment is done by comparing the results of calculation of probability values exceeded the normal values of ﬁeld sizes for all staff categories analyzed. Standard deviations and default the dispersions of measured values, are more pronounced where the measuring points were distributed over large areas with a great variety of equipment and devices that work with large differences between voltages and currents service. However, if one considers that there are sensitivities and different reactions bodies in terms of exposure to electromagnetic ﬁeld as suggested in the literature, along with the assumption accepted the job as the limit values allowable quantities Field pursue distribution normal, then the risk of negative effects on the human body increases. This is evident because the overlap of the two distributions is more pronounced in the lower levels of the two categories of values, measured and admissible. Then probabilistic model adopted is justiﬁed especially if it is found that the values of magnetic induction and electric ﬁeld strength, results of measurements, follow a normal distribution.  
   
  106  
   
  M. Lolea and S. Dzitac  
   
  References 1. Felea, I., Coroiu, N., Stoica, I., Dubău, C.: Evaluarea unor elemente de risc pentru personalul de exploatare al rețelelor electrice. Analele Universității din Oradea, fascicula de energetic, vol. I, pp. 37–50. Secțiunea II/Electroenergetică (2001) 2. Felea, I., Secui, C., Muşet, A.: Evaluation of risk affecting the exposed human organism in operational electromagnetic ﬁeld. In: The 6th International workshop of Electromagnetic Compatibility CEM, Constanţa, Romania, 12–14 November 2009 3. Felea, I.,Coroiu, N., Secui, C.: Asupra riscului de expunere în câmp electromagnetic. Simpozionul Național Siguranța în funcționare a Sistemului Energetic SIG, SC Electrica Deva, 26–28 September, vol II, pp. 402–410 (2001) 4. Virginia, M.: Câmpuri electromagnetice de joasă frecvenţă factori de risc profesional, Rev. Acta Medica Transilvania, II(1), 27–30 (2011) 5. Mihaela, M.: Bioelectromagnetism, Editura Matrix Rom, București (1999) 6. Guvernul României, Hotarârea Nr. 1136 din 30.08.2006 privind cerintele minime de securitate si sanatate referitoare la expunerea lucratorilor la riscuri generate de câmpuri electromagnetice 7. Guvernul României, Hotarârea Nr. 1193 din 29.09.2006 privind limitarea expunerii populatiei generale la câmpuri electromagnetice de la 0 la 300 GHz 8. Munteanu, T., Gurguiatu, G., Bălănuţă, C.: Fiabilitate şi Calitate în Inginerie electrică. Aplicaţii (ed.) Galati University Press (2009). ISBN 978-606-8008-25-7 9. Milham, S.: Dirty Electricity, Electriﬁcation and the Diseases of Civilization. Universe Star, New York (2012). ISBN 13:9781938908187, ISBN 10:193890818X 10. Aliyu, O., Maina, I., Ali, H.: Analysis of electromagnetic ﬁeld pollution due to high voltage transmission lines. J. Energy Technol. Policy 2(7), 1–10 (2012). ISSN 2224-3232 (paper), ISSN 2225-0573 (online) 11. Otto, M., Muhlendahl, K.E.: Electromagnetic ﬁelds (EMF): do they play a role in children’s environmental health (CEH)? Int. J. Hyg. Environ. Health 210, 635–644 (2007). www. elseiver.de/ijheh 12. Hardell, L., Sage, C.: Biological effects from electromagnetic ﬁeld exposure and public exposure standards. Biomed. Pharmacother. Rev. (2), 104–109 (2008). www.elseiver.com/ locate/biopha  
   
  A Communication Viewpoints of Distributed Energy Resource Ravish Kumar1 , Seshadhri Srinivasan2(B) , G. Indumathi3 , and Simona Dzitac4 1  
   
  2  
   
  ABB Corporate Research, Bangalore, India [email protected]  International Research Center, Kalasalingam University, Virudhunagar, India [email protected]  3 Cambridge Institute of Technology, Bangalore, India [email protected]  4 Universtatea Din Oradea, Oradea, Romania [email protected]   
   
  Abstract. Smart Grid provides a ﬂexible and powerful framework to integrate Distributed Energy Resources (DER). DER consisting of energy sources (such as renewable, conventional, storage) and loads. Based on application, there can be diﬀerent modes of operating. It can operate in parallel with, or independently from, the main grid. Because of social, economic, and environmental beneﬁts, the demands of DER system is increasing gradually. Combination of DERs and Loads with control units forms a miniature grid which is known as Microgrid. Integrating of DERs to the Microgrid system has two aspects: electrical and communication. Electrical integration has their own challenges which are addressed in IEEE 1547 standard. However, challenges related to communication and information integration of multi vendor DERs system is still open. Currently, IEC 61850-7-420 is the only standard which deﬁnes information model for DERs, but it is not completely accepted by DER manufacturers. On the other side, IEC 61850 mapped communication protocols like MMS, GOSSE, DNP3 etc. are substation protocols and may not suitable to fulﬁll DERs to DERs communication demands. In this paper, we provide an overview of Smart Grid conceptual framework and highlight DER scope. We discuss DER system components, various applications and required communication features. We review IEC 61850 mapped communication protocol MMS and identify the limitation for using in DERs communication.  
   
  1  
   
  Introduction  
   
  The traditional electrical grid is an interconnected network for delivering electricity from suppliers to consumers. It consists of generating stations that produces electrical power, high-voltage transmission lines that carry power from distant sources to demand centers, and distribution lines that connect individual customers. The growing demand of electricity led to increase numbers of electrical c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 10  
   
  108  
   
  R. Kumar et al.  
   
  grids deployment located at diﬀerent geographical location. The electrical grid is a broadcast grid networks, where a few central power generator provides all the electricity production to the industrial and residential customer via a large network of cables and transformers. Electrical grid structure can summarized as follows: one-way energy ﬂow from central station generators, over a transmission network, through substations onto distribution systems, over radial distribution circuits to end-use customers. To address the increasing energy demands, the traditional electrical grids being enhanced by adding more bulk generators to produce more energy. Bulk generators mostly use fossils fuels for power generation. On this earth, there are limited fossils fuels. Rapid consumption of limited natural resources must be avoided for future sustainable energy generation. To meet the future demands of electricity it is being focused to shift traditional grid generating power from fossils fuels to renewable resources [1]. The renewable resources are solar, wind, small hydro, tidal, biogas etc. The future of electric grid is Smart Grid (SG) [1]. The objective of SG is to improve energy eﬃciency and reduce carbon footprint at all the stages of energy ﬂow: Bulk Generation, Transmission, Distribution and Consumption. SG vision is to provide an open framework and protocol for information and power exchange seamlessly. Unlike traditional electric grid, which is centralized grid, the SG is decentralized grid. It allows to integrate power sources at distribution level. The end consumer can be Prosumers, which acts as electricity consumer and producers at the same time. Prosumer have their own small Distributed Energy Resources (DERs) for electricity generation. Based on local usage, the additional generated power can be supply to utility grid. Presently, most of the prosumers have limitation, they can not supply surplus power to utility grid because of insuﬃcient electrical and communication infrastructure [2]. The surplus overproduced electricity is just thrown away, if prosumer’s energy storage are full. Lack of infrastructure support causes waste of energy. The beneﬁts of the DER integration in smart grids has been discussed in [12–15]. Because of social, economical and environment beneﬁts, DER technology is evolving, new DER systems are getting deployed across the globe. However, research are still lacking for providing standard communication interface for DERs [3] system. Real time information exchange is very crucial to ensure reliable power supply. Presently, most of the DER system communicates with other system either on proprietary protocols or basic protocols like Modbus. There is no standard communication protocol and interface are recommended for DER system by International Standard organization. DER system is considered as an alternative of main power grid. New applications are developed to connect with DER system to enable new features. Lack of standard interfaces and protocols limitation to provide interoperable among diﬀerent manufacture devices and system. International standard IEC 61850 [4] is known and worldwide accepted standard for Substation Automation. It decouples the application data model from communication protocols and provide ﬂexibility for extending this standard for any application. Because of this ﬂexibility, addition of new domain is always  
   
  A Communication Viewpoints of Distributed Energy Resource  
   
  109  
   
  possible with IEC 61850. It is also being consider as a prime mover of SG framework. Since, it brings ﬂexible and open framework for monitor, control, and measurement applications. The IEC 61850 7-420 [5] standard deﬁnes information model for DER, that describe what information and semantics to exchange with other DER system. DER communication with existing IEC 61850 mapped protocols such as MMS, DNP3, GOOSE can be implemented. However, from DER functionality point of view, many of the communication needs may not be fulﬁlled by these protocols. For example, auto device registration and plug and play, session less communication among DERs, etc. Authors in [11] investigated the role of OPC UA and IEC 61850 integration for enabling smart grids and demonstrated how OPC UA can provide communication medium for smart grid elements. Interoperability is the key aspects DER system. One DER system must be interoperable with other DER system. Interoperability is an ability of two systems to communicate and share information with each other. The communication aspect of devices can be divided into four aspects [5]: Information modeling (the type of data to be exchanged-nouns), Service modeling (the read, write, or other actions to take on data-verbs), Communication protocols (mapping the noun and verb models to actual bits and bytes), and telecommunication media (ﬁber optics, radio system, wire, and other equipment). Currently, IEC 618507-420 is the only standard which deﬁnes information model and data model for DER system. However, the existing IEC 61850 mapped protocol seems not to be suitable for DERs communication. Most of the DER system vendors does not support IEC 61850 communication protocols in the DER system. They use their proprietary for simplicity and ease of development. Manufacturers of DER system would like to continue DER communication with their proprietary protocols. As we mentioned earlier, IEC 61850 standard is designed for Substation Automation, where system conﬁgurations is static and preconﬁgured. Therefore, existing IEC 61850 protocols may not be suitable for DER system communication. Yoo et al. [6] has shown IEC 61850 communication architecture based Microgrid communication and only considered static DER system conﬁguration. Suˇci´c et al. [7] highlighted the IEC 61850 communication protocol limitations for DER system and suggested Service Oriented Architecture for DER system. In this paper, we discuss an overview of Smart Grid and DER. Further, we discuss diﬀerent applications of DER system and provide the required communication viewpoints. The rest of the paper is organize as follows. Section 2 provide an brief overview of Smart Grid Architectural Model Framework and discuss diﬀerent domains and zones. In Sect. 3, we discuss the Distributed Energy Resources system, its application, and communication architecture. Section 4, we have evaluated IEC 61850 communication protocols for DER communication. Section 4 discuss challenges for implementing IEC 61850 communication protocols in DER system. And, in Sect. 5 conclude the whole paper.  
   
  110  
   
  2  
   
  R. Kumar et al.  
   
  Smart Grid Conceptual Framework  
   
  Smart Grid (SG) is a combination of diﬀerent technologies and can be seen as complex system. The key enabler of SG framework is an open communication and integration framework, which allows bidirectional information and electricity ﬂow. Figure 1 shows a conceptual Smart Grid Architecture Model(SGAM) proposed by National Institute of Standard and Technology [1].  
   
  Fig. 1. SGAM conceptual framework model [1]  
   
  SGAM framework consists of Business layer, Function layer, Information layer, Communication layer, and Component layer. An interoperability aspect must be satisﬁed among the layer for successful Smart Grid operation. The Smart Grid system is divided into two aspects Electrical process and Information management. In the SGAM framework, domains represent electrical process and Zones represent the information management. Domains physically related to the electrical grid components: Bulk Generation, Transmission, Distribution, Distributed Energy Resources (DERs), and Customer premises. It is arranged according to the electrical energy conversion ﬂow. Zones are related to power system management. Zone reﬂects the hierarchical level based on aggregation and functions separation of each hierarchical level. DER is considered as basic building block for Smart Grid system. Since, it provides ancillary distributed energy resources at distribution level, close of end consumers. The importance of DER are being recognized due to its social, economic, and environmental beneﬁts. Growing number of DER demand is estimated to reach USD 34.94 Billion by 2022, at a CAGR of 10.9% between 2016 and 2022 [8].  
   
  A Communication Viewpoints of Distributed Energy Resource  
   
  3  
   
  111  
   
  An Overview of Distributed Energy Resources System  
   
  DER plan is consisting of diﬀerent energy sources (e.g. renewable, conventional, storage) and loads. It is capable of operating in parallel with, or independently from, the main grid. DER system is more than back-up power source. Figure 2 shows an example of DER system.  
   
  Fig. 2. Distributed Energy Resources system example  
   
  DER plant operates in two modes: Grid Connected (grid mode) and Grid Isolated (islanding mode). In the grid mode, DER plan is connected to utility grid Common Coupling Point (CCP). It is being controlled based on utility grid power supply and cost factor behavior. For example, if DER is generating energy using renewable sources, then the load will use energy from and optimize the utility grid power in order to save overall cost. While in the case of islanding mode, DER is not connected to utility grid. It acts to remote power sources. Load is completely relied on DER. Based on the condition the transition takes place between, grid to islanding mode, and islanding to grid mode. The fundamental operational requirements of DER plant to provide stability of frequency and voltage for ensuring optimal power ﬂow to the load. Grid to islanding mode requires transition and stabilization for minimal load shedding and distribution. Islanding to grid mode requires resynchronization and minimum impact for sensitive loads during transient periods. Each of these operations are highly dependent on underlying communication infrastructure. The growing demand of DER system increased the complexity of multivendor DER elements interconnection, since most of the DER plant vendors use their own proprietary communication protocols.  
   
  112  
   
  R. Kumar et al.  
   
  Typically, DER plant may have three level of controller. Primary, secondary and tertiary controller [9]. Primary controller is machine’s (such as diesel generator) local controller. The secondary controller monitors and controls the primary controller based on the real time to operate and control generating machine behavior. Tertiary controller is used to controller power ﬂow among DER systems located at diﬀerent location. In the below subsection DER applications example are discussed to explain DER operating modes. 3.1  
   
  DER Applications  
   
  DER provides an alternative local power source in parallel or independently from main grid. DER system can be simple or complex as per the application needs and use case. The following are the application scenarios of DER application. 3.1.1 Back up for Poor Power Quality of Main Grid Poor power quality refers inability of main grid to provide stable power supply with any ﬂuctuations. Power quality of grid strongly depends on the load characteristic and transmission and distribution grid infrastructure. Long transmission line with asymmetric loads can easily inﬂuence power quality, which can results into unbalanced voltage, harmonic, in power supply. Poor power quality may lead to power outage, if demands lead to power generation capacity. In such cases, DER system at the consumer site plays an important role. Depending on the ﬁeld of application, military, industrial, commercial, or residential, power quality requirement of diﬀerent DER system can be deployed to provide back up when there is poor power quality supply from main grid. 3.1.2 Natural Disasters Natural disasters such as earthquake, tornados, hurricanes, and tsunamis may damage power grid transmission and distribution network and the area which are not directly aﬀected by natural disasters may suﬀers from power outage for a week to months if damage is severe. Since DER system is not dependent on power supply of the power grid, the immediate construction of DER system can provide an alternate power supply. 3.1.3 Power Grid Failure Large power grid, chances of disturbances due to cyber-attack, terrorist attack, human error, natural incidents, etc. are very high. The cascading eﬀect of one unit failure can end up power outage in larger region. A grid isolated DER systems can be an alternative of Power grid failure in order to maintain power supply for crucial domains. 3.1.4 Addressing of Growing Power Demand The growing power demand results in unstable power supply if generation capacity lags the power demand. Upgrading of power grid generation is not an easy  
   
  A Communication Viewpoints of Distributed Energy Resource  
   
  113  
   
  process it requires huge investment and eﬀort. Alternately, DER system is good candidate for satisfying growing demand of energy by deploying DERs near the high power demand zone. 3.1.5 Continuous Power Supply DER is the primary source of electricity and provides power supply to the load round the clock. 3.1.6 Uninterrupted Power Supply For this application, the crucial task of DER is very short start-up and ramp time to meet load demands. DER system should be stable and eﬃcient. Typically, the operating hours of such DER system is less than two hours. 3.2  
   
  Der Communication Architecture  
   
  From the communication point of view, DER system can be divided into three layers. Layer 1 - Machine/Primary controller to Secondary controller communication, Layer 2, Secondary controller to Central supervisory control, and Layer 3, central supervisory controller to other DER systems. These three layers are depicted in Fig. 3. Every generation unit such as PV array, wind turbine, diesel generator has its own primary controller unit, which locally controls the generator unit. Primary controller can start, stop and regulate the power generation. Primary controller interacts with secondary controller mostly using serial to analog interface. The job of secondary control is very crucial; it monitors the status of generator units and controls the physical aspects of generator based on vital statistics such voltage, frequency, circuitry health, etc. and broadcast the status information horizontally to other Secondary controller and vertically to Central Supervisory  
   
  Fig. 3. Distributed Energy Resources communication architecture  
   
  114  
   
  R. Kumar et al.  
   
  Control system. Communication between primary and secondary controller has highest frequency of message. High frequency of message of message is necessary for capturing and address transient behavior of the generators such as wind turbine, diesel generator etc. The message update cycle between primary controller and secondary controller is 10 ms, Secondary controller to secondary controller is 50 ms, Secondary controller to central supervisory controller is 100 ms, and, DER system to another DER system is more than 1 s. DER system will have advance features for ensuring autonomous operations. Some of these advance features are given below. 3.2.1 Automatic Discovery of DER System This feature allows DER system to discover new DER system in the network and synchronize their activities automatically. For example, if new wind turbine is connected to network, the existing DER system should be able to discover without having any prior inform of DER. 3.2.2 Dynamic System Configuration This feature allows DER system element to reconﬁgure themselves automatically based on the overall plant status in order to provide reliable, eﬃcient and good quality of power supply. 3.2.3 Plug and Play This feature allow new DER element to be part of network automatically. DER system will be conﬁgured automatically by Central Supervisory Control system. 3.2.4 Semantic Data Interpretation It is expected that dataset of DER system should be semantically interpreted by other DER system. This can be achieved if all the DER system support IEC 61850-7-420 information model.  
   
  4  
   
  Analysis of IEC 61850 Communication Protocols for DER System  
   
  The IEC 61850 standard is specially designed for Substation Automation domain. The communication model is designed in way the application speciﬁc data exchange is independent from communication model. Therefore, IEC 61850 can be extended to other domains as well. IEC61850 standard allows the integration of all protection, control, measurement and monitoring functions by one common protocol. It provides the means of high-speed substation applications, station wide interlocking and other functions which needs intercommunication between IEDs. The advantage of using IEC 61850 standard is that it ensures the interoperability and information interchangeability among multivendor devices. Device from any vendor compliant to IEC 61850 standard can communicates  
   
  A Communication Viewpoints of Distributed Energy Resource  
   
  115  
   
  Fig. 4. IEC 61850 based message exchange Table 1. Analysis of IEC 16850 mapped MMS protocol for DER DER required features  
   
  IEC 61850 support  
   
  Data modeling  
   
  Yes  
   
  Interoperability  
   
  Yes  
   
  Scalability  
   
  Yes  
   
  10–100 ms message transfer  
   
  Yes  
   
  Secure communication  
   
  No  
   
  Easy conﬁguration  
   
  No  
   
  Dynamic conﬁguration  
   
  No  
   
  DER auto discovery  
   
  No  
   
  Plug and play integration  
   
  No  
   
  Stable for low resource device  
   
  No  
   
  Point to point communication  
   
  Yes  
   
  Point to multi-point communication Yes Plug and play support  
   
  No  
   
  Less engineering eﬀort  
   
  No  
   
  Time synchronization  
   
  Yes  
   
  TCP/IP  
   
  Yes  
   
  Wireless communication  
   
  No  
   
  Web service support  
   
  No  
   
  Protocol stack extensibility  
   
  No  
   
  File transfer  
   
  Yes  
   
  Publisher/subscriber communication No  
   
  with each other seamlessly. IEC 61850 standard deﬁnes an Abstract Communication Service Interface (ACSI) for information exchange and control among devices. The ASCI deﬁned services are used for polling of data model information, reporting and logging of events, control of switches and functions. Peer to peer communication for fast data exchange between the feeder level devices  
   
  116  
   
  R. Kumar et al.  
   
  (protection devices and bay controller) is supported with GOOSE protocol. Voltage and current readings which are time synchronized are supported with Sampled Value communication model. Figure 4 shows the IEC 61850 based communication between two applications. Disturbance recordings are sent using File Transfer model. A common formal description code, which allows a standardized representation of a systems data model and its links to communication services is presented by the standard and its called as SCL (Substation Conﬁguration Language) [10]. It covers all communication aspects according to IEC 61850. Based on XML schema, this code is an ideal electronic interchange format for conﬁguration data, an equivalent of EDDL in Process Automation applications. The data model and the communication services (deﬁned through ACSI) are decoupled from speciﬁc communication technology. This technology independence guarantees long term stability for the standard and opens up possibility to switch over to future communication technologies. Table 1 shows our analysis of IEC 61850 mapped MMS communication protocol for DER communication. We found MMS protocol may not be suitable for DER communication.  
   
  5  
   
  Conclusion  
   
  Distributed Energy Resources are an important Smart Grid building block. Combining multiple DERs unit forms a Microgrid which can be considered as miniature Smart Grid. Due to social, economic, and environment beneﬁts, the demand of DERs deployment is increasing gradually. Currently DER system having interoperability issue. DER system of one manufacturer may not able to operate together because of their proprietary protocol use. In this paper, we have provided details of DER systems and it communication architecture. And provided communication view of point of DER system, which should be supported by standard protocols interface in coming future.  
   
  References 1. NIST Special Publication 1108R2. NIST Framework and Roadmap for Smart Grid Interoperability Standards, Release 2.0 2. Final report, Standards for Smart Grids. CEN/CENELEC/ETSI Joint Working Group 3. Cleveland, F.M.: IEC 61850-7-420 communications standard for distributed energy resource (DER). In: Proceedings of IEEE PES General Meeting, pp. 1–4 (2008) 4. International Standard IEC 61850: Communication networks and systems for power utility automation 5. IEC 61850-7-420 Ed. 1.0. Communication networks and system in power utility automation - Part 7-420: Basic communication structure - distributed energy resources logical nodes. March 2009. http://www.iec.ch 6. Yoo, B.-K., Yang, S.-H., Yang, H.-S., Kim, W.-Y., Jeong, Y.-S., Han, B.-M., Jang, K.-S.: Communication architecture of the IEC 61850-based micro grid system. J. Electr. Eng. Technol. 5, 605–612 (2011)  
   
  A Communication Viewpoints of Distributed Energy Resource  
   
  117  
   
  7. Suˇci´c, S., Havelka, J.G., Dragiˆcevi´c, T.: A device-level service-oriented middleware platform for self-manageable DC microgrid applications utilizing semantic-enabled distributed energy resources. Int. J. Electr. Power Energy Syst. 54, 576–588 (2014) 8. http://www.marketsandmarkets.com/Market-Reports/micro-grid-electronics-mar ket-917.html. Accessed Aug 2016 9. Kounev, V., Tipper, D., Grainger, B.M., Reed, G.: Analysis of an oﬀshore medium voltage DC microgrid environment– part II: communication network architecture. In: IEEE PES T&D Conference and Exposition, pp. 1–5, Chicago, IL, USA (2014) 10. IEC 61850-6: Communication networks and systems for power utility automation – Part 6: Conﬁguration description language for communication in electrical substations related to IEDs 11. Srinivasan, S., Kumar, R., Vain, J.: Integration of IEC 61850 and OPC UA for smart grid automation. In: 2013 IEEE Innovative Smart Grid Technologies-Asia (ISGT Asia). IEEE (2013) 12. Srinivasan, S., Kotta, U., Ramaswamy, S.: A layered architecture for control functionality implementation in smart grids. In: 2013 10th IEEE International Conference on Networking, Sensing and Control (ICNSC). IEEE (2013) 13. Verrilli, F., Gambino, G., Srinivasan, S., Palmieri, G., Del Vecchio, C., Glielmo, L.: Demand side management for heating controls in microgrids. IFAC-PapersOnLine 49(1), 611–616 (2016) 14. Gambino, G., Verrilli, F., Canelli, M., Russo, A., Himanka, M., Sasso, M., Srinivasan, S., Del vecchio, C., Glielmo, L.: Optimal operation of a district heating power plant with thermal energy storage. In: 2016 American Control Conference (ACC), pp. 2334–2339, July 2016. IEEE (2016) 15. Maﬀei, A., Srinivasan, S., Iannelli, L., Glielmo, L.: A receding horizon approach for the power ﬂow management with renewable energy and energ storage systems. In: 2015 AEIT International Annual Conference (AEIT), pp. 1–6, October 2015. IEEE (2015)  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System State Estimation in Smart Grids Seshadhri Srinivasan1(&), Øystein Hov Holhjem2, Giancarlo Maraﬁoti2, Geir Mathisen2, Alessio Maffei3, Giovanni Palmieri3, Luigi Iannelli3, and Luigi Glielmo3 1  
   
  Berkeley Education Alliance for Research in Singapore, Singapore 138602, Singapore [email protected]  2 SINTEF ICT-Applied Cybernetics, Trondheim, Norway {Oystein.Hov.Holhjem,fgiancarlo.marfioti, geir.mathiseng}@sintef.no 3 Department of Engineering, University of Sannio, Benevento, Italy {amaffei,palmieri,luiannel,glielmo}@unisannio.it  
   
  Abstract. This investigation proposes a CPES architecture and model for engineering energy management application for smart grids. In particular, the investigation considers the implementation of the power systems state estimator (PSSE). The CPES architecture has three layers: physical, monitoring and applications. The physical layer consists of the grid and the various components. Since, the grid is usually engineered with various devices from multiple vendors that have different protocols and standards; data aggregation becomes a problem. The second layer of the CPES architecture overcomes this problem by proposing a middleware that aggregates data from the physical layer. The topmost layer is the applications layer, where the energy management system applications are implemented. These applications require the model, topology and information from the grid. This requires combining the physical aspects of the grid with the cyber ones. This investigation uses the common information model to model the grid and information exchanges. Then the model is combined with measurement and optimization models of the application to realize the PSSE. The proposed approach is illustrated on a Norwegian distribution grid in Steinkjer. Our results show that the CPES approach provides an easier way to engineer future smart grid applications. Keywords: Cyber-physical energy systems (CPES)  Power systems state estimator (PSSE)  Common information models (CIM)  Service oriented architecture (SOA)  Middleware  
   
  1 Introduction Traditionally, core responsibility of power engineers has been to operate power grids and manage the transfer of energy. With the advent of smart grids there is an unprecedented volume of data available that needs to be harmonized with the energy © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_11  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  119  
   
  flow. Consequently, communication and energy infrastructure have to be designed together for achieving cost beneﬁts from smart grids. The communication infrastructure includes middleware, communication networks, data-models, and software platforms. Furthermore, since smart grids are massively distributed systems scalability plays a vital role within various applications such as state estimation, stability analysis and contingency analysis. These applications rely on measurements from heterogeneous sensors that are manufactured by various vendors. Engineering such applications requires a framework for handling both the cyber and physical parts of the grid simultaneously. Cyber Physical Energy Systems (CPES) Approach is touted as a futuristic approach for engineering smart grids. They consider the tight coupling between the physical and cyber domains in their design. CPES is a recent research topic that has attracted signiﬁcant attention [1]. Palensky et al. [2] proposed to study the modern energy systems using the CPES approach with the following categories: physical models, information technology, roles and individual behavior, and aggregated as well as stochastic models. Furthermore, proposed the use of CPES approach as a tool and method for the emerging complexities of the energy grids. While, specialized and useful tools for individual domains of the energy systems exist, there is no methodology to combine the different aspects of the energy and information. Motivated by this CPES approach has been studied for modelling and enabling various aspects of the energy grids. To our best knowledge, Ilic et al. [3] ﬁrst proposed a dynamic model using the CPES approach. The proposed model greatly dependent on the cyber technologies supporting the physical system. Major contributors to the CPES modelling and design are Widl et al. [4–7]. In [4], the author studied the role of the continuous time and discrete-event CPES models for control applications such as demand response, load balancing, and energy storage management. The investigation [7] presented a co-simulation platform for components, controls, and power systems based on software applications such as (GridLAB-D, OpenModelica, PSAT, 4DIAC) for smart charging of electric vehicles. The use of CPES approach for energy optimization in buildings has been studied in [8–10]. The use of model based design methodology for validating control algorithms in a residential microgrid has been studied in [11]. The role of CPES system for electric charging applications has been studied in [12]. Similarly, reducing energy consumption by combining CPES and industry 4.0 was proposed in [13]. More recently, McCalley et al. [14, 15] surveyed the design techniques and applications of CPES. In spite of these developments, the role of CPES approach for handling grid level applications has been minimum. Furthermore, CPES approach encapsulating both the physical and cyber domain has not been investigated. Among the various problems that can be tackled using CPES approach, we focus on the power system state estimation problem that has been studied in energy grids. The PSSE determines the most likely state of the power system from a set of measurements that are captured using supervisory control and data-acquisition systems. The role of PSSE is crucial for many energy management applications such as optimal power flow, monitoring, and contingency analysis. In addition, PSSE also provide snapshots of the network to energy management system applications developed by many third party applications. The role of PSSE in enabling optimal power flow [16, 33], bad-data detections, market  
   
  120  
   
  S. Srinivasan et al.  
   
  operations etc. [17, 32] has been studied in literature. Currently, there are various tools, standards and models used for capturing the various aspects of PSSE. The physical models used for PSSE have been reviewed in [18]. Among the communication standards used for modelling PSSE, IEC 61850 [19] and Common Information Models (CIM) standardized by the International Electromechanical Commission have been studied for implementing the grid. The investigation in [20] viewed PSSE as one of the applications enabled by IEC 61850 without much description about the implementation. The role of IEC 61850 in implementing PSSE for a distribution grid has been proposed in [21]. Similarly, CIM models for state estimation have been proposed in [22–24]. The recent research are converging more towards the use of CIM as a standard for data communication in smart grids (see, [25–30] and references therein). The main contribution of the paper is a CPES architecture and model that can be used to engineer smart grids. The proposed architecture has three layers: physical, middleware and applications. The physical layer is the grid with the various sensors and devices. Typically the grid is composed of various components and devices that have various communication protocols, standards and manufactured by different vendors. Aggregating information from them is difﬁcult. To overcome this, a middleware is used. The top layer of the CPES architecture is the application layer that needs to obtain the data from the middleware map it into the grid model. To model the grid, we use the common information model as it is easily extendable to model various aspects of the grid. The CIM model is tailored to the needs of the PSSE and is used for information exchange to the applications layer as well as among the applications. The application layer in addition contains the optimization and measurement models for mapping the physical variables of the grid. Furthermore, the implementation aspects of the PSSE in the application layer is also presented. The CIM based model maps the cyber aspects with the network topology and to the physical entities directly. Furthermore, the PSSE is also simultaneously realized in the application layer. This leads to a new approach for modelling and realizing future energy management applications. It is worth to mention here that the middleware part of the architecture is beyond the scope of this investigation and has not been treated in detail. The paper is organized as follows. Section 2 presents the implementation aspects of the PSSE. Section 3 presents the CPES architecture and model. Section 4 presents the case study and implementation in the distribution network in Steinkjer. Conclusions and future course of investigation are discussed in Sect. 5.  
   
  2 Power System State Estimation The main objective of a power system state estimator is to estimate the state of each bus, namely voltage magnitude and phase angle, using the set of redundant measurements, usually affected by errors. The set of phasors representing the complex bus voltages are called static state of the system. The State estimator, initially developed as an engineering tool, is slowly transforming into a decision support system that assists control and monitoring tasks. As with any estimator, the SE outcome is an approximation of the current network state. Moreover, from a high level supervisory control and data acquisition module, sensors measurements arrive with different time-granularities so  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  121  
   
  that measurements and state estimate can differ in phase. The physical component of the PSSE can be broken down into two parts: hardware and software. The hardware part consists of the SCADA system that collects the real-time information from the remote terminal units installed in various substations. RTU measurements include active and reactive power flows, power injections, current magnitude, voltage magnitude and phase angles. Figure 1 shows the hardware components of PSSE. Till recently, a direct measurement of voltage phase angles was considered impossible. Then, the introduction of phase measurement units (PMUs) has been made that measurement possible. In recent times, the PMUs have signiﬁcantly improved the measurements accuracy by using the GPS to synchronize the time signals with an accuracy close to 1 µs.  
   
  Fig. 1. Hardware components of the PSSE  
   
  The software components of the PSSE are: measurement pre-ﬁltering, topology processor, observability analysis, state estimator, bad-data detection and bad-data suppression. The pre-ﬁltering block checks for error measurements and unusual data. The topology processor builds the network topology required for the PSSE application using the knowledge of the physical topology. The SE algorithm then computes the state estimates. Finally, the bad data processor checks for the bad data and eliminates the error values. The state estimator block uses iterative algorithms that have ﬁnite convergence time for building the PSSE. In summary, the SE operation serves as a large-scale ﬁlter between remote measurements and high-level applications that constitute the Energy Management System (EMS).  
   
  3 CPES Model Energy management in smart grids require orchestrating several hardware platforms, protocols and devices from multiple vendors. The EMS applications should get access to different data from these various devices. A good solution to solve the heterogeneity  
   
  122  
   
  S. Srinivasan et al.  
   
  issue is to design a middleware. The architecture of such a middleware is shown in Fig. 2. The bottom most layer is the physical layer that models the energy grid. The middleware aggregates the data from the grid and provides it to the PSSE application. The application layer houses the third party and other applications for EMS such as the PSSE. Energy grids typically consider the energy flows in the physical grids, however to orchestrate the smart grid, the information from heterogeneous sensors needs to be aggregated by the middleware and provided to the applications. The physical layer models the energy flows and transfers. This model needs to be augmented with the data model for implementing the EMS. The network topology and other physical aspects needs to be captured in the application layer. The flow of information among the different layers is deﬁned by the CIM model. Here, we do not consider the implementation aspects of the middleware and the services are not elaborated. To propose the CPES model, we propose a top-down approach wherein the application layer has the PSSE application. The PSSE application requires measurements from the grid that is aggregated using the middleware. To process the information, the topology and model of the grid needs to be known. For this purpose the CIM models are used.  
   
  Fig. 2. CPES layered architecture  
   
  The PSSE EMS application is developed in JAVA. In order to facilitate information interoperability an application program interface (API) is deﬁned. This API can enable different applications and services to access data and exchange information independently, alleviating difﬁculties with intrinsic data representation. The CIM speciﬁes the semantics of the API. This also eliminates the difﬁculty of interfacing lower level  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  123  
   
  components with the physical application. The CIM model can be used to build semantics into the middleware as well. The lower level components transmit the information using dedicated communication infrastructure. There are different information models and data formats for the data. As the CIM provides interface to the applications, they are oblivious to the physical entities connected to the grid. This leads to a service oriented architecture for the middleware. In what follows we describe the measurement, optimization and grid model captured using CIM. The implementation aspects of the application layer and different aspects considered in the design of PSSE. A. Measurement Model The State Estimator routine is used to monitor the power network status during normal operation, where the system is in quasi-steady state responding to slowly varying load demand and power generation. It is also assumed that, in the three-phase transmission system, all loads are balanced and all transmission lines are fully transposed so that the network can be represented by its single phase equivalent diagram. Given the single phase diagram, the network is mathematically modelled and all the measurements, previously described Sect. 2, are written as function of the network state variables (i.e. voltage phasors). The equations modelling the power network are nonlinear and do not take into account all possible errors due to the uncertainties in the network parameters, e.g., metering errors and noise that may be introduced through the telecommunication systems. Consider a vector z as the set of all available measurements. This vector can be expressed in terms of power network state variables x as follows: 2  
   
  3 2 3 2 3 h1 ðx1 ; x2 ; . . .; xn Þ z1 e1 6 z2 7 6 h2 ðx1 ; x2 ; . . .; xn Þ 7 6 e2 7 6 7 6 7 6 7 z ¼ 6 .. 7 ¼ 6 7 þ 6 .. 7 ¼ hðxÞ þ e .. 4 . 5 4 5 4 . 5 . zm  
   
  hn ðx1 ; x2 ; . . .; xn Þ  
   
  ð1Þ  
   
  em  
   
  where h(x) is the measurement model, x is the state vector, and e is the error in measurements. The measurement model h(x) is a nonlinear model that maps the state vector to the measurement. B. Optimization Model The mathematical formulation of the presented state estimation problem is based on the maximum likelihood concept. Maximum likelihood estimator (MLE) of a random variable maximizes the likelihood function, which is deﬁned based on assumptions of the problem formulation. The ﬁrst assumption, as previously mentioned, is that the errors are distributed according to a Gaussian (or normal) distribution, with the expected value equal to zero. Thus, a random variable z is said to have a normal distribution if its probability density function f ðzÞ is given as follows: 1 1 2 f ðzÞ ¼ pﬃﬃﬃﬃﬃﬃﬃﬃ e2ðzlÞ=r 2pr  
   
  ð2Þ  
   
  124  
   
  S. Srinivasan et al.  
   
  where l is the expected value (or mean) of z ¼ EðzÞ and r is the standard deviation of z. The previous property holds for the i.i.d. assumption. The second assumption implies that the joint probability density function (pdf) of a set of m measurements can be obtained by taking the product of individual pdfs corresponding to each measurement. The result product function is called likelihood function for the set of m measurements: fm ðzÞ ¼ f ðz1 Þf ðz2 Þ. . .f ðzm Þ  
   
  ð3Þ  
   
  Essentially the likelihood function is a measure of the probability of observing a given set of measurements in vector z. For this reason we are interested in ﬁnding the parameter vector that maximize this function. In order to simplify the procedure of determining the optimum parameters, the function is commonly replaced by its logarithm, obtaining the so called log-likelihood function. Hence, the MLE of the state x can be found by maximizing the log-likelihood function for a given set of observations, z1 ; z2 ; . . .; zm . Thus, the following optimization problem is formulated: minimize JðxÞ ¼  
   
   m  X zi  l 2 i  
   
  ri  
   
  i¼1  
   
  ð4Þ  
   
  Let us deﬁne, ri ¼ zi  li is the residual of measurement i. The expected value E ðzi Þ of measurement zi , can be expressed as li ¼ E ðzi Þ ¼ hi ð xÞ, where hi ð xÞ is a nonlinear function relating the system state vector x to the i th measurement. The minimization problem in (4) can be modelled as an optimization problem for the state vector x: min x  
   
  s:t:  
   
  m X  
   
  Wii ri2  
   
  ð5Þ  
   
  i¼1  
   
  zi ¼ hi ðxÞ þ ri  
   
  8i ¼ 1; . . .; m  
   
  where Wii ¼ r2 is the inverse of the assumed error variance for the measurements. i The reciprocal of the measurement variances can be thought of weights assigned to individual measurements. High values are assigned for accurate measurements with small variance and low weight for measurements with large uncertainties. A little manipulation leads to min  
   
  JðxÞ ¼ r T Wr  
   
  s:t:  
   
  z ¼ hðxÞ þ r  
   
  x  
   
  ð6Þ  
   
  where x; r; z; hð xÞ are vectors of respective quantities and W is the diagonal weighted matrix of the WLS problem equals to the inverse of covariance matrix of the measurements.  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  125  
   
  C. Smart Grid Model As stated earlier CIM has been chosen as a representative mechanism for the smart grid model. The CIM models provide an abstract model for the power network using uniﬁed modelling language (UML). The CIM represents the power system entities using an object oriented approach as classes, attributes, methods and association as deﬁned in IEC 61970 [25] and IEC 61968 [26] standards. The standard IEC 61970-301 provides as semantic model for the power system components at an electrical level and their interrelationships. The IEC 61968-11 extends the semantic models to include the data exchanges for scheduling, asset management and other market operations. Although, CIM contains most classes and their associations to represent the power system, still object models need to be adapted for implementing speciﬁc application. CIM models can be adapted by deﬁning new classes, subclasses, methods and attributes. CIM Proﬁle: A proﬁle is a delimitation of CIM which consists of a subset of classes and attributes that specify information conceptually and the relationships among the different objects. A subset of IEC 61970-456 deﬁnes the CIM necessary to describe the PSSE results. A modular approach is used in the development of CIM proﬁle that four proﬁles: Equipment, Measurement, Topology, and State variable Proﬁle. The equipment proﬁle models physical elements of the network such as network, loads, generators, and switches. The measurement proﬁle contains the measurement information such as active and reactive power, voltages, load angles etc. Topology proﬁle deﬁnes the classes needed to describe the network topology considering the switching status. State variable proﬁle contains the model for deﬁning the state variables in the network. The relationship between the different proﬁles is shown in Fig. 3. The proﬁle connected at the “from” end of the arrow depends on the proﬁle at “to” end of the arrow.  
   
  Fig. 3. CIM proﬁles for implementing the PSSE  
   
  126  
   
  S. Srinivasan et al.  
   
  As a next step the abstract and concrete classes of the various proﬁles are deﬁned. As the treatment of all the proﬁles is beyond the scope of this investigation. Here we provide an example of the topology proﬁle (see, Fig. 4). The topology proﬁle deﬁnes the classes needed to describe how each of the equipment in the network is connected to each other. Topology is given by the association of the buses with the corresponding association of the terminals of the equipment. This way the network model is built as a branch flow model and can be directly used by the PSSE application. The state variable  
   
  Fig. 4. Topology proﬁle  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  127  
   
  proﬁle of the CIM model is shown in Fig. 5. Similarly, the other CIM proﬁles are modelled to describe the network. In addition the abstract and concrete models required of the CIM proﬁles are described. The CIM model maps the network topology with the measurements and state variables. The CIM model deﬁnes the semantics for the PSSE API which is implemented in JAVA. The application uses the middleware services to query the sensors and update the network state using the PSSE application. The middleware services required can be broken down into low-level services and common services. The description of the middleware services are not considered in this investigation. REST interfaces are used to communicate between the middleware and application layer.  
   
  Fig. 5. State variable proﬁle  
   
  D. Software Model of the PSSE Application The PSSE application needs to map the data aggregated from the middleware to the network topology. To this extent the application uses the InterPSS that deﬁnes the network data in the IEEE format for processing. The application implementing the PSSE is written in JAVA and to solve the optimization model in (6) GAMS solver is  
   
  128  
   
  S. Srinivasan et al.  
   
  used due to its symbolic processing capability. The APIs implementing the CIM, and libraries of the InterPSS, GAMS are integrated with the application written in JAVA to realize the PSSE for the EMS. The CPES model described above integrates the physical equations describing the energy flows in the network with the CIM to model the cyber part of the network. The resulting model encapsulates both the cyber and physical aspects of the network. Furthermore, the application software model proposed also uses the InterPSS to map the topology and uses the GAMS for realizing the PSSE. This model along with the CPES description of the network can be used to engineer energy management system application in typical smart grid. The main advantage of the proposed approach is that the method provides a comprehensive framework for co-designing both the physical and cyber aspects of the network, thereby reduces the engineering efforts. Furthermore, provides an interface between the different domain engineers involved in smart grids. The CPES model described above integrates the physical equations describing the energy flows in the network with the CIM to model the cyber part of the network. The resulting model encapsulates both the cyber and physical aspects of the network. Furthermore, the application software model proposed also uses the InterPSS to map the topology and uses the GAMS for realizing the PSSE. This model along with the CPES description of the network can be used to engineer energy management system application in typical smart grid. The main advantage of the proposed approach is that the method provides a comprehensive framework for co-designing both the physical and cyber aspects of the network, thereby reduces the engineering efforts. Furthermore, provides an interface between the different domain engineers involved in smart grids.  
   
  4 Case Study The CPES approach proposed in Sect. 3 was used to engineer PSSE in the energy management system of the distribution grid in Steinkjer, Norway. It is a radial distribution network that consists of a: hydro power plant with 2 generators, 32 aggregating loads, 50 link busses, and 84 transmission lines. The CIM deﬁnes the basic ontology of the set of attribute value pairs. Ontologies are often written in XML or in a Resource Document Framework (RDF), which is a suitable format for middleware information exchange through the common communication bus. The CIM standard IEC 61970-52 deﬁnes the procedure for description of the network model as a serialized RDF schema. The main concept of the RDF is called the tiple and consists of subject-predicate-object expression. An RDF document contains element that are identiﬁed by unique ID attribute and that can be referenced from other elements using that ID in a resource attribute. The CIM proﬁle for implementing the PSSE can be represented using a RDF schema document. In details, after having selected all the classes, attributes and relationship among the classes, tools such as CIMTool can be used for generating the RDF schema. As stated earlier the PSSE application uses the InterPSS and GAMS to provide the state estimates for the different applications. The CIM model also deﬁnes the information exchange among the EMS applications. The CPES engineered PSSE application is tested in the pilot distribution network. The residuals of the PSSE are used to evaluate the accuracy of the state estimates. Figure 7 shows the residuals  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  129  
   
  computed for the real and reactive power in p.u. values. Our results show that the PSSE provided an accurate estimates with error between 2–4% for the 85 buses in the distribution network (Fig. 6).  
   
  Fig. 6. Residuals of the real power in PSSE  
   
  Fig. 7. Residuals of the reactive power in PSSE  
   
  5 Conclusions This investigation proposed a cyber-physical energy systems approach for engineering PSSE in smart grids. The proposed approach modelled both the physical and cyber aspects of the PSSE simultaneously. The physical model was represented by the  
   
  130  
   
  S. Srinivasan et al.  
   
  measurement and optimization model. While, the common information model was used to describe the cyber part of the CPES model. The proposed approach can be used to engineer PSSE applications in smart grids with heterogeneous sensors from various vendors and considering interoperability constraints. Furthermore, the proposed CPES approach can also be used for building a service oriented architecture (SOA) based middleware. The details of the implementation of the middleware are not discussed in the investigation. Extending the CPES approach to model optimal power flow with PSSE is the future course of this investigation. Acknowledgement. This research is supported by the European Union’s Seventh Framework program (FP7 2012-2015) for the ICT based Intelligent management of Integrated RES for the smart optimal operation under the grant agreement n. 318184, project name: I3RES.  
   
  References 1. Khaitan, S.K., McCalley, J.D.: Cyber physical system approach for design of power grids: a survey. In: 2013 IEEE Power and Energy Society General Meeting (PES). IEEE (2013) 2. Palensky, P., Widl, E., Elsheikh, A.: Simulating cyber-physical energy systems: challenges, tools and methods. IEEE Trans. Syst. Man Cybern.: Syst. 44(3), 318–326 (2014) 3. Ilic, M.D., Xie, L., Khan, U.A., Moura, J.M.F.: Modeling future cyber-physical energy systems. In: IEEE Power and Energy Society General Meeting-Conversion and Delivery of Electrical Energy in the 21st Century, pp. 1–9. IEEE (2008) 4. Palensky, P., Widl, E., Elsheikh, A.: Simulating cyber-physical energy systems: challenges, tools and methods. IEEE Trans. Syst. Man Cybern.: Syst. 99, 1–10 (2012) 5. Widl, E., Palensky, P., Elsheikh, A.: Evaluation of two approaches for simulating cyber-physical energy systems. In: Proceedings of 38th Annual Conference on Industrial Electronics, IECON 2012, pp. 3582–3587 (2012) 6. Stifter, M., Widl, E., Filip, A., Elsheikh, A., Strasser, T., Palensky, P.: Modelica-enabled rapid prototyping of cyber-physical energy systems. In: IEEE Workshop on Modeling and Simulation of Cyber Physical Energy Systems, pp. 1–6 (2013) 7. Elsheikh, A., Awais, M.U., Widl, E., Palensky, P.: Co-simulation of components, controls, and power systems based on open source software. In: Proceedings of 2013 IEEE Power and Energy Society General Meeting, pp. 1–5 (2013) 8. Kleissl, J., Agarwal, Y.: Cyber-physical energy systems: focus on smart buildings. In: Proceedings of the 47th ACM Design Automation Conference, pp. 749–754 (2010) 9. Zhao, P., Godoy, S.M., Siddharth, S.: A conceptual scheme for cyberphysical systems based energy management in building structures. In: 9th IEEE/IAS International Conference on Industry Applications (INDUSCON), pp. 1–6 (2010) 10. Shein, W.W., Tan, Y., Lin, A.O.: PID controller for temperature control with multiple actuators in cyber-physical home system. In: 15th IEEE International Conference on Network-Based Information Systems (NBiS), pp. 423–428 (2012) 11. Ge, Y., Dong, Y., Zhao, H.: A cyber-physical energy system architecture for electric vehicles charging application. In: 2012 12th International Conference on Quality Software (QSIC). IEEE (2012) 12. Al Faruque, M.A., Ahourai, F.: A model-based design of cyber-physical energy systems. In: Design Automation Conference (ASP-DAC), 2014 19th Asia and South Paciﬁc. IEEE (2014)  
   
  Cyber-Physical Energy Systems Approach for Engineering Power System  
   
  131  
   
  13. Martin, B., et al.: A new approach to increasing energy efﬁciency by utilizing cyber-physical energy systems. In: 2013 Proceedings of the 11th Workshop on Intelligent Solutions in Embedded Systems (WISES). IEEE (2013) 14. Khaitan, S.K., McCalley, J.D., Liu, C.C. (eds.): Cyber Physical Systems Approach to Smart Electric Power Grid. Springer, Heidelberg (2015) 15. Khaitan, S.K., McCalley, J.D.: Design techniques and applications of cyberphysical systems: a survey. IEEE Syst. J. 9(2), 350–365 (2014) 16. Maffei, A., Srinivasan, S., Iannelli, L., Glielmo, L.: A receding horizon approach for the power flow management with renewable energy and energy storage systems. In: 2015 AEIT International Annual Conference (AEIT), pp. 1–6. IEEE, October 2015 17. Huang, Y.-F., et al.: State estimation in electric power grids: meeting new challenges presented by the requirements of the future grid. Signal Process. Mag. 29(5), 33–43 (2012). IEEE 18. Kashyap, N.: Novel resource-efﬁcient algorithms for state estimation in the future grid. Ph.D. dissertation, Department of Electrical Engineering, Aalto Unieristiy, Finalnd (2012) 19. Srinivasan, S., Kumar, R., Vain, J.: Integration of IEC 61850 and OPC UA for Smart Grid automation. In: 2013 IEEE Innovative Smart Grid Technologies-Asia (ISGT Asia), pp. 1–5. IEEE, November 2013 20. Mohagheghi, S., et al.: Applications of IEC 61850 in distribution automation. In: 2011 IEEE/PES Power Systems Conference and Exposition (PSCE). IEEE (2011) 21. Choi, S., Kim, B., Cokkinides, G.J.: Feasibility study: autonomous state estimation in distribution systems. IEEE Trans. Power Syst. 26(4), 2109–2117 (2011) 22. Xu, K.-N., Xin-Gong, C., Xi-Ji, X., Yan-Shi, C.: Model design of electric system state estimation based on CIM. In: Power and Energy Engineering Conference, 2009. APPEEC 2009. Asia-Paciﬁc. pp. 1–4. IEEE (2009) 23. LiJun, Q., Meng, L., Ying, W., CuiJuan, H., HuaWei, J.: Cimbased three-phase state estimation of distribution network. In: 2011 International Conference on Advanced Power System Automation and Protection (APAP), vol. 1, pp. 667–672. IEEE (2011) 24. Sharma, A., Srivastava, S., Chakrabarti, S.: An extension of common information model for power system multiarea state estimation. Syst. J. PP(99), 1–10 (2014). IEEE 25. Chen, Y.: Industrial information integration—a literature review 2006–2015. J. Ind. Inf. Integr. 2, 30–64 (2016) 26. Cintuglu, M.H., Martin, H., Mohammed, O.A.: An intelligent multi agent framework for active distribution networks based on IEC 61850 and FIPA standards. In: 2015 18th International Conference on Intelligent System Application to Power Systems (ISAP), pp. 1– 6. IEEE, September 2015 27. Belikov, J., Kotta, Ü., Srinivasan, S., Kaldmäe, A., Halturina, K.: On exact feedback linearization of HVAC systems. In: 2013 International Conference on Process Control (PC), pp. 353–358. IEEE, June 2013 28. Soudari, M., Srinivasan, S., Balasubramanian, S., Vain, J., Kotta, U.: Learning based personalized energy management systems for residential buildings. Energy Build. 127, 953–968 (2016) 29. Srinivasan, S., Kotta, U., Ramaswamy, S.: A layered architecture for control functionality implementation in smart grids. In: 2013 10th IEEE International Conference on Networking, Sensing and Control (ICNSC), pp. 100–105. IEEE, April 2013 30. Landa-Torres, I., et al.: The application of the data mining in the integration of RES in the smart grid: consumption and generation forecast in the I3RES project. In: 2015 IEEE 5th International Conference on Power Engineering, Energy and Electrical Drives (POWERENG). IEEE (2015)  
   
  132  
   
  S. Srinivasan et al.  
   
  31. Cavalieri, S., Regalbuto, A.: Integration of IEC 61850 SCL and OPC UA to improve interoperability in Smart Grid environment. Comput. Stand. Interfaces 47, 77–99 (2016) 32. Verrilli, F., et al.: Model predictive control-based optimal operations of district heating system with thermal energy storage and flexible loads. IEEE Trans. Autom. Sci. Eng. 14(2), 547–557 (2017) 33. Maffei, A., Srinivasan, S., Castillejo, P., Martinez, J.F., Iannelli, L., Bjerkan, E., Glielmo, L.: A semantic middleware supported receding horizon optimal power flow in energy grids. IEEE Trans. Ind. Inform. PP(99), 1. doi:10.1109/TII.2017.2655047. http://ieeexplore.ieee. org/stamp/stamp.jsp?tp=&arnumber=7822985&isnumber=4389054  
   
  Knowledge-Based Technologies for Web Applications, Cloud Computing, Security Algorithms and Computer Networks  
   
  About the Applications of the Similarity of Websites Regarding HTML-Based Webpages Doru Anastasiu Popescu1(&), Ovidiu Domșa2, and Nicolae Bold3 1  
   
  Faculty of Mathematics and Computer Science, University of Pitesti, Pitesti, Romania [email protected]  2 “1 Decembrie 1918” University of Alba Iulia, Alba Iulia, Romania [email protected]  3 Faculty of Management, Economic Engineering in Agriculture and Rural Development, University of Agronomic Sciences and Veterinary Medicine Bucharest, Slatina Branch, Bucharest, Romania [email protected]   
   
  Abstract. The study of the similarity between web applications has extended alongside with the informational explosion resulted from the fast communication means through Internet. The copyright of web applications is difﬁcult to be appreciated in this domain and this is the reason for the development of novel web technologies and mechanisms of measuring the similarity between two webpages. In this paper, we will present a modality of measurement of the similarity degree between two webpages regarding the HTML tag-based webpages. The degree of similarity will be determined approximately, being dependent of the webpages used from the both websites and the tags set used in the comparison of the webpages. The selection of webpages in order to determine the degree of similarity between two webpages will be made using genetic algorithms. In the ﬁnal part of the paper there are presented the results obtained with the implementation of the algorithm presented in the paper. Keywords: Webpage  
   
   Tag  Algorithm  Chromosome  Gene  Similarity  
   
  1 Introduction The similarity is a notion which appears frequently in many domains: science, linguistics, copyright, arts, transportation etc. In the last period, different mechanisms of measuring the similarity between different objects were developed, using particularly complex algorithms and mathematical results. A variant of measuring the similarity between two objects presumes the identiﬁcation of certain character sequences which characterize adequately these objects and then these sequences are analyzed by means of speciﬁc algorithms to obtain a number which reflects the similarity. This type of algorithms is used in [4, 5]. We will use this idea in this paper for measuring the similarity of two webpages. The number that will © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_12  
   
  136  
   
  D.A. Popescu et al.  
   
  be obtained to deﬁne to what extent two webpages are similar will be determined by examining the tag sequences which are used at the web pages created using HTML. The large number of ﬁles used for creating the webpages is an impediment for creating algorithms which calculate the similarity between two webpages and this is the reason for which we will use a ﬁxed number of ﬁles for this calculus. The generation of these ﬁles will be made using genetic algorithms, which will provide several variants of these ﬁles and for each variant we will use the editing distance method for the calculus of similarity, presented in detail in [7]. The main motivation for our work is the ﬁnding of the degree of similarity between two web applications. Another motivation is related to ﬁnding different methods of calculating this degree, in this paper being presented a method using genetic algorithms. In Sect. 2 we will present some deﬁnitions and examples necessary for the approximate calculus of the degree of similarity between two webpages. Section 3 will contain the presentation of the selecting modality required for the measurement of the similarity between two web pages, using genetic algorithms. In Sect. 4, we will present the modality of calculating the similarity of webpages using the results from Sect. 3. Section 5 is dedicated to the presentation of several results obtained after the algorithms presented in Sects. 3 and 4 were implemented.  
   
  2 Preliminary Notions In order to determine the similarity between two webpages which will be denoted by WA (web applications): WA1 and WA2, we will use only the ﬁles formed of HTML tags. These ﬁles have the .html and .htm extensions. To simplify the future notations, we will denote by P = {p1, p2, …, pm}, respectively with Q = {q1, q2, …, qn} the sets of web pages associated with the applications WA1, respectively WA2. Next, we will interpret by pi or qj the ﬁle which contains the tags of the corresponding web page (1  i  m, 1  j  n). In the approximate calculus of the similarity between two web pages we will not take into consideration a ﬁxed set of tags, this set being denoted by TG. For the next deﬁnitions, it is useful to denote by T1i the sequence of tags from pi which are not found in TG and by T2j the sequence of tags from qj which are not found in TG, where 1  i  m, 1  j  n. In the calculus of the similarity between two sequences of tags we will use the editing distance (or the Levenshtein distance), presented in detail in [3, 7, 11]. In the classic deﬁnition, the character strings are used, in this paper the characters being replaced by tags. In the paper [7] we have done a similar study. We will use, in this matter, some notations used in the referred paper: – DL(s, t) is the minimum number of operations to transform the string s into the string t; – d(pi, qj) is the degree of similarity between two webpages pi and qj;  
   
  Similarity of Websites Regarding HTML-Based Webpages  
   
  137  
   
  – d(pi, WA2) is the degree of similarity between the webpage pi and the web application WA2; – d(WA1, WA2) is the degree of similarity between two web applications WA1 and WA2; – ad(WA1, WA2) is the approximate degree of similarity between two web applications WA1 and WA2.  
   
  3 The Choice of Files for the Calculus of the Similarity Between Two Webpages At the notations used in the previous sections we add two natural numbers k and h with 1  k  m, 1  h  n. k and h are chosen so that the runtime of the algorithm of the calculus of the similarity between two web pages to be enclosed in limits closed to the ne calculated for all the web pages. In Fig. 1 the general scheme of the algorithm as in [3, 8] is presented. The algorithm will be used twice for generating subsets with k web pages from WA1, respectively with h web pages from WA2.  
   
  Initial Population NoGeneration++ Select next generation  
   
  Mutation NoGeneration > NoF  
   
  Sort the chromosome  
   
  Perform Crossover  
   
  Exit Fig. 1. Scheme of a genetic algorithm  
   
  The algorithm presented next has as input data a string of characters which represents the path where a web application can be found and a natural number k, less or equal with the number of web pages built using HTML tags, denoted by n. The web  
   
  138  
   
  D.A. Popescu et al.  
   
  pages will be codiﬁed with numbers from 1, 2, … to n. The output data of the algorithm will be represented by a bi-dimensional array with k columns, each line representing a chromosome, namely a subset with k distinct elements from {1, 2, …, n}. The subsets obtained from the array will be distinct. The steps of this algorithm are: Step 1. The character sequence s and the number k is read. This sequence represents the path of the web application. Step 2. The ﬁles with the extension .html or .htm from the tree with the subfolders that are rooted in s are determined. The names of these ﬁles will be memorized alongside their path in the string p[1], p[2], …, p[n]. Step 3. The number of generations NoF which will be used in the genetic algorithm is read. Step 4. Using the genetic algorithm presented above, it is built a bi-dimensional array with the elements Pop[i][j], i = 1, Nocrom and j = 1, k, where Nocrom represents the number of chromosomes which will be obtained. Nocrom can be read. Step 5. The chromosome obtained at step 4 are sorted ascendingly depending on the ﬁtness functions, but these chromosomes are not distinct. This is why a new bi-dimensional array will be built. This array contains the elements PopDist[i][j], i = 1, NoCromDist and j = 1, k. Observations 1. In the genetic algorithm from the step 4, the initial population is randomly generated using the numbers from the set {1, 2, …, n}, these numbers being the genes that form the chromosomes, n being the number of web pages from WA. The chromosome is formed from k genes. The initial population used in the implementation presented in Sect. 6 has 1200 chromosomes. 2. For the ith chromosome from the population which contains the genes Pop[i][1], … Pop[i][j], …, Pop[i][k], the ﬁtness is calculated as being the sum of the degrees of similarity of between the pairs of web pages p[Pop[i][j]] and p[Pop[i][r]], 1  j r  k and it is being denoted by f(i). Thus: f ði Þ ¼  
   
  k1;k X  
   
  d ðPop½i½ j; Pop½i½r Þ  
   
  j¼1;r¼j þ 1  
   
  3. The ith chromosome is more performant than the jth chromosome if f(i) < f(j), which means that the web pages from the ith chromosome are more different to each other than the ones from the jth chromosome. 4. The mutation operation is made by identifying a number h (randomly generated) from {1, 2, …, n} which is not found in a chromosome and randomly determining a position poz in the chromosome. After that, the gene from the position poz is replaced with h. 5. For the crossover operation, chromosomes which contain at least one different number are randomly generated. The crossover of the two chromosomes with the indices i and j which have this property will be made in this way:  
   
  Similarity of Websites Regarding HTML-Based Webpages  
   
  139  
   
  – it is built a string of numbers with all the genes from the two arrays, denoted by x = (x1, x2, …, x2k). – the array x is sorted ascending and a string of numbers y = (y1, y2, …, yw) containing the distinct numbers form x. w > k, because of the fact that the two chromosomes has at least one gene (number) different. – two new chromosomes are built from the array y, the ﬁrst chromosome containing the ﬁrst k components from y and the second with the latter k components from y.  
   
  4 The Approximate Calculus of the Degree of Similarity Between Two Webpages In this section, we will keep the notations from the previous sections. The algorithm presented in the next lines will determine the approximate degree of similarity between two webpages WA1 and WA2, using k web pages form WA1 and h web pages from WA2. The steps of this algorithm are: Step 1. Two strings of characters s and t and the natural numbers k and h are read. These two strings represent the paths where the two webpages WA1 and WA2 can be found. Step 2. The ﬁles with the extension .html or.htm from the tree with the folders which are rooted in s are determined. The names of these ﬁles will be memorized alongside with their paths in the string p[1], p[2], …, p[m]. Step 3. The ﬁles with the extension .html or .htm from the tree with the folders which are rooted in t are determined. The names of these ﬁles will be memorized alongside with their paths in the string q[1], q[2], …, q[m]. Step 4. Using the algorithm from the Sect. 4 twice, once for WA1 and once for WA2, we determine two bi-dimensional arrays with chromosomes (web pages indexes): ðPopDist1½i½jÞi¼1;NoCromDist1;j¼1;k for WA1 respectively ðPopDist2½i½jÞi¼1;NoCromDist2;j¼1;h ; for WA2: The applications that contains the web pages with the indexes from the chromosomes from the lines of the previous bi-dimensional arrays will be denoted by (WA1i) i = 1, NoCromDist1 respectively (WA2j) j = 1, NoCromDist2. Step 5. We determine ad(WA1i, WA2j) for i = 1, NoCromDist1and j = 1, NoCromDist2. The average of these numbers will be the number which represents the approximation of the similarity between the webpages WA1 and WA2.  
   
  140  
   
  D.A. Popescu et al.  
   
  Observations 1. The presented algorithm complexity is O(Nocrom∙(max(m, n)2 + Nocrom ∙log (Nocrom))). 2. The algorithm presented in this section and the one from the Sect. 4 can be modiﬁed in order for other deﬁnitions of the similarity between web pages, as the well presented in [6] or [8] or other modalities of measuring the similarity between the character sequences as the ones from [1, 10, 11] to be used.  
   
  5 Implementation The implementation made in Java led to results closed to the ones obtained for the similarity between two webpages using the deﬁnition 5 from the Sect. 2, meaning the fact that all the web pages from the both webpages were included. Table 1 presents some information about the webpages used at the test of the Java program which implements the algorithms from Sects. 5 and 6. The set of tags used at the implementation of the program was made from the tags:  

  Table 2 presents some results obtained for the webpages presented in Table 1: the degree of similarity (using the algorithm from [7]) and the approximation of the degree of similarity (using the algorithm presented in this paper) (Fig. 2). Table 1. Webpages using for Java program Notation Number of ﬁles Number of HTML ﬁles E1 125 23 E2 85 15 E3 90 16 E4 104 24 E5 97 17 E6 2431 476 E7 344 35  
   
  The results obtained using the implementation of the algorithms presented in this paper shows the fact that they can be used to calculate the degree of similarity between two webpages with quite an acceptable error (generally, under 0.01). An important aspect is the fact that the presented algorithms can also be used for other modalities of deﬁning the degree of similarity between two ﬁles.  
   
  Similarity of Websites Regarding HTML-Based Webpages  
   
  141  
   
  Table 2. Results to implement algorithms in the Java language k 12 12 12 12 15 15 100  
   
  WA1 h E1 10 E1 10 E1 15 E1 10 E1 100 E1 20 E6 20  
   
  WA2 E2 E3 E4 E5 E6 E7 E7  
   
  Similarity degree 0.6527269615774745 0.6528103923698071 0.6390043190028488 0.636510512472533 0.34485409963776364 0.319443831408161 0.568263602360978  
   
  Similarity degree  
   
  Approximate similarity degree 0.6151740849736574 0.5965780161873493 0.6247214290536568 0.6347343901389451 0.318678530256979 0.291547650419385 0.536853457204536  
   
  Approximate similarity degree  
   
  0.7 0.65 0.6 0.55 0.5 0.45 0.4 0.35 0.3 0.25 0.2 E1 vs E2 E1 vs E3 E1 vs E4 E1 vs E5 E1 vs E6 E1 vs E7 E6 vs E7 Fig. 2. Results to implement algorithms in the Java language (similarity degree versus approximate similarity degree)  
   
  6 Conclusions This paper showed a model for the approximate calculus of the degree of similarity between two webpages, each of them being made from several other components. Particularizing, the applications are webpages and the components are web pages with the source code built from tags. A central thing of this model is the genetic algorithm, which helps us at the generation of component subsets with certain restrictions. This type of algorithms is used in many situations, in [2, 3, 9] being presented some applications of these algorithms. The presented model can also be adapted for other modalities of deﬁning the similarity between the ﬁles that compose a web application. For a future work, we propose to create a tool which will calculate the approximate similarity between two webpages using several formulas to calculate the similarities between the ﬁles.  
   
  142  
   
  D.A. Popescu et al.  
   
  References 1. Okundaye, B., Ewert, S., Sanders, I.: Determining image similarity from pattern matching of abstract syntax trees of tree picture grammars. PRASA Johannesburg, pp. 83–90 (2013) 2. Caldas, L.G., Norford, L.K.: A design optimization tool based on a genetic algorithm. In: Automation in Construction, ACADIA 1999, vol. 11, no. 2, pp. 173–184 (2002) 3. Darby, S., Mortimer-Jones, T.V., Johnston, R.L., Roberts, C.: Theoretical study of Cu–Au nanoalloy clusters using a genetic algorithm. J. Chem. Phys. 116(4), 1536 (2002) 4. Kim, H.-S., Cho, S.-B.: Application of interactive genetic algorithm to fashion design. Eng. Appl. Artif. Intell. 13(6), 635–644 (2000) 5. Remani, N.V.J.M., Rachakonda, S.R., Kurra, R.S.R.: Similarity of inference face matching on angle oriented face recognition. J. Inf. Eng. Appl. 1(1) (2011) 6. Popescu, D.A., Maria, D.C.: Similarity measurement of web sites using sink web pages. In: 34th International Conference on Telecommunications and Signal Processing, TSP 2011, 18–20 August, Budapest, Hungary, pp. 24–26. IEEE Xplore (2011) 7. Popescu, D.A., Nicolae, D.: Determining the similarity of two web applications using the edit distance. In: 6th International Workshop on Soft Computing Applications, 24–26 July 2014, Timisoara, Romania, 6th IEEE SOFA. LNCS, pp. 681–690 (2014) 8. Popescu, D.A., Dan, R.: Approximately similarity measurement of web sites. In: ICONIP, Neural Information Processing. Proceedings LNCS. Springer, 9–12 November 2015 9. Rahmani, S., Mousavi, S.M., Kamali, M.J.: Modeling of road-trafﬁc noise with the use of genetic algorithm. Appl. Soft Comput. 11(1), 1008–1013 (2011) 10. Dietterich, T.G.: An experimental comparison of three methods for constructing ensembles of decision trees: bagging, boosting, and randomization. Mach. Learn. 40(2), 139–157 (2000) 11. Cormen, T.H., Leiserson, C.E., Rivest, R.R.: Introduction to Algorithms. MIT Press, Cambridge (1990)  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm with Probabilistic Delta Consistency Using Flexible Combination of Push and Pull Algorithm for Wireless Sensor Networks Juhi R. Srivastava(&) and T.S.B. Sudarshan Department of Computer Science and Engineering, Amrita School of Engineering, Bengaluru Campus, Amrita Vishwa Vidyapeetham, Amrita University, Kasavanahalli, Carmelaram P.O., Bangalore 560 035, Karnataka, India [email protected]  , [email protected]   
   
  Abstract. Minimum energy consumption and minimum service delay with maximizing quality of service is key to a worthy WSN. Network lifetime and network connectivity lead to optimization. However, to handle the uncertainties present in WSNs, we need powerful heuristics to solve the optimization problem. A possible way to minimize power consumption is by the use of caching popular data by optimally selecting and placing cache nodes in the network. We propose the use of a powerful searching tool and a well-known soft computing technique; a multi-objective genetic algorithm to achieve optimization goals in the presented work. The proposed work proceeds in two steps to give a complete optimized network system with increased network lifetime. In the ﬁrst step we use genetic algorithm to carefully select and place cache nodes in the network with aims of maximizing ﬁeld coverage and minimizing network energy usage. In the second step we perform cache consistency on the cache nodes for valid data retrieval. We use the Probabilistic Delta Consistency (PDC) with Flexible Combination of Push and Pull (FCPP) algorithm. The cache consistency algorithm is implemented on the MAC layer and comparisons are made with 802.11 MAC layer without cache consistency using metrics; routing load, packet delivery ratio, end-to-end delay, normalized load and energy consumed. The network overhead is reduced considerably leading to speedy data access. The algorithm is designed for a clustered environment and is an extension of our previous work where we have successfully proved that genetic algorithm gives better results for node deployment when compared to the state of the art node placement algorithm ScaPCICC. The results are obtained by running the experiments on Matlab and ns2. Keywords: Genetic algorithm  Cache consistency Network  Optimization  Clustering  
   
    
   
  Wireless Sensor  
   
  © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_13  
   
  144  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  1 Introduction A Wireless Sensor Network (WSN) is comprised of a set of several identical sensor nodes with limited CPU and storage capacity and is a special class of ad hoc networks. In a typical example, nodes are capable of sensing environmental attributes, such as temperature, light and humidity, allowing researchers to monitor an area of interest remotely, inconspicuously and continuously. Some of the unique characteristics of a Wireless Sensor Networks like ability to withstand harsh environmental conditions, ability to cope with node failures, mobility, dynamic network topology, communication failures, heterogeneity of nodes, large scale of deployment, unattended operation makes their use in certain applications indispensable. Many applications for WSN have been discussed in the literature. A few include environmental/habitat monitoring, acoustic detection, seismic detection, military surveillance, inventory tracking, medical monitoring, smart spaces, process monitoring and trafﬁc management. However, to work seamlessly and achieve application and user level satisfaction, a WSN faces many challenges. The goal of achieving application-level QoS, with minimum energy consumption and minimum service delay in WSNs becomes a very challenging task. Minimum energy consumption and minimum service delay with maximizing quality of service is key to a worthy WSN. A sensor node failure due to energy depletion would lead to network partitions, path breaks, new route setup and therefore, latency in service and data provisioning. It is observed that most of the energy spent by a sensor node is during listening to the channel, data routing and sensing. Routing or data transmission is a foremost reason for high energy dissipation by sensor nodes. When compared; the amount of energy spent during computation with the energy spent during communication, it is observed that transmitting a single bit through a transceiver expends more energy than computing a single instruction on a processor. Routing in WSNs is data centric than address centric. All sensors detecting and sensing the event report to the sink generating redundancy of messages. However, one disadvantage associated with routing is every time an information is required, it has to be fetched from the source which might be several hops away from the sink. This also invokes participation of all the sensor nodes present in the path thus leading to energy drainage. Literature show tremendous contributions in the design of exceedingly competent routing algorithms for WSNs, however, even with a highly energy efﬁcient data routing protocol, a WSN that is designed for continuous monitoring application can achieve more energy efﬁciency by other means. Battery life time of a sensor node can be extended if amount of communication and computation done by a node is reduced. A possible way to minimize power consumption is by the use of caching the data. Caching of popular data can save a sensor network from exploitation of many of its scarce resources. To mention a few, caching helps in reducing amount of communication between nodes in the network, reduces network wide transmission, hence, reduces interference because of nodes, overcomes variable channel conditions, reduces network congestion, speeds data access by nodes and provides QoS with minimum energy consumption. However, caching can also considerably impact the system energy expenditure if not implemented efﬁciently; there are two vital design issues to be addressed in caching; ﬁrst selection of appropriate nodes to cache data and their  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  145  
   
  optimal positioning, i.e., optimal cache node placement and second, is cache consistency. Because of the mobility associated with nodes, caching strategy also requires cache consistency schemes to ensure that the cached objects are consistent with those stored in the server. Our study focuses on the data access algorithms using cache for WSNs. In literature, many algorithms have been proposed to address these issues to the best possible way but very few work reflect the use of any soft computing techniques to achieve the same. Soft Computing is the fusion of methodologies that were designed to model and enable solutions to real world problems, which are not modeled, or too difﬁcult to model, mathematically. These problems are typically associated with fuzzy, complex, and dynamical systems, with uncertain parameters. The uncertainty associated with the network state information is inevitable in terms of, both, fuzziness and randomness. A powerful advantage of soft computing is the complementary nature of the techniques. Used together they can produce solutions to problems that are too complex or inherently noisy to tackle with conventional mathematical methods. In our work, we have used genetic algorithm as an optimization technique to place the Caching Nodes (CN) optimally. We also perform a Flexible Combination of Push and Pull (FCPP) [4] algorithm on the cached nodes to provide user-speciﬁed consistency prerequisites using the Probabilistic Delta Consistency (PDC) model. We have used a clustered WSN network environment with cluster head and cluster members to implement our algorithms. We use MATLAB and ns2 simulators for performing our experiments.  
   
  2 Related Works 2.1  
   
  Genetic Algorithm  
   
  Optimization helps to enhance system performance by selecting optimal point within a given set of strictures or circumstances. The key concept in optimization is to be able to make assessment of the system resources and accordingly make decisions that can minimize the exploitation of these resources to achieve the desired objective with maximized desired output. Considering WSNs, we understand that battery life time of a sensor node can be extended if amount of communication and computation done by a node is reduced. In other words, network lifetime and network connectivity lead to optimization. However, to handle the uncertainties present in WSNs, due distance between nodes, communication channel, we need powerful heuristics to solve the optimization problem and therefore soft computing has been involved to achieve the desired optimization goals in the presented work. The aim of the presented work is to optimize the placement of cache nodes in WSNs. We try to select ﬁnest number of nodes in a given WSN to serve as cache nodes for complete network coverage. This optimal number of nodes to be selected as cache nodes is a tricky task as selecting large number of CNs may create redundant messages, caching new information in their small memories will require more enhanced techniques of cache replacement. All this would lead to depletion of vital resources like sensor and network energy, overload network bandwidth and also create network  
   
  146  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  congestion. While a smaller number of CNs may not be able to cover the entire application and may lead to network partitions hence leaving areas un-sensed while reporting an event. It has been observed that for many applications, the search space for optimization is excessively large or excessively expensive in terms of computation leading to a NP-hard search space. In such instances it is advised to use random search algorithms that also form the basis for studying non-linear programming techniques in research. Algorithms for optimization under this category are robust to noise, non-linearities and discontinuities. These random search algorithms can adapt to new environmental situations and yield optimized values even when the system parameters cannot be predicted at priori. Random search algorithms are also called as multi-objective programming methods as they can address more than one objective function for a given problem statement while maintaining coherency with the boundary conditions. Algorithms that mimic human brain and behavior have revolutionized the current available optimization methods. Some of these well-known algorithms are Memetic Algorithm (MA), Genetic Algorithm (GA), Shuffled Frog Leaping (SFL), Particle Swarm Optimization (PSO), Ant Colony Systems and Simulated Annealing (SA) [2]. All these techniques try to solve a problem in a comparable way; however, they still differ marginally in employing their optimization procedure. Each of these algorithms employs a depiction to suit the technique and then arrive at an optimal solution iteratively. Genetic Algorithms are powerful techniques in solving optimization problems with huge search spaces with large number of variables where usage of procedural algorithms is complicated. They can solve optimization problems which are non-linear, stochastic, non-differentiable, discontinuous or combinatorial in nature. Genetic algorithms employ evolution process observed in biological populations for selection of best off springs that lead to optimal solutions in successive iterations. This soft computing method generates chromosomes which are the optimization parameters represented in the form of bit strings that allows encoding of both discrete and continuous parameters contained in the same problem statement. An advantage of using GA is that the variables in GA take values within their described constraints and boundaries and therefore, no solutions fall out of the upper and lower limits deﬁned in the algorithm. If at all leak or violations occur it is due to functional restrictions of the design [2]. Authors Khanna et al. [5] have addressed creation of clustering with optimal cluster heads and cluster members in WSNs using GA. Their work is limited in identifying limits in large networks thereby applying GA and hence ﬁnding shortest convergence time becomes challenging. In his work, author Yang [11] uses GA for placing sink nodes optimally. Their algorithm helps in fast data delivery without much use of energy during data transmission. However, a major limitation of the work is that sink nodes can be located only at certain sites known as feasible sites. Author Youssef et al. [13], has used GA for energy efﬁcient gateway positioning to reduce data access delay. However, their work is not scalable and therefore does not allow large number of gateways in the network. Authors Yong et al. [12], have used GA in a cluster based WSN to ﬁnd optimal transmission power of cluster heads and cluster members for data transmission with  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  147  
   
  reduced energy consumption. Their work does not consider nodes which are out of range for transmissions. Authors Mollanejad et al. [6], focus on repositioning of base stations using GA for faster data transmission. They consider a small error bound along with network parameters like residual energy and distance for optimized location allotment. However, they consider a static network with each sensor having a GPS system thereby increasing the cost. Wang et al. [10] have used GA for placing sensors which lead to an optimal path planning. However, they have not considered energy parameter in their algorithm. Author Hoyingcharoen et al. [3], have used GA for selecting optimal number of sensors to guarantee minimum detection probability. However, his work does not consider energy and connectivity of nodes. Sun et al. [9], use GA for deploying relay nodes for complete network coverage. They have modeled their system as a graph and use only a single objective function with a penalty constraint that removes any leaks in the solution from the constraint. The proposed work is an extension of our previous work [7], where we use genetic algorithm against state of the art algorithm ScaPCICC for optimal cache node placement in WSNs. We have been successful in proving that genetic algorithm performs better in terms of reducing data access delay and number of messages in the network, while achieving energy efﬁcient optimal cache node deployment in WSNs. 2.2  
   
  Cache Consistency  
   
  It is crucial that the data fetched from a cache is not old and represents a fresh version. We can achieve this by using cache consistency schemes that maintain the cached data consistent with those existing in the server (Fig. 1). Cache updates can be initiated by the server, CN or can be a cooperative process. In the server based approach also called push method, invalidation messages are broadcasted by the server to all the CNs  
   
  Fig. 1. Consistency models  
   
  148  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  indicating the update status of data items; whereas in the second case also known as pull mechanism, it is the CN that polls the server to determine the version of the cached item. However, for some applications a combination of push-pull method can be used. This cooperative cache consistency scheme allows for fresh retrievals of cached data at all points of time, however, cooperative schemes combine the advantages and the disadvantages of both the methods. Depending on the application, the server may or may not keep the record of CNs and their associated data items. If records are maintained then it is called the Stateful (SF) approach otherwise it is known as the Stateless (SL) system. Though SF approach is not scalable but yet it is more efﬁcient as server performs multicast of invalidation reports thus reducing on the number of messages in the network. SL keeps track of the Table 1. Summary of cache consistency schemes Cache consistency schemes Push model  
   
  Consistency level  
   
  Cache status maintenance  
   
  Limitations  
   
  STATEFUL  
   
  TTR mechanism  
   
  Strong consistency Weak consistency Strong consistency Strong consistency  
   
  TTL mechanism  
   
  Strong consistency  
   
  STATELESS  
   
  Client Poll/Pull each read mechanism Hybrid mechanism Server invalidation mechanism  
   
  Strong consistency  
   
  STATELESS  
   
  Strong consistency Strong consistency  
   
  STATELESS  
   
  Overhead caused as server has to maintain state of all cache nodes Since cache initiated pull, cache node miss updated data If lease period is more, critical data might not be updated by server TTR value has to be adaptive based on hot and cold data items in order to maintain stringent consistency requirements No assurance from the server that the datum will not be modiﬁed within TTL expires Every read at the cache node adds to round trip delay & network overload due to the generated control messages Disadvantages of both TTL and client poll mechanisms State has to be maintained indeﬁnitely causing wastage of space & many invalidations have to be send when an object is modiﬁed causing network overload Long query latency, nodes having same copies query server separately thus increasing overheads & clients in long dose mode may miss IRs Overhead in network caused due to UIR and IR messages floated  
   
  Pull model LEASE  
   
  STATELESS STATEFUL STATELESS  
   
  STATEFUL  
   
  IR based invalidation mechanism  
   
  Strong consistency  
   
  STATELESS  
   
  UIR based invalidation mechanism  
   
  Strong consistency  
   
  STATELESS  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  149  
   
  update history and occasionally floods the updates through invalidation messages generating extensive communication overhead. However, according to application constraints the consistency requirements can be stringent (strong consistency) leading to all time fresh version delivery otherwise can tolerate data which does not guarantee consistency also called weak consistency. If the tolerance of serving a data is never more than more than D time with the data at the server, then it satisﬁes delta consistency. In MANETS a more common technique used for consistency is called the probabilistic consistency model. Here a query is answered when the data item received back is consistent with the server with a probability of at least C, where C; (0  C  1) is a design pre-deﬁned consistency level. Table 1 gives a summary of various cache consistency schemes [14]. We employ Flexible Combination Of Push and Pull (FCPP) algorithm for cache consistency [4]. The main idea behind using FCPP is that it allows the data source node to delay the update till all the ACKs are received or until the time-out values for all the silent caching nodes expire. FCPP is a strong consistency algorithm that considers Lease protocol as a special case. FCPP beneﬁts users by providing user deﬁned consistency requirements, thus allowing invocation of Pull or Push mechanism whenever necessary. We now proceed to discuss the presented work in detail.  
   
  3 Proposed Algorithm 3.1  
   
  Cache Node Placement Using Genetic Algorithm - Methodology and Network Model  
   
  We propose a multi-objective GA based node placement algorithm for WSNs which optimizes the placement of cache node in WSN by optimizing the network functional parameters like ﬁeld coverage and number of sensors per CN, while minimizing network constraints like network energy usage, the number of out of coverage or unconnected sensor nodes and number of overlapping CNs. The technique is designed for a clustered WSN used for monitoring applications and focuses on positioning of three types of sensor nodes in a 2-dimensional L  L square grid conﬁguration with predeﬁned Euclidean distance between the units. It identiﬁes nodes as CNs, n1 (high signal range, HSR), n2 (low signal range; LSR). The algorithm also considers inactive sensor nodes which have no role and are silent though not dead in the network. GA in the proposed algorithm tries to situate these nodes optimally so that the ﬁeld coverage and number of sensors per CN is maximized. The design assumes placing of each sensing node on the intersection points of the square grid for complete network coverage (Fig. 2). The nodes categorized as CN, LSR, HSR, and inactive nodes sensor nodes are encoded in a row by row style with each individual represented by a bit string of size 2L2 (Fig. 3) [7]. For cache node discovery we use Scaled Power Community Index Cooperative Caching (ScaPCICC) [1]. For a given graph G = (V, E), it is deﬁned as  
   
  150  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  Fig. 2. Network diagram  
   
  Fig. 3. Node representation in WSN  
   
  ScaPCICC ¼ PCIðvÞ=CðvÞ; where, PCI(v) = C(v) =  
   
  ð1Þ  
   
  power community index clustering coefﬁcient  
   
  PCI is deﬁned as one hop direct connection or neighbors of node v which is represented as vertex in the graph. Also known as degree of node v and C(v) is described as  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  cðvÞ ¼ ð2 * LvÞ=ðdv * ðdv  1ÞÞ  
   
  151  
   
  ð2Þ  
   
  where, dv = Degree of node v Lv = # of links among dv neighbor of node v In other words, PCI value of a node indicates its control over other nodes whereas, Scaled PCI gives the minimum cardinality of all the nodes connected in the subgraph and the adjacent nodes in the dominating set of graph G. ScaPCICC displays high accuracy in selection of nodes and can work well for isolated nodes. Nodes selected using ScaPCI become the cache nodes which along with other nodes are encoded in bit string to form chromosomes that can proceed to the next level of optimization process using GA. In the proposed algorithm we use a weighted sum approach to organize all the desired objectives in a single ﬁtness function. F ¼ min  
   
  X5  
   
    
   
  kx i¼1 i i  
   
  ð3Þ  
   
  where, F is deﬁned as F ¼ a1 FC þ a2 SpCN þ a3 NetE þ a4 OpCnE  a5 SORE  
   
  ð4Þ  
   
  and values of coefﬁcients ai = 1, 2, 3, .. are decided based on design constraints and experimentations. We deﬁne ﬁeld coverage consisting of components like Ncn (number of CNs sensors), number of nodes with HSR value; Nn1, number of LSR nodes; Nn2, number of inactive sensors; Ninact, number of out of range sensors; Nor and total number of sensing points; Ntotal. We deﬁne SpCN as Sensors-per-Caching Node, NetE as network energy, OpCnE is deﬁned as Overlaps-per-Caching node- Error and SORE as Sensors-Out-of-Range Error [7]. 3.2  
   
  Cache Consistency Using Flexible Combination of Push and Pull (FCPP)  
   
  Once cached nodes are created and popular or most frequently accessed data are cached then the next step is to maintain cache consistency. Cache consistency is necessary to ensure valid data access between the source node that detects the data ﬁrst and its cached copies. Maintaining cache consistency incurs heavy overhead in WSNs as different users have different consistency requirement. For example some applications require frequent updates like stock market whereas; few applications allow some tolerance level in accessing the data like weather forecast. It therefore, becomes essential to allow users to tune in to their consistency requirements leading to a flexible adaptation to data update rate in the cached nodes. This also results in a trade-off between maintaining user-deﬁned consistency requirements and consistency maintenance cost. The consistency model selected in the presented work is called the Probabilistic Delta Consistency (PDC) method. To further maintain user- speciﬁed consistency condition  
   
  152  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  at minimum cost we use the Flexible Combination of Push and Pull (FCPP) algorithm. We will discuss each technique in detail. Probabilistic Delta Consistency allows users the flexibility to deﬁne their consistency requirements in two dimensions orthogonal to each other. The x-axis indicates the maximum tolerable deviation in d time or value that can exist between the source data and the cached copies. Whereas, the y-axis denotes the probability p, which accounts for the minimum ratio of queries answered by consistent cached copies. PDC model is versatile in setting the consistency requirements in a network. PDC represented as (p, d) helps identify the consistency level of a system. For example PDC (0, 100) indicates strong consistency whereas PDC (*, 0) indicates weak consistency (Fig. 4) [4].  
   
  Fig. 4. Probabilistic delta consistency representation  
   
  To satisfy the consistency requirement with minimum cost we use the FCPP algorithm. FCPP associates a time-out value with every cached copy based on the d and p values. Cache updates are made by the data source node by sending an (INV) message for which it receives an acknowledgement (INV_ACK) from cached nodes for valid time-out values of the cached copies. However, data updates can be postponed until it receives all the ACKs or until the time-out values of the entire un-responding nodes end or the upper limit of the acceptable delay of data update is reached. The key issue in implementing FCPP is to be able to quantify the tradeoff between consistency and cost. FCPP converts to Pull option when the time-out value 1 is shifts to zero, whereas, it transforms to Push format. FCPP works on both cache node and the data source node. On cache node the algorithm is described below: FCPP on caching node Step 1: Receive data request query (a) IF (l > 0) serve the request with the consistent cache copy; (b) ELSE // the time-out value l is decreased to zero  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  153  
   
  Step 2: generate a RENEW message for a new time-out value and update copy if needed; Step3: Time-out value l is renewed; serve the user request with the updated cache copy; FCPP on the data source node Case 1: The source data is ready to be updated Step1: Send invalidation message (INV) to caching node with positive l; Step2: IF (INV_ACK is received from all cached nodes or D seconds have expired) (2.1) Update the source data; Case 2: On arrival of a RENEW message Step3: IF (source data update is complete) (3.1) Send updates to the caching node; Step4: IF (no pending updates) (4.1) Allow cache nodes to cache copies with time-out values 1; FCPP is implemented on to the MAC layer of the cache node. We move to the simulations and results to see the advantages of the proposed algorithms.  
   
  4 Simulation and Results 4.1  
   
  GA Simulation and Results  
   
  GA Simulation parameters are provided in (Table 2). At the start of the GA simulations, each coefﬁcient were assigned a unity value, however, with course of the experimentation the optimal values of the variables were determined. Figure 5 shows  
   
  Fig. 5. Fitness values for the best individuals against average ﬁtness value of the population  
   
  154  
   
  J.R. Srivastava and T.S.B. Sudarshan Table 2. GA simulation parameters  
   
  Parameter Area Crossover Mutation Selection Number of GA runs Number of nodes Stability seen (termination criteria – no change in value) Base station location  
   
  Value Grid size of 700 cm  1200 cm Two-point (p = 0.8) Nonlinear (p = 0.1). elitism Roulette wheel 3000 100 (results shown for 34 nodes) 300 runs Node numbered 0, placed at the centre  
   
  the ﬁtness values for the best individuals against average ﬁtness value of the population during the GA run. The value stabilizes to 37.8 from 300 runs improving the ﬁtness value to 9.2% at 300 runs and 5.7% at 3000 generations (Fig. 5). In spite of initial randomness due to search for best individuals, the network energy stabilizes to optimum value of 1.73 (Fig. 6).  
   
  Fig. 6. Network Energy (NetE)  
   
  Figure 7 shows that the OpCnE parameter which is the number of overlaps between the cache nodes successfully reduces as the GA runs proceed towards stabilization. The OpCnE value becomes zero as the experiment progresses from 300 GA iterations.  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  155  
   
  Fig. 7. Overlaps-per-Caching node-Error (OpCnE)  
   
  From Fig. 8, it is evident that after the experiment stabilizes the sensors out of range for a cache node is reduced by 11.2% (11.2 mark) and ﬁnally diminishes to zero from 300 generations onwards.  
   
  Fig. 8. Sensor Out of Range Error (SORE)  
   
  156  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  Fig. 9. Sensor-per-Cache Node (SpCN)  
   
  Fig. 10. Field coverage (FC)  
   
  Figure 9, is aimed at optimizing the ﬁtness function parameter SpCN. The number of Sensors- per- Cache Node graph indicates an increased value of 22 from its previous value of 3.6 mark. This experiment leads to graph in Fig. 10 which shows 89% increase in the ﬁled coverage. Maximizing ﬁled coverage and reduced data access delay with minimum energy usage achieved through optimal cache node selection and placement is the key concept in the presented work. The optimized network obtained from the MATLAB simulator after running GA gives a text ﬁle with location information of all the nodes in the WSN. The cluster  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  157  
   
  Fig. 11. Connectivity graph of the optimized network obtained after running GA  
   
  heads, cluster members and the identiﬁed cache nodes locations coordinates are now fed into the ns2 simulator for maintaining cache consistency requirements. Table 3 shows the text ﬁle which is the optimized network obtained after using GA for cache placement in WSN for PCI > 70. The PCI value helps to decide the optimal number of CNs required to cover the entire network. Figure 11 shows the connectivity graph of the optimized network (degree of each node) obtained after running GA over WSN for optimal selection and placement of CNs. From Fig. 11 we can understand the roles of each sensor node in the network for one complete cycle of data transmission. A useful cluster conﬁguration is obtained only if we have a good CH (Cluster head) to CM (Cluster member) ratio so that, clustering covers the entire network using minimum network energy enhancing network lifetime. The optimal ratio of CH to CM for N nodes organized in a clustered architecture is given by CH fraction [8]. CHFrac ¼ CH=N  
   
  ð5Þ  
   
  where, N is total number of nodes given by following equation N ¼ jCHj þ jCMj  
   
  4.2  
   
  ð6Þ  
   
  FCPP Simulation and Results  
   
  FCPP simulation parameters are provided in (Table 4). In the presented, work Flexible Combination of Push and Pull (FCPP) algorithm has been deployed on to the MAC Layer. Comparison of FCPP implemented network with 802.11 MAC layer is done in terms of Packet Delivery Ratio, End-to-end delay, normalized routing load, Routing overhead (in terms of number of packets) and Energy consumed (Tables 5 and 6).  
   
  158  
   
  J.R. Srivastava and T.S.B. Sudarshan Table 3. Optimized network generated by using the genetic algorithm Node ID X coordinate 1 978 2 604 3 41 4 605 5 571 6 618 7 1065 8 1042 9 36 10 882 11 465 12 47 13 728 14 585 15 331 16 219 17 88 18 1040 19 534 20 811 21 215 22 777 23 543 24 1065 25 796 26 689 27 160 28 941 29 452 30 338 31 1046 32 94 33 255  
   
  Y coordinate 437 145 301 337 272 655 614 72 268 464 692 126 275 515 154 633 436 586 621 401 408 664 493 311 388 85 209 74 65 524 636 694 373  
   
  Role Head Head Head Member Head Member Member Head Member Head Head Cache node Head Cache node Member Head Head Member Member Cache node Member Head Member Cache node Head Head Member Member Member Cache node Head Member Member  
   
  Figures 12, 13, 14, 15 and 16 shows that FCPP performs better over 802.11 MAC layer. Tables 5 and 6 shows a comparative analysis between FCPP implemented MAC layer with 802.11 MAC layer.  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  159  
   
  Table 4. FCPP simulation parameters Parameter Number of nodes Area Base station/sink Maximum node velocity (Vmax) Minimum node velocity (Vmin) Pause time (Tp) Simulation time MAC Consistency requirement p Consistency requirement d Routing protocol Maximum delay before data update Average update interval Mobility model  
   
  Value 30–100 700 cm  1200 cm Center of the area (node ID = 0), assumed stationary 20 m/s 0 m/s 0 m/s 100 s IEEE 802.11 60–90% 2 s–20 s AODV 2s 20 s–80 s Random way point  
   
  Fig. 12. Packet delivery ratio 802.11 MAC layer versus FCPP implemented MAC layer  
   
  160  
   
  J.R. Srivastava and T.S.B. Sudarshan  
   
  Fig. 13. End-to-end delay 802.11 MAC layer versus FCPP implemented MAC layer  
   
  Fig. 14. Normalized routing load 802.11 MAC layer versus FCPP implemented MAC layer  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  161  
   
  Fig. 15. Routing overhead 802.11 MAC layer versus FCPP implemented MAC layer  
   
  Fig. 16. Energy consumption 802.11 MAC layer versus FCPP implemented MAC layer  
   
  162  
   
  J.R. Srivastava and T.S.B. Sudarshan Table 5. 802.11 MAC layer  
   
  For pause time (in seconds) 5 6 7 8 9  
   
  Packet delivery ratio 60.48 63.56 64.48 59.05 58.49  
   
  End-to-end delay  
   
  Normalized routing load  
   
  Routing overhead  
   
  Energy consumed  
   
  1.234 1.260 1.36 1.42 1.47  
   
  0.954 0.757 0.72 0.64 0.611  
   
  289 289 327 301 322  
   
  54.48 65.05 82.41 85.29 97.42  
   
  Table 6. FCPP implemented MAC layer For pause time (in seconds) 5 6 7 8 9  
   
  Packet delivery ratio 81.64 79.37 78.46 77.90 76.69  
   
  End-to-end delay  
   
  Normalized routing load  
   
  Routing overhead  
   
  Energy consumed  
   
  1.06 1.10 1.13 1.16 1.18  
   
  0.174 0.149 0.129 0.114 0.103  
   
  71 71 71 71 71  
   
  55.53 65.32 75.62 85.89 95.55  
   
  5 Conclusions and Future Work In the presented work we propose a scheme for cache node selection and optimal placement of selected cache nodes in WSNs using genetic algorithm. The proposed algorithm uses a multi objective ﬁtness function and aims at minimizing the network energy usage during data transmission, thus resulting in an increased network lifetime. The technique is designed for a clustered WSN used for monitoring applications. The work further progresses by performing cache consistency on the cached nodes to guarantee valid data retrieval by users. To achieve this we use the Flexible Combination of Push and Pull algorithm which is implemented over the 802.11 MAC layer. The algorithm FCPP is run on cached nodes and data source node for valid data access by users. The cache consistency algorithm is implemented on the MAC layer and comparisons are made with 802.11 MAC layer without cache consistency using metrics like routing load, packet delivery ratio, end-to-end delay, normalized load and energy consumed. The results obtained clearly show that cache placement using GA is effective in achieving maximum ﬁeld coverage of 89% in WSN while reducing network energy consumption thus granting an increase in network lifetime. The cache consistency algorithm FCPP further helps the network in faster data retrieval without message overheads generated in the network. It proves to be a very convenient choice for users to tune their consistency requirements with ease and at the same time avoid too many transmissions in the network thus leading to an energy efﬁcient network system. However, the algorithm FCPP is limited when frequency of data updates are high and the network is unstable. FCPP algorithm performs best when  
   
  Energy Efﬁcient Cache Node Placement Using Genetic Algorithm  
   
  163  
   
  the user requirements are more severe. The experiments were completed using MATLAB and ns2 simulator. For future work, we propose enhancement in the MAC layer to further improvise on the results. We would also like to consider varied needs of dissimilar users for data retrieval using FCPP. We ﬁnally propose to deal with situations with mobile base stations. Conflict of interest. Authors declare that they have no conflict of interest  
   
  References 1. Dimokas, N., Katsaros, D., Tassiulas, L., Manolopoulos, Y.: High performance, low complexity cooperative caching for wireless sensor networks. Wirel. Netw. 17, 717–737 (2011). doi:10.1007/s11276-010-0311-x 2. Elbeltagi, E., Hegazy, T., Grierson, D.: Comparison among ﬁve evolutionary-based optimization algorithms. Adv. Eng. Inf. 19(1), 43–53 (2005). doi:10.1016/j.aei.2005.01.004 3. Hoyingcharoen, P., Teerapabkajorndet, W.: Fault tolerant sensor placement optimization with minimum detection probability guaranteed. In: Eighth International Workshop on the Design of Reliable Communication Networks (DRCN) (2011) 4. Huang, Yu., Cao, J., Jin, B., Tao, X., Lu, J., Feng, Y.: Flexible cache consistency maintenance over wireless adhoc networks. IEEE Trans. Parallel Distrib. Syst. 21(8), 1150– 1161 (2010) 5. Khanna, R., Liu, H., Hwa Chen, H.: Self-organization of sensor networks using genetic algorithms. In: Proceeding of International Conference on Communications, vol. 8 (2006) 6. Mollanejad, A., Khanli, L.M., Zeynali, M.: DBSR: dynamic base station repositioning using genetic algorithm in wireless sensor network. In: Second International Conference on Computer Engineering and Applications, pp. 521–525 (2010) 7. Srivastava, J.R., Sudarshan, T.S.B.: Energy-efﬁcient cache node placement using genetic algorithm in wireless sensor networks, “Soft Computing” Journal, Springer (2014). doi:10. 1007/s00500-014-1473-8 8. Srivastava, J.R., Sudarshan, T.S.B.: A genetic fuzzy system based optimized zone based energy efﬁcient routing protocol for mobile sensor networks (OZEEP), Appl. Soft Comput. J., Elsevier, vol. 37, pp. 863–886, December, 2015. doi:10.1016/j.asoc.2015.09.025 9. Sun, P., Ma, J., Ni, K.: A genetic simulated annealing hybrid algorithm for relay nodes deployment optimization in industrial wireless sensor networks. In: IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA) (2012) 10. Wang, Y., Li, X., Tian, J.: Blackboard mechanism based genetic algorithm for dynamic deployment of mobile sensor networks. In: International Conference on Electronic & Mechanical Engineering and Information Technology (2011) 11. Yang, L.: Determining sink node locations in wireless sensor network. In: IEEE International Conference on Systems, Man, and Cybernetics, vol. 4, Taiwan (2006) 12. Yong, M., Huludao, L., Yu, Y., Yan, W.: Optimization design of coal mine body sensor network based on Genetic Algorithm. In: International Conference on Network Security, Wireless Communications and Trusted Computing (2009). doi:10.1109/NSWCTC.2009.347 13. Youssef, W., Younis, M.: Intelligent gateways placement for reduced data latency in wireless sensor networks. In: Proceedings of the 32nd IEEE International Conference on Communications (ICC 2007). Glasgow, Scotland, UK (2007) 14. Cao, J., Zhang, Y., Xie, L., Cao, G.: Data consistency for cooperative caching in mobile environments. Computer 40(4), 60–67 (2007)  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm: Application to the Security for Transmission of Medical Images Med Karim Abdmouleh(B) , Hedi Amri, Ali Khalfallah, and Med Salim Bouhlel Research Unit: Sciences and Technologies of Image and Telecommunications, Higher Institute of Biotechnology, University of Sfax, Sfax, Tunisia [email protected]  , [email protected]  , [email protected]  , [email protected]   
   
  Abstract. Over the past years, the use of telecommunications and information technologies in medicine is evolving. This involves the development of the applications bound to the telemedicine and based on a network medical image transmission. Therefore, the optimization of medical application performances remains a necessity. In this paper, we propose a novel and eﬃcient crypto-compression algorithm. This novel scheme concerning the application of a partial encryption to the JPEG2000 ﬁle format. Our algorithm is rapid, eﬃcient, secure and it perfectly preserves the performances of the JPEG2000 compression algorithm. In addition, the proposed transmission scheme is adapted to the Telediagnostic sector and can be easily integrated in JPEG2000 coder. Keywords: Crypto-compression · JPEG2000 · RSA · Medical images Transmission · Telemedicine  
   
  1  
   
  ·  
   
  Introduction  
   
  The extraordinary evolution of information technologies in the medical sector is motivated by political, professional and industrial wills. Currently, Telediagnostic is considered as the most potential sector in telemedicine [11–15]. It allows two or several medical teams to exchange medical information and to comment on it in a context of diagnosis help. This sector is the result of the creation of “proﬁciency poles” that is involved by the medical hyper specialization. Given the importance of this sector in the improvement of the care quality, the reduction of treatment costs and the universalization of the medical practices and knowledge, it is necessary to optimise this class of applications. To do this, both encryption and compression must be performed [4]. Various encryption schemes for JPEG2000 images have been proposed [16,17,19,26,30,35,36]. Based on the order to mix compression and encryption c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 14  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  165  
   
  together to reduce the overall processing time [6,7,20,25,28,34], but they are either insecure or too computationally intensive and may induce degradation of coding eﬃciency. In fact, network communication, especially on the World Wide Web, can be intercepted. Therefore, there is a risk of placing at the disposal of eavesdroppers the secrecies of patients’ state during the transmission of medical data through a non-protected network. Thus, the encryption of the medical image is imposed to assure the deontology and the safeguard of patient medical secrecy. In particular, the asymmetric encryption can also be used to assure the authentication of medical image transmission. In addition, because of the important size of medical images after the digitalisation, we must compress them in order, ﬁrst, to improve the capacity of storage, and second to optimize theirs transmission through networks (reduction in the transmission time and in the obstruction of networks). To satisfy these conditions, the classic approach consists in applying a compression algorithm to the medical image [4,27]. The output is then encrypted with an independent cryptographic algorithm. Unfortunately, the processing time in classical cryptographic algorithms is too long to satisfy the Telediagnostic required speed because this type of application is mainly used in a case of emergency. The rest of this paper is organized as follows. In the Sect. 2, the encryption algorithm RSA and the JPEG2000 still image compression algorithm are brieﬂy described to facilitate the development of our proposed algorithm. Section 3 presents the principle of our approach. Then, the proposed encryption and decryption procedure is detailed. After that, the robustness of our algorithm against the diﬀerent types of attacks is discussed. Finally, the advantages of our algorithm are enumerated. Section 4 concludes the paper.  
   
  2 2.1  
   
  Background The Asymmetric Encryption Algorithm: RSA  
   
  The RSA is a public-key cryptosystem that was invented by Rivest et al. [31]. It may be used to provide both conﬁdentiality and authentication, and its security is based on the intractability of the integer factorization. The cryptosystem RSA utilizes two distinct keys: the public key and the private key. The ﬁrst type can be communicated freely, through an insecure channel, to all the correspondents susceptible to exchange data with the possessor of the private key. On the other hand, the private key must remain conﬁdential [2] (Fig. 1). 2.1.1 Key Generation For the creation of an RSA public key and a corresponding private key, each person X should, ﬁrst, generate two large random (and distinct) primes p and q, that have roughly the same size and then compute [29]: n = p × q and φ = (p − 1)(q − 1)  
   
  166  
   
  M.K. Abdmouleh et al. Public key (n, e) Original Image  
   
  Private Key (d) Encrypted Image  
   
  Encryption  
   
  Decryption  
   
  Reconstructed Image  
   
  Insecure Channel  
   
  Fig. 1. Principle of asymmetric encryption.  
   
  Afterwards, he should select a random integer e: 1 < e < φ, such that gcd(e, φ) = 1 Next, the extended Euclidean algorithm is used to compute the unique integer d : 1 < d < φ, such that e · d ≡ 1(modφ) As result, X’s public key is (n, e) and X’s private key is d [29]. 2.1.2 Algorithm Let’s suppose that a person Y wants to send encrypted data to X who must be able to decrypt these encrypted data. If the size of n in bits is t, the encryption processing requires, ﬁrstly, the break of data into k bits of blocks and the conversion of these bocks into their decimal representation (m). To encrypt each integer m, which is in the interval [0, n−1], Y should obtain X’s public key (n, e) and compute the corresponding c: c = me mod n Convert this c into binary representation, redo this operation with all the k bits of blocs, and ﬁnally send the encrypted data to X. After doing all the necessary conversions and breaks, X should use the private key d to recover m from c [29]: m = cd mod n The RSA adds a very signiﬁcant beneﬁt: it can serve to authenticate the sender of the data (e.g. a digital signature) [9,10,21]. In fact, the RSA keys are complementary: if one encrypt with a public key, it must use the private key for recovering the encrypted data (Fig. 2). Inversely, if one encrypt with a private Private Key (d) Original Image  
   
  Public key (n, e) Authentic Image  
   
  Encryption  
   
  Decryption  
   
  Reconstructed Image  
   
  Insecure Channel  
   
  Fig. 2. Principle of authentication with RSA algorithm.  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  167  
   
  key, it must use the public key to recover the encrypted data. Therefore, when X encrypts his own image with his own secret key, Y will be able to use the X’s public key to decrypt the image, and in this case, Y is certain that it is X who sent him the image because he is the only person who possess the secret key. 2.1.3 Security The security of the RSA algorithm is generally equivalent to the hardness of the factoring problem. In fact, to ﬁnd the private key d, the only possibility is the factorization of n [33]. However, we need to be careful in the choice of the key size for RSA because of the increase in computing power and the continuing reﬁnements of the factoring algorithms [33]. The last factoring record was achieved on December 12, 2009 when a sixinstitution research team led by T. Kleinjung threw down a challenge to decrypt RSA-768 number. The eﬀort took almost 2000 2.2 GHz-Opteron-CPU years according to the submitters, just short of three years of calendar time [22]. 2.2  
   
  JPEG2000  
   
  The JPEG2000 standard was created by the Joint Photographic Experts Group (JPEG) [1], also denominated as ISO/IEC 15444. It’s an image compression algorithm that allows great ﬂexibility, not only for the compression of images, but also for the access to the compressed data, such as the several progressive decoding modes: by resolution, by quality, by position or by region. Currently, this standard is divided into fourteen distinct parts, where Part 1 [18] describes the core coding system and Part 2 its extensions. However, only the ﬁrst part reached the International Standard (IS). This part describes mainly the decoding algorithm and the compressed data format: the codestream is the result of a juxtaposition of headers containing coding parameters and bit streams (a compressed form of image data). Since our approach is about the application of a partial encryption in the JPEG2000 ﬁle format, only a short preview about the codestream building will be presented in the next paragraph. The JPEG2000 ﬁle format (JP2 format): This format provides a foundation for the storing application of the speciﬁc data (metadata). A JP2 File represents a collection of boxes (Fig. 3) which design a building block deﬁned by a unique box type and length [1]. As shown in Fig. 4, four ﬁelds compose a box: the LBox, TBox, XLBox, and DBox ﬁelds. The LBox ﬁeld speciﬁes the length of the box in bytes. The TBox ﬁeld indicates the type of box (i.e., the nature of the information contained in the box). The XLBox ﬁeld is an extended length indicator that provides a mechanism for specifying the length of a box the size of which is too large to be encoded in the length ﬁeld alone. If the LBox ﬁeld is 1, then the XLBox ﬁeld is present and contains the true length of the box. Otherwise, the XLBox ﬁeld is not present [1]. The DBox ﬁeld contains data speciﬁc to the particular box type. Some of the JP2 File boxes are independent, and some of those boxes contain other boxes.  
   
  168  
   
  M.K. Abdmouleh et al.  
   
  JP2 File JP2 Signature box Profile box JP2 header box (superbox) Image header box Bit Per Component box Component Definition box Color Specification box 0 Color Specification box n-1 Palette box Resolution box (superbox) Capture resolution box Definition display resolution box Contiguous codestream box 0 Contiguous codestream box m-1 IPR box XML boxes UUID boxes UUID Info boxes (superbox) UUID List box Data Entry URL box  
   
  Fig. 3. Conceptual structure of JP2 File.  
   
  LBox TBox  
   
  XLBox (if required)  
   
  DBox  
   
  32 bits 32 bits  
   
  64 bits  
   
  Variable  
   
  Fig. 4. Box structure.  
   
  Box 0  
   
  Lbox 0  
   
  Box 1  
   
  Lbox 2  
   
  Lbox 3  
   
  Box 2  
   
  Box 3  
   
  Lbox 1  
   
  Box 4  
   
  Lbox 4  
   
  Fig. 5. Illustration of box length.  
   
  As a matter of terminology, a box that contains other boxes in its DBox ﬁeld is referred to as a superbox. The binary structure of a ﬁle is a contiguous sequence of boxes (Fig. 5).  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  3  
   
  169  
   
  The Fast Crypto-Compression  
   
  In this section, we will develop the proposed JPEG2000 based cryptocompression algorithm. This novel scheme concerning the application of a partial encryption to the JPEG2000 ﬁle format (Fig. 6). Firstly, the principle of the novel approach, on which our algorithm is based, is presented. Second, the proposed robustness of our algorithm to the diﬀerent type of attacks is proved. Finally, the advantages of our crypto-compression technique are enumerated.  
   
  Original Medical Image  
   
  Reconstructed Medical Image  
   
  JPEG2000 Compression  
   
  JPEG2000 Decompression  
   
  Partial Encryption in JPEG2000 File Format  
   
  Partial Decryption in JPEG2000 File Format  
   
  Insecure Channel  
   
  Fig. 6. Scheme of our approach.  
   
  3.1  
   
  Principle of Our Approach  
   
  If we examine the JP2 File structure attentively, we conclude that most of the information in this type of ﬁle is independent (Structure in packet). Therefore, to design an eﬃcient crypto-compression algorithm, we must touch the totality of the ﬁle structure. Since the JP2 File format is composed of boxes, and the ﬁrst 32 bits (Lbox) of every box contain the box length information. Actually, the basic idea of our approach consists of encrypting only the Lbox part of every box in the JP2 File format excepting the boxes included in a superbox. Consequently, it will be impossible to recover the original data because the correct box length is unknown. As a result, the image is protected. 3.2  
   
  Encryption Algorithm  
   
  In Sect. 2, it is noted that the principle of the RSA algorithm consists of encrypting a blocs of K bits (where K is the length in bits of the RSA key). Hence, if one uses the RSA algorithm for encrypting, the length L of the data that can be encrypted, in bits must be a multiple of K : L = n × K (n is an integer)  
   
  170  
   
  M.K. Abdmouleh et al.  
   
  Since it is possible that the Lbox bit sequence is not a multiple of K bits, we propose the following encryption procedure: • Regrouping all the Lboxes in a structure of a contiguous bit sequence without changing their order (Fig. 7a). This (32 × B) bit sequence must be placed at the beginning of the JP2 File (where B represents the number of JP2 File boxes excepting those that are included in a superbox). • Adding 32 bits in order to indicate the length of the Lbox sequence length (32 × B bits) because the recovering of the original data requires the transmission of the Lbox sequence length. This few added bits must also be placed at the beginning of the JP2 File but before the Lbox sequence (Fig. 7b). • Determine an integer N that veriﬁes: N < K and (32 + 32 × B + N ) is a multiple of K Then, we encrypt the (32+32×B+N ) bits with the RSA encryption algorithm (Fig. 7c). For decryption the encrypted data in the reception, we must: • Decrypt the K bits from the beginning of JP2 File. The ﬁrst 32 decrypted bits allow the determination of the Lbox sequence length (32 × B bits) (Fig. 7d). • Search the integer N, with the same way that is employed at the encryption stage. Once N is determined, we must decrypt the remaining encrypted data: [(32 + 32 × B + N ) − K] bits. • Delete the ﬁrst 32 bits that indicate the Lbox sequence length. • Place the new ﬁrst 32 bits (corresponding to the Lboxes of the ﬁrst Box in JP2 File) just after the Lbox bit sequence. Consequently, the length of the ﬁrst box is known. The second 32 bits are placed just after the end of the ﬁrst box. Since the length of the second box is known, we can place the next 32 bits at the end of the second box and so forth until all the Lboxes in their original places (Fig. 7e). After the decryption stage, the original image is recuperated by decoding the resulting JP2 File with any classical JPEG2000 decoder. 3.3  
   
  Security  
   
  In this part, we discuss the robustness of our crypto-compression algorithm against diﬀerent attacks through the cryptanalysis that is the study of breaking encryption algorithms. In this discussion, we assume that the cryptanalyst have full access to the description of the algorithms, as well as full access to the insecure channel through which the image is transmitted [33]. The security of our image cryptosystem will be analysed for the following four types of attacks, such as exhaustive key search attack, cipher image-only attack, known-plain image attack, and chosen-plain image attack. In the Exhaustive key search, the cryptanalyst tests each of the possible keys one at a time until the correct plain image is recognized [8]. Since we use  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  171  
   
  LBoxes (32 bits)  
   
  Box 1  
   
  (a)  
   
  A supplementary 32 bits (The Lboxes bit sequence length)  
   
  (b) N bits  
   
  x.K bits (x is an integer)  
   
  Encrypted Data  
   
  (c)  
   
  K bits  
   
  (d)  
   
  (e)  
   
  Fig. 7. The proposed encryption and decryption stages.  
   
  the RSA keys for the encryption and decryption of the box bit sequence in our algorithm, the break of our algorithm with this type of attack is equivalent to the test of all the possible RSA Keys. In the cipher image-only attack, the cryptanalyst has access only to several images that are encrypted with the same key. The cryptanalyst attempts to recover the corresponding plain image or the decryption key [8].  
   
  172  
   
  M.K. Abdmouleh et al.  
   
  Since it is impossible to recovering the RSA decryption key, and it is impossible to recovering any information about the original data without the acquaintance of the length of the JP2 File boxes (Lbox), our algorithm is robust against this type of attacks. In the Known-plain image attack, the cryptanalyst has access to the cipher image and the corresponding plain image of several images encrypted with the same key. The cryptanalyst attempts to recover the key or to design an algorithm to decrypt any image that is encrypted with the same key [33]. In the case of our algorithm, the encryption is made on a bloc of K bits (RSA principle). The result of the RSA encryption of two original K bits blocs that contain few diﬀerent bits is two K bits blocs that are completely diﬀerent. Since the original bit sequence of two similar images contain certainly few diﬀerent bits, it is impossible to ﬁnd a relation between the original and the encrypted blocs. Consequently, it is useless to cryptanalyse our algorithm with a know-plain image attack. In the Chosen-plain image attack, the cryptanalyst is allowed to choose the plain image that is encrypted, and observe the corresponding cipher image. The cryptanalyst’s goal is the same as that in a known-plain image attack. The cryptanalyse of our algorithm is equivalent to that of the bit sequence that is encrypted with RSA encryption algorithm. As a consequence, the break of our crypto-compression algorithm with the chosen plain image attack is equivalent to that of the RSA technique with this type of attack. 3.4  
   
  Advantages of Our Scheme  
   
  • Our algorithm is rapid. In fact, we encrypt only the Lbox part (32 bits) from the whole information that can be contained in the JP2 File. Therefore, our approach allows an enormous reduction of the encrypting-decrypting processing time. • Our algorithm perfectly preserves the performances of the JPEG2000 compression algorithm [32] because the encryption is made after all the compression stages, and therefore, it does not tamper with the compression ratio. The 32 bits, which are added to communicate the Lbox bit sequence length, are too negligible, therefore, one cannot consider this fact as an inconvenient. • Moreover, our algorithm is secure. In fact, it is demonstrated in Sect. 3 that the security of our crypto-compression system is equivalent to that of the RSA algorithm. This security depends essentially on the key length. According to the RSA factoring records, if we use a key size in the range of 1024 to 2048 bits, we can aﬃrm that our algorithm is robust to the diﬀerent attacks for many years. • Our algorithm is adapted to the medical image transmission in Telediagnostic [3,5,23,24]. In addition, since RSA permits the authentication of the sender of the medical image [9,10,21], we can assure a secure and an authentic medical image communication with our algorithm.  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  4  
   
  173  
   
  Conclusion  
   
  In this paper, we proposed a new crypto-compression algorithm that signiﬁcantly reduces the encryption and decryption time and can assure a secure and an authentic transmission in medical image communication. Based on the structure of the JP2 File, which is based on a succession of box and superbox, we developed, in this work, an original approach concerning the encrypting in JP2 File only the part that indicates the length of the boxes (the Lbox). Given the originality and the eﬃciency of this approach, the proposed algorithm, which is derived from, is rapid, secure, and preserves the excellent performance of JPEG2000 algorithm and adapted to the medical image transmission in Telediagnostic sector. In addition, our algorithm can be applied in many other telecommunication sectors like Tele-expertise, secure broadcasting, and distributed image retrieval.  
   
  References 1. ISO/IEC 1.29.15444-1, “JPEG2000 part i ﬁnal committee version 1.0”, September 2004 2. PKCS#1 v2.2, RSA cryptography standard, RSA Laboratories (2012) 3. Amri, H., Hanna, F., Lapayre, J.C., Khalfallah, A., Bouhlel, M.S.: Repro: a new reduction/expansion protocol to increase the performance of image transmission in medical telediagnosis platforms. Biomed. Eng.: Appl. Basis Commun. 27(06), 1550054 (2015) 4. Bouhlel, M.S., Kammoun, F., Garcia, E.: An eﬃcient DCT-based cryptocompression scheme for a secure and authentic medical image transmission. J. Test. Eval. Appl. Sci. Eng. 34(6), 459–463 (2006) 5. Chaabouni, I., Fourati, W., Bouhlel, M.S.: Using ROI with ISOM compression to medical image. IJCVR 6(1/2), 65–76 (2016) 6. Chang, C.C., Hwang, M.S., Chen, T.S.: A new encryption algorithm for image cryptosystems. J. Syst. Softw. 58(2), 83–91 (2001) 7. Chang, H.K.C., Liu, J.L.: A linear quadtree compression scheme for image encryption. Signal Process.: Image Commun. 10(4), 279–290 (1997) 8. Cheng, H., Li, X.: Partial encryption of compressed images and videos. IEEE Trans. Signal Process. 48(8), 2439–2451 (2000) 9. Cramer, R., Damgard, I.: New generation of secure and practical RSA-based signatures. In: 16th Annual International Cryptology Conference, pp. 173–185. Springer Berlin Heidelberg, Berlin, Heidelberg (1996) 10. Cramer, R., Shoup, V.: Signature schemes based on the strong RSA assumption. ACM Trans. Inf. Syst. Secur. 3(3), 161–185 (2000) 11. Dey, N., Bose, S., Das, A., Chaudhuri, S.S., Saba, L., Shaﬁque, S., Nicolaides, A., Suri, J.S.: Eﬀect of watermarking on diagnostic preservation of atherosclerotic ultrasound video in stroke telemedicine. J. Med. Syst. 40(4), 1–14 (2016) 12. Dey, N., Mukhopadhyay, S., Das, A., Chaudhuri, S.S.: Analysis of P-QRS-T components modiﬁed by blind watermarking technique within the electrocardiogram signal for authentication in wireless telecardiology using DWT. Int. J. Image, Graphics Signal Process. (IJIGSP) 4(7), 33–46 (2012)  
   
  174  
   
  M.K. Abdmouleh et al.  
   
  13. Dey, N., Nandi, B., Das, P., Das, A., Chaudhuri, S.S.: Retention of electrocardiogram features insigniﬁcantly devalorized as an eﬀect of watermarking for a multimodal biometric authentication system. In: Advances in Biometrics for Secure Human Authentication and Recognition, pp. 175–212 (2013) 14. Dey, N., Pal, M., Das, A.: A session based blind watermarking technique within the NROI of retinal fundus images for authentication using DWT, spread spectrum and harris corner detection. Int. J. Mod. Eng. Res. (IJMER) 2(3), 749–757 (2012) 15. Dey, N., Samanta, S., Yang, X.S., Das, A., Chaudhuri, S.S.: Optimisation of scaling factors in electrocardiogram signal watermarking using cuckoo search. Int. J. BioInspired Comput. 5(5), 315–326 (2013) 16. Fang, J., Sun, J.: Compliant encryption scheme for JPEG2000 image code streams. J. Electron Imaging 15(4), 043,013–043,013–4 (2006) 17. Grangetto, M., Grosso, A., Magli, E.: Selective encryption of JPEG2000 images by means of randomized arithmetic coding. In: IEEE 6th Workshop on Multimedia Signal Processing, pp. 347–350 (2004) 18. Grosbois, R., Santa-Cruz, D., Ebrahimi, T.: New approach to JPEG2000 compliant region of interest coding. In: SPIE’s 45th Annual Meeting, Applications of Digital Image Processing XXIV, vol. 4472, pp. 267–275 (2001) 19. Gu, G., Ling, J., Xie, G., Li, Z.: A chaotic-cipher-based packet body encryption algorithm for JPEG2000 images. Signal Process.: Image Commun. 40, 52–64 (2016) 20. Jones, D.: Application of splay trees to data compression. Commun. ACM 31(8), 996–1007 (1988) 21. Katz, J.: Digital Signatures. Springer, US (2014) 22. Kleinjung, T., Aoki, K., Franke, J., Lenstra, A.K., Thom´e, E., Bos, J.W., Gaudry, P., Kruppa, A., Montgomery, P.L., Osvik, D.A., Te Riele, H., Timofeev, A., Zimmermann, P.: Factorization of a 768-bit RSA modulus. In: Proceedings of the 30th Annual Conference on Advances in Cryptology, pp. 333–350 (2010) 23. Lazrag, H., Naceur, M.S.: Despeckling of intravascular ultrasound images using curvelet transform. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 365–369 (2012) 24. Lazrag, H., Naceur, M.S.: Wavelet ﬁlters analysis for speckle reduction in intravascular ultrasound images. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 375–379 (2012) 25. Li, X., Knipe, J., Cheng, H.: Image compression and encryption using tree structures. Pattern Recognit. Lett. 18(11–13), 1253–1259 (1997) 26. Lian, S., Sun, J., Zhang, D., Wang, Z.: A selective image encryption scheme based on JPEG2000 codec. In: 5th Paciﬁc-Rim Conference on Multimedia PCM, pp. 65–72 (2004) 27. Lima, J., Madeiro, F., Sales, F.: Encryption of medical images based on the cosine number transform. Signal Process.: Image Commun. 35, 1–8 (2015) 28. Matias, Y., Shamir, A.: A Video Scrambling Technique Based On Space Filling Curves. In: Proceedings of Advances in Cryptology (CRYPTO), pp. 398–417. Springer Berlin Heidelberg, Berlin, Heidelberg (1988) 29. Menezes, A.J., Van Oorschot, P.C., Vanstone, S.A.: Handbook of Applied Cryptography. Taylor & Francis (1997) 30. Modrzyk, D., Staworko, M.: A high-performance architecture of JPEG2000 encoder. In: Proceedings of the 19th European Signal Processing Conference (EUSIPCO), pp. 569–573 (2011) 31. Rivest, R.L., Shamir, A., Adleman, L.: A method for obtaining digital signatures and public-key cryptosystems. Commun. ACM 21(2), 120–126 (1978)  
   
  A Fast JPEG2000 Based Crypto-Compression Algorithm  
   
  175  
   
  32. Saidani, T., Atri, M., Said, Y., Tourki, R.: Real time FPGA acceleration for discrete wavelet transform of the 5/3 ﬁlter for JPEG 2000. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 393–399 (2012) 33. Schneier, B.: Applied Cryptography: Protocols, Algorithms, and Source Code in C. Wiley, New York (1996) 34. Wang, C., Ni, J., Huang, Q.: A new encryption-then-compression algorithm using the rate-distortion optimization. Signal Process.: Image Commun. 39, 141–150 (2015) 35. Wu, H., Ma, D.: Eﬃcient and secure encryption schemes for JPEG2000. In: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 5, pp. 869–872 (2004) 36. Yan, S., Lin, Q.: Partial encryption of JPEG2000 images based on EBCOT. In: International Conference on Intelligent Control and Information Processing (ICICIP), pp. 472–476 (2010)  
   
  IoThings: A Platform for Building up the Internet of Things Andrei Gal(&), Ioan Filip, and Florin Dragan Department of Automation and Applied Informatics, University Politehnica of Timisoara, Bvd. V. Parvan, no. 2, 300223 Timisoara, Romania [email protected]  , {ioan.filip,florin.dragan}@aut.upt.ro  
   
  Abstract. Given the multitude and diversity of smart devices surrounding us, along with the variety of applications distributed on these smart devices, this paper proposes the architecture for a platform that will be used to interconnect different smart devices in terms of hardware capabilities and software features, making feasible the concept of Internet of Things (IoT). The paper deﬁnes the architecture of the platform, expanding the functionality and correlation between modules that make up the platform, and proposes a software representation of a Thing and also a software representation of a Context as used in the IoT network. Using both software representations, platform modules manage tasks that discover all available devices in a surrounding area and create proper context for devices to collaborate, schedule smart device communication and establish communication between available devices in the network. The great advantage of the proposed solution is that it provides an open platform, extensible from an architectural point of view with the possibility to integrate with new smart devices in order to enlarge the IoT network. Keywords: Internet of things Software architecture  
   
    
   
  Smart devices  
   
    
   
  Context-aware  
   
    
   
  Platform  
   
    
   
  1 Introduction A mobile device can be described as being a computational device having a hardware structure similar to that of a personal computer (PC) and also a processing power compared to it. The main design feature of all mobile devices is that they are that small that a person can easily move a device from one place to another. Usually their dimensions are basically compared to that of a human hand. The evolution of mobile devices to what we now deﬁne as being a mobile device took place in quite a small period of time. The impact of the technological development in this direction was great on society affecting it on different levels such as economics, social media, commerce, press, culture, and nevertheless having the greatest impact on the communication level in the society. Below there are deﬁned 5 periods in the evolution of mobile devices:  
   
  © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_15  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  177  
   
  – The Brick (1973–1988) - this is the ﬁrst known era in the mobile telephony as in this period the fundamentals of future cell phone communication were being put in place along with the appearance on the market of the ﬁrst mobile phone (cell phone) invented by Martin Cooper of Motorola company in 1983 [1]. – The Candy Bar (1988–1998) - this era represents one of the biggest leaps in the mobile technology. During this period the design of the cell phones changed drastically both because the usage of second-generation (2G) technology and the increased density of cellular sites [1]. – The Feature Phone (1998–2008) - Taking in consideration the technological advancement to the mobile devices, this era is considered having the lowest impact. Most of the changes occurred to the mobile devices were at a software level as software features were developed to make use of the available hardware such as music listening applications, photo taking applications, game applications. The most groundbreaking change was the introduction of the internet and the addition of GPRS modules along with the usage of the new 2.5G network [1]. – The Smartphone (2002–present) - This era overlapped the one before as there is no clear difference between devices developed during the previous era and this one. Though introducing the internet on a mobile phone might be the event that triggered the so called smartphone era, the real route was made when introducing a common operating system (OS) on each of the devices developed. This addition led to the possibility of developing OS based application which gave birth to the concept of smartphone (a phone that is as smart as a PC). Alongside the development on a large scale of smartphones companies started to extend the area of development creating other smart devices such as smart TV’s, smart watches, smart cards, smart boards, smart pads, smart fridges, smart locks etc. [1]. – The Touch (2009–present) - This era overlaps the one before and is related to the introduction of the touchscreen technology on smart mobile devices but also on simple smart devices. The ﬁrst touchscreen technology was implemented by Apple Inc. on their ﬁrst iPhone and since then every smartphone uses it. As with smartphone technology, touchscreen technology began to be used increasingly more and applied to a number of existing smart devices, nowadays having touchscreen smart TV’s, touchscreen smart watches, touchscreen fridges touchscreen laptops etc. [1].  
   
  2 An Overview of the Used Concepts 2.1  
   
  Internet of Things (IoT)  
   
  During the mobile device development evolution most of the device could communicate between them only by using the GSM network, therefore the devices were mainly used as mobile phones with no possible way to interconnect them. This was mostly related to the fact that there was a limitation of the communication environments that the mobile devices possessed.  
   
  178  
   
  A. Gal et al.  
   
  Along with the development of smartphones with Wi-Fi and Bluetooth modules applications that use these modules to exchange data were more often developed. Most applications exchanged address book information such as contact entries, text messages, and call history but there were also applications developed to exchange ﬁles such as music or photo ﬁles. With the development of these devices and applications the need of having a live interconnection for exchanging relevant data between the existing devices has increased to a point that the concept of Internet of Things appeared. The Internet of Things can be deﬁned as being a network on a global scale for interconnecting smart devices (Things) around the world. Making a comparison with the internet as we know it where people are the agents of communication and data transferred between people is mostly referring general social information, the IoT uses Things as agents of communication, while the data transferred between the Things represent relevant data for the Things engaged in the process of communication. As the concept is being still in early stages there are several possible interpretations of the Things that make up the IoT. Considering the current development of smart devices focused mostly on the home automation services, a possible basic IoT infrastructure can be seen in Fig. 1. All smart devices in Fig. 1 play the role of Things in the IoT infrastructure [2, 3].  
   
  Fig. 1. Basic IoT infrastructure  
   
  In particular, the simplest use of the IoT, by referring to Fig. 1 shown above, could be that of a user being able to just power on/off the smart TV from a simple TV Manager application the user has installed on the smartphone he owns. When referring to the term home automation a more complex infrastructure of the IoT could be represented by involving a lot more Things in the process of automating the home. Things like temperature sensors, pressure sensors, humidity sensors or light sensors embedded in equivalent smart devices can give feedback upon action that could be taken to adjust the ambient comfort in the home. The actions taken to adjust the environment could be done by Things like windows’, air conditioners’, dehumidiﬁers’, electric heaters’, louvers’ all developed as smart devices that could be controlled remotely like in Fig. 2 [3].  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  179  
   
  Fig. 2. Complex IoT infrastructure  
   
  By taking in consideration various points of interest, the IoT infrastructure can be extended by adding Things relevant in ﬁelds of study like health care, smart buildings, waste management, smart roads, social media and a lot more ﬁelds where it can be possible to build a level of abstraction so that Things can be developed to serve purposes like people’s security, replacement of human actions, increased comfort level in an environment, reducing the possibility of human error, etc. In an ideal IoT world, smart devices will serve users by doing autonomous work behind the scenes, accomplishing the ultimate purpose for which such an enlarged IoT infrastructure is created, that being interconnectivity between devices and services that work together to do something useful for mankind [3, 4]. 2.2  
   
  Context-Aware Computing  
   
  To present in a clear light the essential aspects of the proposed platform it can be mentioned that like many current architectures proposed for implementation of IoT infrastructure, IoThings was also designed taking in consideration the paradigms of context-aware computing, especially emphasizing on the main attribute of any context-aware system namely the adaptation of the system to its location, to the people and objects in the system or connected to the system, and also to the changes of the objects over time [5, 6]. The concept was developed based on the ubiquitous computing paradigm proposed in the early 1990’s and it refers to a suite of mobile systems that can take information from their environment and adapt to it by taking appropriate decisions. The core  
   
  180  
   
  A. Gal et al.  
   
  elements of these context-aware systems are represented by the context information and the actions (decisions) taken to adapt the mobile systems to the context at a certain point in time and space. The platform presented in this paper follow the lines drawn by both the context-aware computing concept and IoT concept, proposing a modular platform architecture that encapsulated core aspects from both concepts presented above with the purpose to create a context-aware IoT network where devices can interconnect forming the Internet of Things [7, 8].  
   
  3 IoThings - Software Level Concepts IoThings is a platform designed to support a series of smart devices that are different in terms of hardware functions and could run under different or same operating systems. The platform is designed, to have independent modules overlapping each of the functions of the platform, altogether coordinating the devices to adapt to the environment they reside in, for creating the proposed context. Due to the focus on the context-aware computing concept, the platform is structured around the term of context information. As the platform is being designed for implementing an IoT solution platform, all the smart devices that use the platform are represented as entities belonging to a certain context, and all relevant information about a smart device is translated in a context entity information [9, 10]. 3.1  
   
  Software Representation of a Thing  
   
  As deﬁned by the IoT concept, a Thing is represented in the real world by a smart device and its main characteristic is that it can interconnect with other Things for exchanging data, this way creating a large network of Things which eventually can create the Internet of Things. Having a multitude of various Things that are being different in terms of hardware structure, the platform deﬁnes a set of hardware functionalities that a Thing can have. For example, Things can get measures from the environment, can record sounds/videos, can move, can carry other Things, can sense proximity, can start/stop engines etc. A Thing being represented as a class at a software level, each of the hardware functionalities will be deﬁned as an interface, so for the abstraction of each function a Thing has, it will have to implement that particular interface. In Fig. 3 is presented a class diagram for the interfaces the platform supports. It should be mentioned here that the class diagram can be extended to include any other possible hardware features a Thing can own but also adapt existing features to requirements of an accepted Thing for the platform [11]. As seen in Fig. 3, a Thing represented at a software level in the IoThings platform contains the sum of all functions that that Thing is supporting at a hardware level. Going onwards the platform also reduces to a level of software abstraction the general information a Thing can have like: name, physical form, physical dimension, operating system installed on, operating system version, software version etc. As depicted in Fig. 4 the platform exposes a generic interface that the Thing will have to implement in order to work with the platform.  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  181  
   
  Fig. 3. Deﬁned interfaces for the software representation of a Thing’s functions  
   
  Fig. 4. Deﬁned interfaces for the software representation of a Thing’s general information  
   
  The general information interface contains nine properties as below: – Name – property that deﬁnes the name of the Thing. – OperatingSystem (OS) – property that deﬁnes the operating system under which the software embedded in the Thing runs. This property is relevant in terms knowing how to handle the communication between Things that have different operating systems installed. – OperatingSystemVersion – property that gives the platform the information regarding the version of the OS and as like the one above it’s important in communication between Things running different OS/OS versions. – Form – property that represents the physical form of the Thing. As it can be seen in Fig. 4 this can have several values like: Circle, Sphere, Rectangular, Square, Cube, Triangle. – Height – property that is set to the real height of the Thing. – Width – property that is set to the real width of the Thing. – Depth – property that is set to the real depth of the Thing. – Weight – property that is set to the real weight of the Thing. – IsRound – this property is set if the Thing represented has a round shape. – Radius – this property comes with the one above and it represents the actual radius of the Thing in case it has a round shape.  
   
  182  
   
  A. Gal et al.  
   
  The function of a Thing that can move is represented by the IMoveFunction interface and it contains the following: – IsMoving – property that is set whenever the Thing is in motion. This is relevant in the context of having to give the Thing a command to move knowing it is already in motion. – MoveToLocation – this method is used to give the Thing the command to move to a speciﬁed location in the available space. – LocationChanged – this event is triggered by the Thing whenever its location has been changed. This way the platform is able to locate each of the Things at a speciﬁed moment in time. To represent the capacity of a Thing to take measurements from the environment it resides in the IMeasureFunction interface propose below members: – IsMeasuring – property specifying the fact that the Thing is currently taking measurement from the environment. The property is useful when using Things that work with big data values or have time consuming sensors. – MeasuredValue – property that retains the measured value from the environment at a certain point in time. – MeasureType – this property is set to the relevant type of measurement the Thing deals with. As seen in Fig. 5 the property can have several values like: – MeasureUnit – property is set to the relevant unit of measurement used by the MeasureType property, and it can take values like:  
   
  Fig. 5. Measure types and measure units used by IMeasureFunction interface  
   
  – GetMeasurement – the method is used to retrieve the last value read by the Thing from the environment. This will also update the MeasuredValue property. – NewMeasuredValue – event is used to be triggered whenever a new value has been measure from the environment. The ability of a Thing to execute commands that have an effect on the environment is represented by the ICommandFunction and it has the following composition: – CommandType – property that can be set with the following values as in Fig. 6: Start, Stop, Open, Close, Lock, Unlock, Drag, Move, Push, Pull, Cut.  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  183  
   
  – Status – property that is set with the result of the command’s execution, as for to know whether the command ended successfully has entered some state relevant for the context in which the Thing is. The values possible for this property can also be seen in Fig. 6. – IsExecuting – this property is set whenever a command starts its execution and is reset when the command end the execution. – ExecutionMessage – property will retain the message thrown by the command after ﬁnishing the execution. – AsyncExecuteCommand – the method is used to start the asynchronous execution of the implemented command. As the execution of a command can be time consuming this method offers the possibility to run the execution on a separate thread in case necessary in the context. – ExecuteCommand – the use of this method implies the execution of the command awaiting for it to ﬁnish, blocking the thread from where it is called. – CommandStatusChanged – this event is ﬁred up by the Thing when the status of the command in execution is changed.  
   
  Fig. 6. Command types and command status used by ICommandFunction interface  
   
  For the video ability of a Thing, the IVideoFunction interface has to be implemented having the structure below: – CanPlayVideo – property that deﬁnes whether the Thing can play or not videos. – CanRecordVideo – property that deﬁnes whether the Thing can record or not videos. – NumberOfCameras – property set to the number of available cameras that the Thing has to offer. – OptimalResolution – property set with the optimal resolution for the video. This will be used for the Thing to record/play video by setting the resolution to the one in the property. – GetVideoStream – this method is used to get the video stream from a certain camera and use it as output for any of the applications using the platform and using live streaming feature. – StartVideoPlayer – this method is used to tell the Thing to start playing a video in case it has the CanPlayVideo property set. – StartVideoRecording – this method is used to tell the Thing to start recording video in case it has the CanRecordVideo property set.  
   
  184  
   
  A. Gal et al.  
   
  The structure of the IAudioFunction, making available the audio representation at the software level for a Thing consists of: – HasMicrophone – property set when a Thing has a microphone incorporated for the possibility to record audio. – HasSpeakers – property set if a Thing has speakers available to play audio sounds. – SoundDevice – property specifying the sound device used by the Thing. – GetAudioStream – this method is used to get the audio stream from a certain device and use it as output for any of the applications using the platform and using live audio feature or voice recording feature. – StartAudioPlayer – this is used to start playing and audio ﬁle in case a Thing has HasSpeakers property set. – StartAudioRecording – this method is used to start recording audio is a Thing has HasMicrophone property set. Taking in consideration the context information core element of the IoThings platform, all Things known by the platform have to be included in a context so that the context-awareness paradigm is respected. To include all Things in a certain context the platform integrates the Thing concept into the context information concept by creating a context entity that encapsulates any Thing known by the platform. In order to do a better drawing of the context concept any context entity will consist in two major parts as seen below in Fig. 7.  
   
  Fig. 7. Context Entity structure  
   
  As it can be seen in Fig. 7 a Context Entity is composed of a Location Context and a Thing Context. The Thing Context is represented by the software representation of a Thing which is described above, as the Location Context represents the location of the Context Entity in the context space bordered by the IoT network that is built with the use of IoThings platform. Particularly speaking the Location Context consist of relevant information regarding the position in time and space where a speciﬁc entity is. From a structural point of view, the Location Context consists of: – GPS coordinates – if possible this is to be provided by the Thing in the Context Entity, or could be provided by entities from the same context. – Context reference – a reference to the context that the entity belongs to. – Time reference – a time reference based on where the context resides in terms of geo-location. It can contain data as local time, local day, local month [12].  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  3.2  
   
  185  
   
  Software Representation of a Context  
   
  To be able to have an idea of how IoThings platform uses the Context concept to create an abstraction at the software level we’ll highlight some deﬁnitions of the concept. A Context could be seen as environmental information that is part of an application’s operating environment and that can be sensed by the application. This typically includes the location, identity, activity and state of people, groups and objects that are part of the environment. Another possible deﬁnition of a Context could be that of the interaction between humans and computers in socio-technical systems that takes place referring to the physical and social situation in which computational devices and environments are embedded. The context is determined by the people involved (including their background knowledge and their intentions), the objective of the interaction (including the tasks to be carried out), and the time and place where the interactions occur [13]. Given the two deﬁnitions above, IoThings platform deﬁnes the Context as being a self-aware environment, where entities different in terms of functional abilities can interact between them or with people by giving feedback with a certain status of the environment at a point in time, or accepting commands if necessary, to adjust the environment for serving a predeﬁned scope. Having this in consideration the software representation of a Context from the IoThings platform point of view consists in elements like in Fig. 8: – Name – property set with the name of the Context. – Location – a property that deﬁnes the geographical coordinates where the Context is settled. – Scope – property set with the predeﬁned scope of the Context. – Status – property giving the current status of the Context. Possible status of the Context can be determined by a full analysis of the Scope of the Context. – NetworkID – property set with the ID of a certain network (if any) where the Context establishes communication between entities owned. – AvailableContextEntities – a list of Context Entity objects that are residing in the speciﬁed Context. These entities make up the Context itself by adapting and adjusting Context variables to achieve the predeﬁned Scope. – SelfAwarePercent – property which set the percentage of self-awareness of the Context. The percentage is to be calculated depending on several factors like number of autonomous entities in the Context, number of human interactions in achieving the Scope, number of errors in executing a command in the Context etc.  
   
  Fig. 8. Software representation of a Context  
   
  186  
   
  A. Gal et al.  
   
  4 IoThings Architecture IoThings platform being designed for working with Things in terms of Context Entities, and respecting the used concepts, its architecture is composed of modules that provide functionalities like communication with any known Context Entity, deﬁning a Context using the available entities, managing contexts and context entities, all modules making use of the software representations deﬁned by the platform in order to interfere with the smart devices inhabiting a real context environment. The platform’s architecture, represented at the modules level is depicted in Fig. 9.  
   
  Fig. 9. IoThings architecture  
   
  a. Context Entity Service - this module represents a service exposed by the platform that gives the possibility for any Context Entity to communicate with the platform. Through this module a smart device that is deﬁned as a possible Context Entity will be known by the platform as an available Context Entity and can be used in a proper Context based on the location and the hardware functions that the device is capable of. Also the service can be used for communication between different devices that cannot communicate due to hardware/software interoperability problems. b. Context Entity Analyzer – this module deals with the analysis of all entities in terms of both location context and functions that the entity is capable of, resulting in the creation of a new Location Context where the analysed entity will be included or in the attachment of the analysed entity to an already existing Location Context. c. Context Entity Manager – this module represents the management level of the platform related to the entities communicating with the platform, and it performs three major functions: extracts all possible entities that can communicate with the platform into a Contact Entity Container, establishes communication between the external applications available to interact with a certain context via IoThings and relates any deﬁned Context with an external application or with any of the entities owned by the Context. d. Context Manager – this module represents the management level of the platform related to the contexts that are deﬁned by it. The module communicates with the Context Entity Analyzer and based on the result of the analysis manages the  
   
  IoThings: A Platform for Building up the Internet of Things  
   
  187  
   
  resulting Location Context in order to create a new Context or manage existing ones in a Context Container. Also this module provides information for any of the external applications regarding any context created and managed by the platform. e. Application Service – this module acts as a service exposed by the platform in order to allow external applications to communicate with it. The applications are used by people in certain environments to either get feedback from the Things in the environment, or to command Things that can be triggered actions on.  
   
  5 Conclusions This paper presents a platform which is able to manage smart devices that have different hardware functions and software installed components, by putting together two abstractions at a software level for concepts deﬁned in the Internet of Things and Context-Aware Computing ﬁelds of interests. A Thing is represented by the platform as a class that implements an interface related to general information that a Thing has, and also interfaces related to different functions that a Thing possesses. A Context is represented by the platform as a class that puts altogether relevant information that deﬁnes a context-aware system like: location, scope, status, context entities belonging to the context and self-awareness. The platform architecture is designed to communicate with all Things that are deﬁned respecting the proposed software representation of a Thing, in order to create a container with all available Things for the platform. The platform will extract Things from the container, and by subjecting them to an analysis based on the location of the Thing and its capabilities, will create Contexts that will serve a predeﬁned scope. The platform will manage both Things and Contexts in order to create an interconnection between the two terms by attaching to a Context as many Things as needed for serving the scope for which the Context was deﬁned. The connection will be translated in real situations, where smart devices forming a real environment, will adapt to be able to maintain/achieve a certain desired state of the environment. Also the platform will tend to increase the degree the self-awareness for each of the Contexts deﬁned by emphasizing the use of the Things in an autonomous mode. The platform makes available an application level where external applications can communicate with the platform for getting feedback from a certain Context or for sending commands to Things that act as actuators in the Context. In particular, the application level enables the human factor the possibility to intervene by just visualizing the state of the Context or by acting on some Things in that certain Context. Acknowledgments. This work was developed through the Partnerships in Priority Areas PN II, with the support of ANCS, UEFISCDI, Project No. 36/2012, Code: PN-II-PT-PCCA2011-3.2-1519.  
   
  188  
   
  A. Gal et al.  
   
  References 1. Fling, B.: Mobile Design and Development. O’Reilly Media Inc., Sebastopol (2009) 2. Stankovic, J.A.: Research directions for the internet of things. IEEE Internet Things J. 1, 3–9 (2014) 3. Jie, Y., Pei, J.Y., Jun, L., Yun, G., Wei, X.: Smart home system based on IOT technologies. In: International Conference on Computational and Information Sciences (ICCIS), pp. 1789– 1791 (2013) 4. Moser, K., Harder, J., Koo, S.G.M.: Internet of things in home automation and energy efﬁcient smart home technologies. In: IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 1260–1265 (2014) 5. Schilit, B., Adams, N., Want, R.: Context-Aware Computing Applications, pp. 85–90 (1994) 6. Yürür, O., Liu, C.H., Sheng, Z., Leung, V.C.M.: Context-awareness for mobile sensing: a survey and future directions, In: IEEE Communications Surveys & Tutorials, pp. 68–93 (2014) 7. da Costa, C.A., Yamin, A.C., Resin, C.F.R.: Toward a general software infrastructure for ubiquitous computing. IEEE Pervasive Comput. 7, 64–73 (2008) 8. Kindberg, T., Fox, A.: System software for ubiquitous computing. IEEE Pervasive Comput. 1, 70–81 (2002) 9. Salber, D., Dey, A.K., Abowd, G.D.: The context toolkit: aiding the development of context-enabled applications. In: SIGCHI Conference on Human Factors in Computing Systems, pp. 434–441 (1999) 10. Hristova, A., Bernardos, A.M., Casar, J.R.: Developing an ambient home care system: context toolkit-based design and implementation. In: Ninth International Conference on Parallel and Distributed Computing, Applications and Technologies, pp. 455–461 (2008) 11. Wang, W., De, S., Toenjes, R., Reetz, E., Moessner, K.: A comprehensive ontology for knowledge representation in the internet of things. In: IEEE International Conference on Trust, Security and Privacy in Computing and Communications, pp. 1793–1798 (2012) 12. Zafari, F., Papapanagiotou, I., Christidis, K.: Microlocation for internet-of-things-equipped smart buildings. IEEE Internet Things J. 3, 96–112 (2015) 13. Gerhard, F.: Context-aware systems: the ‘right’ information, at the ‘right’ time, in the ‘right’ place, in the ‘right’ way, to the ‘right’ person. In: International Working Conference on Advanced Visual Interfaces, 22–25 May, pp. 287–294 (2012)  
   
  Imperialist Competition Based Clustering Algorithm to Improve the Lifetime of Wireless Sensor Network Ali Shokouhi Rostami1, Marzieh Badkoobe1, Farahnaz Mohanna1, Ali Asghar Rahmani Hosseinabadi2(&), and Valentina Emilia Balas3  
   
  3  
   
  1 Department of Communication Engineering, University of Sistan and Baluchestan, Zahedan, Iran [email protected]  , [email protected]  , [email protected]  2 Young Researchers and Elite Club, Ayatollah Amoli Branch, Islamic Azad University, Amol, Iran [email protected]  Aurel Vlaicu University, Bd. Revolutiei 77, 310130 Arad, Romania [email protected]   
   
  Abstract. In Wireless Sensor Network (WSN) nodes have limited energy and cannot be recharged. Clustering is one of the major approaches to optimize consumption of energy and data gathering. In these networks, clustering must be special to prolong network lifetime. In WSN, clustering has heuristic nature and belongs to NP-hard problems. In complex problems, search space is too big and grows exponentially. Because it takes too much time and cost, ﬁnding a deterministic optimized solution is difﬁcult in such a short time. In this situation population-based algorithms are beneﬁcial in ﬁnding optimum solutions. In this paper, a clustering algorithm is investigated and a novel idea, in line with the population-based algorithm, is presented. The proposed algorithm uses Imperialist Competition Algorithm (ICA) for the clustering of nodes. The results show that this algorithm postpones the dead time of nodes and prolongs network lifetime, compared to other discussed clustering algorithms. Keywords: Clustering  Imperialist Competition Algorithm  Lifetime  WSN  
   
  1 Introduction Wireless sensor network (WSN) consists of many tiny sensor nodes. These nodes are typically equipped with battery, processor, memory and radio to send and receive data, which will be deployed compactly in the area for a speciﬁc purpose. Having gathered the required information from the environment, sensor nodes that are connected with each other via wireless links process them, and then deliver them to Base Station (BS) that is responsible for gathering information [1, 2]. A wireless sensor node (node) is a small electronic device which has a limited energy resource, and generally the battery cannot be changed or recharged. Therefore lifetime of a sensor node is absolutely dependent on battery life [3, 4]. In WSN, most of © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_16  
   
  190  
   
  A.S. Rostami et al.  
   
  the energy is consumed in data transmission, therefore approaches that reduce transmission greatly save energy and increase network lifetime. Clustering is one of the most popular approaches used in reducing energy consumption. Clustering protocols, in comparison to direct protocols, not only decrease data transmission, but also, due to load balancing between nodes, reduce energy consumption [5, 6]. Selecting Cluster Heads (CH) and cluster formation procedures must make the clusters balanced, reduce the exchange of messages and keep the time complexity constant which is independent of the growth of the network. This selection process is very challenging [1, 7]. Clustering protocols proposed in the literature are, in general, classiﬁed into two groups: clustering protocols in homogeneous networks and clustering protocols in heterogeneous networks. The important clustering protocols in homogeneous networks are LEACH [8], extensions of LEACH [9, 10], PEGASIS [11], extensions of PEGASIS [12], TCCA [13], EEHC [14], HEED [15] and TEEN [16]. The important clustering protocols in heterogeneous networks are SEP [17], BSIDR [18], DEEC [19] and extensions of DEEC [20]. Clustering has a heuristic nature and belongs to NP-hard problems [9]. In heuristic problems, search space is too big and grows exponentially. In such cases, ﬁnding a deterministic answer needs too much time and cost, therefore it is difﬁcult to ﬁnd deterministic optimized answers in a short time. In this situation population-based algorithms are beneﬁcial to determine optimum answers. Genetic Algorithm (GA) [21], Particle Swarm Optimization (PSO) [22], Gravitational Emulation Local Search Algorithm (GELS) [23–25], Gravitational Search Algorithm (GSA) [26–30] and Imperialism Competition Algorithm (ICA) are the popular population-based algorithms. These optimization protocols are applied to WSN to decrease the amount of data transmission and therefore prolong the network lifetime by ﬁnding the most suitable route in transmission and selecting optimal CHs [31]. These protocols are effective in many aspects like: optimal formation of clusters [32], selecting optimal nodes as cluster heads [10, 33], ﬁnding optimal number of clusters, and ﬁnding the optimal paths [34, 35]. In this paper, ICA is used for clustering. This protocol considers the conditions and limitations of WSN. In clustering topic, a protocol is needed that reduce data transmission and subsequently reduces energy consumption. This leads to an increase in network lifetime. In order to achieve these objectives, a new clustering protocol is proposed which ﬁrst clusters all nodes using ICA and then in each cluster chooses the appropriate nodes as cluster heads. By using this protocol, more energy is remained in the nodes, and the lifetime of the network increases signiﬁcantly.  
   
  2 Related Work Many algorithms in the ﬁeld of energy efﬁciency have been proposed in the past and clustering is one of the most effective methods in this ﬁeld. Following are a few of them.  
   
  Imperialist Competition Based Clustering Algorithm  
   
  2.1  
   
  191  
   
  Low-Energy Adaptive Clustering Hierarchy (LEACH)  
   
  LEACH [8] is one of the ﬁrst and most popular energy efﬁcient hierarchical clustering algorithms for WSN that is designed for reducing energy consumption. As the role of CH is rotated randomly and CHs directly forward their data to the BS with a one-hop route, this algorithm provides energy balancing. In LEACH formation of clusters and selection cluster heads, the CHs are completely distributed and there is no central coordination. CHs are selected randomly and all nodes have the same chance to be a cluster head. LEACH provides the following key areas of energy saving: • No overhead is wasted in deciding which node becomes cluster head as each node decides this independent of other nodes. • CDMA allows clusters to operate independently, as each cluster is assigned a different code. • Each node calculated the minimum transmission energy required to communicate with its cluster head and transmits with this optimized power level. 2.2  
   
  Stable Election Protocol (SEP)  
   
  SEP [17] is an extension of the LEACH algorithm. It is represented for heterogeneous networks. There are two types of node bases on initial energy and equipment: normal node and advance node. Advance nodes have more chances to be the cluster head. The other stages are similar to LEACH. This protocol improves lifetime and provides better energy balancing, compared to LEACH. 2.3  
   
  Distributed Energy Efﬁciency Clustering (DEEC)  
   
  DEEC [19] is used for both homogeneous and heterogeneous networks. Unlike LEACH and SEP, in this protocol cluster heads are not chosen randomly, but they are selected based on residual energy. According to this, in each round, nodes that have more energy, have a better chance of becoming the cluster head. All nodes must have global knowledge of the network to calculate the residual energy in each round. This adds a large overhead on the network.  
   
  3 Imperialist Competition Algorithm (ICA) To solve the optimization problems, different methods have been proposed such as Genetic Algorithm (GA) [36], Particle Swarm Optimization (PSO), and the Ant Colony Optimization (ACO). Imperialism Competition Algorithm (ICA) is a new evolutionary optimization method inspired by imperialism competition [37]. Like other evolutionary algorithms, ICA starts with an initial population called country [38]. There are two types of countries, colonies and imperialists. Some of the best countries in the population will be imperialists and the rest become colonies, which together forms the empires. Imperialistic competition takes place between these empires. During this competition, weak empires collapse and powerful ones take possession of their colonies. The power of an empire which is the counterpart of ﬁtness function in GA, is inversely proportional to its cost.  
   
  192  
   
  A.S. Rostami et al.  
   
  After competition, the imperialists are selected and colonies are divided, then colonies move toward their imperialist. After dividing all colonies among imperialists and creating the initial empires, the competitions are started. Colonies start moving toward their relevant imperialist based on assimilation policy. Empires that cannot succeed in this competition and cannot increase their power (or at least prevent a power loss), are eliminated from the competition. This competition leads to a gradual increase in powerful empires and decrease in the weak ones. Eventually weak empires collapse and lose their power. Imperialistic competition converges to a state in which there exists only one empire and colonies have the same cost function value as the imperialist. In an N dimensional optimization problem, a country is a 1  N array. This array is deﬁned as below: Country ¼ ½P1 ; P2 . . . PN  The cost of a country is found by evaluating the cost function f at the variables (P1, P2… PN), then CI ¼ f ðcountryi Þ ¼ f ðPi1 ; Pi2 . . . PiN Þ The algorithm starts with N initial countries called Npop, and Nimp best of them are chosen for imperialists. Ncol remaining countries are colonies that each belongs to an empire. Powerful empires have greater number of colonies and the weaker one have less number of colonies. To distribute the colonies among imperialists proportionally, the normalized cost of an imperialist is deﬁned as follows: Cn ¼ maxi ci  cn  
   
  ð1Þ  
   
  where cn- is the cost of nth imperialist and Cn is its normalized cost. Imperialists began to improve their colonies and colonies move towards imperialists. This motion is shown in Fig. 1. In this movementɵ and x are random numbers with uniform distribution as illustrated in formula (2) and d is the distance between colony and the imperialist. x  Uð ; b  dÞ h  U ðc; cÞ  
   
  ð2Þ  
   
  where b is a number greater than 1. If b > 1, colonies and imperialist are closing together. c is an adjustment of deviation from the original direction. The values of b and c are arbitrary. The total power of each empire is determined by the sum of its power and average power of its colonies. TCn ¼ costðimperialistÞ þ n  meanfcostðcolonies of empiresÞg Where TCn is the total cost of n-th Empire and f is a positive number which is considered less than one.  
   
  Imperialist Competition Based Clustering Algorithm  
   
  193  
   
  The main steps of ICA are as follows: • Select some random point and initialize the empires. • Move colonies toward their relevant imperialist (Assimilation). • Randomly change the position of some colonies (revolution), If there is a colony with the imperialist. • Exchange the position of the colony and imperialist. • Until reaching similar empires. • Compute the total cost of all empires. • Pick the weakest colony from the weakest empire and hand it over to one of the empires (Imperialist competition). • Eliminate the powerless empires. • Exit if stop condition are satisﬁed, otherwise do further assimilation and continue.  
   
  Fig. 1. Colony moving toward imperialist [38]  
   
  4 The Proposed Algorithm In this work a WSN is considered as composed of n nodes which are the same and have two modes: Cluster Head Nodes (CH) and normal nodes. Since the energy consumption of CHs are greater than normal nodes; appropriate CHs are chosen in each cluster that needs less energy for transferring data to the base station and for receiving data from cluster members. This protocol is part of a ﬁxed clustering algorithm and done with ICA. ICAAlgorithm consists of three phases: the set up phase, the cluster head selection phase, and the steady up phase. Set up phase is executed just once in the base station, whereas other phases are repeated in each round. In CH selection phase, appropriated CHs are chosen for each cluster. In the steady up phase, nodes gather data and then each node transfers its data to the corresponding CH’s. The CHs then transfer this received data to the base station.  
   
  194  
   
  4.1  
   
  A.S. Rostami et al.  
   
  Setup Phase  
   
  In this phase, nodes are clustered into kopt cluster using ICA. After nodes are located in their place, they send their located information to the base station. Then the BS, by using this information, calculates kopt. Nodes are clustered using ICA and the clusters are formed. BS broadcasts this information to all nodes. Location of nodes is given to the ICA as input parameters. In this case, ﬁnding the kopt point as the center of cluster is the objective. In so doing, sum of square distance of each cluster members to center of cluster, plus sum of square distance of center of clusters to BS, are minimized. 4.2  
   
  CH Selection Phase  
   
  Unlike the pervious phase which is performed only once in the BS, this phase is repeated in each round. After clusters are formed in the BS and cluster information is broadcasted to all the nodes, each node will realize who belongs to which cluster. Each node sends a message to its neighbors which are in the range of its transmission and thereby will inform its ID and cluster number. Each node receives its neighbor’s message, saves it in the table information of nodes which have similar cluster number to it. Then this table is sent to other cluster members. Using this table, every member node, can update its tables, thus all cluster members are identiﬁed. Most energy is consumed in transmission and transmission distance has direct and exponential direct in energy consumption. Center of cluster is center of gravity, too, for this reason if CH located around center of gravity, distance between all cluster members to CH will be approximately equal, hence energy consumption in transfer of data, will be almost same for all nodes. This causes better balance energy consumption of nodes and prevents preterm death. If CH is located around the center of gravity, it is optimized, however this condition is not sufﬁcient for cluster head selection. As the numbers of nodes that are located around center, are limited, and if it was the only criterion, the energy of nodes adjacent to center is quickly ﬁnished and nodes will die soon. As a result, load balancing and energy balancing is destroyed. Hence, there are other criteria for selecting cluster heads. CHs consume more energy than member nodes, therefore the remaining energy of nodes must be noted in CH selection. Nodes which have more residual energy have higher priority than those which have less residual energy. Accordingly, in choosing CH, remained energy should be considered. Other criteria that are involved in selecting CH, is the distance between node and BS. The closer to the BS the CHs are placed, the lesser the energy used to transfer data. If this does not happen, the node that play role of CH, is remained as its role until its energy is ﬁnished end and node dies. This causes CHs to die sooner than members and the network balancing energy to be destroyed. The optimal status is when energy of all nodes is ﬁnished at the same time. Though, if the role of CH don’t replace, it will not happen.  
   
  Imperialist Competition Based Clustering Algorithm  
   
  4.3  
   
  195  
   
  Steady up Phase  
   
  This phase starts after CH selection phase and repeat in each round. To avoid collision and energy efﬁciency, TDMA scheduling is run and a time slot is allocated for each member node so that it can send its data to CH. To avoid wasting energy, the rest of time, they are inactive. CH receives data from all cluster members, then aggregate received data and send them to BS. When all CHs send their aggregated data to BS, the round is ﬁnished. Model of energy consumption is the same energy model proposed in [8] in order to achieve an acceptable. Signal-to-noise ratio (SNR) in transmitting an L bit message over a distance d, energy expanded by the radio is given by:  ETX ðL; d Þ ¼  
   
  L  Eelec þ L  efs  d 2 L  Eelec þ L  emp  d 4  
   
  if d  d0 if d d0  
   
  ð3Þ  
   
  Where Eelec is the energy dissipated per bit to run the transmitter or the receiver circuit, efs and emp depend on the transmitter ampliﬁer model we use, and d the distance between the sender and the receiver. By equating the two expressions at d = d0, we have rﬃﬃﬃﬃﬃﬃﬃ efs d¼ emp  
   
  ð4Þ  
   
  To receive an L bit message the radio expends ERX ðLÞ ¼ L  Eelec  
   
  ð5Þ  
   
  5 Simulation Result For simulation of this algorithm, we have selected a rectangle area where 100 nodes are randomly distributed in the 100  100 area. The base station is located at the center (50, 50). The simulation is done with MATLAB. The parameters of simulation are listed in Table 1. Table 1. Simulation parameters Value 0.5 J 10pJ/bit/m2 0.0013pJ/bit/m4 50 nJ/bit 4000 bit 50 nJ/bit 87.7 m 3000  
   
  Parameters Initial energy Efs Emp EDA Packet length Eelec D0 Round number  
   
  196  
   
  A.S. Rostami et al.  
   
  In this simulation we suppose a network with assumptions as follows: • • • • •  
   
  All nodes are located randomly. All nodes are static and have limited energy. At the beginning energy of all nodes are the same. All nodes are aware of their position and their amount of remaining energy. All nodes can be both Cluster head and normal node.  
   
  For clustering of nodes, the ﬁrst step is the calculating the optimal number of clusters. According to [8] and simulation parameters, it will be 75 m < dtoBS < 185 m. Therefore it is expected that the optimal number of clusters be in the range 1–6. Figures 2 and 3 show that by increasing the number of clusters, the average residual energy of the network is increased, death of nodes is delayed and network lifetime is  
   
  Fig. 2. Average residual energy in the various number of clusters  
   
  Fig. 3. Number of dead nodes in the various number of clusters  
   
  Imperialist Competition Based Clustering Algorithm  
   
  197  
   
  increased. In this experiment the optimal number of clusters is considered 6. ICA divides the network into 6 clusters so that the total distance of each cluster member to cluster center and the total distance from all cluster heads to the base station, is minimized. Figure 4 shows the formation of nodes in 6 clusters. Circles same in color are same cluster members and squares indicate center of each cluster (Fig. 5).  
   
  Fig. 4. Clustering nodes into 6 cluster using ICA  
   
  Fig. 5. ICA convergence rate  
   
  Simulation parameters for ICA are shown in Table 2. The result of this protocol is compared to discuss clustering algorithm. The results of these comparisons are shown in Figs. 6 and 7.  
   
  198  
   
  A.S. Rostami et al. Table 2. ICA simulation parameters Value 100 10 0.1 100 6  
   
  Parameter Number of Number of Revolution Iteration Number of  
   
  countries imperialist probability cluster  
   
  In this protocol, one of the cluster head selection parameter is proximity to the cluster center. The closer the nodes are to the center, the more their chance of being a cluster head is. Therefore the nearest nodes to center are the ﬁrst priority to become cluster heads.  
   
  Fig. 6. Comparing numbers of alive nodes in each round  
   
  Figures 6 and 7 show in ICA, regardless of the percentage of nodes that are dead in early rounds, the remaining nodes almost die at the same time. As shown in Fig. 8, in early rounds ICA-Clustering have lesser average remaining energy than other algorithms. The reason is that some percentage of nodes die very quickly, but in other rounds ICA-Clustering have more remaining energy in each round and therefore the lifetime is improved than the others. ICA-Clustering is compared to  
   
  Imperialist Competition Based Clustering Algorithm  
   
  199  
   
  Fig. 7. Comparing number of dead nodes in each round  
   
  Fig. 8. Comparing number of average residual energy in each round  
   
  LEACH, SEP, DEEC and could obtain lifetime improvement about 40%, 36% and 26% respectively than them. The lifetime of this protocol is compared to some clustering algorithm shown in Fig. 9.  
   
  200  
   
  A.S. Rostami et al.  
   
  Fig. 9. Comparing lifetime of proposed algorithm and some clustering algorithm  
   
  6 Conclusion Wireless Sensor Network consists of a large number of tiny nodes that are distributed in the environment for speciﬁc purposes. Sensor nodes have limited energy and cannot be recharged. Algorithms used in WSN must both be energy efﬁcient and improve network lifetime. Clustering is one of the approaches that is used for energy efﬁciency. In this paper we introduce a new ﬁxed-clustering algorithm named ICA-Clustering. In this algorithm nodes are clustered with ICA in base station and then in those cluster nodes which are closer to the center of the cluster and have more residual energy. This improves its chance of being a cluster head. This algorithm, compared with other proposed clustering algorithms, leads to more energy efﬁciency and improves network lifetime.  
   
  References 1. Rabeay, J.M., Ammer, M.J., da Silva, J.L., Patel, D., Roundry, S.: PicoRadio supports ad hoc ultra-low power wireless networking. IEEE Comput. Mag. 33, 42–48 (2000) 2. Elahi, A., Hosseinabadi, A.R., Rostami, A.S.: Multi-hop fuzzy routing for wireless sensor network with mobile sink. Int. J. Sci. Eng. Res. 4(7), 2431–2439 (2013) 3. Kumarawadu, P., Dechene, D.J., Luccini, M., Sauer, A.: Algorithms for node clustering in wireless sensor networks: a survey, pp. 295–300, December 2008 4. Tavakkolai, H., Yadollahi, N., Yadollahi, M., Hosseinabadi, A.R., Rezaei, P., Kardgar, M.: Sensor selection wireless multimedia sensor network using gravitational search algorithm. Indian J. Sci. Technol. 8(14), 1–6 (2015) 5. Karenos, K., Kalogeraki, V., Krishnamurthy, S.: Cluster-based congestion control for sensor networks. ACM Trans. Sensor Netw. 4, 1–39 (2008) 6. Rostami, A.S., Bernety, H.M., Hosseinabadi, A.R.: A novel and optimized algorithm to select monitoring sensors by GSA. In: International Conference on Control, Instrumentation and Automation (ICCIA), pp. 829–834 (2011)  
   
  Imperialist Competition Based Clustering Algorithm  
   
  201  
   
  7. Elahi, A., Hosseinabadi, A.R., Rostami, A.S.: Improving news document clustering based on a hybrid similarity measurement. In: International Conference on Intelligent Computing and Intelligent Systems (ICIS), pp. 1–6 (2011) 8. Heinzelman, W.R., Chandrakasan, A., Balakrishnan, H.: An application-speciﬁc protocol architecture for wireless microsensor networks. In: IEEE Tmns. Wireless Commun. pp. 660– 670, October 2002 9. Heinzelman, W.R., Chandrakasan, A., Balakrishnan, H.: An application-speciﬁc protocol architecture for wireless microsensor networks. In: IEEE Transactions on Wireless Communications, pp. 660–670, October 2002 10. Wang, A., Yang, D., Sun, D.: Clustering algorithm based on energy information and cluster heads expectation for wireless sensor networks. Comput. Electr. Eng. 38(3), 662–671 (2012) 11. Lindsey, S., Raghavendra, C.S.: PEGASIS: Powere-fﬁcient Gathering in Sensor Information System. In: Proceedings IEEE Aerospace Conference, pp. 1125–1130, March 2002 12. Yueyang, L., Hong, J., Guangxin, Y.: An energy-efﬁcient PEGASIS-based enhanced algorithm in wireless sensor networks, China Commun. Technol. Forum (2006) 13. Selvakennedy, S., Sinnappan, S.: An adaptive data dissemination strategy for wireless sensor networks, Int. J. Distrib. Sens. Netw., 3(1), 23–40 (2007) 14. Bandopadhya, S., Coyle, E.: An energy efﬁcient hierarchical clustering algorithm for wireless sensor networks. In: Proceeding of IEEE INFOCOM, vol. 3, pp. 1713–1723, April 2003 15. Fahmy, S., Younis, O.: HEED: a hybrid energy-efﬁcient distributed clustering approach for ad hoc sensor networks. IEEE Trans. Mobile Comput. 3(4), 366–379 (2004) 16. Manjeshwar, A., Agrawal, D.P.: TEEN: a protocol for enhanced efﬁciency in wireless sensor networks. In: The Proceedings of the 1st International Workshop on Parallel and Distributed Computing Issues in Wireless Networks and Mobile Computing, April 2001 17. Smaragdakis, G., Matta, I., Bestavros, A.: SEP: a Stable Election Protocol for clustered heterogeneous wireless sensor networks. In: Proceedings of the International Workshop on SANPA, pp. 251–261 (2004) 18. Varma, S., Nigam, N.: U.S. Tiwary, Base Station Heterogeneous Wireless Sensor Network using clustering, pp. 1–6 (2008) 19. Qing, L., Zhu, Q., Wang, M.: Design of a distributed energy-efﬁcient clustering algorithm for heterogeneous wireless sensor networks. Comput. Commun. 29(12), 2230–2237 (2006) 20. Liu, Z., Zheng, Q., Xue, L., Guan, X.: A distributed energy-efﬁcient clustering algorithm with improved coverage in wireless sensor networks. Future Gener. Comput. Syst. 28(05), 780–790 (2012) 21. Haupt, R.L., Haupt, S.E.: Practical Genetic Algorithms, 2nd edn. Wiley, Hoboken (2004) 22. Kennedy, J., Eberhart, R.: Particle swarm optimization. Proc. IEEE Int. 4, 1942–1948 (1995) 23. Hosseinabadi, A.R., Siar, H., Shamshirband, S., Shojafar, M., Nizam, M.H., Nasir, M.: Using the gravitational emulation local search algorithm to solve the multi-objective flexible dynamic job shop scheduling problem in Small and Medium Enterprises. Ann. Oper. Res. 229(1), 451–474 (2015). Springer 24. Rostami, A.S., Mohanna, F., Keshavarz, H., Hosseinabadi, A.R.: Solving multiple traveling salesman problem using the gravitational emulation local search algorithm. Appl. Math. Inf. Sci. 9(2), 699–709 (2015) 25. Hosseinabadi, A.R., Kardgar, M., Shojafar, M., Shamshirband, S., Abraham, A.: GELS-GA: hybrid metaheuristic algorithm for solving multiple travelling salesman problem. In: International Conference on Intelligent Systems Design and Applications (ISDA), pp. 76–81 (2014)  
   
  202  
   
  A.S. Rostami et al.  
   
  26. Hosseinabadi, A.R., Yazdanpanah, M., Rostami, A.S.: A new search algorithm for solving symmetric traveling salesman problem based on gravity. World Appl. Sci. J. 16(10), 1387– 1392 (2012) 27. Hosseinabadi, A.R., Farahabadi, A.B., Rostami, M.S., Lateran, A.F.: Presentation of a new and beneﬁcial method through problem solving timing of open shop by random algorithm gravitational emulation local search. Int. J. Comput. Sci. 10(1), 745–752 (2013) 28. Hosseinabadi, A.R., Ghaleh, M.R., Hashemi, S.E.: Application of modiﬁed gravitational search algorithm to solve the problem of teaching hidden Markov model. Int. J. Comput. Sci. 10(3), 1–8 (2013) 29. H. Tavakkolai, A. R. Hosseinabadi, M. Yadollahi, T. Mohammadpour, “Using Gravitational Search Algorithm for in Advance Reservation of Resources in Solving the Scheduling Problem of Works in Workflow Workshop Environment”, Indian Journal of Science and Technology, Vol. 8(11), 1–16, June 2015 30. Hosseinabadi, A.R., Kardgar, M., Shojafar, M., Shamshirband, S., Abraham, A.: Gravitational search algorithm to solve open vehicle routing problem. In: 6th International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2015), Chapter Advances in Intelligent Systems and Computing, Kochi, India, pp. 93–103. Springer (2016) 31. Shijun, H., Yanyan, D., Zhou, R., Zhao, S.: A clustering routing for energy balance of WSN based on genetic algorithm. In: International Conference on Future Computer Support Education, IERI Procedia, vol. 2, pp. 788–793 (2012) 32. Shahvandi, L.K., Teshnehlab, M., Haroonabadi, A.: A novel clustering in wireless sensor networks used by imperialist competitive algorithm. Int. J. Adv. Eng. Sci. Technol. 8(2), 276–280 (2011) 33. Bayraklı, S., Zafer Erdogan, S.: Genetic algorithm based energy efﬁcient clusters (GABEEC) in wireless sensor networks. In: The 3rd International Conference on Ambient Systems, Networks and Technologies, vol. 10, pp. 247–254 (2012) 34. MurtalaZungeru, A., MinnAng, L., PhooiSeng, K.: Classical and swarm intelligence based routing protocols for wireless sensor networks: a survey and comparison. J. Netw. Comput. Appl. 35, 1508–1536 (2012) 35. Bore Gowda, S.B., Puttamadappa, C., Mruthyunjaya, H.S., Babu, N.V.: Sector based multi-hop clustering protocol for wireless sensor networks. Int. J. Comput. Appl. 43(13), 33– 38 (2012) 36. Shojafar, M., Kardgar, M., Hosseinabadi, A.R., Shamshirband, S., Abraham, A.: TETS: a genetic-based scheduler in cloud computing to decrease energy and makespan. In: 15th International Conference on Hybrid Intelligent Systems (HIS 2015), Chapter Advances in Intelligent Systems and Computing 420, Seoul, South Korea, vol. 420, pp. 103–115. Springer (2016) 37. Shamshirband, S., Shojafar, M., Hosseinabadi, A.R., Abraham, A.: OVRP_ICA: an imperialist-based optimization algorithm for the open vehicle routing problem. In: International Conference on Hybrid Artiﬁcial Intelligence Systems (HAIS), vol. 9121, pp. 221–233. Springer, LNCS (2015) 38. Atashpaz-Gargari, E., Lucas, C.: Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. IEEE Congr. Evol. Comput. 7, 4661– 4666 (2007)  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring Ola E. Elnaggar, Rabie A. Ramadan(B) , and Magda B. Fayek Cairo University, Giza, Egypt ola [email protected]  , [email protected]  , [email protected]   
   
  Abstract. Oil tanks monitoring is an important problem in the ﬁeld of oil production. Tanks might be distributed in large areas and dedicated people might be assigned for each tank to monitor it in terms of its temperature, the surrounding area, and even the level of oil inside. Wireless Sensor Networks (WSNs) could be one of the best solutions to this problem. The problem of these tanks is that they are far from each other and they might have obstacles among them that block the sensors’ signals. At the same time, WSN consists of many low-cost nodes with limited power and communication. In addition, these sensors are either randomly deployed in the monitored ﬁeld or deterministically installed in speciﬁc places. In both cases, gaps may appear in the network leaving uncovered areas/tanks. In this paper it is improved the connectivity of the network used for oil tanks monitoring by adding minimum number of relay nodes to it. To solve the problem of oil tanks monitoring by using WSN are used the following algorithms: the Divided Network Area Algorithm (DNAA) by dividing the network area to small squares and connecting theses small areas; the Best Path Algorithm (BPA) by making the network connected when selecting the best path for all sensors and guarantee that all nodes are connected; and the Adjustable Communication Range with Best Path Algorithm (ACR-BPA) working with both the communication ranges and the network paths. With diﬀerent problem settings, the proposed algorithms are examined and compared to a state-of-art greedy algorithm.  
   
  1  
   
  Introduction  
   
  Wireless Sensor Networks (WSNs) are taking huge attention due to its wide range of application in the last few years. Some of these applications are air pollution monitoring, health care monitoring, forest ﬁre detection, Oil & Gas Remote Monitoring applications for example pipeline monitoring [9] and tank level monitoring [10], etc. WSN consists of large number of wireless sensor nodes, which are deployed in particular area to measure certain phenomenon such as temperature, sound, pressure, etc. These sensors send their measured data to a central processing unit, which collects all the data and develops the decision. Each sensor has its sensing rang, communication rang and limited power. Sensing rank is the monitored area around the sensor. Communication rank is the minimum distance between two sensors to send the data between them. c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 17  
   
  204  
   
  O.E. Elnaggar et al.  
   
  Due to the limitations of the wireless sensors prolonging their lifetime becomes the important attribute in WSN. Another problem in WSN is the gaps between sensors due to the random deployment of the sensors. Random deployment of sensor nodes most of the time makes WSN disconnected. To solve this problem we need to add some relay nodes to the network to make it connected. In order to achieve better communication and maximize the network lifetime, relay nodes are deployed in the network using an eﬃcient deployment algorithm. One of the most important applications of WSNs is monitoring oil tanks. Oil tanks are containers available in many shapes: vertical and horizontal cylinder; open top, close top and ﬂat bottom. Sensors could be deployed in/on the tanks to measure certain features such as tank’s temperature, oil level, and surrounding environment. However, with large number of tanks, the connectivity of these sensors might be a problem. To solve this problem we need to deploy a minimum number of relay nodes on the disconnected areas in the network to make the network connected. At the same time, WSN lifetime is another issue that has to be considered during the relay deployment which makes the problem more complex. The paper presents three algorithms to solve the monitoring oil tanks problem. The ﬁrst algorithm, entitled Divided Network Area Algorithm (DNAA), in which it divides the network area into grid of cells, could be in a form of squares. Relay nodes will be added to the center of these cells for their purpose is to enhance sensors connectivity. The second algorithm, entitled Best Path Algorithm (BPA), exploits the concept of best path to the centralized node (sink node/base station). It computes the best path for each sensor node and tries to add the relay nodes on these paths. The last algorithm is named Adjustable Communication range with Best Path Algorithm (ACR-BPA). This algorithm is a modiﬁcation to BPA with the use of one of the sensors features which is the adjustable communications ranges. The remainder of the paper is organized as follows. Section 2 states some of the most related work to the work done in this paper. Section 3 presents the problem deﬁnition. The algorithms involved to solve the oil monitoring problem are shown in Sect. 4. Section 5 presents the simulation and the comparison of the algorithms. Conclusion of the paper and the future work is presented in the ﬁnal section.  
   
  2  
   
  Related Work  
   
  The scientiﬁc literature includes papers that consider the connectivity and the energy consumption in WSNs [1–6]. In [1], the authors considered deploying of few additional nodes possible to reconnect a disconnected network. In [2,7], the main goal is to fully enhance the connectivity of the wireless sensor networks by adding an available set of relay nodes to the network after going through some stages called levels. In the ﬁrst level, the authors divided the network area into certain numbers of equal regions and represented each region by a relay in its center. In the  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  205  
   
  second level, the best K relays’ locations are chosen by solving a semi-deﬁnite programming (SDP) optimization. Through the third level, it iteratively reﬁnes the solution by dividing each obtained relay’s region into a number of smaller regions and repeating the same procedure. In [3], a relay sensor placement algorithm to maintain the connectivity is proposed. They formulated this problem into a network optimization problem, named Steiner Minimum Tree with Minimum Number of Steiner Point (SMT-MSP). This study restricts the transmission power of each sensor to smallest value, then add relay nodes to guarantee the connectivity. In [4], three heuristic algorithms are proposed for achieving connectivity of a randomly deployment ad hoc wireless networks. This work connects the network with minimum number of relay nodes with maximum utility from a given number of the additional nodes for the disconnected network. Another work proposed in [6] where the authors studied single-tiered constrained relay node placement problems, under both the connectivity requirement and the survivability requirement. In this paper, we study relay node deployment problem in WSN. Oil tanks monitoring is considered as a realistic case study application. In oil tank problem we need to make all sensors on each tank connected to the base station by adding minimum number of relay nodes in the optimal places to prolong the network lifetime.  
   
  3  
   
  Oil Tanks Monitoring Problem  
   
  The Oil & Gas industry is one of the most prevalent industries for the application of Wireless Sensor Technology. WSN solutions for the oil, gas and power generation reducing maintenance costs, lowering the energy consumption, minimizing downtime, improving equipment performance, enhancing safety and centralize controls. Wireless technology has the potential to be beneﬁcial in many regards. Eliminating the need for cables can contribute to reduced installation and operating costs; it enables installations in remote areas and it allows for cost eﬃcient. Examples on Oil & Gas Remote Monitoring applications are Pipeline Integrity Monitoring and Tank Level Monitoring. In this paper, we focus on Tank Level Monitoring problem using WSN. Oil tanks are containers holding oil with open top, close top and Oil Pumping Units (OPU). Most of the Oil Pumping Units (OPU) are manually monitored (Fig. 1). This oil-pumping system use a high power-consuming process and is incapable of OPU’s structural health monitoring. In Tank Level Monitoring with WSN, the condition of the oil storage tanks can be monitored using sensors: level sensor, temperature sensor and gas sensor. These sensors are ﬁxed inside the oil storage tanks. The sensor output is given to the sink node. Based on the condition of the oil storage tanks and the oil pumping motor is controlled. The motivations of using WSN in Tank Level Monitoring are: the special nature of oil exploration (the majority of oil pumping units are spread over barren hills, mountains and deserts) and the existing oil-pumping systems with manual control.  
   
  206  
   
  O.E. Elnaggar et al.  
   
  Fig. 1. Wireless sensor network on area L × L.  
   
  Manual control systems have three disadvantages: (1) The OPU administrator must go to the oil ﬁeld frequently to see the OPU status regardless the weather and the place. (2) Power consumption for OPU is huge during the oilpumping process. (3) It is hard to ﬁx the monitoring problem because it depends on people. For these reasons, WSN is used to monitor oil tank levels. Let consider a wireless sensor network in a two dimension space. All sensor nodes (terminal nodes) need to send all information about oil level on a certain tank to a sink node. The connectivity of these sensors depends on the position of the sensors and their communication ranges. As can be seen in Fig. 2, as an example, all sensors need to send all data to the Sink Node (SN). Sensor S2 can send to SN without a problem because S2 is directly connected to SN but for sensor S1, some relay nodes need to be added for the purpose of connectivity. Therefore, the work in this paper is step towards solving this problem using minimum number of relay nodes and saving the overall network lifetime.  
   
  4  
   
  Algorithms for Solving the Oil Tanks Monitoring Problem  
   
  In this section, three algorithms are proposed to solve the oil tanks monitoring problem. The algorithms try to add some relay nodes to the WSN to make it connected with minimum number of relay nodes and try to prolong the network lifetime as well. The algorithms are: Divided Network Area Algorithm (DNAA), Best Path Algorithm (BPA) and Best Path Algorithm with Ant Colony Optimization (BPA-ACO). The following subsection introduces the Ant Colony Optimization algorithm that will be further used in the BPA-ACO algorithm.  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  4.1  
   
  207  
   
  Ant Colony Optimization  
   
  Ant Colony Optimization (ACO) is a class of algorithms. The ﬁrst algorithm, Ant System, was initially proposed by Colorni, Dorigo and Maniezzo [11–13]. The base of ACO is to simulate the real behavior of ants in nature. The ant colony provides indirect communication with the help of ant’s pheromone. Pheromones are chemical substances which attract other ants searching for food. The attractiveness of a given path depends on the quantity of pheromones detected by an ant. The quantity of pheromone is governed by some rules and depends on the attractiveness of the route. The use of attractive route ensures that the ant exudes more pheromones on its way back and so that the path is much attractive for other ants. The evaporation of pheromones is time dependent. When the way is no longer used, pheromones are evaporated and the ants begin to use other paths. ACO steps are as follows. First Step: For ﬁrst sensor, martiﬁcial ant start with random number from 1 to maximum number of communication levels (in this paper there are 6 levels). Second Step: Each ant builds a solution by adding one communication level after the other until it reaches the last sensor. The selection of the next communication range depends on certain probability. The probability pik of transition of a virtual ant from the node i to the node k is given by formula 1; τi - indicates the attractiveness of transition in the past, ηi - adds to transition attractiveness for ants, ni- set of nodes connected to point i, without the last visited point before i, β, α- system dependent parameters. (η α + τiβ ) pik =  i β (ηni α + τni )  
   
  (1)  
   
  Third Step: Pheromone update, virtual ant is using the same reverse path as the path to the food source based on its internal memory, but in opposite order and without cycles. After elimination of the cycles, the ant puts the pheromone on the edges of reverse path according to formula (2); τij (t) is the value of pheromone in step t, Δτ is the value by ants saved pheromones in step t. Values Δτ can be constant or they can be changed depends on solution quality. τij (t + 1) = ρτij (t) + Δτ (t)  
   
  (2)  
   
  Fourth Step: At last, the pheromones on the edges are evaporated. The evaporation helps to ﬁnd the shortest path and provides that no other path will be assessed as the shortest as given in Eq. (3); ρ is a user-deﬁned parameter called evaporation coeﬃcient. (3) τij (t + 1) = (1 − ρ)τij (t) In our problem, a group of artiﬁcial ants searches solutions by starting each ant with random communication level for ﬁrst sensor and completing the path until last one ﬁnishes depending on certain probability. This operation is inspired from the Theorem 1 given in [8]:  
   
  208  
   
  O.E. Elnaggar et al.  
   
  Theorem 1. To maximize the lifetime of the WSN, for the sensor nodes Ni and Nj, the power level assignment should satisfy xi ≥ xj for i < j. The high communication range is given high probability when the sensor is far away from the sink node and low probability is given to the nearest sensor to the sink node. When all ants reach to the end of the path, the pheromone gets updated depending on the path length and the consumed power. Therefore, the path covering the pipe with law power consumption has high pheromone value. ACO will stop after reaches the maximum number of iterations and returns the best path. 4.2  
   
  Greedy Algorithm  
   
  In [8] is solved the oil tanks monitoring problem using the Greedy algorithm. The greedy algorithm starts with certain number of sensor nodes are deployed with certain position (the position of sensor nodes are on the top of oil tanks). The greedy algorithm includes the following three phases: Initial Graph Phase: Find the initial graph G(Nt , E(Lt , Rt )) where Nt is the terminal nodes with location Lt and communication range Rt . When the distance between two sensors is less than the communication range, the two sensors are connecting. In this phase, no relay nodes are added. Constructing Delaunay Phase: Construct Delaunay by using the terminal nodes. The construction of the Delaunay is illustrated as follows. Let S be the set of the points in the two dimension space. The Voronoi diagram of S, denoted as Vol(S) which is decomposed into Voronoi cells {Va: a ∈ S} deﬁned as: V a = {x ∈ R2 : |x − a| ≤ |x − b|, ∀b ∈ S}. The dual of the Voronoi diagram is the Delaunay triangulation Del (S ). Del (S ) is geometrically realized as a triangulation of the convex hull of S. After constructing Delaunay, the algorithm calculates the length of the three edges of each triangle. If the length of the edge is not larger than the transmission range Rt, then connect it. Triangle Type Phase: After Phase 1, the algorithm divides the Delaunay triangles into three types. In Type 1, the length of all edges of the triangle is larger than Rt and smaller than 2Rt. In Type 2, the longest edge of the triangle is at most 4Rt, while the shortest edge is larger than Rt and at most 2Rt. The properties of triangles diﬀerent from Types 1 and 2 are deﬁned as Type 3. For the triangles of Type 1. The algorithm places one relay node to connect ﬁve nodes that are formed by three adjacent triangles. Second, it places one relay node to connect four nodes that are formed by two adjacent triangles. Third, it adds one relay node to connect three nodes of one triangle. For the triangles of Type 2, it tries to place two relay nodes to connect three nodes of one triangle. For the triangles of Type 3, it adds relay nodes to connect the nearest disconnected nodes pair along the edge of the triangle. See [8] for other details on the greedy algorithm.  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  4.3  
   
  209  
   
  Divided Network Area Algorithm  
   
  The Divided Network Area Algorithm (DNAA) starts with a certain number of sensor nodes (N ) deployed on the top of the oil tanks. All sensor nodes start with the same communication level Rt and the same power level. Sensor nodes assume to send its own data about the oil level, temperature, pressure, and any other features from the oil tank to the ink node (SN). DNAA includes the following phases: Dividing Area Phase: Divide the network area to squares with edges equal to the communication rang Rt . On each square which include at least one sensor, add one relay node at the center of it. DNAA didn’t add any relay nodes in squares without sensor nodes. Each two sensors with distance less than Rt are connected. In Fig. 2 are ten sensors. Assume sensor number 1, s1, is the sink node. All sensors need to send the data to s1. After DNAA had divided the area to squares, it adds relay nodes at the center of each square that has at least one sensor in it, see s12, s13, s15, etc. then, it draws a line (line with dark blue) between the two sensors that have distance d between them where d ≤ Rt (s12 and s3). Connecting Sensor Nodes Phase: Make the disconnected node connected with the nearest node with adding relay nodes like sensor number 6 in Fig. 3 or without relay node if the distance between the two sensors is less than Rt . For instance, from Fig. 2, to connect s1 with s2 DNAA adds a relay node s18 and the same for s6 and s15, it adds s19. Relay Nodes Connected Phase: Make the main relay nodes (relay nodes added in the center of the square) connected by adding other relay node(s) on the shortest path between the two of them as shown in Fig. 3. All of the sub-graphs need to be connected (Fig. 3). DNAA connects subgraphs: s1, s2, s11, s18 with sub-graphs: s13, s14, s4, s5 and some relay nodes s20:s23. Repeat this phase until all of the sub-graphs are connected.  
   
  Fig. 2. (a) Before deploying the relay nodes, (b) after adding relay nodes at the center of the square.  
   
  210  
   
  O.E. Elnaggar et al.  
   
  Fig. 3. Making the disconnected nodes connected (left) and the disconnected relay nodes connected (right).  
   
  4.4  
   
  Best Path Algorithm  
   
  BPA starts with the same conditions for greedy algorithm and DNAA. It starts with a certain number of sensor nodes (N) are deployed on the top of the oil tanks. All sensor nodes are assumed to have the same communication rang Rt and the same power level. Sink node collect all data from all sensor nodes in the WSN. The BPA consist of the following phases. Connection Without Relay Node Phase: In this phase, each two sensors with distance less than Rt are assumed connected. Connection With Relay Node Phase: In this phase BPA adds relay nodes to make the network connected. BPA ﬁrst computes all paths from each sensor to the sink node. BPA calls the path as the best path if the number of relay nodes added to make the path connected was minimum number than others. To do this, BPA gives each link in the path a weight. The weight of a disconnected link is the needed number of relay nodes to make it connected. Every connected link has a weight equal to zero. The path weight is equal the sum of all links’ weight, see Fig. 4. As in Fig. 4, all sensors need to send its data the sink node (s1 is the sink node in this example). The links with green color mean that the two sensor are connected (the distance between them is less than Rt ) with weight w = 0. Links with red color means that the distance between the two sensors is greater than Rt ; in this case, the algorithm must add some relay nodes to make the link connected. Links with w = 3 means that they need three relay nodes to the link connected. For instance, sensor 4 can send its data to the sink node through many paths. For example, Path 1 goes through nodes 4, 9, 2, and 1 with weight = weightlink (4:9) + weightlink (9:2) + weightlink (2:1) which is equal to 1 + 0 + 0 = 1. Path 2 goes through nodes 4, 3, and 1 with weight equals to 0+3 =3. Sensor 4 will send its data through path 1 because it has the minimum weight. In the next step link (4:9) will be with w = 0 because it will be connected. The algorithm will repeat step two until all sensors will be connected.  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  211  
   
  Fig. 4. Path weight in BPA. (Color ﬁgure online)  
   
  4.5  
   
  Adjustable Communication Rang with Best Path Algorithm  
   
  ACR-BPA assumes sensors with adjustable communication range R1, R2 . . . R6 as in [8] instead of using one communication range. The algorithm starts with a certain number of sensor nodes deployed on the top of oil tanks with certain positions. All sensor nodes are assumed to have the same communication power and adjustable communication range. In the ﬁrst step, the algorithm selects the best path for all sensors while the second step consists of two parts: Part A: Choose the communication range (RC) of the sensors depending on the distance between them. For example, in Fig. 4, if the distance d between two sensors is less than or equal to R6 (the maximum communication range), ACRBP doesn’t add any relay node. When: R5 < d ≤ R6, RC for the two sensors is R6; R4 < d ≤ R5, RC for the two sensors is R5 . . . d ≤ R1, RC for the two sensors is R1. Part B: Add the relay nodes to the link when d > Rmax. To deploy relay nodes in this step ACR-BP uses Ant Colony Optimization (ACO) deployment algorithm.  
   
  5  
   
  Numerical Experiments and Discussions  
   
  In this section, the results for using WSN in Level Tank Monitoring problem will be illustrated. The next subsections show the eﬀect of using the proposed algorithms on the network lifetime in case of diﬀerent network settings. Experiment 1: Comparison among the four algorithms in terms the required numbers of relay nodes. In this experiment, there are certain number of oil tanks are established randomly on square area with length L, L = 100 m. One sensor node is deployed on the top of each tank. The experiment studies the eﬀect of using the four algorithms to make the wireless sensor nodes connected.  
   
  212  
   
  O.E. Elnaggar et al.  
   
  Fig. 5. The number of relay nodes added in the four algorithms in square area with L = 100 m (left) and L = 500 m (right).  
   
  The wireless sensor nodes, n, (where n is the number of oil tanks) changes from n = 10 to n = 100 sensors. All sensors as assumed to have the same power level. Sensors communication ranges as assumed the same for all algorithms except for ACR-BPA in which it utilizes diﬀerent communication ranges in its operation. From the results in Fig. 5, DNAA used the maximum number of relay nodes even more than greedy algorithm. ACR-BPA seems to be the best in terms of the required number of the relay nodes added for the network to be connected. ACR-BPA uses the minimum number of relay nodes compared with the rest of the algorithms. These results apply to all diﬀerent networks with diﬀerent number of nodes. Therefore, the algorithms could be ranked from the best to the worst in terms of the deployed number of relays as ACR-BPA, BPA, Greedy, and then DNAA. In fact, the implementation of DNAA on a real environment could be somehow diﬃcult due to the special nature of oil exploration and oil drilling, the majority of oil pumping units (OPU) are spread over barren hills, mountains and deserts. Experiment 2: Comparison among the proposed algorithms in terms of the required numbers with large monitored area. In this experiment, again the number of oil tanks are changed from 10 to 100; however, the monitored area in this set of experiments are considered as a square of side length L = 500 m. This large area certainly aﬀects the required number of relay nodes. Therefore, the purpose of this set of experiments is to examine the behavior of the proposed algorithms as well as the greedy algorithm. As can be seen in Fig. 5, DNAA still requires the maximum number of relay nodes; on the other hand, ACR-BPA used the minimum number of relay nodes. At the same time the behavior of the greedy algorithm and BPA is almost similar in terms of the number of the relay nodes they use. ACR-BPA enhances the results from Greedy algorithm with almost 23.2%, and BPA acts much better than the greedy algorithm with almost 0.009%.  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  213  
   
  Fig. 6. The eﬀect of adding relay nodes on the network lifetime in the four algorithms on square area with L = 100 m (left) and L = 500 m (right).  
   
  Experiment 3: Network lifetime under the operation of the proposed algorithms. In this set of experiments, we examine the performance of the proposed algorithms compared to the greedy algorithm in terms of network lifetime. The area of oil tanks is assumed a square shape L×L where L = 100 m. A sensor is deployed on the top of each oil tank. The term network lifetime mean, in this context, either the ﬁrst node dies or a relay nodes dies. The network lifetime is computed as the number of the round before any or both of these conditions occurs. As shown in Fig. 6, the number of oil tanks as well as the number of sensors change from 10 to a 100 on a square area of 100 × 100 m. Oil tanks are deployed randomly in all cases. The Fig. 6 shows that ACR-BPA gives the best lifetime over all of the other algorithms. For instance, at 60 oil tanks, the network still operated for 26 rounds. In addition, DNAA algorithm comes in the second rank after the ACR-BPA in which at 60 oil tanks, it keeps the network operate for 24 rounds. At the same time, BPA and the greedy algorithms have the same performance for almost 12 rounds with 50 oil tanks are deployed. The results is conﬁrmed in Fig. 6 even when the monitored area is increased to a square with side length L = 500 m. Experiment 4: Comparison among the proposed algorithms in terms of the required number of relay nodes and network lifetime with monitored area of equilateral triangle shape. Here the performance of the algorithms are examined when equilateral triangle area are used. The network topology in this case is assumed to diﬀer from the square monitored area. There is a certain number of oil tanks are established randomly on equilateral triangle area with edge L = 200 m. One sensor node is deployed on the top of each tank. The set of experiments illustrate the eﬀect of the network shape on the network lifetime and the number of relay nodes. The number of oil tanks increases from n = 10 tanks to n = 100. DNAA can’t implement in this experiment because it requires the monitored areas to be divided area into square shapes which is not valid in our case. From the results shown in Fig. 7, the change in the shape of the network area (oil tank area) causes a change in the required number of relay nodes and  
   
  214  
   
  O.E. Elnaggar et al.  
   
  Fig. 7. The number of relay nodes added (left) and eﬀect of adding relay nodes on the network lifetime (right) into the four algorithms in equilateral triangle area with L = 200 m  
   
  the network lifetime. However, ACR-BPA still over-performing other algorithms in terms of required number of relay nodes and network lifetime. At the same time, BPA and the greedy algorithm performing almost similar to each other especially with the large number of oil tanks. For instance after 60 oil tanks are deployed in the monitored ﬁeld, their curves are overlapping as can be seen in Fig. 7.  
   
  6  
   
  Conclusion and Future Work  
   
  In this paper, the problem of oil tanks monitoring is solved using three proposed algorithms. The algorithms are compared to each other and with an existing greedy algorithm. ACR-BPA algorithm based on ACO seems to have the best performance over the compared ones. However, ACR-BPA is suitable only for nodes with multilevel communication ranges. Therefore, BPA could be suitable for nodes with ﬁxed communication range and ACR-BPA will be the best for network with nodes having variable communication range. The conducted extensive set of experiments show that the ACR-BPA and BPA are much better than the greedy algorithm in terms of the number of deployed relays and network lifetime. For our future work, we would like to examine the performance of the proposed algorithm on network with diﬀerent topologies and monitored areas with diﬀerent shapes. Acknowledgements. The study was conducted under the auspices of the IEEE-CIS Interdisciplinary Emergent Technologies task force.  
   
  References 1. Li, N., Hou, J.C.: Improving connectivity of wireless ad hoc networks. In: Proceedings of the Second Annual International Conference on Mobile and Ubiquitous Systems: Networking and Services (MobiQuitous 2005), pp. 314–324 (2005)  
   
  Wireless Sensor Networks Relay Node Deployment for Oil Tanks Monitoring  
   
  215  
   
  2. Ibrahim, A.S., Seddik, K.G., Ray, K.J.: Improving connectivity via relays deployment in wireless sensor networks. IEEE GLOBECOM, pp. 1159–1163 (2007) 3. Cheng, X., Du, D.Z., Wang, L., Xu, B.: Relay sensor placement in wireless sensor networks. Wirel. Netw. 14(3), 347–355 (2008) 4. Koskinen, H., Karvo, J., Apilo, O.: On Improving Connectivity in Static Ad Hoc Networks by Adding Nodes. Med-Hoc-Net (2005) 5. Hou, Y.T., Shi, V.Y., Sherali, H.D., Midkiﬀ, S.F.: On energy provisioning and relay node for wireless sensor network. IEEE Trans. Wirel. Commun. 4, 2579–2590 (2005) 6. Misra, S., Hong, S.D., Xue, G., Tang, J.: Constrained Relay Node Placement in Wireless Sensor Networks to Meet Connectivity and Survivability Requirements (2008) 7. Chang, J.-H., Jan, R.-H.: An eﬃcient relay sensor placing algorithm for connectivity in wireless sensor network. In: Embedded and Ubiquitous Computing. Lecture Notes in Computer Science, Vol. 4096, pp. 874–883 (2011) 8. Guo, Y., et al.: Sensor placement for lifetime maximization in monitoring oil pipelines, In: Proceedings of the 1st ACM/IEEE International Conference on Cyber-Physical Systems, pp. 61–68 (2010) 9. Elnaggar, O.E., Ramadan, R.A., Fakry, M.B.: WSN in monitoring oil pipelines using ACO and GA. In: The 5th International Conference on Sustainable Energy Information Technology (SEIT-2015), vol. 52, pp. 1198–1205 (2015) 10. Barani, R., Jeyashmi, V.: Oil well monitoring and control based on wireless sensor network using atmega 2560 controller. Int. J. Comput. Sci. Commun. Netw. 3, 341–346 (2013) 11. Colorni, A., Dorigo, M., Maniezzo, V.: Distributed optimization by ant colonies. In: Proceedings of ECAL 1991, European Conference on Artiﬁcial Life. Elsevier Publishing, Amsterdam (1991) 12. Dorigo, M., Maniezzo, V., Colorni, A.: The ant system: an autocatalytic optimizing process, Technical report TR91-016. Politecnico di Milano (1991) 13. Dorigo, M.: Optimization, learning and natural algorithms. Ph.D. thesis. Politecnico di Milano, Milano (1992)  
   
  A Smart Way to Improve the Printing Capability of Operating System Adeel Ahmed1, Muhammad Arif1(&), Abdul Rasheed Rizwan2, Muhammad Jabbar1, and Zaheer Ahmed1 1  
   
  Department of Computer Science, University of Gujrat, Gujrat, Pakistan [email protected]  , {m.arif,m.jabbar,zaheer}@uog.edu.pk 2 Department of Computer Science, Virtual University of Pakistan, Lahore, Pakistan [email protected]   
   
  Abstract. Operating system is the core of computer science and task scheduling is the major topic in this domain. Priority base scheduling is always remains hot topic in the domain of operating systems. In Priority base printing always higher priority given to those printings jobs which are processed more quickly rather than the lower priority base printings jobs. In this way low priority jobs are delayed again and again. In this research detail study is conducted regarding the scheduling algorithms in operating system. Priority base printings become bottlenecks who are assigned lowest priority. They may have to wait till their turn may be up to mid night in large departments. Now we are going to discuss a speciﬁc algorithm which can solve above issues in a smart way. A new method is proposed to solve the priority scheduling problems. This method is very handy for those users who are assigned a higher priority authority in printing mechanism. It also allows the lowest priority base printing to print data. In this solution we are not going to ignore the highest printing jobs. The highest priority base printing jobs will be continued in the same way. Our main objective is to maintain a balance between the high priority and low priority printing jobs without suffering from continues delay. Keywords: Priority printing  Printer scheduling  Printing capability  
   
    
   
  Spooler  
   
    
   
  Algorithm  
   
    
   
  Smart  
   
  1 Introduction Priority base scheduling is always remains hot topic in the domain of operating systems. Printing Architecture (PA) is a major component of any Operating System. PA is consists on printer driver and the application which sends the prints to printer [1]. Operating system is the core of computer science and task scheduling is the major topic in this domain. Printer drivers are attached with spool simultaneous peripheral operations on-line used to add printing job to buffer. Spooling provides best behavior to such I/O which has different data rates in receiving and sending mechanisms. Spooler is a kind of queue which takes input from rear and out at front part of the queue. The spooler sends data to target printer’s I/O port which can be in serial, network, USB, wireless © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_18  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  217  
   
  communication channel and parallel [2]. In Priority base printing always higher priority given to those printings jobs which are processed more quickly rather than the lower priority base printings jobs. In this way low priority jobs are delayed again and again. In this research detail study is conducted regarding the scheduling algorithms in operating system. Priority base printings become bottlenecks who are assigned lowest priority. They may have to wait till their turn may be up to mid night in large departments. Every printing job has some operating to complete its printing processes. For e.g., user sends printing command from an application which include direct printing, networks printing and internet base printing, after sending a command from the application it enters to the spooler (Simulates Peripheral Operation online) [3]. It also allows the lowest priority base printing to print data. In this solution we are not going to ignore the highest printing jobs. The highest priority base printing jobs will be continued in the same way. Our main objective is to maintain a balance between the high priority and low priority printing jobs without suffering from continues delay. Now we are going to discuss a speciﬁc algorithm which can solve above issues in a smart way. A new method is proposed to solve the priority scheduling problems. This method is very handy for those users who are assigned a higher priority authority in printing mechanism [4]. It also allows the lowest priority base printing to print data. In this solution we are not going to ignore the highest printing jobs. The highest priority base printing jobs will be continued in the same way. Our main objective is to maintain a balance between the high priority and low priority printing jobs without suffering from continues delay. The spooler performs speciﬁc processing on the sent job and passes to the printer driver. The printer driver translates the job according to the bitmap of the printer. Printing job to local or remote computer is performed by printer provider. Printer provider is responsible for print queue, functions and Printing Priority Queue (PPQ) [5]. PPQ performs high priority job before the low priority for printing. We can set the priority of individual documents in the general tab, use the priority slider (Windows OS) low priority is 1 and highest priority is 99.  
   
  2 Related Works Priority queue is different from normal queue. The normal queue data structure is base on FIFO. But priority queue is a kind of box which receives different priority jobs and sent the highest priority out to the calling function. Here is a conceptual picture of a priority queue is shown in the Fig. 1. Figure 1 shows how that printing jobs are inserted in to the queue and the highest priority job is taken out at ﬁrst. It also shown that the lowest priority jobs are remained in the queue waiting for their turn. Printing jobs are sent to priority queue to sort their positions; different kinds of method are used for sorting their priorities just as array representation, link list representation and heap sort etc. [4]. All these data structure have computation time to sort the requested prints. If a printer is already working on hundreds request and so much busy and in that position while a printer is going to print documents at this position it may receive another request and it have to compute sort on all prints, and this situation may exists for long time. This can stop the working of all prints [6]. We can see before sorting priority queue jobs, this job can enter the priority  
   
  218  
   
  A. Ahmed et al.  
   
  Fig. 1. Priority queue [2]  
   
  queue in different order. After entering the jobs into priority queue an algorithm is applied to sort them. Absolutely this algorithm takes time to sort them. Figure 2 illustrates the before sorting view.  
   
  Fig. 2. Before sorting overview  
   
  Starvation can be caused in PPQ. Just e.g., there 1 to 99 priorities for users according to their work in a origination. 99 have the highest priority and 1 has the lowest priority in case of Microsoft OS. From 99 to let’s say 20 users are already in printing but remaining 19 to 1 may b in starvation. It can be from 1 to 19 has urgent information to give his boss but he is the victim of starvation. So just PPQ is not so better in such kinds of case for printing jobs. Figures 3 and 4 illustrates the priority Queue.  
   
  Fig. 3. Priority queue [7, 8]  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  219  
   
  Fig. 4. Priority queue enqueue and dequeue [13]  
   
  In Fig. 4 it is shown that enque and dequqe functions are takinf the highest priority job ﬁrst and then move to the lowest priority jobs. Assigning different priority level for different kinds of groups with high and low priority level of queue is applied to Microsoft Windows server edition [5]. According to Microsoft to use the best way of priority level printing, create multiple logical printer of the target printer. Each priority level should be different to other group of priority level. For example users in Group A should be able to connect with printer with highest priority just as priority number one. And Group no. 2 should access the printer with the priority level two and further so on [9, 10, 16]. The method printing not only support LAN but also the WAN in client systems [11]. This will become a huge network so we have to manage it in a smart way. The method of printing ﬁrst include to identify the server method to receive and print the jobs [16]. We can customize printing priority level for others groups. Click on start button and click on Open Printers and Faxes. Right click on target printer, click on selected printer Properties, and then choose Advanced tab. Now click on Priority tab, click the up or down arrows, and then click OK. Here you can set priority level from 1 to 99. “99” is the highest priority level and “1” is lowest priority level in printing [17]. Select the appropriate priority level and click OK. Now to add new logical printer so to add a new logical printer click on Add Printer to add another logical printer for the same existing physical printer. Now again we have to set its priority level according to our feet needs. Allow the low level users to use the ﬁrst logical printer and medium level users allow them to use second logical  
   
  220  
   
  A. Ahmed et al.  
   
  printer, following the way we set high level user for the highest logical printer. When we need to open Printer and Faxes dialog box, we have to click on start button and next click on Printer and Faxes [12].  
   
  3 Problem Statement Microsoft does not allow it to manage lowest priority jobs automatically. Microsoft Server provides manually setting to overcome this issue. In Microsoft environment we have to change the priority of documents which are waiting to get printer. Even the selected job’s priority changing does not affect other priority jobs, yet it is not a good solution for large business environments. It is also happen in Microsoft Server edition the lowest priority base printing is ﬁxed up to a ﬁx time of night. The lowest printing priority is selected at midnight for printings. The time setting is hard set so in time of free printer, the time set priority documents are not allowed to printer to use the printer resource. So this solution to the problem is not so much efﬁcient. Higher priority should in top ascending order numeric numbers and lower priority job should rear part of ascending order in numeric numbers.  
   
  4 Results and Discussions Queue is a linear data structure where an item is removed from top end (Front) and new item is inserted at back end (Rear). This is shown in the Fig. 5.  
   
  Fig. 5. Queue insertion and deletion  
   
  Figure 5 shows the insertion and deletion of the jobs in the queue box. This is a common fashion which is used in normal kind of queue and data structure. But we are going to use this queue data structure in a different way with the help of linked list. Linked list allow to add and remove a node in anywhere of the list. We don’t have to shift up and down of other part in linked list to remove or to add a node as in array data structure. Let’s suppose the following is a linked list queue. In above ﬁgure different priority numbers are shown in Fig. 6, let’s suppose these are the priority numbers of printing commands. And we need to send command of  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  221  
   
  Fig. 6. Priority numbers  
   
  priority number two, which is recently entered into queue. But due to its priority we have to send it ﬁrst to printer. Here we need to remove this node from the linked list. Now we can see according to its data structure nature we should send command of top node to printer. We also not are going to sort it according to its priority, because we don’t want to use CPU cycle here due to efﬁciency issue. After removing the target node, now see in Fig. 7 [13].  
   
  Fig. 7. Target node removal  
   
  After knowing all kinds of issues in PPQ lets solve these issues in a smart way [14]. Before going in detail of our algorithm ﬁrst take overview the flow chart of our algorithm. This describes the working of algorithm in better understanding [15, 16]. 4.1  
   
  Proposed Methodology (Boss Algorithm)  
   
  Boss Algorithm is operating section of our algorithm. It should receive the print command before going to spooler. In standard scenario printing command works as [Application > Spooler > Printer]. But in BA this order should [Application > BA > Spooler > Printer]. When BA will receive a printing command from an application it should check the priority of the printing job. If the priority is one, it should directly send to Ready Priority Queue (RPQ). In other case if the sent priority print is not one it should send to Printing Priority Queue (PPQ) [17]. The Boss Algorithm is depicted in the Fig. 8. The pseudo code of the algorithm is given below. If (priority == 1) { Move to the RPQ Spooler Printing } Else { Move to PPQ RPQ Spooler Printing }  
   
  222  
   
  A. Ahmed et al.  
   
  Fig. 8. Boss algorithm  
   
  4.2  
   
  Printing Priority Queue (PPQ)  
   
  PPQ should receive all kinds of prints which have not priority of one. Suppose we have following prints which are recently sent to PPQ. Before going in detail of PPQ, ﬁrst let discuss its structure. In Fig. 9 we can see the different prints have arrived in PPQ, different color boxes telling us the different prints in PPQ. Above white color numeric numbers are telling us the priority numbers which are 3, 5, 13, 8, 7 up to 9. Below numbers of the ﬁgure such as 0  001, 0  002 so on up to 0  00n. These numbers are addresses of the prints which are in PPQ in a link list point of view. PPQ data structure should program with link list. It is because we need add and delete operation, we know add and delete operations are much fast in link list against any other data structure. When a print enters into PPQ, its priority should be written and it address should also append with the print. Other words we can say that two kinds of information should have with every print. The Fig. 6 has different priorities without having the highest number priority [18]. When PPQ will receive a print having priority number 2, it should send before other prints to RPQ with the same priority number. We can see in Fig. 6 there is one print which has the priority number two. It should directly send to RPQ without further processing. It is because we also need a difference in RPQ which is receiving only priority number one. If we change the priority up to one in PPQ then it will be difﬁcult for RPQ which job should send to printer ﬁrst. So we should send print from PPR to RPQ in priority number two. When RPQ send command to printer which having the priority number two, RPQ should signal to PPQ I am serving your request and now you should rescan your printing jobs again. This process should do on each process which having the priorities number two in RPQ. PPQ is responsible for following processes.  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  223  
   
  I. Send the print to RPQ which has priority number 2 without further processing. II. Increase the priority up to two, which has low priority than 2. III. After sending print to RPQ, PPQ is responsible to delete the node and join nodes. Now we take an example to understand PPQ. Now again see the following picture of Fig. 9.  
   
  Fig. 9. Prints arrival in the queue  
   
  After ﬁnishing all jobs which have the priority number 1, RPQ should signal to PPQ to send it printing jobs. So PPQ should send the priority number two printing job to RPQ, after it PPQ should delete the node after sending RPQ.  
   
  Fig. 10. Print job is sending to Ready Priority Queue  
   
  Figure 10 is showing that priority number 2 print job is sending to Ready Priority Queue (RPQ) without scanning and increasing priority number. After sending the print job, now PPQ should delete and join the sent printing job.  
   
  224  
   
  A. Ahmed et al.  
   
  Fig. 11. Delete and join node  
   
  Figure 11 is showing after sending, deleting and joining the node process. Next PPQ should wait and receive all prints commands while PPQ does not receive the signal of scanning. After scanning the signal of scanning PPQ should scan again all prints and increase the priority with number one, if there is again a printing command which the priority number two, it should directly send to RPQ without further processing. In Fig. 11 we can see there are two print commands which have priority number 3, mean on one scanning its priority should 2.  
   
  Fig. 12. Increasing the priority number  
   
  Now we can see the difference in Figs. 11 and 12 after scanning and increasing the priority number. Now we can see there are two prints commands which have priority level two. Now PPQ should send these two prints commands to RPQ, and after it PPQ should delete these nodes.  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  225  
   
  Fig. 13. PPQ after deleting and joining two nodes  
   
  Figure 13 is showing PPQ after deleting and joining two nodes. Now PPQ should again wait signal from RPQ for further scanning, increasing priority, sending print jobs, deleting and joining nodes. 4.3  
   
  Ready Priority Queue (RPQ)  
   
  RPQ should attach to spooler for sending prints commands to printer. RPQ should have two kinds of priority type prints number one, and number two. Priority prints which have priority one, should send to printer before the printing having the priority number two. RPQ can differentiate easily that which print should send to printer ﬁrst. When priority having number one should not in RPQ then priority two should send to printer for printing in batch sequence [19]. If printer is busy in priority two batch sequence and a new printing command inter in RPQ, after completing the prints of the under process printing then next turn should priority number one. When RPQ is working on priority number two, it should signal to PPQ for further scanning and increasing the priority which it has in its queue. This situation may happen there is one print RPQ and PPQ have many other prints jobs. There is no such priority exists which level increase to two for RPQ in just one scan. On empty queue of RPQ is should signal again and again to send print command to it. Now let’s take an example to understand RPQ.  
   
  Fig. 14. Two types of priorities are in RPQ  
   
  In Fig. 14 we can see two kinds of priorities are in RPQ, the priority number one came directly from BA after checking its priority. The priority number two is come from PPQ. This number of priority might be up to level two. In PPQ if the priority is two it should directly send to RPQ without increasing and extra processing over it.  
   
  226  
   
  A. Ahmed et al.  
   
  In Fig. 14 the right side command ﬁrst came into RPQ so it should send to spooler ﬁrst, second from the right side second last print command came into RPQ so it should send to spooler at position number two. Now next is priority number two which is in third number from right side. Because we have more prints which have priority number one, so the number two priority should not send to printer. The next print is also the priority number one which is at ﬁfth number from left to right in Fig. 14.  
   
  Fig. 15. Way of numbering  
   
  Figure 15 is showing us the way of numbering in which prints should send to spooler for printing. The new coming prints should treat in FCFS fashion if they have the same priority, the only difference is that priority number one and priority number two. On serving priority number two RPQ should signal to PPQ to rescan the priority numbers and increase the numbers according to its appropriate sequence. 4.4  
   
  Join Node (JN)  
   
  Join Node is sub program part of PPQ, JN should perform two kinds of work. It should ﬁrst remove the current sent print job node, after it, it should join the deleted node left and right nodes.  
   
  Fig. 16. Complete picture of join node  
   
  A Smart Way to Improve the Printing Capability of Operating System  
   
  227  
   
  Figure 16 is showing a complete picture of JN, JN should work Delete and Join Node. When a print should send to RPQ, PPQ should call next Join Node function. The ﬁrst part of the Join Node should delete the sent print command node, after deleting the node next JN should call its next function to join node [20]. While working in Deleting and joining the nodes PPQ should wait and not to scan the nodes. When JN return its control to PPQ, then PPQ should precede its next work.  
   
  5 Conclusion and Future Work BOSS algorithm is best way for printing all kinds of priority level. It provides turn to every level of priority and it also gives ﬁrst priority to the highest level priority users. It never let down or star-vat the low priority users. Low priority level users not have to wait their print in mid night. There is no need to add virtual printer and extra overhead for server and low priority level users. BA is complex in sense handling all kinds of priorities in same time. Change the priority of the queued jobs in every search setup the over head of CPU. In this way this proposed solution can be implemented in huighly demanded environment where printing capabilities are lacked. In future we are planning to implement this scenario in well developed organization and gain the beneﬁts of newly designed technique. This will be more beneﬁcial for the print and press industries to groom their business. This idea can be utilized for priority based process scheduling mechanism.  
   
  References 1. Macauley, R.M., Martin, T.S., Vachon, G.C., Cosgrove, P.A., Sasson, S.J., Wilson, E.D.: Distributed Printing Social Network. Google Patents (2015) 2. Shaw, L.F., Teng, C.-C., Sykes, K.W., Endres, R.E.: Device Independent Spooling in a Print Architecture. Google Patents (1998) 3. Laurent, M.S., Onischke, M., Kuindersma, M., Krishnammagaru, D., Stairs, J., Noreikis, K.: System and Method for Releasing Print Jobs Based on Location Information. Google Patents (2015) 4. Sanders, R.E., Frazier, D.P.: System and Method for Batch Printing High-Volume Electronic Documents from a Network. Google Patents (2010) 5. Gould, K.V.W., Small, G.J., Galipeau, S.R., Kirkland, C.J.: Methods and Systems for Data Prioritization. Google Patents (2014) 6. Zhang, D., Dechev, D.: A lock-free priority queue design based on multi-dimensional linked lists. IEEE Trans. Parallel Distrib. Syst. 27, 613–626 (2016) 7. Gruber, J., Träff, J.L., Wimmer, M.: Benchmarking Concurrent Priority Queues: Performance of k-LSM and Related Data Structures. arXiv preprint arXiv:1603.05047 (2016) 8. Lenharth, A., Nguyen, D., Pingali, K.: Priority queues are not good concurrent priority schedulers. In: European Conference on Parallel Processing, pp. 209–221 (2015) 9. Kinoshita, K., Higashizaki, Y.: Remote e-mail printing. Google Patents (2011) 10. Nan, X., He, Y., Guan, L.: Optimal resource allocation for multimedia cloud based on queuing model. In: 2011 IEEE 13th international workshop on Multimedia signal processing (MMSP), pp. 1–6 (2011)  
   
  228  
   
  A. Ahmed et al.  
   
  11. Abaev, P., Gaidamaka, Y., Samouylov, K.E.: Queuing model for loss-based overload control in a SIP server using a hysteretic technique. In: Internet of Things, Smart Spaces, and Next Generation Networking. Springer, pp. 371–378 (2012) 12. Nakayama, Y., Takewa, Y., Sumikura, H., Yamanami, M., Matsui, Y., Oie, T., et al.: In-body tissue-engineered aortic valve (Biovalve type VII) architecture based on 3D printer molding. J. Biomed. Mater. Res. Part B: Appl. Biomater. 103, 1–11 (2015) 13. Lansing, S., Pantelias, N., Vu, Y., Gomez, F.J.: System and Method for Dropping Lower Priority Packets that are Slated for Wireless Transmission. Google Patents (2011) 14. Al Hanbali, A., Alvarez, E., Heijden, M.: Approximations for the waiting time distribution in an M/G/c priority queue (2013) 15. Stanford, D.A., Taylor, P., Ziedins, I.: Waiting time distributions in the accumulating priority queue. Queueing Syst. 77, 297–330 (2014) 16. Singh, C.J., Jain, M., Kumar, B.: MX/G/1 queuing model with state dependent arrival and second optional vacation. Int. J. Math. in Oper. Res. 4, 78–96 (2012) 17. de Souza, R.M., Morabito, R., Chiyoshi, F.Y., Iannoni, A.P.: Incorporating priorities for waiting customers in the hypercube queuing model with application to an emergency medical service system in Brazil. Eur. J. Oper. Res. 242, 274–285 (2015) 18. Takagi, Y., Nakagawa, M.: Printing System, Printing Method, Print Server, Control Method, and Computer-Readable Medium. Google Patents (2012) 19. Alistarh, D., Kopinsky, J., Li, J., Shavit, N.: The SprayList: a scalable relaxed priority queue. ACM SIGPLAN Not. 50, 11–20 (2015) 20. Kim, C., Choi, S.: A Study on Efﬁcient Join Mechanism Using Streaming-Service-Time in Mobile P2P Environment (2014)  
   
  A Comparative Study for Ontology and Software Design Patterns Zaheer Ahmed, Muhammad Arif(&), Muhammad Sami Ullah, Adeel Ahmed, and Muhammad Jabbar Department of Computer Science, University of Gujrat, Gujrat, Pakistan {zaheer,m.arif,msamiullah,adeel.ahmed, jabbar.ahmed}@uog.edu.pk  
   
  Abstract. Ontology design patterns have been extended from software design patterns for knowledge acquirement in semantic web. The main concern of ontology design patterns is to how concepts, relations and axioms are established in a ontology using ontological elements. Ontology design pattern provide the solution of quality modeling for ontologies. In user prospective the presentation of ODP play a central role for the reusability of ontologies. This research determine the improvement areas in the presentation of content ODPs. Improvement in presentation can ultimately improve the understandability of a pattern from user perspective. Our objective is to analyze the template of different software engineering patterns (SEP) and ODP. On the basis of this analysis we suggest possible changes in current template and pattern presentation. It also includes determining the most important information about patterns which can help an ontology engineer in selecting an appropriate pattern. Presentation of design patterns is related to issues such as reuse, guidance and communication. Our main goal is to evaluate the current patterns presentation. The evaluation is focused on the analysis of current patterns. The ontology design pattern templates were compared with existing templates of other patterns for determine the improvement areas. The template of an ODP consists of many parts, the ﬁrst question is to identify the most important and vital information concerning the design patterns. This information would help an ontology engineer to select an appropriate design pattern for the required ontology. The second question is about the users who work with ontology design patterns. Generally, users are divided into two categories; novice and expert ontology engineers. Novice users are the end-users who use design patterns to implement in the ontologies. Expert ontology engineers are those who actually develop ontology design patterns. Each category of user has its own information requirement regarding design patterns. Keywords: Ontology design pattern  Templates pattern  Software engineering pattern  
   
    
   
  Content ontology design  
   
  1 Introduction ODPs are semantic patterns that provide quality modeling solutions for ontologies. ODPs play an important role in learning and teaching ontology engineering [1]. They facilitate the automatic and semi-automatic ontologies construction and provide a base © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_19  
   
  230  
   
  Z. Ahmed et al.  
   
  for creating ontologies in different domains [2]. In user prospective the reusability of ontology depends on presentation of ODP. So far only a small catalogue of patterns exist which is available online at the ontology design pattern portal. In this portal, ODPs are described using a template with a set of headings that should be ﬁlled out when entering a new pattern. The template deﬁnes a standard way for constructing new patterns. There are possibilities to discuss modeling issues, review and suggest changes in patterns [4]. In computer and information science ontology is deﬁned as a “formal, explicit speciﬁcation of a shared conceptualization” [3]. One of the main problem areas is reusability of ontologies. The existing ontologies are available at online ontology repositories which provide guidelines to ontology users. Due to unfamiliar logical structure the existing ontologies provide limited support. Must be learned the good practices form literature. This problem is solved by implementing common solution as we learn in software engineering [4]. The patterns facilitate and to some extent automate the construction of ontologies. The development of patterns in the ontology ﬁeld is very popular as that in software engineering. The patterns are deﬁned for reuse and aim at facilitating the construction process very much like the way it is done in software engineering or architectural planning of buildings [5]. The purpose of design patterns is to solve the design problems. The patterns provide a useful way for handling the problems of reusability in a development process. In SE the common practices to build software through design and architecture patterns. This practice also follow in ontology engineering [2]. Ontology design patterns provide modeling solutions of ontologies design problems. They provide a base for creating ontologies in different domains. Patterns are also used for evaluation of ontologies [4]. Ontology design patterns (ODPs) are of several types. They are divided into 6 families; Content patterns, Structural Patterns, Presentation patterns, Correspondence Patterns, Lexico-Syntactic Patterns and Reasoning Patterns [6]. This thesis deals with the presentation of content ontology design pattern. It describes the design issues of the presentation of ontology design patterns. There may be certain information that an ontology user need to understand a pattern but it is not available in the description, our next task will be to examine the missing information in the current ontology design pattern templates. Finally, based on the results of above questions, we will made suggestions for the potential improvement in the current templates of ODP presentation.  
   
  2 Related Work Knowledge reuse is common way to improve the quality of work artifacts. Pattern is a common way to improve reusability. There are other ways to support reusability, i.e. in object oriented programming the concept of program components related to the reusability of design. To achieve reusability, number of design technique available in object oriented software development model for more reusable building block. An obstacle for reuse methodologies is the lack of motivation among developers. Before  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  231  
   
  starting the process, the developer needs to establish a reuse library which requires extra efforts. Reuse process is divided in to two steps Design for reuse and Design by reuse. To expedite design by reuse, ﬁrst the design for reuse process must be established [5, 7]. Reusability is applied at different levels. In software engineering, reusability can be applied at following three levels [5]: Requirements Reuse: It deals with the models of the domain or the generic model of the requirement domain. Design Reuse: It deals with the models, data structures and algorithms. Software Component Reuse: It deals with reuse of software classes and editable source code. The development process of ontology is time consuming and more effort required form developer. Reuse of an ontology from an ontological engineering perspective can be hard. This is even more when there are large ontologies to be reused [8]. Ontology Library: For ontologies to be grouped and organized so that they may be reused further and for ontology integration, maintenance, mapping and versioning, an important tool known as ontology library systems was developed. These systems must fulﬁll all ontological reuse needs and must be easily accessible [9]. Ontology Matching: Ontology matching is a process of judging correspondence between semantically related ontologies, solving the problem of semantic heterogeneity and can be used in ontology merging, query answering, data translation etc. So ontology matching facilitates interoperability between matched ontologies [10]. A pattern is something re-occurring that can be applied from one time to another and also from one application to another. These concepts are in use in our daily life and also in our professional life. We use old solution as patterns. We search patterns in our surroundings that can be useful. In reuse the pattern are best practices that provide the good design [5, 11]. Currently in the computer science ﬁeld the most common and popular patterns are software patterns. Most of the software development projects, where applying functional or object oriented design are conducted using patterns. The patterns are used for increasing reusability, product quality and for managing complexity of the system development process. According to the phase of the development process where they are used these patterns are divided into different kinds [5]. The most common categories are the following: • • • •  
   
  Analysis Patterns [5, 12]. Architecture Patterns [5, 13]. Design Patterns (see [11, 14–17]). Programming Language Idioms (see [3, 13]).  
   
  232  
   
  Z. Ahmed et al.  
   
  Analysis patterns are used to describe the conceptual structures of business processes for the different types of business domains like how to transform these processes into software [3, 12, 18]. An overall structuring principle is used while constructing a viable software architecture. Architectural patterns are considered as templates for solid software architectures [3]. Design pattern describe the common solution of overall design problem in certain context through the depiction object and class communication. Design pattern provide the description of participation classes, their instance, their roles and interaction, distribution of responsibility. One object oriented design problem address by the certain design pattern that also provided sample code to describe the partial solution of the problem [14]. The lowest level of patterns is represented by idioms. The implementation of particular design issue is dealt with by the idioms. The aspects of both, the design and implementation, are treated by them [13]. 2.1  
   
  Problem Statement  
   
  The ontology design patterns (ODPs) have divided in grouped of six different families: Structural ODPs, Content ODPs, Reasoning ODPs, Presentation ODPs, Correspondence ODPs and Lexico Syntactic ODPs [6]. Graphically the types of patterns are represented as (Fig. 1):  
   
  Codesolution: Ontology Design patterns  
   
  Reasoning ODP  
   
  Structural ODP  
   
  Architecture ODP  
   
  Content ODP  
   
  Logical ODP  
   
  Lexio-Syntatic ODP  
   
  Name ODP  
   
  Presentation ODP  
   
  Annotation ODP  
   
  Reengineering ODP  
   
  SchemaReengineering ODP  
   
  LogicalMacro ODP  
   
  Correspondence ODP  
   
  Aligment ODP  
   
  Refactoring ODP  
   
  Transformation ODP  
   
  Fig. 1. Group of ontology design pattern [19]  
   
  In this paper, our focus of research will be the Content ODPs. The comparison of ODPs is limited to software patterns and data model patterns because these are the most used and well known patterns. There are many ontology languages available for development but we will only focus on OWL ontologies [19].  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  233  
   
  This research guide the improvement areas in the presentation of content ODPs. Improvement in presentation can ultimately improve the understandability of a pattern from user perspective. The focus of research is to analyze different content ODPs and provide some possible recommendation in current templates of the ODP presentation. It also includes determining the most important information about patterns which can help an ontology engineer in selecting an appropriate pattern. Presentation of design patterns is related to issues such as reuse, guidance and communication. Our main goal is to evaluate the current patterns presentation. The evaluation is focused on the analysis of current patterns. The template of an ontology design pattern consists of many parts, the ﬁrst question is to identify the most important and vital information concerning the design patterns. This information would help an ontology engineer to select an appropriate design pattern for the required ontology. The second question is about the users who work with ontology design patterns. There may be certain information that an ontology user need to understand a pattern but it is not available in the description, our next task will be to examine the missing information in the current ontology design pattern templates.  
   
  3 Methodologies There are many types of patterns but we have limited our comparison to those of software engineering and data models patterns, since these are the well know and common use patterns. Software patterns have been compared to ontologies by Devedzic in one of his article [16] where the author argued that there is a signiﬁcant overlap between the two concepts and that it is the aim, while generality and practical usage of these concepts differ. The concepts of patterns and ontologies have some common goals, e.g. sharing and reusing of knowledge. Both these concepts necessitate hierarchies of concepts, relationships, vocabularies and constraints. Moreover, both of them can be seen as using an object-oriented paradigm [3]. First, we analyze what current templates exist in other ﬁelds and then compare them to ontology design pattern templates to analyze the difference. In our study, evaluation was done on the results of the evaluation of different patterns. Templates of the patterns were compared to identify the difference and similarities in their presentation. Each part of the templates was studied with respect to its objective and the content provided in that part [19]. A template of a pattern is a standard way of representing a pattern. In a broad sense, a pattern template has four important elements. These elements are: Name, Problem, Solution and Consequences [3, 11, 19]. The different kinds of pattern templates are given below with their description.  
   
  234  
   
  3.1  
   
  Z. Ahmed et al.  
   
  Design Pattern Template  
   
  This template proposed by Guarino [11] in their book “Design pattern Element of Reusable Object-Oriented Software” [11]. Table 1 shows the different parts of the template and their description (Table 2).  
   
  Table 1. Design pattern template [11, 19] Design pattern template Elements Description Pattern name and Name is a short summary of the pattern. There are several DP, we classiﬁcation need a way to classiﬁed them in a family. The section classiﬁcation refers these families of design pattern Intent It is a brief description that explain the following. How the design pattern work? What is the main goal of the pattern and what are the particular design issues or problem solve by the pattern Also known as Another name of the pattern, If the pattern has other name Motivation It has a scenario that describes a design problem and explain the class and object structures in the pattern describe the problem solution. The problem solution will facilitate you to understand the more abstract description of the pattern Applicability This section discus the situations in which the design pattern applicable Structure It illustrates a detailed speciﬁcation of the structural aspects of the pattern. It includes a graphical representation of the classes in the pattern using the notation of OMT (Object Modeling Technique). This section also has interaction diagrams to illustrate sequences of requests and collaboration diagram for description of collaboration between objects Participants This section describes the different parts of the pattern and their relation. In design pattern the participants are classes and/or objects Collaborations This section describes how the participants collaborate to carry out their responsibilities Implementation Implementation gives guidelines for implementing the pattern. It gives hints and techniques which one should be aware before implementing the pattern. For example if there are language speciﬁc issues Sample code Sample code is a code fragment that illustrates how you might implement the pattern in a programming language Known uses Known Uses is the examples of the use of the pattern in real systems. It includes a minimum of two examples from different domains Related patterns Related patterns are described, i.e. what are the closely related patterns to this given pattern? What are important differences? With which other patterns should this one be used?  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  235  
   
  Table 2. Builder design pattern [19] Builder design pattern Elements Pattern Name and Classiﬁcation Intent  
   
  Also Known As Motivation Applicability  
   
  Structure Participants Collaborations  
   
  Implementation Sample code  
   
  Known uses  
   
  Related patterns  
   
  Description Builder, creational patterns To split the construction of the complex object from its representation so that[same construction process can create different representations Fig. 2 When the builder pattern are used • The algorithm for creating a complex object should be independent of the parts that make up the object and how they’re assembled • The construction process must allow different representations for the object that’s constructed Fig. 3 Builder, ConcreteBuilder, Director, Product The given interaction diagram describe how Builder and Director cooperate with a client Fig. 4 Fig. 5 /Abstract Builder class abstract class TextConverter{ abstract void convertCharacter(char c); abstract void convertParagraph(); } . . . . public static void main(String args[]){ Client client = new Client(); Document doc = new Document(); client.createASCIIText(doc); system.out.println(“This is an example of Builder Pattern”); } } The RTF converter application is from ET++. Its text building block uses a builder to process text stored in the RTF format Abstract factory  
   
  236  
   
  Z. Ahmed et al.  
   
  Fig. 2. Builder design pattern  
   
  Fig. 3. Builder design pattern  
   
  Fig. 4. Sequence diagram  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  237  
   
  Fig. 5. Class diagram  
   
  3.2  
   
  Analysis Pattern Templates  
   
  Given below is the Analysis Pattern template described by Fernandez and Liu in their article “The Account Analysis Pattern” [20]. This template is also described in the book “Pattern-Oriented Software Architecture” [21] (Tables 3 and 4). Table 3. Analysis pattern template [19, 21] Analysis pattern template Elements Description Pattern name It describes the name for referring to the pattern and also other names if the pattern has another name Intent It is a short statement that answers many questions like what does that design pattern do? What is the main goal of the pattern and what are the particular design issues or problems solved by the pattern Example Provides a real world example, which shows an existing problem and exempliﬁes the need of the pattern Context The section context is a fundamental component of a pattern. It provides an indication of the applicability of a pattern Problem It deﬁnes the recurring problem that is solved by the general solution. Problem is a fundamental component of a pattern because it is the reason for the pattern. The problem which is addressed by the pattern is described in this section Solution The solution details the participating entities in the solution, the collaborations between them and their behavior Example resolved Example Resolved gives the solution of the given example Know uses Know Uses is the example of the use of the pattern in a real system. It includes a minimum of two examples from different domains Consequeses It details the beneﬁts that a pattern can offer and any possible restrictions Related patterns Related patterns are described what are the closely related patterns to this given pattern? What are important differences? With which other patterns should this one be used?  
   
  238  
   
  Z. Ahmed et al. Table 4. Account analysis pattern [19, 22]  
   
  Account analysis Elements Pattern name Intent  
   
  Example  
   
  Content  
   
  Problem  
   
  Solution  
   
  Example resolved  
   
  Know uses  
   
  Consequneses  
   
  Related patterns  
   
  pattern template Description Account Analysis Pattern The Account pattern keeps track of accounts of customers in institutions. These customers can perform transactions of different types against the accounts Consider a banking institution, where customers have accounts of different types, e.g., checking, savings, loan, mortgage, etc. For the convenience of their customers, the bank may have several branches or ofﬁces located in different places There are many institutions, e.g., banks, libraries, clubs, and others, that need to provide their customers or members with convenient ways to handle ﬁnancial obligations, charge meals, buy articles, reserve and use materials, etc. Without the concept of account users need to carry large amounts of cash, may have trouble reserving items to buy or borrow, and would have serious problems sending funds to remote places Start from class Account and add relevant entities; in this case customers, cards, and transactions. Build an institution hierarchy describing the branches of the institution and relate accounts to the branches Fig. 6 An example for Bank accounts is shown in Figure. The classes contained in the model include Bank, BranchOfﬁce, Account, CheckingAccount, Customer, BankCard, TransactionSet (TXSet), and Transaction, with their obvious meanings. Class TXSet collects all the transactions for a user on his account for a given period of time. There are, of course, other types of accounts Fig. 7 The following are examples of uses of this pattern: • Banks, where customers have ﬁnancial accounts of different types • Libraries, where patrons can borrow books and tapes • Manufacturing accounts, where materials are charged The pattern has the following advantages: • It is clear that this model provides an effective description of the needs and can be used to drive the design and implementation of the software system. Not using a similar model would result in code that is hard to extend and probably incorrect • One can easily add other use cases: freeze account and activate/deactivate account The liabilities of this pattern come from the fact that to limit the size of the pattern and to make it more generic we have left out: Different types of customers. Each variety of customers could be handled in a special way. Accountability pattern  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  239  
   
  Fig. 6. Class diagram  
   
  Fig. 7. Class diagram  
   
  3.3  
   
  Architecture Pattern Templates  
   
  This template was described by Ayodele Oluyomi in his article “Patterns and Protocols for Agent-Oriented Software Development” for the Agent internal ArchitectureStructure Patterns [22] (Table 5). Example The pattern description has been slightly abbreviated for readability issues (Table 6).  
   
  240  
   
  Z. Ahmed et al. Table 5. Architecture pattern template [19, 21]  
   
  Architecture Pattern Template Elements Description Name A brief summary of the pattern Problem It deﬁnes the problem which a pattern can solve Context Different kinds the circumstances in which a pattern can be applied Forces It contains description of various forces and constraints that can affect the desired objectives Solution This section describes the different part of the pattern and their relation Known uses Know Uses are examples of the use of the pattern in real system. We include minimum two examples from different domains Result This section description of possible effects on the initial context when the context solution is applied and also the resulting advantages and disadvantages Related patterns are described; What are the closely related patterns to this Related pattern given pattern? What are important differences? With which other patterns should this one be used? Table 6. Agent as delegate pattern [19, 22] Elements Name Classiﬁcation Problem Context Forces  
   
  Solution  
   
  Known uses Result context  
   
  Related pattern  
   
  Description Agent as delegate Multiagent system architecture-deﬁnitional How should the role of a user be converted to an agent or agents in an agent based system while maintaining conﬁdentiality of user information? A user role carries out activities in a system where conﬁdentiality of user information is critical Goals: to achieve optimum performance and maximize gains by taking decisions based on outcome of activities carried out Responsibilities: the responsibilities of this role involve carrying out both non trivial operational tasks and making concluding decisions based on the execution of the tasks carried out. User speciﬁc information is used in making the decisions. However, the user information should not be included in the execution of the operational tasks for security and conﬁdentiality reasons This pattern describes an approach for translating a role into agents. It prescribes translating a complex user with sensitive data into two types of agents which are User Agent and Task Agents. The pattern speciﬁes the relationship and control that should exist between these two types of agents Know Uses section mentions the use of the pattern in various scenarios. It includes minimum two examples from different domains The interaction between the assistant agent and the task agents has to be analyzed, modeled and implemented Adaptation/Integration: a user role can be translated into more than one assistant agents depending on the complexity and volume of the user information and decision making process Agent as mediator  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  3.4  
   
  241  
   
  Data Model Patterns  
   
  Data Model Patterns help modelers to develop quality models by standardizing common and well-tested solutions for reuse [3]. The objective of data model pattern is to explain a starting point for data modelers [23]. A data model pattern can be implemented by adding additional attribute to any entity in a model or by adding a new entity or a relationship to an existing model. David Hay presented a Universal Data Model in [24]. It is a theoretical model which explains the basic principles of a data model pattern. See Fig. 8:  
   
  Fig. 8. Universal data model [19, 23]  
   
  In [38], Hay mentioned conventions for building data models. These conventions are guidelines for creating new patterns. They help in establishing a framework which data modelers can follow to reuse data model patterns. The modeling conventions are divided into three levels; Syntactic Conventions, Positional Conventions and Semantic Conventions [19]. Syntactic Conventions: This is the ﬁrst type of conventions of modeling and deals with the symbols to be used. In the process of syntactic convention evaluation, the crucial point to remember is that there are two audiences in data modeling. The ﬁrst audience is that community of users which use the models and their descriptions for the verifying whether or not the environment and requirements are actually understood by the analysts. The set of systems designers is the second audience. They make use of the rules of business as implied by the models to be the basis on which their design of computer systems is based [25]. Positional Conventions: This is the second type of Data modeling convention and dictates how entities of a model are laid out. They are concerned with the organization of elements and the overall structure of a model [25]. Semantic Conventions: Semantic conventions are those conventions that address the question of how can the meaning of a model be conveyed. These conventions help to represent common business scenarios in a standard way [25].  
   
  242  
   
  3.5  
   
  Z. Ahmed et al.  
   
  Template of Content Ontology Design Patterns  
   
  Ontology design patterns are similar to software design patterns. The core idea of describing software design patterns is to use a template and collect them by means of a catalogue. In order to describe ODPs we can use a similar approach as used in software engineering but the difference is that, the template used for the presentation has been optimize for the web and deﬁned in an OWL annotation schema. It is the same used on the semantic web portal http://www.ontologydesignpatterns.org. This part contains a template of Content ODPs which is composed of the following information ﬁelds, deﬁned in the annotation schema [2, 5, 26] (Table 7):  
   
  Table 7. Content ontology design pattern template [2, 5, 19] Elements Name  
   
  Submitted by Also known as Intent Domain Competency question  
   
  Solution description Reusable OWL Building Block  
   
  Consequences: Scenarios Known uses  
   
  Other references  
   
  Description It contains the name of the pattern. The names of patterns should be descriptive and unique names that help in identifying and referring to the patterns This part of the template includes author names. In the portal it gives the link to the author page It gives the alternative names for the ODP, since it might be possible that the pattern has some other name but this part is not compulsory This part of the template describes the goal of the ODP. Intent is a description of the goal behind the pattern and the reason for using it This part of the template concerned with the area, domain and where the ODP is applicable It contains a list of competency questions expressed in natural language that are covered by the pattern. A competency question is a classical way of capturing a use case. A competency question is a simple query which an ontology engineer can submit to knowledge base to perform a certain task It describes how the given pattern provides the solution to a design problem in a certain context It is a reusable representation of the pattern. This part is basically the implementation of the design pattern. It contains the URI of the OWL implementation of the content pattern, i.e. the reusable component available for download This part of the template contains a description of the beneﬁts and/or possible trade-offs when using the ODPs Giving examples or scenarios where the given pattern implemented This part of the template gives examples of real ontologies where the ODP is used. This part of template is the example of real usages of the pattern This part of the template contains references to resources (e.g. papers, theories, and blogs) that are related to the knowledge encoded in the ODPs (continued)  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  243  
   
  Table 7. (continued) Elements Examples  
   
  Description This ﬁeld contains a link of an example owl ﬁle which is reusable. The example owl ﬁle presents a possible scenario which may sometime also include a UML diagram of classes and their relationships Extracted from Contains the URI (if any) of the ontology from which the pattern has been extracted Reengineered from It contains the name of the reference ontology which has been used reused in the pattern Has components This ﬁeld refers to components of the Content ODP which are in turn ODPs themselves Specialization of This part of the template refers to ontology elements or ODPs. The specialization relation between ontology elements of ODPs consists of creating subclass of some ODP class and/or sub properties of some ODP properties Related ODP This part contains the names of the patterns which related to the current pattern based on generalization, specialization or composition. It also mentions other patterns that are used in corporation with the current pattern Elements This part of the template describes the elements (classes and properties) included in the ODP, and their role within the ODP Diagram representation This part of the template depicts a graphical representation of the ODP Additional information In Additional information authors provided that informatuion which is not avalible in the rest of the template  
   
  Example (See Table 8).  
   
  Table 8. Classiﬁcation pattern [4, 19] Elements Name Submitted by Also known as Intent  
   
  Domain Competency question  
   
  Description Classiﬁcation ValentinaPresutti To represent the relations between concepts (roles, task, parameters) and entities (person, events, values), which concepts can be assigned to. To formalize the application (e.g. tagging) of informal knowledge organization systems such as lexica, thesauri, subject directories, folksonomies, etc., where concepts are ﬁrst-order elements General • What concept is assigned to this entity? • Which category does this entity belong to? (continued)  
   
  244  
   
  Z. Ahmed et al. Table 8. (continued)  
   
  Elements Solution description Reusable OWL Building Block Consequences:  
   
  Scenarios Known uses Web references Other references Examples Extracted from Reengineered from Has components Specialization of Related ODP Elements  
   
  Description http://www.ontologydesignpatterns.org/cp/owl/classiﬁcation.owl It is possible to make assertions about e.g., categories, types, roles, which are typically considered at the meta-level of an ontology. Instances of Concept reify such elements, which are therefore put in the ordinary domain of an ontology. It is not possible to parametrize the classiﬁcation over different dimensions e.g., time, space, etc. Mac OSX 10.5 is classiﬁed as an operating system in the Fujitsu-Siemens product catalog  
   
  http://www.loa-cnr.it/ontologies/DUL.owl  
   
  • Concept (owl:Class). A concept is a Social Object. The classiﬁes relation relates concepts to entities at some time • Entity (owl:Class). Anything: real, possible, or imaginary, which some modeller wants to talk about for some purpose • classiﬁes (owl:ObjectProperty). A relation between a Concept and an Entity, e.g. the Role ‘student’ classiﬁes a Person ‘John’ • is classiﬁed by (owl:ObjectProperty). A relation between a Concept and an Entity, e.g. ‘John is considered a typical rude man’; your last concert constitutes the achievement of a lifetime; ‘20-year-old means she’s mature enough’ Diagram representation Fig. 9 Additional information  
   
  Fig. 9. Class diagram  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  245  
   
  4 Study Analysis and Results The work starts with the literature review. Our ﬁrst task was to study the current patterns that exist in other ﬁelds and compare them to ontology design patterns’ templates to analyze the difference. 4.1  
   
  Comparison of Pattern Templates  
   
  The basic knowledge of problems is in software engineering modeled by conceptual models that are known as Analysis patterns. The patterns could be illustrated using a UML notation [3]. For Example the Analysis Pattern is implemented by using a UML Class diagram, Sequence Diagram and State Diagram which were described in section. Looking at an example of an analysis pattern, one can easily gauge the above relationship between ontologies and Software Patterns, and other patterns used in Computer Science. This similarity is evident even in, for example, graphical representations of an Analysis Pattern and an ontology pattern [3]. 4.2  
   
  Comparison of Templates of Software Patterns and Content ODPs  
   
  This comparison is between the templates of software patterns and content ontology design patterns. We have described the elements of both software pattern templates and content ODPs in this chapter in Sects. 3.1 to 3.5, which provide us with a good starting point for comparison. There are several types of software patterns that are available and several techniques to present them but we selected Analysis Patterns, Architecture Patterns and Design Patterns. The template of a pattern is a standard way of representing a pattern. In a broad sense, a pattern template has four essential elements. These elements are: Name, Problem, Solution and Consequences as describe in Sect. 3. This comparison is based on similarities and differences between the Content ODP template and software pattern templates. We compare each element of the ODP template with software pattern templates. Comparison is based on the names, content and the overall presentation of the template. The parts described in Table 9 are considered as basic parts of a pattern. The description of these parts is stated. The table shows how these basic parts are described in software patterns and ODP templates. Context: In Software Patterns, the section context describes the situations where the given pattern is applied. Every pattern has a context based on its application area. In content ODPS, context is deﬁned in the form of domains and scenarios where the pattern is applicable. Problem: For Analysis Patterns, Design Patterns and Architectural Patterns, the section Problem or Motivation describes the problem that can be solved by implementing these patterns. In analysis patterns, the section problem describes some generic use cases. In Design Patterns, some of the patterns use scenarios for giving more description of patterns. Such description should be able to clarify the details of the problem. In ODPs, the Problem is described by Competency Questions. Competency Questions consists of a list of competency questions expressed in natural language that  
   
  246  
   
  Z. Ahmed et al. Table 9. Representing basic elements of other patterns [19]  
   
  Pattern type Ontology design pattern  
   
  Context Domain  
   
  Problem Competency question  
   
  Analysis pattern  
   
  Context  
   
  Problem  
   
  Design pattern  
   
  Applicability Motivation  
   
  Architecture pattern  
   
  Context  
   
  Problem  
   
  Solution Consequence Example OWL Building Block, Consequence Scenario, Example Element, Solution (OWL description and ﬁle) Graphical Representation Solution Consequence Example, example resolved Structure, Participant Not provided Sample code Collaboration, implementation and sample code Solution Not provided Not provided  
   
  are covered by the pattern. The section Competency Question describes the problem which is to be solved by the ODP. Competency questions are the requirements that an ontology should fulﬁll. Solution: In Analysis Patterns, Architecture Patterns and Design Patterns, the section Solution gives a fundamental solution principle to be used in the pattern for solving a problem. In Analysis Patterns, the solution is described by using UML diagram and also a brief description of different parts of the pattern is given. In Design Pattern, the sections structure, participants and collaboration describe the solution. The section Structure is a graphical representation of the classes in the pattern which use the notation of the object modeling technique (OMT). It also uses interaction diagrams to illustrate the sequence and collaboration between the objects. The section participants give a detailed description of the classes and objects and their responsibilities. The section collaboration describes how the participants collaborate to carry out their responsibilities. In Architecture pattern, the section solution gives the description, using text and a graphical representation, as to how we can achieve the intended goals and objectives. It also describes the variants and specializations of the solution. It gives the description of people and computing actors and their collaboration. In ODPs, the section solution consists of four parts: OWL Building Block, Elements, Solution description and Graphical Representation. The section Solution description describes how a given pattern can solve the problem in the context. The section OWL Building Block contains an OWL ontology with reusable classes and reusable properties. The section Elements briefly describes Classes and Properties of the pattern implementation and the role of these classes and properties within the ODP. The Graphical representation gives a visual presentation of the pattern classes and their relations. 5Consequence: In both software patterns and content ODPs, the section consequence describes the possible beneﬁts and limitations on the solution after using the pattern. What are the results of using the pattern? In some ODPs it is more about unexpected consequences and limitations.  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  247  
   
  Example: For Analysis Patterns, Design Patterns and Architecture Patterns, the section Example gives the real world example, which shows the existence of problems and needs for the patterns. For Analysis Patterns and Design Patterns the section example consists of two parts. In the ﬁrst part the problem and in second part the implementation. In content ODPs, example is given in the form of a scenario and an example OWL ﬁle which is the OWL implementation of the scenario. Table 10 describes the common elements of the template of content ontology design patterns and software patterns (analysis patterns, design patterns and architecture patterns). These elements are described in the background chapter with details in Sect. 2.3.2. The section motivation of design pattern is similar to the section problem of other software patterns. In Table 10 the vertical line had different columns that shows the label of different pattern. The horizontal line shows the template heading and symbol X describes the presence of common element.  
   
  Table 10. Representing common elements of other patterns [19] Template heading Name Known uses Intent Consequences Also known as Classiﬁcation  
   
  Ontology design pattern       
   
  Analysis pattern      
   
  Design pattern        
   
  Architecture pattern     
   
    
   
  The template of content ODPs has developed by following the template of software design patterns. The comparison of both patterns reveals that both patterns have a lot of similarities and the current template of content ODPs includes all the elements of software patterns except ‘forces’. Forces deﬁne constraints and problems that can affect the solution. In content ODPs, only the beneﬁts and/or possible trade-offs when using the ODPs on the initial problem are mentioned. Apart from the software patterns, the content ODPs has some additional parts which have been added according to the pattern requirements. Unique Sections: Content ODPs have some unique sections, which are not described in other Software Pattern Templates. These sections are: EXTRACTED FROM, REENGINEERING FROM and HAS COMPONENTS, as mentioned in the background chapter in Sect. 2.5. 4.3  
   
  Comparison of Data Model Patterns and Ontology Design Patterns  
   
  Data model patterns and ODPs are different to each other because data model patterns are presented only in graphical form while ODPs have much more detailed graphical and textual description. While content ODPs have an ofﬁcial catalogue where users can select from a list of patterns, there is no ofﬁcial catalogue for data model patterns.  
   
  248  
   
  Z. Ahmed et al.  
   
  The template of an ODP has a description of different parts of the pattern which is presented in the graphical and textual form. To implement an ODP, an ontology engineer has to study the description to understand a pattern. A data model pattern is presented in the form of an UML diagram. The diagram is built by following conventions which are a set of rules. These conventions standardize a data model hence makes it easier for a data modeler to reuse a pattern. The reusability of both patterns depends on different factors. Content ODPs can also be used directly as they are, just like data models, although they are usually specialized but this depends on their generality. In data model patterns, it is up to the data modeler to decide whether to use a real model to make some minor adjustments or to use a completely abstract model of a problem. The similarities of data model patterns and ODPs lie in the graphical representation of a problem. Also as we saw in Table 11, different parts of both patterns can be mapped to each other hence knowledge from data model patterns can be translated into ODPs. The use of conventions in data model patterns makes it easier to understand the diagram. These conventions and practices can be translated into guidelines for creating more uniform diagrammatic notations for ODPs. Table 11. Mapping of elements of data model pattern and ontology design pattern [19, 22] Data model pattern Entity Attribute Subtype/supertype Relationships Mutually exclusive sets  
   
  Ontology design pattern Concept Relation to “attribute” Subsumption hierarchy Relations Disjoint concepts  
   
  Overall, the comparison of software patterns and data model patterns with content ODPs shows that there are a lot of similarities in the templates of software patterns and content ODPs. The difference lies in the presentation of the content. The graphical representation of content ODPs can be made uniform by deﬁning conventions as it is done in data model patterns. In an experiment, the knowledge from data model patterns was translated into ontology design patterns by mapping the parts using the KAON tool [2]. Table 11 shows the mapping between the different parts. The above mapping shows that the knowledge stored in the data model patterns can be translated into ODPs. This knowledge can be reused to create new ODPs from existing data model patterns.  
   
  5 Conclusions The purpose of this study was to improve the presentation of content ontology design patterns. This research is part of an effort to solve the larger problem of engineering high quality ontologies. One possible solution to this problem is to introduce reuse in ontology engineering which can standardize the ontology development process and  
   
  A Comparative Study for Ontology and Software Design Patterns  
   
  249  
   
  reduce the time and effort involved in it. ODPs are considered best practice to achieve this objective. To encourage the use of ODPs for ontology development, their presentation must be explicit and precise. Suggestions are based on the comparison of the different patterns with the ontology design patterns. Based on the literature review, we propose following improvements in the current template for content ODP: The Graphical Representation should have a more uniform diagrammatic notation. This can be done by deﬁning standards or conventions which ontology engineers can follow while creating patterns. As guidance, the conventions used in data model patterns can be studied to deﬁne similar conventions for content ODPs. Also, namespaces provided in the Graphical Representation section should be made explicit in the Additional Information section. Scenarios should be more explicit. While scenarios presented in the General Description section are simple, they can be more complex in general. Further, the scenario section should describe the binding from concrete elements to the pattern elements. At ODP portal, scenarios of several patterns are missing. They must be included in each pattern because they were considered as important parts. Software patterns include the implementation section with the solution of complex problem. Implementation help user to understand the pattern. This research is part of an effort to solve the larger problem of engineering high quality ontologies. One possible solution to this problem is to introduce reuse in ontology engineering which can standardize the ontology development process and reduce the time and effort involved in it. ODPs are considered best practice to achieve this objective. To encourage the use of ODPs for ontology development, their presentation must be explicit and precise.  
   
  6 Future Works This study will be improved through experiment. Determine how well the current ODP template supports the understanding and usage of Content ODPs. To get experts opinions on the current structure of the Ontology design pattern template. There may be certain information that an ontology user need to understand a pattern but it is not available in the description. This research will improve by examine the missing information in the current ontology design pattern templates.  
   
  References 1. Uschold, M., Gruninger, M.: Ontologies and semantics for seamless connectivity. ACM SIGMOD Record 33(4), 58–64 (2004) 2. Blomqvist, E.: Fully automatic construction of enterprise ontologies using design patterns: initial method and ﬁrst experiences. In: OTM Confederated International Conferences On the Move to Meaningful Internet Systems. Springer (2005) 3. Gruber, T.R.: A translation approach to portable ontology speciﬁcations. Knowl. Acquis. 5 (2), 199–220 (1993)  
   
  250  
   
  Z. Ahmed et al.  
   
  4. Presutti, V., Gangemi, A.: Content ontology design patterns as practical building blocks for web ontologies. In: International Conference on Conceptual Modeling. Springer (2008) 5. Blomqvist, E.: State of the Art: Patterns in Ontology Engineering (2004) 6. Gangemi, A., Presutti, V.: Ontology design patterns. In: Handbook on Ontologies, pp. 221– 243. Springer (2009) 7. Pree, W.: Meta patterns—a means for capturing the essentials of reusable object-oriented design. In: European Conference on Object-Oriented Programming. Springer (1994) 8. Doran, P.: Ontology reuse via ontology modularisation. In: KnowledgeWeb Ph.D. Symposium. Citeseer (2006) 9. Prabhu, V., Kumara, S., Kamath, M.: Scalable Enterprise Systems: An Introduction to Recent Advances, vol. 3. Springer Science & Business Media, New York (2012) 10. Rebstock, M., Janina, F., Paulheim, H.: Ontologies-Based Business Integration. Springer Science & Business Media, Heidelberg (2008) 11. Guarino, N.: Semantic matching: formal ontological distinctions for information organization, extraction, and integration. In: Information Extraction a Multidisciplinary Approach to an Emerging Information Technology, pp. 139–170. Springer (1997) 12. Fernandez, E.B., Yuan, X.: An analysis pattern for reservation and use of reusable entities. In: Proceedings of PLoP (1999) 13. Buschmann, F., et al.: Pattern-oriented software architecture: a system of patterns (1996). Part II, 2001 14. Kampffmeyer, H., Zschaler, S.: Finding the pattern you need: the design pattern intent ontology. In: International Conference on Model Driven Engineering Languages and Systems. Springer (2007) 15. Cooper, J.W.: The Design Patterns Java Companion, vol. 218. Addison-Wesley, Upper Saddle River (1998) 16. Devedzic, V.: Ontologies: borrowing from software patterns. Intelligence 10(3), 14–24 (1999) 17. Gamma, E.: Design Patterns: Elements of Reusable Object-Oriented Software. Pearson Education India, Delhi (1995) 18. Fernandez, E.B.: Building systems using analysis patterns. In: Proceedings of the Third International Workshop on Software Architecture. ACM (1998) 19. Lodhi, S., Ahmed, Z.: Content Ontology Design Pattern Presentation (2011) 20. Fernandez, E.B., Liu, Y.: The account analysis pattern. In: EuroPLoP (2002) 21. Buschmann, F., et al.: Pattern-Oriented System Architecture: A System of Patterns, pp. 99– 122. Wiley, Chichester (1996) 22. Oluyomi, A.O.: Patterns and protocols for agent-oriented software development (2006) 23. Silverston, L., Inmon, W.H., Graziano, K.: The Data Model Resource Book: A Library of Logical Data Models and Data Warehouse Designs. Wiley, Hoboken (1997) 24. Hay, D.: Data Model Patterns Conventions of Thought. Dorset House, New York (1996) 25. Hay, D.C.: A comparison of data modeling techniques (1999) 26. Gangemi, A.: Ontology design patterns for semantic web content. In: International Semantic Web Conference. Springer (2005)  
   
  Biomedical Applications  
   
  MainIndex Sorting Algorithm Adeel Ahmed1, Muhammad Arif1(&), Abdul Rasheed Rizwan2, Muhammad Jabbar1, Zaheer Ahmed1, and Muhammad Sami Ullah1 1  
   
  Department of Computer Science, University of Gujrat, Gujrat City, Gujrat, Pakistan {m.arif,adeel.ahmed,m.jabbar, zaheer,msamiullah}@uog.edu.pk 2 Department of Computer Science, Virtual University of Pakistan, Lahore, Pakistan [email protected]   
   
  Abstract. Sorting algorithm remained hot topic in computer science from the birth of computer science to achieve maximum performance. Fortunately this achievement became possible due to good and fast sorting algorithms, such as heap sort, merge sort, radix sort and other sorting algorithms. Till this achievement is also under research to ﬁnd more efﬁcient algorithms. In sorting algorithm arrays and link list data structures are commonly used. We know arrays are efﬁcient if we need consecutive kind of data structure and link lists are useful when we need to add and remove items in the data structure. In other word we can say both data structures have own its merits and demerits. So in our sorting algorithm we are going to use both kinds of data structure. We will use in our MainIndex sorting algorithm arrays as the MainIndex and link list as sorting cells. MainIdex sorting algorithm need some kind of information just the length of the number which is going to sort and the value of the number which is going to sort in sorting cell. Keywords: MainIndex  Sorting cell  Selection sort  Link list  Merge sort  Bubble sort  Quick sort  
   
  1 Introduction A sorting algorithm exchanges the numbers in a speciﬁc order according to the ﬁt needs of the users. Any sorting algorithm has merging and searching functions. Some other exist which used the functions to sort the numbers [1]. The data is mostly taken from an array which is faster in sense of random access [2]. Link list provide a fast method when we need to add or delete node for numbers against arrays [3]. Sorting algorithms remain hot topic since the birth of computer due to time complexity. Time complexity is the total time required by an algorithm of the program to complete its given task [4]. The time complexity is measurement by big O notation of the algorithm. The numbers of elements are measured to compute the complexity time. Sorting algorithms are the fundamental concepts for a computer programmer, computer scientist and IT  
   
  © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_20  
   
  254  
   
  A. Ahmed et al.  
   
  professionals [5]. When we search in database mostly used ORDER BY clause, using this query actually we are using the sorting algorithm. A common example is our phone book of address, we save our contact numbers in the mobile in a different order, but when we need to ﬁnd a contact they are listed into a sequence [6]. First look we should compare various sorting algorithms in dealing with large set of data, in large set of data some algorithms become very slow in practical use. Next look is about the memory usage of the algorithms, mostly faster algorithms takes large memory rather than slow one algorithm [7]. If we look about the progress in the memory usage of today, large memory is not main issue, but issue is faster algorithms [8]. But we even imagine which algorithm is fastest; the speed of the algorithm depends on the working and environment where the sorting is done. In sense which kind of data is being to sort? We cannot use the same algorithm for sorting 200 numbers on such kind of database which cannot ﬁt into memory, so such kinds of algorithms are designed in different ways.  
   
  2 Related Works Today many programming languages are providing built in functionalities which are usable for sorting numbers [9]. Java API, .Net framework and C++ all provides built-in sorting techniques [10]. For different kinds of data types such as floating numbers, integer number and characters need to sort according to the requirements. But sometime we need a generic kind of sorting algorithms for generic data structure [11]. This thing leads us to a complicated problem. But OOP provides us to solve such kinds of problems [12]. So many good algorithms are designed but no one algorism is Silver Bullet. At this point we see the complexity of ﬁve algorithms. As given in the Table 1.  
   
  Table 1. Complexity of the algorithms Sorting algorithm Bubble sort Insertion sort Merge sort Heap sort Quick Sort  
   
  2.1  
   
  Worst case O(n2) O(n2) O(n log n) O(n log n) O(n2)  
   
  Average case O(n2) O(n2) O(n log n) O(n log n) O(n log n)  
   
  Best case O(n) O(n) O(n log n) O(n log n) O(n log n)  
   
  Bubble Sort  
   
  The bubble sort algorithm is a well-known sorting algorithm. Its belongs to O (n2) sorting algorithm. But bubble sort is not very efﬁcient for sorting of large amount of data, other hand it is stable and adaptive algorithm [13].  
   
  MainIndex Sorting Algorithm  
   
  255  
   
  Bubble Sort Algorithm for i = 1 to n; swapping = false for j = n: i+1; if a [j] < a [j-1]; swap a[j,j-1]; swapping = true; if not swapping; break; end 2.2  
   
  Insertion Sort  
   
  Insertion sort is elementary sorting algorithm and its time complexity in wore case is O(n2). Insertion Sort is a good choice when data is nearly related to each other due to adaptive algorithm. But it is not good when data size is small. Insertion Sort is recursive by nature when the problem size is small [14].  
   
  Insertion Sort Algorithm for i = 2 to n; for (k = i; j > 1 and a[j] < a[j-1]; j--); swap a[j,j-1]; end 2.3  
   
  Merge Sort  
   
  Merge sort bases on divide and conquer algorithm. It divides the problem into two parts and sorts them, after sorting them it merges them. Merge Sort is best choice for different kinds of environments for example when sorting with link list, stability and fast result is required. But it is expensive when the problem is in array [15]. 2.4  
   
  Heap Sort  
   
  Heap Sort algorithm bases on binary heap. In some sense it is similar to selection sort where we ﬁnd the maximum value in start and rearrange it at the end; we repeat the same process for remaining numbers in the problem [16]. 2.5  
   
  Quick Sort  
   
  Quick Sort also works in Divide and Conquer method just as Merge sort. It takes a number as pivot and make the partition according to the selected pivot. Selecting a pivot is grand work in this method. Different kinds of ways are to select the pivot. • Pick ﬁrst number as pivot. • Pick last number as pivot.  
   
  256  
   
  A. Ahmed et al.  
   
  • Pick random number as pivot. • Pick middle number as pivot [17].  
   
  3 Problem Statement We took an overview on different kinds of sorting algorithms and saw each algorithm is using a speciﬁc data structure such as arrays or link list. So every sorting algorithm has own its pros and cons, some need more memory but they are sharp in sorting the numbers, some algorithm needs less memory but it takes more time to sort the numbers. Different sorting algorithms take different time to sort the numbers. Every algorithm behaves different according to the nature of the problem. We are going to discuss speciﬁc method which behave constant in every nature of sorting data and takes less time against all sorting algorithms. In Main Index sorting algorithm we will use both kinds of data structure such as link list and arrays according to their efﬁcient point of view.  
   
  4 The Proposed Solution Now we are going to discuss a new sorting algorithm, we have following unsorted array. 32, 18, 45, 56, 22, 64, 8, 88, 67, 105, 77, 440, 11, 90, 16 We have these unsorted serials of numbers in array. To sort them in order ﬁrst of all we should compute the maximum length in unsorted numbers. We are not going to ﬁnd the maximum number in unsorted numbers. In our unsorted list 32 is the ﬁrst number, in this we need two kind of information number one the value of ﬁrst digit which is 3 in case of 32. Second we need the length of 32 which is 2. The length 2 numeric numbers should store in LIndex2. Later we will see what mean of LIndexN. Before going in detail of MainIndex ﬁrst we should take an over view of the sketch of the MainIndex. Following is the basic detail ﬁgure of the MainIndex. As shown in the Fig. 1.  
   
  Fig. 1. Sketch of the MainIndex  
   
  MainIndex Sorting Algorithm  
   
  4.1  
   
  257  
   
  MainIndex  
   
  MainIndex has a array from 1 to 9, this section will use appropriate position according to the value of the number, let’s take 32 has example here again, 32 has ﬁrst digit 3 so it should enter in array of 3 in MainIndex. The arrow is a pointer which is pointing to LIndex1. LIndex1 mean length of index 1 which is core structure with the MainIndex. All those numeric numbers which have its length one those should store in this index. Other LIndexN should create when a numeric number has different length against already created LIndexN. But LIndex1 should create automatically when MainIndex starts. 4.2  
   
  LIndexN  
   
  L mean length of the numeric number which is going to store in the sorting sequence, N is index number. Every LIndexN has its own sorting cells which should program in link list; we need compression of existing numbers with the new coming number, after compression it should store in its appropriate place. Internal structure of sorting cells is as following. It is given in the Fig. 2.  

  B) then a signal with a single component is more likely to have a component only. Otherwise, the analyzed signal has more components. This statement is veriﬁed by the data available in Table 2. C. Information Measures Table 3 presents the numerical values of the absolute (RH) and differential Renyi entropies (DRH). The differential entropy is obtained by subtracting the entropy of the case #1 from the absolute values of all others entropies. Two distributions are considered, namely WVD and PWVD. Figure 7 shows a comparison between entropies, as solution describing the complexity of the analyzed signal, in all ten considered cases. It is important to notice the superiority of the entropies. If the complexity of the signal is growing (at least as the number of components) then the entropy is rising, too. Moreover, differential entropies  
   
  Table 3. Renyi entropies No WVD RH 1. −0.2012 2. −0.2075 3. −0.2075 4. −0.2075 5. +1.1465 6. +1.1469 7. +1.1469 8. +2.0483 9. +2.0895 10. +2.5921  
   
  DRH 0.0 −0.0063 −0.0063 −0.0063 +1.3477 +1.3480 +1.3481 +2.2495 +2.2907 +2.7933  
   
  PWVD RH −0.0548 −0.1896 −0.2030 −0.2055 1.2647 0.9987 0.9262 2.0225 1.7881 2.4355  
   
  DRH 0.0 −0.1349 −0.1482 −0.1507 +1.3195 +1.0535 +0.9810 +2.0772 +1.8429 +2.4903  
   
  442  
   
  D. Aiordachioaie  
   
  Fig. 7. Evolution of the main descriptors (entropies), information-based  
   
  are able to predict the number of the components in the analyzed signal, as it was described in Sect. 3B. The information obtained from entropies combined with the ratios of statistical parameters, as described above, could drastically improve the results of the signal analysis, both on qualitative (as number of components) and quantitative aspects (localization and width in time and frequency). D. Detection and Filtering of Interferences With reference to the system of Fig. 1, let TInxn be a block image for testing. Let bInxn (bad image) be the block image with artifacts and let NInxn (normal image) be the block image with no interferences. The masking decision is based on the decision rule: IF corrðTI; bIÞ ¼ max AND THEN FILTER TI  
   
  corrðTI; NIÞ ¼ min  
   
  ð24Þ  
   
  where corr(.,.) is the statistic correlation operator working on square matrices. Figure 8 presents four block images: two for clean (correct) images, x1 and x4, and two block images with interferences, x12 and x34. The interference images have two speciﬁc features, which could be used in automatic detection and classiﬁcation: (i) it contains a lot of parallel ellipses; (ii) The main diagonals are parallel to the segment which connects the centers of the closest neighbored components. This set of features could be used to distinguish the real from false components in time-frequency images. In this case, the self-checking procedure could be used before calling a classiﬁer for recognition purposes. Figure 9 presents the TFI for case # 8 and the results of the cross-correlation between the TFI and the bad block assigned to x12. The maximum cross-correlation indicates the position of the most similar block, which should be processed. Finally, Fig. 10 shows the effect of removing two bad blocks (block with interferences) from the raw time-frequency image (TFI), for the same case (#8).  
   
  On Time-Frequency Image Processing for Change Detection Purposes  
   
  443  
   
  Fig. 8. Samples from the feature image data base: with and free of interference  
   
  Fig. 9. Raw TFI image and the cross-correlation image between x12 and raw TFI  
   
  The complete set of experiments can ﬁx the performance of the system. The results are as expected for all cases with double components. For the cases with more components, the results depend on the distance between components. If some components are in the middle, between two or more components, then they are modiﬁed and the reconstruction becomes quite difﬁcult with this system.  
   
  444  
   
  D. Aiordachioaie  
   
  Fig. 10. Raw and ﬁltered TFI images, case 8  
   
  5 Conclusions A system meant to analyze, detect and ﬁlter artifacts in images coming from time-frequency transforms was considered and discussed, in the context of change detection and diagnosis of industrial equipment, which generates mechanical vibrations. The complexity of the input signal is well described by the Renyi entropy, which increases when the complexity of the analyzed signal is growing (number of components, mainly). The average parameters of time and frequency are good descriptors only for mono-components signals. Otherwise, they refer to the average content. The detection system uses the correlation between small (blocks) images and scanned input images. The raw time-frequency image is decomposed in basic (small) blocks of size nxn = 100  100. The decomposition could be static, by scanning the raw image on vertical and horizontal axis, in steps of one or several pixels, or could be dynamic, by changing the size of the scanning steps, based on the content of the image. Sparse blocks will generate higher scanning steps. The dynamic scanning speeds up the analysis of the image. The interference images have two speciﬁc features, which could be used in automatic detection and classiﬁcation: (i) it contains a lot of parallel ellipses; (ii) The main diagonals are parallel to the segment which connects the centers of the closest neighbored components. This set of features could be used to distinguish the real from false components in time-frequency images. The system needs a training stage (time) to complete a database with what means good and bad features in the analyzed images. This process is supervised and could be run all the time. The similarity checking between the content of the raw image and the selected features for database is made on cross-correlation basis. The performance of the system is acceptable for signals with well-separated components, in time and frequency, which is the case of many real faults in the industry of rotating machines. If the components and the artifacts interfere, the system cannot work as expected, and generates errors. It could be involved in estimating the values of the real components, but this aspect is not considered here.  
   
  On Time-Frequency Image Processing for Change Detection Purposes  
   
  445  
   
  Acknowledgement. The authors thank the Executive Agency for Higher Education, Research, Development and Innovation Funding (UEFISCDI) for its support under Contract PN-II-PTPCCA-2013-4-0044 (VIBROCHANGE).  
   
  References 1. Isermann, R.: Supervision, fault-detection and fault-diagnosis methods. CEP 5(5), 639–652 (1997) 2. Patton, R.J., Frank, P., Clark, R. (eds.): Fault Diagnosis in Dynamic Systems – Theory and Application. Prentice Hall, Upper Saddle River (1989) 3. Basseville, M., Nikiforov, I.: Detection of Abrupt Changes – Theory and Application. Prentice Hall, Upper Saddle River (1993) 4. Gustafson, F.: Statistical signal processing approaches to fault detection. ARC 31, 41–54 (2007) 5. Basseville, M.: On-board component fault detection and isolation using the statistical local approach. Publication Int. No. 1122, IRISA (1997) 6. Timusk, M., Lipsett, M., Mechefske, C.K.: Fault detection using transient machine signals. Mech. Syst. SP 22, 1724–1749 (2008) 7. Venkatasubramanian, V., Rengaswamy, R., Yin, K., Kavuri, S.N.: A review of process fault detection and diagnosis, part I: quantitative model-based methods. Comput. Chem. Eng. 27, 293–311 (2003) 8. Wang, W.J., McFadden, P.D.: Time-Frequency Domain Analysis of Vibration Signals for Machinery Diagnostics, (III) The Present Power Spectral Density, University of Oxford, Report No. OUEL 1911/92 (1992) 9. McFadden, P.D., Wang, W.: Time-Frequency Domain Analysis of Vibration Signals for Machinery Diagnostics. (I) Introduction to the Wigner-Ville Distribution, University of Oxford, Report No. OUEL 1859/92 (1990) 10. The VIBROCHANGE project, Experimental Model for Change Det. and Diag. of Vibrational Proc. Using Advanced Measuring and Analysis Techn. Model-Based (2015). www.etc.ugal. ro/VIBROCHANGE 11. Cohen, L.: Time-frequency distributions - a review. Proc. IEEE 77(7), 941–980 (1989) 12. Hlawatsch, F., Boudreaux-Bartels, F.: linear and quadratic time-frequency signal representations. IEEE Sig. Process. Mag. 9, 21–67 (1992) 13. Flandrin, A.P., Gonçalvès, P., Lemoine, O.: Time-Frequency Toolbox For Use with MATLAB, CNRS (France)/Rice Univ. (USA) (1995–1996) 14. Auger, F.: Representations Temps-Frequence Des Signaux Nonstationnaires: Synthese Et Contributions. Ph.D. thesis, Ecole Centrale de Nantes, France (1991) 15. Flandrin, P.: Temps-frequence, Hermes, Trait des Nouvelles Technologies, serie Traitement du Signal (1993) 16. Popescu, T., Aiordachioaie, D.: Signal segmentation in time-frequency plane using renyi entropy - application in seismic signal processing. In: 2nd International Conference on Control and Fault-Tolerant Systems, SysTol-2013, 9–11 October, Nice, France, pp. 312–317 (2013) 17. Aiordachioaie, D.: Signal segmentation based on direct use of statistical moments and renyi entropy. In: 10th International Conference on Electronics, Computer and Computation (ICECCO 2013), Istanbul, Turkye, pp. 359–362 (2013) 18. Barbarossa, S.: Analysis of multicomponent LFM signals by a combined wigner-hough transform. IEEE Trans. Sig. Process. 43(6), 1511–1515 (1995)  
   
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter J´ ozsef Dombi1(B) and Adrienn Dineva2,3 1  
   
  3  
   
  Institute of Informatics, University of Szeged, ´ ad t´er 2, Szeged, Hungary 6720 Szeged Arp´ [email protected]  2 Doctoral School of Applied Informatics and Applied Mathematics, ´ Obuda University, 1034 Budapest B´ecsi u ´t 96/b, Budapest, Hungary [email protected]  Doctoral School of Computer Science, Department of Information Technologies, Universit´ a degli Studi di Milano, Crema Campus, 65 Via Bramante, 26013 Crema (CR), Italy  
   
  Abstract. Noise cancellation is the primary issue of the theory and practice of signal processing. The Savitzky-Golay (SG) smoothing and diﬀerentiation ﬁlter is a well studied simple and eﬃcient technique for noise eliminating problems. In spite of all, only few book on signal processing contain this method. The performance of the classical SGﬁlter depends on the appropriate setting of the windowlength and the polynomial degree. Thus, the main limitations of the performance of this ﬁlter are the most conspicious in processing of signals with high rate of change. In order to evade these deﬁciencies in this paper we present a new adaptive design to smooth signals based on the Savitzky-Golay algorithm. The here provided method ensures high precision noise removal by iterative multi-round smoothing. The signal approximated by linear regression lines and corrections are made in each step. Also, in each round the parameters are dynamically change due to the results of the previous smoothing. The applicability of this strategy has been validated by simulation results.  
   
  Keywords: Savitzky-Golay ﬁlter Iterative smoothing · Denoising  
   
  1  
   
  ·  
   
  Adaptive multi-round smoothing  
   
  ·  
   
  Introduction  
   
  Many areas of signal processing require highly eﬃcient processing methods in order to achieve the desired precision of the result. In a particular class of tasks, for e.g. chemical spectroscopy, smoothing and diﬀerentiation is very signiﬁcant. An ample number of studies have been revealed the details of the smoothing ﬁlters. In 1964 a great eﬀort has been devoted to the study of Savitzky and Golay, in which they introduced a particular type of low-pass ﬁlter, the so-called digital smoothing polynomial ﬁlter (DISPO) or Savitzky-Golay (SG) ﬁlter [17]. c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 38  
   
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter  
   
  447  
   
  The main advantage of the SG-ﬁlter in contrast to the classical ﬁlters - that require the characterzation and model of the noise process-, is that both the smoothed signal and the derivatives can be obtained by a simple calculation. Critical reviews and modiﬁcations of the original method can be read, for instance in [15,21]. The core of this algorithm is ﬁtting a low degree polynomial in least squares sense on the samples within a sliding window. The new smoothed value of the centerpoint obtained from convolution. There is a rapidly growing literature discussing the properties and improvements of SG ﬁlters [1,3,6,7,12,16,24,25]. Also the importance and applicability of a digital smoothing polynomial ﬁlter in chemometric algorithms are well established [8,11,22]. The frequency domain properties of SG-ﬁlters are addressed in [2,10,18,19]. In [14], the properties of the SG digital diﬀerentiator ﬁlters and also the issue of the choice of ﬁlter length are discussed. Paper [13] concerns the calculation of the ﬁlter coeﬃcients for even-numbered data. Also the fractional-order SG differentiators have been investigated, for e.g., by using the Riemann-Lioueville fractional order deﬁnition in the SG-ﬁlter. For instance, the fractional order derivative can be calculated of corrupted signals as published in [4]. There are several sources and types of noise that may distort the signal, for e.g., eletronic noise, electromagnetic and electrostatic noise, etc. [23]. In the theory of signal processing it is commonly assumed that the noise is an additive white Gaussian noise (AWGN) process. However, in engineering practice often nonstationary, impulsive type disturbances, etc., can degrade the performance of the processing system. Since, for the noise removal issue of signals with a large spectral dynamic or with a high rate of change, the classical SG ﬁltering is an uneﬃcient method. Additionally, the performance depends on the appropriate selection of the polynomial order and the window length. The arbitrary selection of these parameters is diﬃculty for the users. Usually the Savitzky-Golay ﬁlters perform well by using a low order polynomial with long window length or low degree with short window. This latter case needs the repetition of the smoothing. It has also been declared that the performance decreases by applying low order polynomial on higher frequencies. Nonetheless, it is possible to further improve the eﬃciency. With this goal, in this work we introduce an adaptive smoothing approach based on the SG ﬁltering technique that ensures acceptable performance independent of the type of noise process.  
   
  2  
   
  Mathematical Background of the Savitzky-Golay Filtering Technique  
   
  In this section we brieﬂy outline the premise behind the SavitzkyGolay ﬁltering according to [9]. Let us consider equally spaced input data of n{xj ; yj }, j = 1, . . . , n. The smoothed values derives from convolution, given by gi =  
   
  m  i=−m  
   
  ci yk+i ,  
   
  (1)  
   
  448  
   
  J. Dombi and A. Dineva  
   
  where the window length M = 2m + 1, i = −m, . . . , λ, . . . , m, and λ denotes the index of the centerpoint. The k th order polynomial P can be written as P = a0 + a1 (x − xλ ) + a2 (x − xλ )2 + . . . + ak (x − xλ )k  
   
  (2)  
   
  The aim is to calculate the coeﬃcients of Eq. (2) by minimizing the ﬁtting error in the least squares sense. The Jacobian matrix is as follows J=  
   
  ∂P ∂a  
   
  (3)  
   
  The polynomial at x = xλ is a0 , hence in order to evaluate the polynomial in the window we have to solve a system of M equations which can be written in matrix form J ·a=y (4) ⎞ ⎞ ⎛a ⎞ ⎛y 0 λ−m 1 (xλ−m − xλ ) · · · (xλ−m − xλ )k .. ⎟ ⎜ .. ⎟ ⎜ .. ⎟ ⎜ .. .. .. ⎜ ⎟ . ⎟ ⎜. ⎟ ⎜ . . . ⎟ ⎜ . ⎟ ⎜ ⎟ ⎜ ⎜ ⎜ ⎟ . . ⎜1 ⎟×⎜ . ⎟=⎜ . ⎟ 0 ··· 0 ⎜ ⎟ ⎜ . ⎟ ⎜ . ⎟ ⎜. ⎟ ⎜ . ⎟ ⎜ . ⎟ .. .. .. ⎝ .. ⎠ ⎝ . ⎠ ⎝ . ⎟ . . . . . ⎠ k 1 (xλ+m − xλ ) · · · (xλ+m − xλ ) ak yλ+m ⎛  
   
  The coeﬃcients are found from the normal equation in the following writing  
   
  so Since  
   
  J T (Ja) = (J T J)a  
   
  (5)  
   
  a = (J T J)−1 (J T y).  
   
  (6)  
   
  P (xλ ) = a0 = (J T J)−1 (J T y),  
   
  (7)  
   
  by replacing y with a unit vector in Eq. (6) the c0 coeﬃcient can be calculated as cj =  
   
  k+1   
   
  |(J T J)−1 |0i Jij .  
   
  (8)  
   
  i=1  
   
  With a size of (2m + 1)x(k + 1) the G matrix of the convolution coeﬃcients G = J(J T J) = [g0 , g1 , . . . , gj ].  
   
  (9)  
   
  Figure 1 demonstrates the performance of the classical SG-ﬁlter. It can be observed that the smoothing is not precise. To overcome this problem, the following section will present an adaptive strategy (Table 1).  
   
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter  
   
  449  
   
  Fig. 1. Performance of the SG ﬁlter. Upper chart: signal with contaminating noise. Lower chart: dotted line - original signal, solid line - smoothed signal, k = 3, M = 35 Table 1. Some SG coeﬃcients. M = 2m + 1 is the window length and k denotes the polynomial degree Savitzky-Golay coeﬃcients M k Coeﬃcients 2*9 2 -0.0909 0.0606 0.1688 0.2338 0.2554 0.2338 0.1688 4 0.0350 -0.1282 0.0699 0.3147 0.4172 0.3147 0.0699 2*11 3 -0.0839 0.0210 0.1026 0.1608 0.1958 0.2075 0.1958 0.1608 5 0.0420 -0.1049 -0.0233 0.1399 0.2797 0.3333 0.2797 0.1399  
   
  3 3.1  
   
  0.0606 -0.0909 -0.1282 0.0350 0.1026 0.0210 -0.0839 -0.0233 -0.1049 0.0420  
   
  Adaptive Multi-round Smoothing Based-On the SG Filtering Technique Multi-round Smoothing and Correction  
   
  This new adaptive strategy aims setting automatically the suitable polynomial order and window length at the diﬀerent frequency components of the signal. Hence, it is possible to avoid the undershoots and preserve the peaks that could be important from diﬀerent data analysis aspects. Since we perform in the time domain, this method provides eﬃcient results independent of the type of contaminating noise. At ﬁrst, the classical Savitzky-Golay ﬁltering is performed. Assuming that only the corrupted signal is available, this step serves for revealing the peaks, hence the window length and degree of the polynomial may be arbitrary. After the ﬁrst smoothing, the coordinates of the local minimum and maximum points can be obtained. From now on, we can also deﬁne the d distace vector which contains the number of samples between two neighboring points  
   
  450  
   
  J. Dombi and A. Dineva  
   
  of local minima and maxima. Then, the next step is the separation of the highand low frequency components using the bordering points and setting the proper parameters for the smoothing. The window should match the scale of the signal and the polynomial degree should vary by depending on the framesize and frequency. Since the next fuzzy relation can be deﬁned between the section length; F (dmax >> d¯R ) =  
   
  1 1+  
   
  e−(δmax −d¯R )  
   
  ∈ [0, 1]  
   
  (10)  
   
  where δ¯R stands for the average length of the sections in the current R parts of the signal, while δmax = max(d) in the observed signal. If g(dmax , d¯R ) = 1, the current part of the signal contains high freqency componenst. Hence, the following rules are applied: if 1 > g(dmax , d¯R ) > 0.9 then k = 5, M = nint(0.3δ¯R ) if 0.89 > g(dmax , d¯R ) > 0.75 then k = 4, M = nint(0.5δ¯R ) if 0.75 > g(dmax , d¯R ) > 0.45 then k = 3, M = nint(δ¯R ) if 0.44 > g(dmax , d¯R ) > 0.2 then k = 2, M = nint(0.5Rn )  
   
  (11)  
   
  else k = 1, M = nint(0.8Rn ), where Rn is the total number of samples of the R part, and we can assign the k and M values to each R part of the signal. The values for the bounds have been determined according to the forlmula 2k modiﬁed by experimental results. 3.2  
   
  Approximation Using Modified Shephard Method for Corretion  
   
  The correction carried out with taking the linear approximation of the obtained signal. Then, it is extracted from the smoothed one. This step reveals the higher deviation, thus the next smoothing procedure can be modiﬁed accordint to its result. As we have the coordinates of the local minimum and maximum points and the vector d, we can easily ﬁt a regression line on the points between two local extrema. In this case, the ending and starting points of two consecutive lines do not necessary follow so as to match at the same value. In order to ensure the continuous joining of the lines we can perform this step by appling the Lagrange-multiplicator method given by   (m1 x(i) + b1 − y (i) )2 + (m2 x(i) + b2 − y (i) )2 ⇒ min, (12) xi ∈[x1 ,x2 ]  
   
  xi ∈[x1 ,x2 ]  
   
  with the following constraints: m1 x2 + b1 − m2 x2 + b2 .  
   
  (13)  
   
  However, in some cases the peaks can contain the information of interest. Therefore, the form of the peak or valley should be processed with special care. To addres this issue, a modiﬁed Shepard - method can be applied. Let us consider  
   
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter  
   
  451  
   
  Fig. 2. Illustration of the problem of joining of the regression lines  
   
  the points around the local extrema in radius r. The new values are calculated by weighting according to the neighboring points distance. There are several variations of the Shepard method [20], now let us consider the GM S (Groundwater M odeling System) form below i 2 ( d−d ddi ) . wi = n i 2 ( d−d ) ddi  
   
  (14)  
   
  i=1  
   
  Equation 14 can be trasformed into i 2 ( 1−u ui ) , wi = n u−u ( uj j )2  
   
  (15)  
   
  j=1  
   
  i  
   
  (x) in which ui (x) = dd(x) . Now, using the similarity between the form of Eq. 15 and the Dombi operator [5] we can deﬁne the following new parametric weighting function: 1 wi = (16) 1−uj λ ui 2 1 + ( 1−ui ) ( uj ) j=1  
   
  in which the setting of λ and radius r (where it performs) have the eﬀect on the smoothness of the result (Fig. 2).  
   
  4  
   
  Simulation Results  
   
  The performance of the proposed method have been tested on a noisy signal (see, Fig. 3). The simulation has been carried out by using Matlab 8. Figure 4 shows the approximated signal after the ﬁrst round. In Fig. 5 the resulted and the original signal can be seen after two rounds. It can be observed that the applied technique can eﬃciently recover the signal.  
   
  452  
   
  J. Dombi and A. Dineva  
   
  Fig. 3. The corrupted signal  
   
  Fig. 4. The approximation of the signal after the ﬁrst round.  
   
  Fig. 5. The recovered (blue) and the original (magenta) signal.  
   
  Adaptive Multi-round Smoothing Based on the Savitzky-Golay Filter  
   
  5  
   
  453  
   
  Conclusions  
   
  In this paper a new adaptive smooting strategy has been introduced based on the Savitzky-Golay ﬁltering technique. The proposed method allows to evade the main diﬃculties of the original SG ﬁlter by automatically setting the smoothing parameters. Furthermore, for the precise reconstruction of the signal a multi round correction has been applied using the linear approximation of the signal. For the reconstruction of the peaks and valleys that may contain the important information, a new weighting function has been introduced with the combination of the GM S method and the Dombi operator. The applicability and eﬃciency of this new strategy have been validated by simulation results. Acknowledgement. This work has been sponsored by the Hungarian National Scientiﬁc Research Fund (OTKA 105846). The authors also thankfully acknowledge the support of the Doctoral School of Applied Informatics and Applied Mathematics of Obuda University.  
   
  References 1. Ahnert, K., Abel, M.: Numerical diﬀerentiation of experimental data local versus global methods. Comput. Phys. Commun. 177, 764–774 (2007) 2. Bromba, M.U.A., Ziegler, H.: Application hints for Savitzky-Golay digital smoothing ﬁlters. Anal. Chem. 53(11), 1583–1586 (1981) 3. Browne, M., Mayer, N., Cutmore, T.: A multiscale ﬁlter for adaptive smoothing. Digit. Sig. Proc. 17, 69–75 (2007) 4. Chen, D., et al.: Digital fractional order Savitzky-Golay diﬀerentiator. IEEE Trans. Circ. Syst. 58(11), 758–762 (2011) 5. Dombi, J.: Towards a general class of operators for fuzzy systems. IEEE Trans. Fuzzy Syst. 16(2), 477–484 (2008) 6. Edwards, T., Willson, P.: Digital least squares smoothing of spectra. Appl. Spectrosc. 28, 541–545 (1974) 7. Engel, J., et al.: Breaking with trend in pre-processing? Trends Anal. Chem. 2013, 96–106 (2013) 8. Finta, C., Teppola, P.J., Juuti, M., Toivanen, P.: Feasibility of parallel algorithms and graphics processing unit acceleration in chemical imaging. Chemometr. Intell. Lab. Syst. 127, 132–138 (2013) 9. Flannery, B., Press, H., Teukolsky, A., Vetterling, W.: Numerical Recipes in C: The Art of Scientiﬁc Computing, 2nd edn. Cambridge University Press, New York (1992) 10. Hamming, R.W.: Digital Filters, 3rd edn. Prentice-Hall, Englewood Cliﬀs (1989). Chap. 3 11. Komsta, L.: A comparative study on several algorithms for denoising of thin layer densitograms. Anal. Chim. Acta 641, 52–58 (2009) 12. Krishnan, R., Seelamantula, C.: On the selection of optimum Savitzky-Golay ﬁlters. IEEE Trans. Sig. Process. 61(2), 380–391 (2013) 13. Luo, J., Ying, K., Bai, J.: Savitzky-Golay smoothing and diﬀerentiation ﬁlter for even number data. Sig. Process. 85(7), 1429–1434 (2005)  
   
  454  
   
  J. Dombi and A. Dineva  
   
  14. Luo, J., Ying, K., He, P., Bai, J.: Properties of Savitzky-Golay digital diﬀerentiators. Digit. Sig. Proc. 15(2), 122–136 (2005) 15. Madden, H.: Comments of Savitzky-Golay convolution method for least squares ﬁt smoothing and diﬀerentiation of digital data. Anal. Chem. 50, 1383–1386 (1978) 16. Persson, P.O., Strang, G.: Smoothing by Savitzky-Golay and legendre ﬁlters. In: Rosenthal, J., Gilliam, D.S. (eds.) Mathematical Systems Theory in Biology, Communications, Computation, and Finance, vol. 134, pp. 301–315. Springer, New York (2003) 17. Savitzky, A., Golay, M.J.: Smoothing and diﬀerentiation of data by simpliﬁed least squares procedures. Anal. Chem. 36(8), 1627–1639 (1964) 18. Schafer, R.W.: On the frequency-domain properties of Savitzky-Golay ﬁlter. In: Proceedings of the the 2011 DSP/SPE Workshop, Sedona, AZ, pp. 54–59 (2011) 19. Schafer, R.W.: What is a Savitzky-Golay ﬁlter? (lecture notes). IEEE Sig. Process. Mag. 28(4), 111–117 (2011). doi:10.1109/MSP.2011.941097 20. Shepard, D.: A two-dimensional interpolation function for irregularly-spaced data. In: Proceedings of the 1968 ACM National Conference, pp. 517–524 (1968) 21. Steiner, J., Termonia, Y., Deltour, J.: Comments on smoothing and diﬀerentiation of data by simpliﬁed least squares procedura. Anal. Chem. 4, 1906–1909 (1972) 22. Tong, P., Du, Y., Zheng, K., Wu, T., Wang, J.: Improvement of nir model by fractional order Savitzky-Golay derivation (FOSGD) coupled with wavelength selection. Chemometr. Intell. Lab. Syst. 143, 40–48 (2015) 23. Vaseghi, S.V.: Advanced Digital Signal Processing and Noise Reduction, 4th edn. Wiley, Hoboken (2008) 24. Wayt, H.J., Khan, T.R.: Integrated Savitzky-Gola ﬁlter from inverse Taylor series approach. In: Proceedings of the 2007 15th International Conference on Digital Signal Processing (DSP 2007), pp. 375–378. IEEE (2007) 25. Zhao, A., Tang, X., Zhang, Z.: The parameters optimization selection of SavitzkyGolay ﬁlter and its application in smoothing pretreatment for FTIR spectra. In: Proceedings of the IEEE 9th Conference on Industrial Electronics and Applications (ICIEA), pp. 516–521 (2014)  
   
  Point Cloud Processing with the Combination of Fuzzy Information Measure and Wavelets Adrienn Dineva1,2(B) , Annam´ aria R. V´ arkonyi-K´ oczy3 , Vincenzo Piuri4 , 5 and J´ ozsef K. Tar 1  
   
  Doctoral School of Applied Informatics and Applied Mathematics, ´ Obuda University, B´ecsi u ´t 96/b, Budapest 1034, Hungary [email protected]  2 Doctoral School of Computer Science, Department of Information Technologies, Universit´ a degli Studi di Milano, Crema Campus, 65 Via Bramante, 26013 Crema (CR), Italy 3 Department of Mathematics and Informatics, J. Selye University, Komarno, Slovakia [email protected]  4 Department of Information Technologies, Universit´ a degli Studi di Milano, Crema, Italy [email protected]  5 ´ Antal Bejczy Center for Intelligent Robotics (ABC iRob), Obuda University, Budapest, Hungary [email protected]   
   
  Abstract. Processing of remotely sensed point clouds is a crucial issue for many applications, including robots operating autonomously in real world environments, etc. The pre-processing is almost an important step which includes operations such as remove of systematic errors, ﬁltering, feature detection and extraction. In this paper we introduce a new preprocessing strategy with the combination of fuzzy information measure and wavelets that allows precise feature extraction, denoising and additionally eﬀective compression of the point cloud. The suitable setting of the applied wavelet and parameters have a great impact on the result and depends on the aim of preprocessing that usually is a challenge for the users. In order to address this problem the fuzzy information measure has been proposed that supports the adaptive setting of the parameters. Additionally a fuzzy performance measure has been introduced, that can reduce the complexity of the procedure. Simulation results validate the eﬃciency and applicability of this method. Keywords: Point cloud processing · Fuzzy information measure · Signal processing · Denoising  
   
  1  
   
  Introduction  
   
  Recently, there is a growing interest in several areas of engineering practice for the automatic processing methods of three-dimensional remotely sensed models. c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 39  
   
  456  
   
  A. Dineva et al.  
   
  Most of the 3D scanning devices produce a set of data points of the environment usually deﬁned with their Descartes (x, y, z) coordinates. The resulted data set can contain faulty sensor values of the environment, disturbing noises, etc.,. Since the sampling of the raw point cloud is insuﬃcient for most applications the main steps of processing includes the outlier (extreme values) removal, noise cancellation and smoothig, surface reconstruction and feature extraction. Additionally, depending on the speciﬁc requirements of the application further post processing techniques can be used [10]. Classical approaches, for instance linear ﬁltering, can remove the noise, but with weak feature localization ability. To overcome this deﬁcieny nonlinear ﬁlters have been proposed [8,16]. Among the classical signal processing techniques, wavelet-based noise reduction has a major potential application to ﬁlter data, due to its excellent feature localization property. It reveals the information at a level of detail, which is not available with Fourier-based methods [4]. The so-called wavelet shrinkage employs nonlinear soft thresholding functions in the wavelet domain [6]. Also, the fast discrete wavelet signal transform (DWT) algorithms can fulﬁl time-critical needs. However, the selection of the appropriate wavelet and number of resolution levels, threshold function, etc. is still a challenging task. The point cloud may contain several objects, artifacts with diﬀerent surface complexity thus the diﬀerent parts need the appropriate shrinkage method. This paper introduces the fuzzy information measure for supporting the adaptive shrinkage procedure selection. The here described method conserns outlier removal and feature extraction. The complexity of an object is determined by the number of edges. In order to conserve precisely the shape that may contain the information of interest with simultaneously ﬁltering out the noise, the objects with high complexity are processed with higher levels of resolution and appropriate threshold function. While the other parts can be smoothed. Furthermore, processing all of the points can be time-consuming, thus the fuzzy performance measure proposed for selecting the minimum amount of data that is necessary for obtaining the desired result. This serves also a basis for eﬃcient data compression. The applicability and eﬃciency of this method have been validated via simulation results.  
   
  2 2.1  
   
  Point Cloud Processing with the Combination of Fuzzy Information Measure and Wavelets Principles of Discrete Wavelet Shrinkage  
   
  The point cloud contains points that are returned from the terrain objects, including ground, buildings, bridges, vehicles, trees, and other non-ground features. For many applications it is important to detect, separated, or removed the artifacts in order to extract the required information [17]. Many mathematical tools have been derived for other applications need the precise reconstruction of the artifacts or involve searching for the minimum of a continuous function or  
   
  Point Cloud Processing with the Combination of Fuzzy Information Measure  
   
  457  
   
  a sizing optimization process [11]. Thus, the pre-processing is almost important step which includes operations such as remove of systematic errors, ﬁltering, feature detection and extraction, etc. The utilization and theory of wavelets is well established, for e.g. see [4]. The discrete wavelet transform analyses the signal at diﬀerent frequency scales with diﬀerent resolutions by reducing the signal into approximate and detail information. For removing noise, wavelet shrinkage employs nonlinear soft thresholding functions in the wavelet domain. The popularity of this nonparametric method is due to the excellent localization and feature extracting behavior. However several threshold estimators exist, it is still a challenging task to select the appropriate shrinkage method that ﬁts to the type of signal and contaminating noise and further, is robust against impulse type noises [6]. The other major issue in noise reduction is minimizing the eﬀects of extreme values or elements that deviate from the observation pattern (outliers) (see, for e.g. [2]). The ﬁrst step of wavelet shrinkage is the decomposition of signal into the wavelet (detail and approximate) coeﬃcients, as described in [9]. The basic idea behind wavelet shrinkage is setting the value of these coeﬃcients with small magnitude to zero (hard thresholding), or setting their value determined by a lambda (λ) threshold level [7]. After, the reconstruction is carried out by performing the inverse discrete wavelet transform (IDWT). Generally, the shrinkage methods construct nonlinear threshold functions that relies on some statistical considerations. For instance, the smoothness-adaptive method (SureShrink) [7] is proposed to threshold each dyadic resolution level using the principle of Steins Unbiased Estimate of Risk [12], while the universal bound thresholding rule provides results with low computational complexity. The rule of the latter is deﬁned, as follows [7], √ (1) ν = σM AD 2 log sj median(ω )  
   
  where σM AD = 0.6745 j denotes the absolute median deviation. The speciﬁc choice of the wavelet function, decomposition level, and thresholding rule allows to construct many diﬀerent shrinkage procedures. 2.2  
   
  The Concept of Fuzzy Information Measure  
   
  The key issue of image processing, image understanding, data storage, information re-trieval, etc. is what carries the information in images or scenes. However, a wide range of possible concepts replies to this question, containing statistical approaches. Another, more sophisticated approach may also consider the elimination of the additive noises. This raises another question: What is noise? The main problem of answering this questions that noise is an ill-deﬁned category, because noise is usually dependent on the situation and on the objective of the processing [15]. What is characteristic or useful information in one application can be noise in another one. Based on these consideration, the amount of information in an image or point cloud strongly related to the number and complexity of the objects in it [15]. The most characteristics of the objects are their boundaries, i.e. the edges that can be extracted. Since the boundary edges  
   
  458  
   
  A. Dineva et al.  
   
  of the objects contain the primary information about the object shape, these serve as base for classiﬁcation, object recognition, etc. According to the concept of F uzzy Inf ormation M easure revealed in [14,15], also the point clouds content information can be represented by the characteristic features, like boundary edges. Thus, the amount of information in the 3D map is proportional to the number of characteristic boundary lines. 2.3  
   
  Fuzzy Information Measure for Feature Extraction  
   
  There are also some studies proposing edge detecting procedures for 3D point clouds [3]. Generally, the precise construction of a 3D edge map of the environment from remotely sensed data can be limited. The method proposed further extends our previously approach [5]. It has been shown that applying robust ﬁtting on the wavelet coeﬃcients can eﬃciently denoise the data. However, objects with high complexity need shrinking with higher resolution levels and performing the ﬁtting with higher order polynomials for preserving the details. While, the other regions that contain unimportant or sparse information can be smoothed. For separating complex objects the number and distance of the most characteristic edges are counted that carries the information. For this reason, it is not necessary to construct the full edge map, just deﬁning the areas where the density of these edges are high. For properly setting the parameters of the wavelet resolution and smoothing the fuzzy information measure, the approach supports this clustering task. As has been described, for e.g. in [3], the local neighborhood of the point is used to test whether a point lies on a potential edge or not. If there is a depth discontinuity in the lidar scan at the point is at a maximum, then that point is part of a contour edge. According to this concept, the fuzzy-edgeness is determined by the depth discontinuity. The discontinuity is determined in the wavelet domain. The μ(r) = 1 fuzzy membership value belongs to a region that carries the highest information. The fuzzy information measure of each region is determined as follows, 1 (2) μ(ri ) = (nrmax −nri ) 1+e in which nrmax denotes the number of edges in the rmax region that contains the maximum number of edges, while nri is the number of edges in the ith region. After, the areas with a high number of edges are at ﬁrst decomposed with symlet wavelets using six levels. This step serves for the separation of the noise and the parts of the signal that carries the important information. After this, the robust ﬁtting is performed on the approximate coeﬃcients. Then, the iterative reweighting of the atoms is performed based on their residuals and using a trisquare function in a short running window, according to [3]. At last, the inverse discrete wavelet transform (IDWT) is performed. The same procedure holds for the regions with lower measure, but with applying daubechies wavelets with two levels of decomposition and for the ﬁtting a bisquare function within a long sliding window.  
   
  Point Cloud Processing with the Combination of Fuzzy Information Measure  
   
  2.4  
   
  459  
   
  Fuzzy Performance Measure  
   
  In engineering practice, the compression ratio measures the relative decrease in complexity of data in a raw form comparing it to the complexity of the compressed form after processing. However, several measures have been applied [13]. In the presented approach the robust ﬁtting performed on the wavelet coeﬃcients can be time consuming if we calculate the weights and new values  
   
  Fig. 1. The raw test data (available at [1]) with additive white Gaussian noise (AWGN).  
   
  Fig. 2. Result of the denoising using wavelet shrinkage and fuzzy information measure. The raw data is available at [1].  
   
  460  
   
  A. Dineva et al.  
   
  for all the points. Once a point selected for evaluation it is not necessary for calculating again the weights in its vicinity. For selecting the points for the procedure the evaluated fuzzy information measure of the region can be used. In region ri the running window size determined by the dmax distance of the edges. In the regions mu(ri ) > 0.8 the 85% of the points are selected for evaluation, while within the regions 0.8 > mu(ri ) > 0.6 the 50% of the points are enough. These boundaries can be set according to experimental results.  
   
  3  
   
  Simulation Results  
   
  The proposed approach has been tested on a lidar data available at [1]. The data set contains 65536 points. In Fig. 1 the raw data can be seen that has been aﬀected by noise. Figure 2 shows the result of the denoising with the combined approach. It can be seen, that the here described procedure ensures acceptable performance.  
   
  4  
   
  Conclusions  
   
  In this paper a novel concept has been proposed for denoising and feature extracting of remotely sensed point clouds. The here described method relies on the combination of fuzzy information measure and wavelets that allows precise feature extraction, denoising and additionally eﬀective compression of the point cloud. The suitable setting of the applied wavelet and parameters have a great impact on the result and depends on the aim of preprocessing that usually is a challenge for the users. In order to address this problem the fuzzy information measure has been proposed that supports the adaptive setting of the parameters. However, the evaluation of all the points in a large data set is time consuming. For this reason, a fuzzy performance measure has been introduced, that can reduce the complexity of the procedure by reducing the number of points due to the separated regions fuzzy information measure values. Simulation results validate the eﬃciency and applicability of this method. Acknowledgements. This work has been sponsored by the Hungarian National Scientiﬁc Research Fund (OTKA 105846). This publication is also the partial result of the Research & Development Operational Programme for the project “Modernisation and Improvement of Technical Infrastructure for Research and Development of J. Selye University in the Fields of Nanotechnology and Intelligent Space”, ITMS 26210120042, co-funded by the European Regional Development Fund.  
   
  References 1. ISPRS test on extracting DEMs from point clouds: a comparison of existing automatic ﬁlters. http://www.itc.nl/isprswgiii-3/ﬁltertest/ 2. Alvera-Azc´ arate, A.: Outlier detection in satellite data using spatial coherence. Remote Sens. Environ. 118, 84–91 (2012)  
   
  Point Cloud Processing with the Combination of Fuzzy Information Measure  
   
  461  
   
  3. Borges, P., Zlot, R., Bosse, M., Nuske, S., Tews, A.: Vision-based localiztaion using edge map extracted from 3D laser range data. In: IEEE International Conference on Robotics and Automation, pp. 4902–4909, May 3–8, Anchorage, Alaska, USA (2010) 4. Daubechies, I.: The wavelet transform, time frequency localizlocal and signal analysis. IEEE Trans. Inf. Theory 36, 961–1005 (1990) 5. Dineva, A., V´ arkonyi-K´ oczy, A.R., Tar, J.K.: Improved Denoising with Robust Fitting in the Wavelet Transform Domain. In: Technological Innovation for CloudBased Engineering System. IFIP Advances in Information and Communication Technology, vol. 450, pp. 179–187. Springer, Cham (2015) 6. Donoho, D.: Denoising by soft-thresholding. IEEE Trans. Inf. Theory 41(3), 613– 627 (1995) 7. Donoho, D., Johnstone, M.: Adapting to unknown smoothness via wavelet shrinkage. J. Am. Stat. Assoc. 90, 1200–1224 (1995) 8. Hamming, R.W.: Digital Filters, 3rd edn. Prentice-Hall, Englewood Cliﬀs (1989) 9. Mallat, S.: Multiresolution approximations and wavelet orthonormal bases of l2 . Trans. Am. Math. Soc. 315, 69–78 (1989) 10. Orfanidis, S.J.: Introduction to Signal Processing. Prentice-Hall Inc, Upper Saddle River (1995). ISBN 0-13-209172-0 11. Park, J.Y., Han, S.: Application of artiﬁcial bee colony algorithm to topology optimization for dynamic stiﬀness problems. Comput. Math. Appl. 66, 1879–1891 (2013) 12. Stein, C.M.: Estimation of the mean of a multivariate normal distribution. Ann. Stat. 9(6), 1135–1151 (1981) 13. Teolis, A.: Computational Signal Processing with Wavelets. Birkhauser, Boston (1998) 14. V´ arkonyi-K´ oczy, A.R., Hancsicska, S., Bukor, J.: Fuzzy information measure for improving HDR imaging. In: Shabbazova, S. (ed) In: Proceedings of the 4th World Conference on Soft Computing, WConSC 2014, pp. 491–497 (2014) 15. V´ arkonyi-K´ oczy, A.R., T´ oth, J.: A fuzzy information measure for image quality improvement. In: Nagatsu, M. (ed) In: Proceedings of the 14th International Conference on Global Research and Education in Intelligent Systems, Interacademia 2015, pp. 30–37 (2015) 16. Vaseghi, S.V.: Advanced Digital Signal Processing and Noise Reduction, 4th edn. Wiley, Hoboken (2008) 17. Vosselmann, G., Maas, H.G. (eds.): Airborne and Terrestrial Laser Scanning. Whittles Publishing, Dunbeath (2010)  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms in Vocal Emotion Conversion Susmitha Vekkot and Shikha Tripathi(&) Department of Electronics and Communication Engineering, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Amrita University, Bengaluru, India {v_susmitha,t_shikha}@blr.amrita.edu  
   
  Abstract. The objective of this work is to explore the signiﬁcance of efﬁcient glottal activity detection for inter-emotion conversion. Performance of popular glottal epoch detection algorithms like Dynamic Projected Phase-Slope Algorithm (DYPSA), Speech Event Detection using Residual Excitation And a Mean-based Signal (SEDREAMS) and Zero Frequency Filtering (ZFF) are compared in the context of vocal emotion conversion. Existing conversion approaches deal with synthesis/conversion from neutral to different emotions. In this work, we have demonstrated the efﬁcacy of determining the conversion parameters based on statistical values derived from multiple emotions and using them for inter-emotion conversion in Indian context. Pitch modiﬁcation is effected by using transformation scales derived from both male and female speakers in IIT Kharagpur-Simulated Emotion Speech Corpus. Three archetypal emotions viz. anger, fear and happiness were generated using pitch and amplitude modiﬁcation algorithm. Analysis of statistical parameters for pitch after conversion revealed that anger gives good subjective and objective similarity while characteristics of fear and happiness are most challenging to synthesise. Also, use of male voice for synthesis gave better intelligibility. Glottal activity detection by ZFF gave results with least error for median pitch. The results from this study indicated that for emotions with overlapping characteristics like surprise and happiness, inter-emotion conversion can be a better choice than conversion from neutral. Keywords: Glottal Closure Instants Inter-emotion conversion  
   
    
   
  DYPSA  
   
    
   
  SEDREAMS  
   
    
   
  ZFF  
   
    
   
  1 Introduction Emotions form a vital part of human communication. An emotion can be deﬁned as that state of mind which conveys the non-linguistic information from the speaker. Emotions can be expressed through multiple modalities like facial expressions, hand gestures or speech. Vocal emotion forms the non-linguistic part of expression and has a range of variations depending on speaker gender, state of mind, physiology and language. Due to this, the recognition and analysis of human emotions has always been a challenging task. Vocal emotions form part of the para-linguistic information conveyed © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_40  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms  
   
  463  
   
  in the form of spoken language. With the advent of robotic communication technology, human-machine interaction has been gaining immense momentum during the last decade. Effective portrayal of emotions by robots requires that the parameters characterising the synthesis of emotions are estimated, analysed and manipulated at segmental, supra-segmental and sub-segmental levels. In Fants source-ﬁlter model of speech production, the source signal produced at lungs and manipulated by glottal constrictions is linearly ﬁltered through the vocal tract. The operation can be compared to convolution using a glottal source and ﬁlter. The vocal tract shapes the characteristics of the vibrations emitted from the source. The resulting sound is emitted to the surrounding air through lips [1]. Glottal Closure Instants (GCIs) are deﬁned as instances of signiﬁcant excitation of resonances of vocal tract ﬁlter which corresponds to high energy in the glottal signal during voiced segment of speech and the onset points of frication in case of unvoiced speech [2]. Accurate detection of GCIs can aid in applications such as prosody modiﬁcation, speech coding/compression and speaker recognition [3]. The essence of speech production starts from glottal flow and hence a reliable estimate of parameters contributing to emotion impression in speech has to start from accurate determination of dynamics of glottal flow. Modulation characteristics of airflow can be studied by analysing and comparing the glottal waves across multiple emotions. Different algorithms have been proposed for determination of GCIs of voiced speech. These algorithms follow different approaches. Majority of them use Linear Prediction residual (LPR) for epoch extraction which can be used as the best alternative for glottal wave/its derivative [4, 5]. Fewer techniques are available for directly estimating glottal instants from speech. Researchers have been interested in developing accurate methods for glottal activity detection from the last few years. One of the important algorithms for GCI detection is done by Naylor in [6], popularly known as Dynamic Projected Phase-Slope Algorithm (DYPSA). A breakthrough algorithm for accurate detection of GCIs using Zero Frequency Filtered Signal (ZFF) was proposed in [8, 9]. One of the prominent works on glottal activity detection was carried out by Sturme by using multiscale analysis through wavelet transforms [10]. The authors computed absolute maxima along various scales and generated a tree representation. The GCIs were located at the top of the tree branches. A critical evaluation of the various algorithms for detecting GA regions was done in [11]. Important algorithms like DYPSA [6], SEDREAMS [7], ZFF [8] and wavelet based Lines Of Maximum Amplitude (LOMA) [10] were compared using data from speakers of CMU-ARCTIC database. SEDREAMS was found to have better accuracy in terms of identiﬁcation rates. Another useful technique for detecting GOIs is by estimating the Hilbert transform of the LP residual of speech [12]. Here, GOIs are estimated from difference EGG by picking secondary peaks. Performance evaluation showed an identiﬁcation rate of 99.91%. In this paper we focus on the signiﬁcance of glottal activity detection in conversion across multiple emotions. The rest of the paper is organised as follows: Sect. 2 describes the algorithms used to obtain the GCIs in the paper, Sect. 3 describes the implementation of inter-emotion conversion using the various epoch detection algorithms while Sect. 4 describes the results and objective evaluation using statistical values and comparison of error percentage. Finally, the paper is concluded in Sect. 5 with insights into the challenges involved and future scope of work.  
   
  464  
   
  S. Vekkot and S. Tripathi  
   
  2 Algorithms for Glottal Epoch Detection This section throws light on the algorithms used for epoch detection from speech signals. 2.1  
   
  Dynamic Projected Phase-Slope Algorithm (DYPSA)  
   
  The algorithm described in [6] uses a modiﬁcation of [13] in which Group Delay function is used to determine instants of signiﬁcant excitation of glottis. As the name implies, DYPSA algorithm works on the slope of unwrapped phase of Short-Time Fourier transformed Linear Prediction (LP) residual, which is known as phase slope in Group Delay Algorithm [6]. The peak GCI candidates are identiﬁed from the positive going and projected zero-crossings of the above function. Finally, a dynamic programming approach is used to select the optimum candidates for glottal closure by minimising an objective function. 2.2  
   
  Speech Event Detection Using Residual Excitation and a Mean-Based Signal (SEDREAMS)  
   
  Speech Event Detection using Residual Excitation And a Mean-based Signal (SEDREAMS) uses a mean-based signal for epoch detection [7]. This signal is obtained as given in Eq. 1: N X 1 ym ¼ wðmÞ x ðn þ mÞ ð1Þ 2N þ 1 m¼N where x(n) is speech signal and w(m) is the window used. The GCI intervals extracted from the above signal may not give accurate detection. Hence mean based minima are found out and intervals between 2 successive minima (starting from mean based minima till 0.35 times local pitch period) are taken to represent the relative positions of GCIs [7]. For an accurate estimation, the local maxima within the above interval is found out which reﬁnes the actual GCI positions. 2.3  
   
  Zero Frequency Filtering  
   
  ZFF algorithm locates epochs in speech by computing the zero frequency ﬁltered signal [8]. Initially, the speech signal is pre-processed to remove any irregularities in recording: dðnÞ ¼ sðnÞ  sðn  1Þ ð2Þ d(n) is known as difference speech. This is ﬁltered through a cascade of two ideal zero-frequency resonators:  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms  
   
  yðnÞ ¼  
   
  4 X  
   
  ak yðn  kÞ þ dðnÞ  
   
  k¼1  
   
  465  
   
  ð3Þ  
   
  fa1 ; a2 ; a3 ; a4 g ¼ f4; 6; 4; 1g For removing the trend in y(n), the local mean subtraction is done at each sample to get the zero frequency ﬁltered signal, yZFF(n). yZFF ðnÞ ¼ yðnÞ   
   
  N X 1 yðn þ mÞ 2N þ 1 m¼N  
   
  ð4Þ  
   
  where 2N + 1 is the window length used. Epoch locations can be estimated by locating the positive zero-crossings of yZFF(n).  
   
  3 Implementation 3.1  
   
  Database Used  
   
  The database used for experimentation is IITKGP-SESC (Indian Institute of Technology Kharagpur Simulated Emotion Speech Corpus) which is recorded using 10 (5 male and 5 female) experienced professional artists from All India Radio (AIR) Vijayawada, India. For analysing the emotions 15 emotionally neutral Telugu sentences are considered in which each artist speaks with 8 emotions viz. neutral, anger, happy, fear, compassion, sarcasm, surprise and disgust. Each emotion has 1500 utterances, thus making the total utterances to 12000, lasting for around 7 h [14]. The speech signal was sampled at 16 kHz. For the current study, we have considered 4 basic emotions in IIT-KGP database viz. neutral, anger, happy and fear from male and female artists. For each of the emotions, statistical values i.e. median, mean and standard deviation of pitch are calculated from 10 different utterances. For each speech sample, GCIs are located using each of the above discussed algorithms and used for inter-emotion conversion using the statistical values computed. Inter-emotion conversion among the above 4 emotions is carried out and results are tabulated. The statistical values for pitch of the emotions considered in this paper for male and female speakers are given in Table 1. 3.2  
   
  Pitch Transformation Scales  
   
  Using the statistical values obtained above, the transformation scales for conversion across different emotions have been obtained using Eq. 5: Pitchfactorð%Þ ¼  
   
  T arg etpitch  Originalpitch  100 Originalpitch  
   
  ð5Þ  
   
  For analysis, the percentage change is chosen by taking the median value of each of the pitch parameters in the database. This is done to overcome the changes in the mean  
   
  466  
   
  S. Vekkot and S. Tripathi Table 1. Gender-wise statistical pitch values obtained for IIT-KGP SESC database Gender Emotion Median Male Neutral 187.38 Anger 272.72 Fear 249.76 Happy 219.56 Surprise 252.23 Female Neutral 303.69 Anger 370.50 Fear 309.62 Happy 316.5 Surprise 355.99  
   
  Mean 186.83 264.64 248.67 216.87 251.36 310.19 381.52 310.6 338.07 361.34  
   
  Standard deviation 40.09 50.77 28.27 42.83 56.85 80.4 95.96 52.72 94.8 85.85  
   
  value due to few irregularities in parameter values. Median of a data distribution gives a more accurate estimation as it does not take into account the irregularities. Also, the median and mean differ by less than 5% [15]. The percentage change to be incorporated in original emotions for conversion in each case is given in Table 2. Applying the pitch transformation scales below, the variations in pitch has been effected corresponding to each emotion. After pitch scaling, the resulting speech sample is subjected to amplitude scaling by multiplying the intermediate signal with the amplitude tier of the target emotion. Thus pitch and amplitude scaling for each emotion is performed. The statistical parameters are recalculated after conversion. The results are compared with the median values for target emotion as we have derived the transform scales based on median value. 3.3  
   
  Inter-emotion Conversion  
   
  Implementation of emotional conversion is carried out in this paper as a two-stage process. The ﬁrst stage involves incorporating the transformation scales obtained from Table 2 in pitch modiﬁcation algorithm. The ﬁrst stage of the conversion process makes use of dynamic pitch modiﬁcation algorithm depicted by Govind et al. [16]. This method has been chosen based on the efﬁciency in preserving the prosodic variations for high arousal emotions. Stage I 1. Estimate the instants of signiﬁcant excitation/glottal closure using the algorithm chosen for GCI detection. 2. Get the epoch intervals as difference between successive GCIs. 3. Modiﬁcation factor, mq for every qth interval is expressed as an integer ratio Aq/Bq. The initial value for modiﬁcation factor is the transformation scale value derived from Table 2. 4. mq corresponding to each emotion is derived based on transform scale Eq. 5. 5. New epoch instants are obtained by equally dividing the qth and q + Ath location into Bq intervals.  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms Table 2. Transformation scales obtained for inter-emotion conversion Gender Original emotion Target emotion Male Neutral Anger Fear Happy Surprise Anger Neutral Fear Happy Surprise Fear Neutral Anger Happy Surprise Happy Neutral Anger Fear Surprise Surprise Neutral Anger Fear Happy Female Neutral Anger Fear Happy Surprise Anger Neutral Fear Happy Surprise Fear Neutral Anger Happy Surprise Happy Neutral Anger Fear Surprise Surprise Neutral Anger Fear Happy  
   
  Change (%) 45.54 33.28 17.17 34.60 −31.29 −8.43 −19.49 −7.52 −24.97 9.2 −12.1 0.99 −14.65 24.22 13.76 14.88 −25.71 8.13 −0.99 −12.95 23.00 1.95 4.20 17.22 −18.03 −16.40 −14.57 −3.92 1.91 19.67 2.22 14.98 −4.05 17.06 −2.18 12.47 −14.69 4.08 −13.03 −11.09  
   
  467  
   
  468  
   
  S. Vekkot and S. Tripathi  
   
  6. The modiﬁed epoch locations are derived from modiﬁed instants computed in step 5 of the algorithm. 7. Similarly, the modiﬁed instants for each successive interval are calculated by incrementing qth location value by 1. 8. Repeat steps 3–7 until end location to generate new instants sequence. 9. Modiﬁed instants are concatenated and new pitch anchor points generated. 10. Speech waveform is reconstructed by copying the speech samples existing in each epoch interval to the adjacent modiﬁed epoch interval in the modiﬁed instants sequence obtained [17]. Figure 1 plots the target and synthesized happy speech with their pitch contours and spectrograms after Stage I (pitch scaling using transformation scale obtained in each case) of the algorithm.  
   
  Fig. 1. Results obtained after pitch modiﬁcation for neutral to happy conversion with GCI estimation using different algorithms. (a) Original happy speech segment, pitch contour and spectrogram. (b) Converted happy, pitch contour and spectrogram with GCI estimation using DYPSA. (c) Converted happy speech, pitch contour and spectrogram with GCI estimation using SEDREAMS. (d) Converted happy speech, pitch contour and spectrogram with GCI estimation using ZFF  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms  
   
  469  
   
  The second stage involves intensity modiﬁcation by imposition of amplitude changes of target emotion into the pitch modiﬁed signal from the ﬁrst stage. The algorithmic steps involved in conversion are listed below: Stage II 1. The pitch modiﬁed speech signal is saved as.wav ﬁle and extracted for further processing. 2. The target emotion speech ﬁle is processed to separate the intensity tier. 3. The amplitude variations in target emotion are imposed on pitch modiﬁed speech by multiplying the extracted amplitude tier with the pitch modiﬁed speech signal.  
   
  4 Results and Objective Evaluation The statistical parameters are again calculated after conversion. The results are compared with the median values for original emotion as we have derived the transform scales based on median value. Table 3. Comparison between statistical values for synthesised emotion and target emotion based on GCI algorithms GCI algorithm  
   
  Gender Statistical value  
   
  Source emotion Neutral Fear Happy Surprise Anger  
   
  Target values  
   
  Target emotion  
   
  DYPSA  
   
  Male  
   
  282.77 293.44 58.83 289.54 294.3 83.50 212.87 200.46 56.78 236.15 234.68 78.25 222.08 209.4 64.26 298.27 313.74 79.64 281.17 265.24 47.96 331.86 326.53 62.80  
   
  – – – – – – 193.26 197.26 45.8 245.20 294.05 115.4 213.55 208.44 22.18 300.00 295.00 92.48 – – – – – –  
   
  272.7 264.64 50.77 357.61 351.68 75.84 249.76 248.67 28.27 290.15 284.79 51.05 219.56 216.86 42.83 305.33 327.57 72.3 272.70 264.64 50.77 357.61 351.68 75.84  
   
  Anger  
   
  Female  
   
  Male  
   
  Female  
   
  Male  
   
  Female  
   
  SEDREAMS Male  
   
  Female  
   
  Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev  
   
  278.6 272.21 37.87 371.80 367.37 48.78 – – – – – – 227.36 213.87 38.97 233.68 234.94 71.75 312.85 305.00 24.50 398.38 392.21 22.20  
   
  276.17 252.75 62.63 343.67 359.42 58.94 215.59 207.83 30.45 244.72 239.18 32.00 – – – – – – 291.37 286.82 31.46 332.46 334.19 86.32  
   
  299.42 265.53 78.92 398.95 363.23 84.59 214.88 188.13 49.09 297.73 284.2 60.04 255.70 254.17 38.46 310.00 304.40 38.56 299.40 298.33 51.86 467.2 467.56 10.75  
   
  Fear  
   
  Happy  
   
  Anger  
   
  (continued)  
   
  470  
   
  S. Vekkot and S. Tripathi Table 3. (continued)  
   
  GCI algorithm  
   
  Gender Statistical value Male  
   
  Female  
   
  Male  
   
  Female  
   
  ZFF  
   
  Male  
   
  Female  
   
  Male  
   
  Female  
   
  Male  
   
  Female  
   
  Source emotion Neutral Fear Happy Surprise Anger  
   
  Target values  
   
  Target emotion  
   
  Median  
   
  216.78 –  
   
  249.76  
   
  Fear  
   
  Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev Median Mean Std. Dev  
   
  227.35 36.52 309.82 296.54 62.03 228.13 237.36 39.00 309.86 330.85 89.00 263.86 268.33 47.87 372.15 361.91 64.27 223.62 232.98 37.48 271.68 265.67 37.12 224.90 233.23 39.86 301.60 293.08 60.50  
   
  – – – – – 219.02 210.34 29.30 338.50 328.57 74.76 272.87 269.92 33.97 373.88 377.50 55.70 – – – – – – 221.30 219.74 18.81 281.10 297.46 42.12  
   
  235.42 240.48 38.90 252.65 250.22 11.28 – – – – – – 270.59 261.30 36.36 351.78 371.05 47.34 230.60 224.68 29.59 320.90 309.97 94.00 – – – – – –  
   
  233.54 43.00 303.47 291.24 46.48 238.61 235.36 37.73 310.24 306.89 20.77 236.24 246.00 52.77 279.82 323.48 89.97 234.74 235.80 43.60 298.12 301.77 78.35 242.76 225.99 45.20 302.49 316.09 67.77  
   
  218.16 31.60 203.58 238.99 92.53 204.4 195.27 40.75 193.00 216.3 70.04 – – – – – – 220.44 215.23 32.98 248.00 245.82 60.62 202.97 202.27 19.62 260.70 278.07 44.96  
   
  248.67 28.27 290.15 284.79 51.05 219.56 216.86 42.83 305.33 327.57 72.3 272.70 264.64 50.77 357.61 351.68 75.84 249.76 248.67 28.27 290.15 284.79 51.05 219.56 216.86 42.83 305.33 327.57 72.3  
   
  Happy  
   
  Anger  
   
  Fear  
   
  Happy  
   
  The results for converted (synthesized) emotion are tabulated in Table 3 and are compared with target emotion in each case. The percentage error rates have been calculated for each GCI algorithm based inter-emotion conversion and the results have been listed in Table 4. A graphical comparison between the algorithms has been drawn in Fig. 2. As we have used the scaling factor taking into account the median values, a comparison has been drawn based on median values.  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms  
   
  471  
   
  Table 4. Comparison of error (%) for inter-emotion conversion based on GCI algorithms Gender GCI algorithm Error (%) when target emotion is: Anger Fear Happy Male DYPSA 4.23 16.25 4.60 SEDREAMS 8.60 6.85 1.36 ZFF 4.33 8.97 1.56 Female DYPSA 1.85 11.78 6.49 SEDREAMS 6.95 7.85 5.70 ZFF 3.69 1.89 6.18  
   
  Fig. 2. Comparison of various GCI algorithms based on percentage error. The values are calculated based on median of anger, fear and happy emotions for both male and female speakers  
   
  From the experiments, some observations have been made: • Median value forms a better estimate for probabilistic study of various emotions as it is free from irregularities. • Conversion efﬁciency is higher for anger target in both neutral-emotion and inter-emotion cases. This is because anger is mainly categorized by higher pitch and intensity. The variations done as part of this work also focussed on pitch and intensity scaling. Anger gave best results for perception also. • Most deviation in results was obtained for conversion to/from fear emotion. Fear emotion is characterised with large variance and lower energy with the addition of a panic or anxiety component, thus giving rise to a breathy quality to voice. Mere pitch, duration and amplitude variations are unable to incorporate the harmonics and voice quality of fear.  
   
  472  
   
  S. Vekkot and S. Tripathi  
   
  • Conversion to/from happy also yielded average perception results. But the pitch contour of the synthesised emotion was found to be matching with original happy to some extent as shown by Fig. 1. Though the algorithm succeeded in bringing the pitch and intensity to the required level, it still failed to bring in the smooth rippling kind of inflexions normally found in happy speech. • From the error comparison Table 4, the minimum percentage error is obtained for emotion conversion in case of male speaker. As far as inter-emotion conversion is concerned, though the trends are fluctuating for the various algorithms we can see that an optimal choice of ZFF for epoch estimation gives acceptable error values. Also, the conversion error is maximum for fear case in both male and female speakers which is rightly correlated by experimental ﬁndings and perception. • The average computation time required for execution of conversion algorithm from neutral to emotion and between emotions were computed for each GCI algorithm and it was found that they are closely similar (around 220–260 µs). This shows that no restriction exists while choosing the mode of conversion (neutral emotion/emotion - emotion) and either can be chosen depending on interrelationship between source and target. For instance, conversion from surprise to happy yielded good objective and perceptive results in all cases (Table 3). This is due to the fact that surprise is depicted in the database as “pleasant”. • We found that the conversion efﬁciency depends on expressivity of database to a large extent. Emotions like happy and fear can be better distinguished from angry and sadness if the speaker displays the emotion with characteristic precision. In some cases, the enacted database fails to bring in the complex inundations and voice modulations of emotions while spontaneous recording can bring in a much perceivable quality to the target.  
   
  5 Conclusions The experiments on inter-emotion conversion gave acceptable results for pitch variations. Conversion to anger yielded best objective and perceptive results while fear and happiness conversions failed to bring in the dynamics of emotion involved. For emotions like happiness and surprise, the synthesised emotion was better perceived when converted from each other than from neutral emotion. However, though the computation time required for inter-emotion conversion using various GCI detection algorithms were similar, ZFF gave best results in terms of conversion error rate (%). Studies proved that in addition to incorporating variations in prosody, determining the voice quality parameters in emotion conversion and embedding these at proper instances are instrumental in making the target more expressive and intelligible. The challenge lies in suitably inserting the parameters thus determined without distorting the spectral characteristics of normal speech and further, making a generalized framework for emotion conversion which is database, speaker and language independent.  
   
  Signiﬁcance of Glottal Closure Instants Detection Algorithms  
   
  473  
   
  Acknowledgements. We would like to thank Dr. Govind. D, Amrita Vishwa Vidyapeetham, Coimbatore for providing us with IIT-KGP SESC database used in this research.  
   
  References 1. Fant, G.: Acoustic Theory of Speech Production. Mouton, The Hague (1960) 2. Murthy, K.S.R., Yegnanarayana, B.: Epoch extraction from speech signals. IEEE Trans. Audio Speech Lang. Proc. 16(8), 1602–1614 (2008) 3. Rao, K.S., Yegnanarayana, B.: Prosody modiﬁcation using instants of signiﬁcant excitation. IEEE Trans. Audio Speech Lang. Proc. 14, 972–980 (2006) 4. Ananthapadmanabha, T.V., Yegnanarayana, B.: Epoch extraction from linear prediction residual for identiﬁcation of closed glottis interval. IEEE Trans. Acoust. Speech Signal Proc. ASSP-27, 309–319 (1979) 5. Prasanna, S.R.M., Govind, D.: Analysis of excitation source information in emotional speech. In: Proceedings of the Interspeech, Makuhari, Chiba, pp. 781–784 (2010) 6. Naylor, P., Kounoudes, A., Gudnason, J., Brookes, M.: Estimation of glottal closure instants in voiced speech using the dypsa algorithm. IEEE Trans. Audio Speech Lang. Proc. 15(1), 34–43 (2007) 7. Drugman, T., Dutoit, T.: Glottal closure and opening instant detection from speech signals. In: Proceedings of Interspeech, 6–10 September 2009, pp. 2891–2894 (2009) 8. Yegnanarayana, B., Murthy, K.S.R.: Event-based instantaneous fundamental frequency estimation from speech signals. IEEE Trans. Audio Speech Lang. Proc. 17(4), 614–624 (2009) 9. Murthy, K.S.R., Yegnanarayana, B., Joseph, A.: Characterisation of glottal activity from speech signals. IEEE Signal Process. Lett. 16(6), 469–472 (2009) 10. Sturmel. N., d’Alessandro, C., Rigaud, F.: Glottal closure instant detection using lines of maximum amplitudes (LOMA) of the wavelet transform. In: Proceedings of ICASSP, pp. 4517–4520 (2009) 11. Cabral, J.P., Kane, J., Gobl, C., Carson-Berndsen, J.: Evaluation of glottal epoch detection algorithms on different voice types. In: Proceedings of the Interspeech, Florence, Italy, pp. 1989–1992 (2011) 12. Ramesh, K., Prasanna, S.R.M., Govind, D.: Detection of glottal opening instants using hilbert envelope. In: Proceedings of the Interspeech, Lyon, France, pp. 44–48 (2013) 13. Smits, R., Yegnanarayana, B.: Determination of instants of signiﬁcant excitation in speech using group delay function. IEEE Trans. Audio Speech Lang. Proc. 3, 325–333 (1995) 14. Koolagudi, S.G., Maity, S., Vuppala, A.K., Chakrabarti, S., Rao, K.S.: IITKGP-SESC: speech database for emotion analysis. In: Proceedings of IC3, Noida, pp. 485–492 (2009) 15. Akanksh, B., Vekkot, S., Tripathi, S.: Inter-conversion of emotions in speech using TDPSOLA. In: Proceedings of the Advances in Signal Processing and Intelligent Recognition Systems, SIRS 2015, pp. 367–378. Springer, Trivandrum (2015) 16. Govind, D., Joy, T.T.: Improving the flexibility of dynamic prosody modiﬁcation using instants of signiﬁcant excitation. Circ. Syst. Sig. Process. 35(7), 2518–2543 (2016). doi:10. 1007/s00034-015-0159-5 17. Govind, D., Prasanna, S.R.M.: Dynamic prosody modiﬁcation using zero frequency ﬁltered signal. Int. J. Speech Technol. 16(1), 41–54 (2013). doi:10.1007/s10772-012-9155-3  
   
  Analysis of Image Compression Approaches Using Wavelet Transform and Kohonen’s Network Mourad Rahali(&), Habiba Loukil, and Mohamed Salim Bouhlel Sciences and Technologies of Image and Telecommunications, High Institute of Biotechnology, University of Sfax, Sfax, Tunisia [email protected]  , [email protected]  , [email protected]   
   
  Abstract. Since digital images require a large space on the storage devices and the network bandwidth, many compression methods have been used to solve this problem. Actually, these methods have, more or less, good results in terms of compression ratio and the quality of the reconstructed images. There are two main types of compression: the lossless compression which is based on the scalar quantization and the lossy compression which rests on the vector quantization. Among the vector quantization algorithms, we can cite the Kohonen’s network. To improve the compression result, we add a pre-processing phase. This phase is performed on the image before applying the Kohonen’s network of compression. Such a phase is the wavelet transform. Indeed, this paper is meant to study and model an approach to image compression by using the wavelet transform and Kohonen’s network. The compression settings for the approach to the model are based on the quality metrics rwPSNR and MSSIM. Keywords: Image compression Learning algorithm  
   
   Kohonen’s networks  Wavelet transform   
   
  1 Introduction Digital images pose a problem of transmission time and storage volume. The compression techniques can reduce the space needed to represent a certain amount of information. The compression techniques are divided into two main categories. First, the lossy compression in which some of the information in the original image is lost. Second, the lossless compression exploits the information redundancy in the image to reduce its size. The lossy compression methods [1] are more likely to achieve higher compression ratio than those obtained by the lossless methods [2, 5]. The methods of image compression by neural networks [3] yield acceptable results. Yet, these methods have a limit on the compression ratio and the reconstructed image quality. To improve the reconstructed image quality, we combine the discrete wavelet transform (DWT) [11] and the quantization by Kohonen’s networks [4]. Thereafter, we use the Huffman coding to encode the quantized values [6, 14]. In this paper, we are interested in the study of an approach to image compression through the use of the wavelet transform and Kohonen’s network. We will, in particular, detail the learning © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_41  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  475  
   
  process of image compression and evaluate the compression result with a new quality metric rwPSNR “relative weighted PSNR”. To develop and improve the assessment, we will use another quality metric; namely, the MSSIM “Means Structural SIMilarity”. Next, we test the image compression by using the wavelet and Kohonen’s network together. Lastly, we make a comparison by using Kohonen’s network only without the wavelet transform and the second comparison between the proposed approach and various compression methods.  
   
  2 Proposed Approach 2.1  
   
  Image Compression  
   
  Image compression is carried out through the following steps: • Apply a wavelet transform [9, 22] to an original image depending on the decomposition level and the wavelet type. • Decompose the image into blocks according to a block size (for example 2  2, 4  4, 8  8 or 16  16). • Search the codebook for each block and the code word with a minimum distance from the block. The index of the selected word is added to the index vector that represents the compressed image. • Code the index vector by a Huffman coding [14]. • Save the index vectors coded for use during decompression. The Fig. 1 depicts the steps of compression.  
   
  Original Image  
   
  Wavelet transform  
   
  Kohonen  
   
  Huffman coding  
   
  Compressed Image  
   
  Fig. 1. Image compression steps  
   
  2.2  
   
  Learning Phase  
   
  In fact, learning [7, 8] is deemed to be a very important step to compress images by the neural network. The goal is to construct codebooks to be used during compression. The learning process is described in Fig. 2. The ﬁrst step of learning is the wavelet transform of an original image to obtain four sub-images: an approximation image and three detail-images (Fig. 4) in different resolutions depending on the decomposition level and the wavelet choice. The second step is to decompose the four sub-images in blocks according to the block sizes (2  2, 4  4, 8  8 or 16  16). The blocks are arranged in linear vectors to be presented in the Self-Organizing Map (SOM) [4, 16] one after the other. The third step is to adjust the weight-coupling according to an index vector. The weights obtained at the end of learning represent the codebook which will be used for compression. The codebook obtained depends on several settings such as the choice of the learning image, the type  
   
  476  
   
  M. Rahali et al.  
   
  of the wavelet transform, the decomposition level, the block size and the size of the self-organizing map. Therefore, we should create several codebooks to improve the compression.  
   
  Original image  
   
  Wavelet Transform  
   
  Decompose image  
   
  Codebook SOM  
   
  Fig. 2. Learning phase  
   
  2.3  
   
  Image Decompression  
   
  Image decompression is realized throughout these steps: • Replace each code by the corresponding index to obtain the index vector. This is the decoding step. • Find the three detail-images and the approximation image by replacing each element of the index vector by the corresponding block in the codebook. In order to improve the reconstructed image quality, in our approach, we keep the approximation image un-indexed by the self organization map. • The inverse transform is applied to the sub-images obtained after de-quantization to display the reconstructed image. The Fig. 3 described the decompression steps.  
   
  Compressed Image  
   
  Decoding  
   
  Dequantization  
   
  Inverse transform  
   
  Reconstructed Image  
   
  Fig. 3. Image decompression steps  
   
  The same codebook is used during both compression and decompression. 2.4  
   
  Kohonen’s Network Algorithm  
   
  Kohonen’s network algorithm [4, 10] follows these steps: • Find the winning neuron of the competition  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  dðX; wc Þ  dðX; wi Þ; 8i 6¼ c  
   
  477  
   
  ð1Þ  
   
  where, X is input vector, wc is weight vector of the winning neuron c and wi is weight vector of the neuron i. • Update weight wi wi ðt þ 1Þ ¼ wi ðtÞ þ hðc; i; tÞ  ½X  wi ðtÞ  
   
  ð2Þ  
   
  where, wi is the weight vector of the neuron i in instant t and h is a function deﬁned by:  hðc; i; tÞ ¼  
   
  aðtÞ; i 2 Nðc; tÞ with aðtÞ 2 ½0; 1 0; else if  
   
  ð3Þ  
   
  The function h deﬁned the extent of the correction to the winning neuron c and its neighborhood. In instant t, the neighbors of winning neuron c are determined by the function Nðc; tÞ. The ﬁnal neighbors of a neuron consist of the neuron itself. The function hðc; i; tÞ assigns the same correction aðtÞ for all neurons belonging to the neighbors of the winning neuron at instant t [18]. 2.5  
   
  Image Pretreatment Using Wavelet Transform  
   
  The two-dimension-wavelet transform [9, 10] is adopted in our approach. Figure 4 shows the image division into sub-images for the case of seven-band decomposition. The sub-image LL2 represents the lowest frequency of the original image. As a matter of fact, the restoration of the wavelet coefﬁcients in the sub-image LL2 will directly affect the image quality. The sub-images HH1, LH1, HL1, HH2, LH2, and HL2 contain detail information of the edge, the outline and the vein of the image at different decomposition layers. Concretely, the sub-image HL2 and the sub-image HL1 denote the image-coefﬁcient at the vertical edge after the ﬁrst and the second layers wavelet decomposition. The sub-image LH2 and the sub-image LH1 indicate the image coefﬁcients at the horizontal edge. The sub-image HH1 and the sub-image HH2 signify the image coefﬁcients on the cross edge. LL2  
   
  HL1 HL1  
   
  LH1  
   
  LH1  
   
  HH1  
   
  HH1  
   
  Fig. 4. Decomposition on the frequency by wavelet  
   
  478  
   
  M. Rahali et al.  
   
  3 Objective Assessments: The Quality Index To improve our method, we use tow quality metric: rwPSNR and MSSIM. 3.1  
   
  The Relative Weighted Peak Signal to Noise Ratio rwPSNR  
   
  The PSNR quantiﬁes an intensity of the distortion. It does not adjust to the dynamic characteristics of the image. Indeed, the deterioration is more visible in less textured zones (weak variance) and is less visible in more textured zones (stronger variance) [20]. Accordingly, we take the variance of the picture into consideration. Hence, it increases when the variance is high and decreases in the opposite case. We will have a new deﬁnition of the MSE. Let X = {xij | I = 1, …, M; j = 1, …, N}and Y = {yij | I = 1, …, M; j = 1, …, N} be the original image and the test image, respectively. The wMSE is given as:   2 1 X N 1   X xm;n  ym;n  1 M wMSE ¼ MN m¼0 n¼0 1 þ Var ðM; N Þ  
   
  ð4Þ  
   
  Where Var(M, N) is the test image variance. The human eyes do not have an equal sensitivity across the different intensities. In fact, there is a threshold of sensitivity that must be exceeded before an increase of the intensity so that it can be detected. So, as a complement to the wPSNR, we introduce our rwPSNR [12] “relative weighted PSNR” which takes account of the relative difference of the image-gray levels because the noticeable difference of the two stimuli is roughly proportional to the intensity of the stimulus. Actually, an error between two pixels of two images can not translate the same error deviation between two pixels of two other images with the same intensity difference. Indeed, if the intensity difference (10) between the pixels is 10 and 20, it remains numerically the same as that between a pair of pixel values 110 and 120. However, the perception differs on the visual plan. In the ﬁrst case, the error is quantiﬁed at 100% (20 to 10). But, in the second case, the error is quantiﬁable at 10% (120-110). Therefore, one has to think about the necessity of introducing the relative difference notion in the calculation of the wPSNR from which rwPSNR is derived. So, we have a new deﬁnition of the MSE noted as rwMSE “relative weighted Mean Square Error” which takes account of the variance and the image intensity. Our rwMSE is deﬁned as follows: Let X = {x | i = 1, …, M; j = 1, …, N} and Y = {y | i = 1, …, M; j = 1, …, N} respectively be the original image and the test image. The rwMSE is given as: 2 1 X N 1  X 1 M jðx  yÞ=ðx þ yÞj rwMSE ¼ 2 MN m¼0 n¼0 1 þ Var ðM; N Þ The expression of our relative weighted peak signal to noise ratio is given by:  2  xmax rwPSNR ¼ 10  log10 rwMSE  
   
  ð5Þ  
   
  ð6Þ  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  3.2  
   
  479  
   
  The Structural Similarity Means MSSIM  
   
  The new image quality measurement design is based on the assumption that the human visual system is highly adapted to extract the structural information of the visual ﬁeld. The measurement of the structural information change can provide a good approximation of the distortion of the perceived image. The error sensitivity approach estimates the perceived errors to quantify the image degradation [21]; whereas, the new philosophy considers the degradation of the image as the perceived changes in the structural information. The luminosity of the surface of the observed object is the product of illumination and reflection. But the structures of the objects in the scene are independent of illumination [23]. Therefore, to explore the structural information in an image, we have to eliminate the influence of illumination. Therefore, the structural information in an image is deﬁned as the attributes that represent the structures of the objects. Since luminosity and contrast may vary across the scene, we use luminosity and the local contrasts in our deﬁnition. The system breaks the task of similarity measurement into three comparisons: Luminosity Lðx; yÞ, Contrast Cðx; yÞ and Structure Sðx; yÞ. The combination of the three comparisons determines the structural similarity index (SSIM) [13]. SSIMðx; yÞ ¼  
   
  ð2lx ly þ C1 Þð2rxy þ C2 Þ þ l2y þ C1Þðr2x þ r2y þ C2 Þ  
   
  ðl2x  
   
  ð7Þ  
   
  When applying, only one total quality measurement of the whole image is required; whence, a means SSIM index (MSSIM) to assess the overall quality of the image is determined. MSSIMðX; YÞ ¼  
   
  M 1X SSIMðxi ; yi Þ M i¼1  
   
  ð8Þ  
   
  4 Subjective Assessments The objective assessment is insufﬁcient to assess the visual quality of the compression methods. The subjective assessment analyzes the degradation of visual quality of images. Also, the human eye can judge the compression quality to compare the result between compression methods [19]. In our work, we compare tow compression methods with and without wavelet transform. 4.1  
   
  Quantitative Assessments of Results  
   
  In our work, we change the compression parameters: the decomposition level (j) of the wavelet, the input block size (BS), the wavelet type (haar, Coiflets, Daubechies, Symlets, …) and the size of the self organizing map (SOM). To evaluate the performance of our approach in image compression, we use the following measures: bits per pixel (Nbpp), the means square error (MSE), the relative weighted peak signal to the noise ratio (rwPSNR) and the structural similarity means (MSSIM) and we compare our approach to image compression without using the wavelet transform (Tables 1 and 2).  
   
  480  
   
  M. Rahali et al. Table 1. With wavelet transform Image Lena  
   
  Nbpp rwPSNR MSE  
   
  4.60 4.17 3.02 1.94 0.59 0.34 Cameraman 4.71 3.90 2.79 2.32 1.82 1.29 0.57 Barbara 4.14 2.96 2.42 1.83 1.36 0.59 0.21  
   
  66.98 66.87 62.94 61.06 60.76 58.06 61.75 61.47 60.04 59.82 59.20 58.08 57.72 62.82 61.18 60.49 60.13 57.60 57.68 56.42  
   
  41.60 43.43 66.88 175.21 208.31 502.25 90.08 93.58 114.65 120.43 135.9 385.75 403.24 155.29 204.50 246.09 258.69 394.86 469.14 624.43  
   
  MSSIM Parameters 0.954 0.946 0.933 0.785 0.732 0.526 0.932 0.928 0.899 0.892 0.859 0.724 0.664 0.899 0.857 0.813 0.770 0.650 0.526 0.369  
   
  J J J J J J J J J J J J J J J J J J J J  
   
  = = = = = = = = = = = = = = = = = = = =  
   
  1; 1; 1; 2; 2; 3; 1; 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 3,  
   
  BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS  
   
  = = = = = = = = = = = = = = = = = = = =  
   
  4; SOM = 256 4; SOM = 64 16; SOM = 256 16; SOM = 256 256; SOM = 16 64; SOM = 16 4; SOM = 256 4, SOM = 64 16, SOM = 256 16, SOM = 64 16, SOM = 4 16, SOM = 64 256, SOM = 64 4, SOM = 64 16, SOM = 256 4, SOM = 4 256, SOM = 4 16, SOM = 64 64, SOM = 4 256, SOM = 4  
   
  Table 2. Without wavelet transform Image Lena  
   
  Nbpp rwPSNR MSE  
   
  3.92 2.54 1.91 1.66 0.82 0.31 Cameraman 3.72 2.23 2.01 1.39 0.75 0.42 0.39 Barbara 3.23 2.99 2.36 1.56 0.75 0.47 0.33  
   
  63.45 61.14 60.70 59.73 61.03 57.47 60.43 59.86 56.04 57.21 57.65 55.79 55.65 61.53 60.09 57.56 56.61 58.62 55.61 54.83  
   
  92.43 133.26 151.82 175.75 248.99 566.33 120.62 177.74 253.46 211.84 415.16 454.63 530.23 156.83 181.62 265.42 316.59 366.85 507.30 563.21  
   
  MSSIM Parameters 0.938 0.869 0.845 0.753 0.738 0.486 0.898 0.863 0.833 0.739 0.703 0.661 0.502 0.865 0.837 0.792 0.687 0.643 0.541 0.364  
   
  BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS BS  
   
  = = = = = = = = = = = = = = = = = = = =  
   
  4; SOM = 256 4; SOM = 64 16; SOM = 64 16; SOM = 16 64; SOM = 16 256; SOM = 16 4; SOM = 256 4; SOM = 64 16; SOM = 64 16; SOM = 16 64; SOM = 16 256; SOM = 64 256; SOM = 16 4; SOM = 256 4; SOM = 64 16; SOM = 64 16; SOM = 16 64; SOM = 16 256; SOM = 64 256; SOM = 16  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  481  
   
  Table 3 shows an objective assessment of the relative weighted peak signal to the noise ratio (rwPSNR) depending on the number of bits per pixel (Nbpp). The blue curve represents the rwPSNR of the compressed images using the discrete wavelet transform and Kohonen’s network. The green curve represents the rwPSNR of the compressed images using only Kohonen’s network without the wavelet transform. Thus, we see very well that the image quality calculated by our metric (rwPSNR) has been improved by the compression approach using the wavelet transform compared to the other approach without wavelet transform. Table 4 shows an objective assessment of the structural similarity means (MSSIM) depending on the number of bits per pixel (Nbpp). The blue curve represents the MSSIM of the compressed images using the discrete wavelet transform and Kohonen’s network. The green curve represents the MSSIM of the compressed images using only Kohonen’s network without the wavelet transform.  
   
  Table 3. Curves of rwPSNR = f(Nbpp)  
   
  Table 4. Curves of MSSIM = f(Nbpp)  
   
  482  
   
  4.2  
   
  M. Rahali et al.  
   
  Assessment of the Images Visual Quality  
   
  The Figs. 5, 6, 7, 8, 9 and 10 provide the assessment of the visual quality of three images (Lena, Cameraman and Barbara) which are compressed by our approach.  
   
  (a) MSE=41.60,  
   
  (b)MSE=175.21,  
   
  (c)MSE=502.25,  
   
  rwPSNR=66.98,  
   
  rwPSNR=61.06,  
   
  rwPSNR=58.06,  
   
  mssim = 0,954  
   
  mssim= 0,785  
   
  mssim= 0,526  
   
  Fig. 5. The visual quality With wavelet transform of Lena  
   
  (a’)MSE=92.43,  
   
  (b’)MSE=175.75,  
   
  (c’)MSE=566.33,  
   
  rwPSNR=63.45,  
   
  rwPSNR=59.73,  
   
  rwPSNR=57.47,  
   
  mssim= 0.938  
   
  mssim= 0.753  
   
  mssim= 0.486  
   
  Fig. 6. The visual quality without wavelet transform of Lena  
   
  (a)MSE=93.58,  
   
  (b)MSE=135.972,  
   
  (c)MSE=403.24,  
   
  rwPSNR=61.47,  
   
  rwPSNR=59.20,  
   
  rwPSNR=57.72,  
   
  mssim= 0,928  
   
  mssim= 0.859  
   
  mssim= 0,664  
   
  Fig. 7. The visual quality with wavelet transform of Cameraman  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  (a’)MSE=120.62,  
   
  (b’)MSE=211.84,  
   
  (c’)MSE=530.23,  
   
  rwPSNR=60.43,  
   
  rwPSNR=57.21,  
   
  rwPSNR=55.65,  
   
  mssim= 0.898  
   
  mssim= 0.739  
   
  mssim= 0.502  
   
  Fig. 8. The visual quality without wavelet transform of Cameraman  
   
  (a)MSE=246.09, rwPSNR=60.49, mssim=0,813  
   
  (b)MSE=258.69, rwPSNR=60.13, mssim=0,770  
   
  (c)MSE=469.14, rwPSNR=57.68, mssim=0,526  
   
  Fig. 9. The visual quality with wavelet transform of Barbara  
   
  (a’)MSE=265.42,  
   
  (b’)MSE=316.59,  
   
  rwPSNR= 57.56,  
   
  rwPSNR=56.61, mssim= 0.753  
   
  mssim= 0.792  
   
  (c’)MSE=507.3, rwPSNR=55.61, mssim= 0.541  
   
  Fig. 10. The visual quality without wavelet transform of Barbara  
   
  483  
   
  484  
   
  4.3  
   
  M. Rahali et al.  
   
  Comparison Between Our Approach and Various Methods  
   
  To evaluate our result, we use the standard image quality metrics for comparisons with other methods. The standard metrics is Peak Signal to Noise Ratio (PSNR) and Compression Ratio (CR). Tables 5 and 6 show the comparison between the proposed approach and various methods [10, 15, 17]. The methods were applied on standard images 256 * 256 (Lena and Cameraman): Neural Network one level, Neural Network two level [15], standard and modiﬁed Self-Organization Map SOM [10] and wavelet transform combined by Vector Quantization VQ [17]. Table 5. Comparison results for Lena image Methods Proposed method  
   
  Nbpp 1.39 1.8 Neural Network one level 2.32 Network neuron two levels 1.49 Modiﬁed SOM 1.84 Standard SOM 1.7 Wavelet transform and Vector Quantization 3.2  
   
  CR 82.59 78 71 81.3 77 79 60  
   
  PSNR 25.18 27.39 27.3 24.7 22.15 19.15 26.2  
   
  Table 6. Comparison results for Cameraman image Methods Nbpp Proposed method with wavelet transform 1.77 Modiﬁed SOM 2.32 Standard SOM 1.79  
   
  4.4  
   
  CR 77.8 71 77.6  
   
  PSNR 25.44 23.65 20.67  
   
  Simulation and Results  
   
  Our work is based on the comparison of different compression methods. The performance evaluation using various image quality metrics like PSNR, rwPSNR, MSE and MSSIM indicates that the best method is the wavelet transform and kohonen’s network. After comparing the two compression methods with and without wavelet transform, we can show the importance of using the wavelet transform in compression. In fact, the wavelet transform allows reducing the entropy of the image and separating its details to improve the quality of the reconstructed image according to the number of bits per pixel (Tables 3 and 4). The reconstructed image quality is acceptable; i.e. for rwPSNR it is more than 59 and for MSSIM it is between 0.7 and 1. The block effect is remarkable if the block size (BS) is higher than 256 and the degradation of the visual quality if the level of decomposition of the wavelet (J) is superior or equal to 2. For performance evaluation, the proposed method is compared with various methods [10, 15, 17]. The comparison is done using various measures such as PSNR, the number of bits per pixel Nbpp and compression ratio CR. From Tables 5 and 6, we can be deduced that the PSNR according of bits per pixel compression ratio of our  
   
  Analysis of Image Compression Approaches Using Wavelet Transform  
   
  485  
   
  method is better than of the some compression methods. From Table 5, the PSNR of our method is 25.18 and the CR is 82.59% but the PSNR of NNs with two levels [15] is 24.7 and CR is 81.3%. So, the PSNR and CR are better in proposed approach  
   
  5 Future Scope and Conclusion In this paper, we use an image compression approach based on the wavelet transform and the vector quantization by Kohonen’s network and the Huffman coding. We use two metrics to assess the reconstructed image quality: rwPSNR and MSSIM. We compare our method with other compression methods. The comparison is done using various standard measures such as PSNR and CR, it can be recognized that the PSNR according to CR of our method is better than some of the methods. To improve the reconstructed image quality and the compression ratio, we will add a phase of pre-treatment before the wavelet transform. We will use Weber-Fechner law and the A-law, which are used in the ﬁeld of telephony, to quantify an image through the semi-logarithmic method.  
   
  References 1. Koff, D., Shulman, H.: An overview of digital compression of medical images: can we use lossy image compression in radiology? Can. Assoc. Radiol. J. 57(4), 211–217 (2006) 2. Zhang, N., Wu, X.: Lossless compression of color mosaic images. IEEE Trans. Image Process. 15(6), 1379–1388 (2006) 3. Kotyk, T., Ashour, A.S., Chakraborty, S., Balas, V.E.: Apoptosis analysis in classiﬁcation paradigm: a neural network based approach. In: Healthy World Conference 2015 - A Healthy World for a Happy Life, At Kakinada (AP) India, September 2015 4. Kohonen, T.: The self-organizing map. Proc. IEEE 78(9), 1464–1480 (1990) 5. Mtimet, J., Benzarti, F., Amiri, H.: Lossless binary image coding using hybrid coding method. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2012, Sousse-Tunisia, 21–24 March 2012, pp. 448–452 (2012) 6. Pujar, J., Kadlaskar, L.: A new lossless method of image compression and decompression using Huffman coding techniques. J. Theor. Appl. Inf. Technol. 15(1/2), 18–23 (2010) 7. Ribés, J., Simon, B., Macq, B.: Combined Kohonen neural networks and discrete cosine transform method for iterated transformation theory. Signal Process.: Image Commun. 16(7), 643–656 (2001) 8. Hore, S., Bhattacharya, T., Dey, N., Hassanien, A.E., Banerjee, A., Chaudhuri, S.R.: A real time dactylology based feature extractrion for selective image encryption and artiﬁcial neural network. In: Image Feature Detectors and Descriptors. Studies in Computational Intelligence, vol. 630, pp. 203–226, February 2016 9. Raghuwanshi, P., Jain, A.: A review of image compression based on wavelet transform function and structure optimization technique. Int. J. Comput. Technol. Appl. 4, 527–532 (2013) 10. Boopathi, G.: An image compression approach using wavelet transform and modiﬁed self organizing map. Int. J. Comput. Appl. 28(2), 323–330 (2011)  
   
  486  
   
  M. Rahali et al.  
   
  11. Lewis, A.S., Knowles, G.: Image compression using the 2-D wavelet transform. IEEE Trans. Image Process. 1(2), 244–250 (1992) 12. Loukil, H., Kacem, M.H., Bouhlel, M.S.: A new image quality metric using system visual human characteristics. Int. J. Comput. Appl., 60(6) (2012) 13. Brooks, A.C., Zhao, X., Pappas, T.N.: Structural similarity quality metrics in a coding context: exploring the space of realistic distortions. IEEE Trans. Image Process. 17(8), 1261–1273 (2008) 14. Mathur, M.K., Loonker, S., Saxena, D.: Lossless Huffman coding technique for image compression and reconstruction using binary trees. Int. J. Comput. Technol. Appl. 3(1), 76–79 (2012) 15. Alshehri, S.A.: Neural network technique for image compression. IET Image Process., 1–5 (2015) 16. Zribi, M., Boujelbene, Y., Abdelkaﬁ, I., Feki, R.: The “self-organizing maps of Kohonen in the medical classiﬁcation”. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2012, Sousse-Tunisia, 21–24 March 2012, pp. 852–856 (2012) 17. Wang, H., Lu, L., Que, D., Luo, X.: Image compression based on wavelet transform and vector quantization. In: International Conference on Machine Learning and Cybernetics, Beijing, November 2002 18. Samanta, S., Ahmed, S.S., Salem, M.A., Chaudhuri, S.: Haralick features based automated glaucoma classiﬁcation using back propagation neural network. In: International Conference on Frontiers of Intelligent Computing: Theory and Applications (FICTA), At Bhubaneswar, vol. 327, pp. 351–358 (2014) 19. Sudhakar, R., Karthiga, M.R., Jayaraman, S.: Image compression using coding of wavelet coefﬁcients? A survey. ICGST-GVIP J. 5(6), 25–38 (2005) 20. Chaouch, D.E., Foitih, Z.A., Khelﬁ, M.F.: A sliding mode based control of 2DoF robot manipulator using neural network. In: 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2012, Sousse-Tunisia, 21–24 March 2012, pp. 906-911 (2012) 21. Mili, F., Hamdi, M.: Comparative study of expansion functions for evolutionary hybrid functional link artiﬁcial neural networks for data mining and classiﬁcation. Int. J. Hum. Mach. Interact. (IJHMI) 1(2), 44–56 (2014) 22. Dey, N., Mishra, G., Nandi, B., Pal, M., Das, A., Chaudhuri, S.: Wavelet based watermarked normal and abnormal heart sound identiﬁcation using spectrogram analysis. In: Computational Intelligence & Computing Research (ICCIC), pp. 1–7, December 2012 23. Espartinez, A.S.: Self-fulﬁllment and participation of the human person in and through actions. Int. J. Hum. Mach. Interact. (IJHMI) 2(2), 28–31 (2015)  
   
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra Vansha Kher, Garvita Khajuria, Purnendu Prabhat(&), Meena Kohli, and Vinod K. Madan Model Institute of Engineering and Technology, Jammu, India [email protected]  , [email protected]  , [email protected]  , {purnendu.cse,meena.ece}@mietjammu.in  
   
  Abstract. A nuclear spectrum is a Type II digital signal. It is processed to extract the qualitative and the quantitative information about the radioisotopes. Noise reduction is usually a step in processing a spectrum, and smoothing ﬁlters are employed for this. Perhaps the most widely used ﬁlters for the spectral ﬁlter-ing since the last 50 years have been Savitzky-Golay (S-G) ﬁlters. Incidentally S-G ﬁlters are not well known to the digital signal processing community. In this paper the authors have employed rather unknown high ﬁdelity Higham ﬁlters used by actuaries of the 19th century for ﬁltering real observed nuclear spectra, and compared their performance with that of an optimal S-G ﬁlter. It was observed that the performance of the Higham ﬁlters and S-G ﬁlters compared favorably amongst each other. This paper describes theory of S-G and Higham ﬁlters, their application to nuclear spectra, and presents the results. Higham ﬁlters have potential for more applications. There is a scope of exploring more treasure of the past, and merging tools from various disciplines, for more interdisciplinary research. Keywords: Nuclear spectral processing  Type I and Type II signals ﬁlters  Savitzky-Golay ﬁlters  Higham ﬁlters  
   
    
   
  FIR  
   
  1 Introduction A nuclear spectrum e.g. a gamma-ray spectrum is processed to extract the qualitative and the quantitative information about the radioisotopes emitting gamma photons. In a typical observed nuclear spectrum over 90% of the information is lost thus greatly reducing the information capacity of a nuclear spectrometer. Processing of a spectrum usually involves employing a smoothing ﬁlter to reduce noise. It is desired that the ﬁlter should retain spectroscopic information content of the spectrum while attenuating noise. It is sometimes assumed that smoothing is manipulation of data without clear theoretical justiﬁcation. Digital signal processing (DSP) gives a clear theoretical justiﬁcation of a smoothing operation. In the frequency domain the signal containing the desired information gets concentrated in the low-frequency region while distortions extend up to p rad. The separation of signal and distortions appears most clear in the frequency domain. In any other domain like sequency domain, the clarity of separation gets obscured. A smoothing ﬁlter is thus adequately justiﬁed [1–8]. © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_42  
   
  488  
   
  V. Kher et al.  
   
  Perhaps the most widely used smoothing ﬁlters for the nuclear spectra since the last 50 years have been due to Savitzky and Golay [8]. These are linear phase, noncausal, FIR smoothing ﬁlters, also known as polynomial smoothing ﬁlters, or least squares smoothing ﬁlters. They have been widely used but not well known to the digital signal processing (DSP) community, and “only one out of about 20 had heard of them” [9]. One of the authors (VKM) interacted with both communities, DSP experts as well as nuclear scientists, and had similar experience, and was comforted to read lecture notes of Prof. Schafer [9], a highly respected DSP expert. Earlier the author happened to contribute to a bandwidth matching smoothing criterion for the S-G ﬁlters [3]. To bridge the gap between the two communities, he had contributed to a new classiﬁcation of digital signals viz. Type I and Type II based on the fundamental problems of aliasing and quantization noise. The classiﬁcation has widened the role of DSP to many disciplines [1, 4, 5]. In the larger perspective DSP techniques to nuclear spectral processing have hardly been used, though the beneﬁts of DSP are widely accepted in diverse applications of science and technology. The least squares peak ﬁtting functions entirely dominate the literature of this ﬁeld, and these methods fall to a large extent within the category of “art-forms” rather than of “direct methods” [5]. Though DSP methods have not been widely used for the processing of nuclear spectra, they hold a good potential. Only a few researchers have reported the use of DSP techniques in this area. DSP methods for spectral processing, however, proved to be advantageous. They have enhanced the understanding of nuclear spectra while helping in the reﬁnement, extension, and consolidation of various algorithms. The methods have further helped in developing new algorithms especially suited to the spectra and are extremely simple, easy, and fast [1–3, 5, 6]. In the 19th century FIR ﬁlters were employed for actuarial data processing [10–12]. The authors have explored two linear phase, high ﬁdelity, FIR Higham ﬁlters from that era to ﬁlter real observed gamma spectra, and compared their performance with an optimal S-G ﬁlter for ﬁltering the same spectra. The performance of the three ﬁlters was found favourable with respect to each other. To the authors knowledge Higham ﬁlters have neither been used in electrical engineering nor in nuclear spectrometry. Besides nuclear spectrometry, the ﬁlters hold a potential for their application to infrared spectrometry, analytical chemistry, heart rate monitoring using an accelerometer, speech and image processing etc. and that needs to be explored. This paper describes Type I and Type II signals, smoothing ﬁlters viz. S-G and Higham, and their application to ﬁltering real observed nuclear spectra.  
   
  2 Type I and Type II Signals A digital signal can be represented as a mathematical function: yðxÞ ¼ A sin ð2p fx þ hÞ  
   
  ð1Þ  
   
  where both y(x) and its argument, x, are quantized. The quantity A is the amplitude, f is the frequency and h is the phase angle.  
   
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra  
   
  489  
   
  To widen the scope of DSP, a new classiﬁcation of digital signals was given by Madan and Sinha [4, 5]. It is based on the fundamental problems of aliasing and quantization noise. Aliasing is a phenomenon where higher-frequency components take on the identity of lower-frequency components because of low sampling rate. It is addressed along the abscissa. Quantization error is the difference between the actual value of the signal and its quantized value. The noise power associated with the quantization of signals is called quantization noise. Type I digital signals are those where the problems of aliasing and quantization noise are addressed along the abscissa and the ordinate respectively. In Type II digital signals both the problems are addressed along the abscissa. DSP methods, widely used for processing Type I signals, are generally not used for processing Type II signals. The methods have, however, numerous advantages for processing Type II signals, e.g. nuclear spectra and age returns [4, 5]. The classiﬁcation of signals arises because of the acquisition process of signals. While acquiring a DSP signals, both Type I and Type II, one has to ensure that aliasing should not be there, and quantization noise should be below a threshold. Once signals have been acquired, DSP techniques like ﬁltering, deconvolution, Fourier domain processing etc. can be employed to process the signals. It may be mentioned that DSP techniques have demonstrated advantages, both theoretically and in implementation, for processing Type II signals like nuclear spectra and age returns. These methods, however, have hardly been employed. Figure 1 describes generation of a Type I digital signal like a speech signal, while Fig. 2 describes generation of a Type II digital signal like a nuclear spectrum. Figure 1 is well known to electrical engineers while Fig. 2 is not well known to the engineers.  
   
  analog signal in time domain  
   
  sampled – quantized signal Type I signal  
   
  sampled signal  
   
  x  
   
  ZOH  
   
  ADC  
   
  reconstructed signal in time domain DSP sampling pulses ZOH  
   
  Fig. 1. Acquisition and processing of a Type I signal  
   
  The Fig. 2 is described in more detail. Sampling instant is considered as the time when a given pulse arising out of nuclear radiation is detected, and immediately after the process of sampling, the pulse is quantized. Since the output of the nuclear analog to digital converter (NADC) will continue to be a time domain signal, as a matter of  
   
  490  
   
  V. Kher et al.  
   
  fact it is deliberately rotated 90° as the amplitude of each quantized pulse (or code, or energy channel in nuclear parlance) is quantiﬁed as the abscissa of histogram where all the pulses having assigned a particular code (or amplitude or energy) are counted in the same channel. It may be mentioned that a NADC has more stringent speciﬁcation compared to those of commercial available ADC chips from manufacturers [1, 2]. preamplifier output in time domain histogram in the energy domain (Type II signal)  
   
  original spectrum  
   
  shaper output  
   
  ZOH  
   
  COUNTER  
   
  DSP  
   
  energy quantizer  
   
  DSP filtered spectrum ZOH  
   
  NADC 90° rotation: energy goes on the horizontal axis (time information lost)  
   
  Fig. 2. Acquisition and processing of a Type II signal  
   
  Let’s go through the signal theory for the two different situations. Figure 1 depicts electrical waveform in a common digital signal processing chain. Assume x(t) as the input waveform which is sampled at uniform intervals of time T. It is assumed that T is a constant irrespective of the variations in an analog signal, and due to jitter, which is assumed to be insigniﬁcant. The sampled signal xs(t) is given as: xs ð t Þ ¼  
   
  þ1 X  
   
  xðnT Þdðt  nT Þ  
   
  ð2Þ  
   
  n¼1  
   
  where, dðt  nT Þ is a unit impulse at time instant t = nT. In Fig. 1 quantization is done by a commercial ADC. In Fig. 2 it is done by a NADC, and the digital signals are condensed into a histogram thus generating a nuclear spectrum. The histogram is generated by employing the reconstruction ﬁlter. It is a zero order hold (ZOH) ﬁlter. It helps in maintaining the same level of the signal in a spectral channel.  
   
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra  
   
  491  
   
  ZOH is a low pass ﬁlter with a transfer function GT(s) which is given by: GT ðsÞ ¼  
   
   1 1  esT s  
   
  ð3Þ  
   
  In Fig. 2, the second ﬁlter in the box DSP is a smoothing ﬁlter.  
   
  3 Gamma-Ray Spectrometer Figure 3 describes block diagram of a typical gamma-ray spectrometer. A gamma ray source emits gamma rays and they are detected by a HPGe detector. The charge collected by the detector, and then processed by the preampliﬁer produces sharp rising and pulses which decay with a large time constant. The pulses are shaped into Gaussian like pulses by the spectroscopy ampliﬁer and they are condensed into histogram by a multichannel analyser (MCA) thus generating a nuclear spectrum. The spectrum is ﬁltered and then further processing like background removal, deconvolution etc. is carried out to eventually extract the information about the radioisotoes emitting the nuclear radiation [1, 2].  
   
  HPGe Detector  
   
  Spectroscopy  
   
  Preamplifier  
   
  MCA  
   
  Spectral Processing  
   
  Amplifier  
   
  (including smoothing)  
   
  Source Detector Bias  
   
  Oscilloscope  
   
  Supply  
   
  Fig. 3. Block diagram of a gamma-ray spectrometer  
   
  4 Savitzky-Golay and Higham FIR Smoothing Filters In this section S-G and two Higham FIR ﬁlters are described. Both ﬁlters are noncausal, linear phase (symmetric) ﬁlters. S-G ﬁlters have been widely used and are easily found in the open literature albeit not in most DSP textbooks. Most DSP experts have not even heard of S-G ﬁlters [9]. As far Higham FIR ﬁlters, the authors have neither seen their application in electrical engineering nor in nuclear ﬁeld. Described below is the theory of S-G and Higham ﬁlters. 4.1  
   
  Savitzky-Golay Filters  
   
  The S-G FIR smoothing ﬁlters, are also known as polynomial smoothing, or least-squares smoothing ﬁlters. It is a happy coincidence that the least squares polynomial ﬁtting turns out to be FIR symmetric smoothing ﬁlters. S-G ﬁlters preserve high-frequency content representing peaks in a nuclear spectrum while attenuating noise.  
   
  492  
   
  V. Kher et al.  
   
  Savitzky and Golay put a polynomial to a set of input samples and then at the single point, evaluated the resulting polynomial with least squares ﬁtting [8, 9]. Mathematically it proved to be a discrete convolution having ﬁxed symmetric ﬁnite impulse response. The smoothing ﬁlter obtained by the least squares method helps in reduction of noise while preserving the shape and height of the nuclear spectral peaks. Consider for the moment the group of (2M + 1) samples of the signal x[n] centered at n = 0, we obtain the coefﬁcients, ak , of a polynomial, pðnÞ, that minimizes pðnÞ ¼  
   
  XN k¼0  
   
  ak nk  
   
  ð4Þ  
   
  the mean-squared approximation error eN for the group of input samples centered on n = 0. eN ¼ ¼  
   
  XþM  
   
  ð pð nÞ  x ½ n Þ 2 !2 N X k ak n  x ½ n  
   
  n¼M þM X n¼M  
   
  ð5Þ  
   
  K¼0  
   
  The analysis is the same for any other group of (2M + 1) input samples. We will refer to M as the “half width” of the approximation interval. In S-G ﬁlter, the ﬁtted polynomial to the sampled signal is similar to a ﬁxed linear combination of the local set of input samples; the set of (2M + 1) input samples which are within the approximation interval are combined by a ﬁxed set of weighting coefﬁcients that can be calculated once for a given polynomial of order N, and remains same for another approximation interval of length 2M + 1. The polynomial coefﬁcients, ak , represent impulse response h[n] of the FIR ﬁlter. Thus the output samples can be obtained by a discrete convolution method of the form: y ½ n ¼  
   
  þM X  
   
  h½mx½n  m  
   
  m¼M  
   
  ¼  
   
  nX þM  
   
  ð6Þ h½n  mx½m  
   
  m¼nM  
   
  4.2  
   
  Higham Filters  
   
  Higham proposed ﬁlters that have high ﬁdelity and are simple to implement. We briefly describe here Higham ﬁlters using the notation used by the then actuaries. Let n point boxcar average be represented as: 1 yi ¼ ½nxi n  
   
  ð7Þ  
   
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra  
   
  493  
   
  where xi is the input signal and yi is the output signal. The operator [n] is deﬁned as: ½nxi ¼ xim þ xim þ 1 þ . . . þ xi þ m1 þ xi þ m  
   
  ð8Þ  
   
  Higham ﬁlters are depicted in Fig. 4. It has input signal xi and the output signal as yi. In operator form, it can be represented as: AT ¼ faA1 bA2 g  
   
  ð9Þ  
   
  where A1 and A2 are both summation ﬁlters, and a and b are scalars. Higham designed a number of ﬁlters including the following two. The authors could not ﬁnd the detailed derivations of the Higham ﬁlters in the literature they had access to. The derivations were derived by the authors by hand using the Eqs. 10 and 11, and let these ﬁlters be called as Higham Filter 1 and Higham Filter 2 respectively. Both the ﬁlters resulted in 17 points smoothing ﬁlters [10–15]. 1 ½2½53 ½4½2  3½54 xi 125   64 4 4 2 ½5  ½5 ½9 xi yi ¼ 10000 300  
   
  ð10Þ  
   
  yi¼  
   
  A1  
   
  ð11Þ  
   
  a +  
   
  xi  
   
  yi A2  
   
  b  
   
  -  
   
  Fig. 4. Representation of a Higham ﬁlter  
   
  5 Experimental Results The real observed gamma-ray spectra were used in this paper. The spectra were taken from two earlier publications by one of the authors [3, 7]. These two spectral data sets were acquired using two different nuclear spectrometers. S-G, Higham Filter 1, and Higham Filter 2 ﬁlters were employed to ﬁlter the spectra. An optimal smoothing interval of 17 was chosen for all the smoothing ﬁlters [3]. It may be mentioned that in the earlier two publications [3, 7] employed only S-G ﬁlters to the spectra. The effect of smoothing on the spectra was investigated by employing all the three ﬁlters. The investigation included visual inspection, observing monotonicity in spectral peaks viz. it should be monotonically increasing before and monotonically decreasing after the peak position, change in full width at half maximum (FWHM), change in percentage peak areas using difference between sum of counts in the peak region of raw and smoothed spectra, and sum of the squared values of difference between the raw and  
   
  494  
   
  V. Kher et al.  
   
  smoothed spectral counts in the peak region, and it is called error squared values. The percentage change in peak area used the following formula: Percentage Change in Peak Area ¼ 100  
   
  Raw spectral area  smoothed spectral area raw spectral area  
   
  Fig. 5. Raw and smoothed spectra, shifted vertically arbitrarily, using Higham Filter 1 and S-G ﬁlter  
   
  Figure 5 depicts the raw, and the smoothed spectra obtained by employing the Higham Filter 1, and the S-G ﬁlter to one set of data, while Fig. 6 depicts the raw, and the smoothed spectra obtained by employing the Higham Filter 2, and the S-G ﬁlter to the other set of data. The visual inspection of the smoothed spectra employing Higham Filter 1, Higham Filter 2, and S-G on both the observed spectra indicated that smoothing effects were pronounced. The spectra were shifted vertically arbitrarily to get clarity of display in the ﬁgures. The channel number and counts in the ﬁgures correspond to energy and intensity respectively of nuclear radiation. From the printout of the ﬁltered spectral data it was observed that the monotonicity as mentioned above was met in all the smoothed spectra. The changes in FWHM for all the smoothed spectral peaks were found by plotting the raw, and the smoothed spectra. It was observed that the change in FWHM was on the order of 0.1 channels for all the smoothed spectra. It is negligible. This indicates all the ﬁlters preserved high-frequency content representing peaks in a nuclear spectrum while attenuating noise. The Tables 1 and 2 depict sum of error squared values, and percentage change in peak areas respectively between the raw and the smoothed spectra. From the Table 1, it is observed that the sum of the error squared values for Higham ﬁlters were little better those for the S-G ﬁlters. It is observed from the Table 2 that the percentage change in peak areas by employing Higham and S-G ﬁlters were within 0.02% and hence negligible.  
   
  Application of Higham and Savitzky-Golay Filters to Nuclear Spectra  
   
  495  
   
  Fig. 6. Raw and smoothed spectra, shifted vertically arbitrarily, using Higham Filter 2 and S-G ﬁlter Table 1. Sum of error squared values Filter type Spectrum 1 Spectrum 2 Higham Filter 1 9474 39531 Higham Filter 2 9286 38639 S-G ﬁlter 11588 49805 Table 2. Percentage change in peak areas Filter type Spectrum 1 Higham Filter 1 −0.0158% Higham Filter 2 −0.0191% S-G ﬁlter −0.0126%  
   
  Spectrum 2 −0.0093% −0.0119% −0.0177%  
   
  However the relative error squared values depicted in Table 1, and the relative changes in percentage peak areas depicted in Table 2 can be considered as within the experimental limits. Hence from the above performance metrics it is concluded that the smoothing performance of all the three ﬁlters was favorable with respect to each other. Higham ﬁlters have potential for their application to many areas and that should be explored.  
   
  6 Conclusion For nuclear spectral ﬁltering, perhaps the most widely used ﬁlters since the last 50 years have been S-G ﬁlters. However the ﬁlters are not well known to the DSP community, and “only one out of about 20 had heard of them” [7]. The authors have employed rather unknown Higham ﬁlters from the 19th century for ﬁltering of real observed nuclear spectra. To the authors knowledge these ﬁlters  
   
  496  
   
  V. Kher et al.  
   
  have neither been employed in electrical engineering nor for nuclear applications. The performance of the Higham ﬁlters and S-G ﬁlter compared favorably with respect to each other. This paper demonstrated an interdisciplinary approach to nuclear spectral ﬁltering. It has merged modern and 19th century tools from disciplines with encouraging application to nuclear spectrometry. Higham ﬁlters have potential for their application to infrared spectrometry, analytical chemistry, heart rate monitoring using an accelerometer, speech and image processing etc. and that needs to be explored. There is a scope of exploring more treasure of the past, and there is a need, perhaps more than ever, for merging of tools from various disciplines for the interdisciplinary research to be effective and fruitful. Acknowledgments. The authors would like to thank Director, MIET Prof. Ankur Gupta for his encouragement. This paper is respectfully dedicated to Prof. S.C. Dutta Roy.  
   
  References 1. Madan, V., Balas, M., Staderini, E.: Novel original digital signal processing techniques of nuclear spectra: a review. In: Kulczycki, P., Szafran, B. (eds.) Information Technology and Computational Physics (2016, designated for inclusion). Special Issue 2. Madan, V., Balas, M.: Nuclear spectrometry. Presented at the Congress of Information Technology, Computational and Experimental Physics (CITCEP 2015), Kraków, Poland, 18–20 December 2015, pp 194–198 (2015) 3. Kekre, H.B., Madan, V.K., Bairi, B.R.: A fourier transform method for the selection of a smoothing interval. Nucl. Instr. Meth. A279, 596–598 (1989) 4. Madan, V.K., Sinha, R.K.: Digital smoothing of census data employing fourier transforms. Comput. Stat. Data Anal. 20, 285–294 (1995) 5. Kekre, H.B., Madan, V.K.: Frequency domain and sequency domain ﬁltering of nuclear spectral data. Nucl. Instr. Meth. A245, 542–546 (1986) 6. Madan, V.K., Abani, M.C., Bairi, B.R.: A digital processing method for analysis of complex gamma spectra. Nucl. Instr. Meth. A343, 616–622 (1994) 7. Madan, V.K., Sachdev, M.S.: A simpler method to reduce noise in uranium gamma spectra. Presented at the International Conference Radiation Safety in Uranium Mining, Saskatoon, Sask., Canada, 25–28 May (1992) 8. Savitzky, A., Golay, M.: Smoothing and differentiation of data by simpliﬁed least squares procedures. Anal. Chem. 36, 1627–1639 (1964) 9. Schafer, R.W.: What is a Savitzky Golay ﬁlter? IEEE Sig. Process. Mag. 28(34), 111–117 (2011) 10. Higham, J.A.: On the adjustment of mortality tables. J. Inst. Actuar. 23, 335–352 (1882) 11. Higham, J.A.: On the adjustment of mortality tables. J. Inst. Actuar. 24, 44–51 (1883) 12. Higham, J.A.: On the graduation of mortality tables. J. Inst. Actuar. 25, 15–24 (1884) 13. Finlaison, J.: Report on the Law of Mortality of the Government Life Annuitants. The House of Commons, London (1829) 14. Wilkinson, R.H.: Early history of the high-ﬁdelity ﬁnite-impulse-response ﬁlter. In: IEE Proceedings, vol. 133, pt. G, no. 5, October 1986 15. Madan, V.K.: Digital signal processing: from antiquity to emerging paradigms with emphasis on nuclear spectrometry. ASET Colloquium, Tata Institute of Fundamental Research, Mumbai, 4 October 2013. http://www.tifr.res.in/*aset/  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes Based on the Human Visual System Nessrine Elloumi(&), Habiba Loukil Hadj Kacem, and Med Salim Bouhlel Research Unit: Sciences and Technologies of Image and Telecommunications, Higher Institute of Biotechnology, University of Sfax, Sfax, Tunisia [email protected]  , [email protected]  , [email protected]   
   
  Abstract. The representation of content as a 3D mesh is a very emerging technology. These three-dimensional meshes can be a scan of objects, characters or 3D scenes. Mesh quality is a determining factor in treatment of effectiveness, accuracy of results and rendering quality. You can show users these 3D meshes with a texture on the 3D mesh surface. The estimated quality by an observer is a very complex task related to the complexity of the Human Visual System (HVS). In this paper we present the efﬁciency of perceptual quality metrics 3D meshes based on the human visual system. Keywords: Perceptual quality  
   
   3D metric  3D meshes  HVS  
   
  1 Introduction For several years, researchers in image [1] processing and computer graphics have worked on the deﬁnition of an effective objective metric, able to predict the perceived quality of images, videos and 3D scenes [2]. To design such a system, it was necessary to study and determine the structures of visual content. This task is more complex when we look at 3D content represented in the form of triangular meshes. These 3D meshes are generally discrete packets of a non- uniform way to represent objects and scenes. Also, many operation can be performed on this 3D meshes [3], for example If we want to protect the 3D content we can use watermarking mesh algorithms for security purposes. It is also possible to apply a compression scheme to transmit on a low bandwidth network [4, 5] to reduce the size of 3D meshes [6]. Other operations on 3D meshes can be used, among which we mention: the quantiﬁcation, enameling or deformation. These algorithms usually introduce inevitable distortion on the geometry sufaces mesh. It is therefore important to measure and evaluate the effect of these distortions that affect the quality triangular meshes.  
   
  2 The Perceptual Quality 3D Meshes The study of perceptual quality is an important task since most visual data are for a ﬁnal human observer. Measuring the perceptual quality can be carried out using measurements made by observers (subjective measures) or measurements from © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_43  
   
  498  
   
  N. Elloumi et al.  
   
  algorithmic processes (objective measures). For each observer, quality can have a different deﬁnition of personal criteria. The main objective of measuring the perceptual quality is to analyze the behavior of the HVS [7] and quantify the quality as perceived by observers [8]. Human Vision System is based on two mechanisms: low-level mechanisms that affect the biophysical structure of the sensory system and high-level mechanisms related to human cognitive system.  
   
  3 Objective Measures of Quality Meshes The estimate of the perceptual quality is an important element in assessing the meshes quality after treatments. The objective of the perceptual quality metrics is to judge the quality of a mesh based on human perception characteristics [9]. To do this, there are different approaches the top-down approach considers the HVS as a black box and tries to imitate the behavior of the system from the perspective of inputs/outputs and the bottom-up approach based on simulation and imitation of each component of HVS. To develop a 3D metrics [10], researchers can use two alternatives: either they use existing metrics of perceptual quality 2D images [11–13] on two-dimensional projections of 3D meshes (metric-based images and videos) or they use develop metrics based-models that exploit the term mesh geometry and connectivity signal to evaluate the quality [14]. To estimate the quality of 3D meshes, other classiﬁcation of the quality metrics is possible. * Metrics “Full – Reference”: The original model is available in full, in which case we will try to quantify the existing difference between the original image and the degraded version. * Metrics to “Reduced Reference”: The original image is available in its entirety, but is represented by a vector containing a reduced set of attributes. In this case, an attempt to quantify the difference existing between the vectors associated to the original image and the vector resulting from a distorted version. * Metrics “No – Reference”: The original image is not available. In this case, it is possible to work with a priori on the degradation types that may be encountered, or, conversely, by making no assumption about possible distortions. Many of these metrics exploit the proprieties of the human visual system. To compare two 2D images or 3D meshes, it is common to use the signal to noise ratio measurements or geometric distances. These geometrical measurements do not include the properties of human vision system. From the literature it is approved that the metric based on the HVS are more appropriate than others [15].  
   
  4 The Human Visual System The human visual system is a complex sensory system and not yet fully mastered. Nevertheless, it may be considered an information transcription system turned into usable data by the brain (Fig. 1). A conversion step can capture the received information and decoded into signals by the brain.  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes  
   
  499  
   
  Fig. 1. Human visual system: simpliﬁed  
   
  It is the role of the eye that converts light energy into sensory signals and then transmits them to the visual cortex via the optic nerves and geniculate nucleus. The visual cortex decrypts and processes the information. To better understand the flow of information and operation of the HVS, we recall the essential elements that are involved in the process of gathering and processing of visual information (Capture, conversion, transmission and processing of information). 4.1  
   
  Sensor  
   
  – The eye: Which an optical system whose primary role is to converge the light signals to the conversion zone and transmit the decoded form in the brain. It comprises several important elements including: – The cornea: is a convex spherical surface which separated the eye from the external environment. Its primary role is to focus the light rays received to the retina. – Iris: Adapts the light intensity by varying its opening. So acts as an optical diaphragm. – The crystalline: Allows to redirect the light flow to the retina where it’s arranged into photoreceptor cells (Cones and rods). It plays the role of variable focus lens. 4.2  
   
  Conversion  
   
  – The retina: It converts the light signal captured by the receiving photocells into electrical signals which are then transmitted to the visual cortex via the optic nerve. – The retina: is composed essentially of two types of receptors. – Cones: Which are responsive to detail. – Rods: Which are sensitive to low luminance (blurred vision and course) and intervene rather at night vision (monochrome). 4.3  
   
  Transmission  
   
  – The optic nerve: it transports information from the retina to the visual cortex, through the chiasm and lateral geniculation body.  
   
  500  
   
  N. Elloumi et al.  
   
  – The chiasm: the direction Information goes through from the right eye and the left eye, chiasm’s role is to transmit the information received to the lateral geniculation body. 4.4  
   
  Analysis and Decryption  
   
  – The visual cortex: His major role is the decrypting (or decoding) and the analyzing of the received signals.  
   
  5 The Human Visual System and the Perception of Visual Quality Most of the existing metrics follow the approach Top – Down to study the human visual system and imitate its behavior. The existing metrics has for objective to maximize the correlation of the results (proﬁts) of prediction with the subjective scores. The subjective evaluation of the meshing quality is established by means of observers through psychometric experiments. Many databases were developed to have measures of the real structure of the 3D meshes perceptual quality. There are two important properties of the HVS that we have to consider in order to measure the perceptual quality of the 3D meshing [16]. 5.1  
   
  Contrast Sensitivity Function  
   
  The function of spatial contrast sensitivity (notes CSF) models the sensitivity of the human visual system to spatial frequencies of the visual stimulus. The ﬁrst Research Campbell - Robson on CSF have shown that Works with the HVS selectivity on spatial frequencies, sensitivity achieved its Maximum Value around four cycles per degree of visual angle [17]. Figure 2(a) shows that the pixel intensity is modulated by a horizontal sine function. When the spatial frequency of the pixel increases in a logarithmical way (on the horizontal axis), the contrast increases from top to bottom. Although the change contrast is the same for all frequencies, we observe that the bars appear to be highest in the middle of the image following the shape of the sensitivity function in Fig. 2(b). This effect is not made by the image, it’s rather made by the property of frequency selectivity of the human vision system. In the context of dynamic visual content (2D videos, dynamic meshes, etc.), the CSF must be modulated by stimuli speed. This is due to the variability of the contrast sensitivity depending on the speed of the stimulus movement. Since 1977, Kelly has presented an experimental study for modulating the function of contrast sensitivity affected by the test conditions (see Fig. 3(a)). In 1998, Daly has developed a dynamic model of CSF through a time function of CSF tends to move to lower frequencies. These studies were performed for achromatic data. Other studies have integrated color effect on the CSF: The contrast sensitivity (Fig. 3(b)). With increasing speed, the CSF  
   
  501  
   
  Contrast  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes  
   
  Fréquency SpaƟal  
   
  (a)  
   
  (b) Fig. 2. The spectral properties of the HVS: (A) - graph illustrating Campbell- Robson contrast sensitivity (CSF), (b) - curve of HVS sensitivity as a function of spatial frequency.  
   
  curve tends to shift towards low frequencies. These studies were realized to achromatic data [18]. 5.2  
   
  The Masking Effect  
   
  Masking is the effect of modiﬁcation of the component bordures visibility in a multimedia content (masked signal) by the presence of another component (masking signal). The magnitude of this effect is measured by the change of the masked signal visibility with or without the presence of the masking signal [19]. Masking may intervene in the same frequency band (in-band masking) or between different frequency bands (inter-band masking). This type of mask in literature, called the entropy masking effect [20]. There is another type of contrast masking named masking contrast connected to the  
   
  502  
   
  N. Elloumi et al.  
   
  Fig. 3. Kelly Illustration (a) - for the presentation of the combination of the effect of spatial and temporal frequency on contrast sensitivity, and (b) - the CSF illustration depending on the speed. The time function of CSF in (b) is calculated from an empirical equation. The speeds V are measured in degree/second.  
   
  change of the surface visibility as a function of the contrast values. The spatial masking effect is often linked to the concept of surface roughness for 3D meshes [21]. 5.3  
   
  The Perceptual Quality 3D Mesh  
   
  To measure the distance between two 3D meshes [22] many 3D metrics exist. We represent in the following sheet, the perceptual metrics developed for 3D meshes [23]. 5.3.1 The 3D Watermarking Perception Metric Corsini et al. have developed a new metric of quality [24]. Their approach, called 3DWPM (3D Watermarking Perception Metric), is based on the calculation of the perceptual distance between two meshes resting on surface roughness. This measured 3DWPM distance between two meshes M1 and M2 are identiﬁed by:  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes  
   
  3DWPMðM1; M2Þ ¼ logð  
   
  qðM2  qðM1Þ þ KÞ  logðkÞ qðM1Þ  
   
  503  
   
  ð1Þ  
   
  where qðM1 Þ and qðM2 Þ measure the overall roughness of the two meshes and k is a constant varied digital. Two variants of 3DWPM were developed using descriptors of roughness differences. The ﬁrst descriptor of roughness is used to 3DWPM1, is inspired by that of Lavoué [25]. The roughness measurement is calculated through measuring the dihedral angles between the normal facets in vicinity. The normal facet of a smooth surface does not vary greatly. In contrast, on textured regions (rough) these normal vary more signiﬁcantly. A Multi - scale analysis of these entities is considered [26] to evaluate dihedral angles using the direct vicinity (1 ring) and the extended vicinity (1 ring, 2 rings, etc.). The second roughness measurement adopted by Corsini et al. is 3DWPM2, it is based on estimating of the roughness of surfaces by Wang et al. [27]. Their approach is based on the comparison of a mesh and smoothed versions of the same mesh. Smooth regions correspond to small differences while the rough areas have more signiﬁcant differences. 5.3.2 The Mesh Structural Distortion Measure Metric The MSDM (Mesh Structural Distortion Measure) uses the amplitude of the average curvature of the 3D mesh surface to quantify the perceptual distortion. This metric has been improved recently under the name MSDM2 by integrating multi-scale analyses [25]. In 2006, Lavoué et al. have introduced a structured distortion measurement called Structural Mesh Distortion Measure (MSDM) [28]. This quality measure was inspired by the quality measurement of 2D pictures SSIM (Structural SIMilarity index) introduced by Corsini et al. [24]. The MSDM is based on the statistical difference of the average amplitude curves to measure the perceptual difference of two meshes. The average curvatures (CMsi) are calculated for each as the average of the minimum and maximum curvatures: CMsi ¼  
   
  ðCMsi Þ ¼ jCmin; sij þ jCmax; sij 2  
   
  ð2Þ  
   
  The amplitude of minimum and maximum curvatures (jCmin; sij and jCmax; sij) are deducted from the fair values of the curvature tensor. The approximation of the curvature tensor used, is that introduced by Cohen-Steiner et al. on spatial vicinity deﬁned by the geodesic disc resulting from the projection of a sphere of radius h on the surface of mesh. The average and standard deviation of the average curvature in a spatial window w containing n peaks, denoted respectively lw and rw are deﬁned as: 1X CMsi; si2w n rﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 1X rw ¼ ðCMsi  lw Þ2 ; si2w n lw ¼  
   
  ð3Þ ð4Þ  
   
  504  
   
  N. Elloumi et al.  
   
  The covariance between the curvatures of two window s w1 and w2 of the compared meshes M1 and M2 is deﬁned as: r w1 w 2 ¼  
   
  rww11 w2 þ rww21 w2 2  
   
  ð5Þ  
   
  1 where rw w1 w2 deﬁnes the covariance calculated on the window w1:  
   
  rww11 w2 ¼  
   
       1X w1 w2  l CM  l CM w w S S2i 1 2 1i S1i 2w1 n  
   
  ð6Þ  
   
  where S2i is the nearest summit to S1i on S1i the covariance rw2 w1w2 on the window w2 is calculated in the same way. To calculate the overall distance between two meshes, MSDM based on local distances, we note MSDML: 1  
   
  MSDML ¼ ða  LðsÞa þ b  CðsÞa þ c  M ðsÞa Þa  
   
  ð7Þ  
   
  With a, b, c and a are scalars for combining different quantities. The parameters L, C, M represent respectively the differences bends, contrasts and structures measured by: LðsÞ ¼  
   
  jjlw1  lw2 jj MAX ðlw1 ; lw2 Þ jjrw1  rw2 jj MAXðrw1 ; rw2 Þ  
   
  ð9Þ  
   
  jjrw1 rw2  rw1 rw2 jj rw1 rw2  
   
  ð10Þ  
   
  Cðw1; w2Þ ¼ M ðw1; w2Þ ¼  
   
  ð8Þ  
   
  where w represents the number of local windows on mesh surfaces to compare, and a parameter that has the same value as in the Eq. 7. An improved version of MSDM named MSDM2 was proposed in 2011 by integrating a multi-scale analysis [29]. MSDM2 also compares two meshes that do not share the same connectivity through a matching step through the structure data AABB tree implemented in the CGAL [30]. We note that to establish a measure of perceptual symmetrical distance, MSDM2 calculates the average of the two distances unidirectional (respectively M1 to M2 and M2 to M1 ). MSDM and MSDM2 are based only on statistics of the curvatures magnitudes. 5.3.3 The Fast Mesh Perceptual Distance Metric In 2012, a new metric for estimating the perceptual quality was introduced par Corsini et al. [31]. It is entitled Fast Mesh Perceptual Distance (FMPD). The type of this metric is reduced-reference, it is based on the comparison of overall roughness measurements calculated on the two grids to compare. The roughness descriptor retained in FMPD is  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes  
   
  505  
   
  derived from Laplacian of the Gaussian curvature. For each summit Si the Gaussian curvature (noted CGi) is established by the following equation:   X   CGi ¼ 2p  a ð11Þ  j jN ðF Þ i  
   
  or Ni (F) represents all vicinity facets at the summit Si and the j angle aj represent the crossing facet with the actual summit. The local roughness, calculated on a top si is approximated by the quantity: P    j2Ni ðSÞ Dij CGj   RLi ¼ CGi þ  D  
   
  ð12Þ  
   
  ii  
   
  where Ni ðsÞ is the set of neighboring vertices aware summit, the matrix D it’s the array of discrete Laplace established by:     cot bij þ cot bij pourjNi ðsÞ Dij ¼ 2 X Dii ¼  D j ij  
   
  ð13Þ ð14Þ  
   
  where bij and bij′ are the opposite angles in which the peak relies si to sj. Figures 4(b) and (d) represent respectively the color card of the roughness measurement on the surface of the Armadillo and Venus meshes. The warm colors match at high RL values, cold colors correspond to low values of RL. We note that this descriptor is able to properly evaluate and classify the surfaces of meshes into smooth and rough areas regions. FMPD in the local roughness measurements are modulated by a power function [32] to establish local values of roughness RLFi in each peak si. This modulation is performed to capture the spatial masking effect on the mesh surfaces.  
   
  Fig. 4. (a) - and (c) - respectively present the 3D meshes of Armadillo and Venus, (b) - and (d) present colors of the cards from the respective surfaces roughness Armadillo of mesh and mesh Venus.  
   
  506  
   
  N. Elloumi et al.  
   
  The overall roughness is subsequently calculated by a steady sum of the local measurements: P i RLFi ai RG ¼ P ð15Þ i ai where ai is a coefﬁcient connected to the area of the incident facets at the summit si the measure of the perceptual distance FMPD is established as the difference between the values of global roughness RG1 and RG2 of two meshes M1 and M2 to compare: FMPD ¼ cjRG1  RG2 j  
   
  ð16Þ  
   
  With c as a scalar set a scale parameter for the FMPD in the interval distances [0; 1]. 5.3.4 The Dihedral Angle Mesh Error Metric Recently, Vasa and Rus have developed a new metric of perceptual quality for static 3D mesh based on the dihedral angles [33]. This metric, named DAME (Dihedral Angle Mesh Error) offers a compromise between the complexity and the prediction efﬁciency. On each pair of triangles (t1 = {S1S2S3}; t2 = {S3S2S4}) neighbors of the mesh, the dihedral angle oriented are calculated use this expression: Dt1t2¼arccosðn1;n2Þsgnðn1:ðs4s3ÞÞ  
   
  ð17Þ  
   
  where n1 and n2 represent respectively the surface normal associated with t1 and t2 triangles. Measurement of DAME perceptual distance is calculated as follows: 1 jjXjj  
   
  ð18Þ  
   
    Dt1t2  Dt2t2   mt1t2 :ðw1 þ w2 Þ  
   
  ð19Þ  
   
  DAME ¼ X ft1;t2g2X  
   
  where Dt1t2 and Dt1t2 respectively represent the measurements of the dihedral angles of the two meshes to compare, m and w represent respectively a masking modeling function and a visibility coefﬁcient.  
   
  6 Conclusion In this paper, we have studied the importance of perceptual quality 3D meshes compared to the objective measures meshes. We have also enumerated the different existing approaches which are based on the metrics of the perceptual quality 3D meshes. We have also detailed various properties of the HVS, such as the CSF and the masking effect. It is important to consider these properties for guiding quality measures development process perceptual 3D meshes. These existing perceptual objective  
   
  The Efﬁciency of Perceptual Quality Metrics 3D Meshes  
   
  507  
   
  metrics mainly considers the spatial masking effect to establish quality metrics collected for 3D meshes. Finally we have itemized metrics which are based on the HVS properties.  
   
  References 1. Lecuire, V., Duran-Faundez, C., Krommenacker, N.: Energy-efﬁcient image transmission in sensor networks. Int. J. Sens. Netw. 4(1/2), 37–47 (2008) 2. Salehpour, M., Behrad, A.: 3D face reconstruction by KLT feature extraction and model consistency match reﬁning and growing. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), Sousse, pp. 297–302 (2012) 3. Chan, A.T., Gamino, A.: Integration of assistive technologies into 3D simulations: an exploratory study. In: Information Technology: New Generations, Advances in Intelligent Systems and Computing, vol. 448, pp. 425–437. Springer (2016). ISBN 978-3-319-18295-7 4. El-Bendary, M.A.M., El-Tokhy, M., Kazemian, H.B.: Efﬁcient image transmission over low-power IEEE802.15.1 network over correlated fading channels. In: The 6th International Conferences: Sciences of Electronics, Technologies of Information and Telecommunications “SETIT 2012”, Mars 2012, Sousse-Tunisie, IEEE Conferences, pp. 563–567 (2012). doi:10. 1109/SETIT.2012.6481973 5. Abderrahim, Z., Techini, E., Bouhlel, M.S.: State of the art: compression of 3D meshes. Int. J. Comput. Trends Technol. (IJCTT) 4(6), 765–770 (2012) 6. Tang, H., Joshi, N., Kapoor, A.: Learning a blind measure of perceptual image quality. In: Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition, pp. 305–312 (2011) 7. Hemanth, D.J., Balas, V.E., Anitha, J.: Hybrid neuro-fuzzy approaches for abnormality detection in retinal images. In: Proceedings of the 6th International Workshop Soft Computing Applications, SOFA 2014, Timisoara, Romania, 24–26 July 2014, pp. 295–305 (2014) 8. El-Bendary, M.A.M., El-Tokhy, M., Shawki, F., Abd-El-Samie, F.E.: Studying the throughput efﬁciency of JPEG image transmission over mobile IEEE 802.15.1 network using EDR packets. In: The 6th International Conferences: Sciences of Electronics, Technologies of Information and Telecommunications “SETIT 2012”, Mars 2012, Sousse-Tunisie, IEEE Conferences, pp. 573–577 (2012). doi:10.1109/SETIT.2012. 6481975 9. Escribano-Barreno, J., García-Muñoz, J.: Integrated metrics handling in open source software quality management platforms. In: Information Technology: New Generations. Advances in Intelligent Systems and Computing, vol. 448, pp. 509–518. Springer (2016). ISBN 978-3-319-18295-7 10. Triki, N., Kallel, M., Bouhlel, M.S.: Imaging and HMI, fondations and complementarities. In: The 6th International Conferences: Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2012, Mars 2012, Sousse-Tunisie, IEEE Conferences, pp. 25–29 (2012). doi:10.1109/SETIT.2012.6481884 11. Nandi, D., Ashour, A.S., Samanta, S., Chakraborty, S., Salem, M.A., Dey, N.: Principal component analysis in medical image processing: a study. Int. J. Image Min. 1(1), 65–86 (2015) 12. Cho, J.-W., Prost, R., Jung, H.-Y.: An oblivious watermarking for 3-D polygonal meshes using distribution of vertex norms. IEEE Trans. Sig. Process. 55(1), 142–155 (2007)  
   
  508  
   
  N. Elloumi et al.  
   
  13. Wang, K., Lavoué, G., Denis, F., Baskurt, A.: Robustand blind mesh watermarking based on volume moments. Comput. Graph. 35(1), 1–19 (2011) 14. Abderrahim, Z., Techini, E., Bouhlel, M.S.: Progressive compression of 3D objects with an adaptive quantization. Int. J. Comput. Sci. Issues (IJCSI) 10(2), 504–511 (2013) 15. Campbell, F.-W., Robson, J.-G.: Application of Fourier analysis to the visibility of gratings. J. Physiol. 197, 551–566 (1968) 16. Hirai, K., Tsumura, N., Nakaguchi, T., Miyake, Y., Tominaga, S.: Spatio-velocity contrast sensitivity functions and video quality assessment. In: International Symposium on Intelligent Signal Processing and Communication Systems, pp. 1–4 (2010) 17. Ninassi, A., Meur, O.L., Le Callet, P., Barba, D.: On the performance of human visual system based image quality assessment metric using wavelet Domain. In: Proceedings of the SPIE Human Vision and Electronic Imaging (2008) 18. Ninassi, A., Meur, O.L., Le Callet, P., Barba, D.: Which semi-local visual masking model for wavelet based image quality metric In: Proceedings of IEEE International Conference on Image Processing, pp. 1180–1183 (2008) 19. Fernandez-Maloigne, C., Larabi, M.-C., Bringier, B., Richard, N.: Spatio temporal characteristics of the human color perception for digital quality assessment. In: Proceedings of International Symposium on Signals, Circuits and Systems, pp. 203–206 (2005) 20. Kelly, D.-H.: Visual contrast sensitivity. Opt. Acta: Int. J. Opt. 24(2), 107–129 (1977) 21. Daly, S.-J.: Engineering observations from spatio velocity and spatio temporal visual models. In: Proceedings of the SPIE Human Vision and Electronic Imaging III, vol. 3299, pp. 180–191 (1998) 22. Wang, Z., Bovik, A.-C.: Modern Image Quality Assessment. Morgan & Claypool, San Rafael (2006) 23. Rogowitz, B.-E., Rushmeier, H.-E.: Are image quality metrics adequate to evaluate the quality of geometric objects. In: Proceedings of SPIE Human Vision and Electronic Imaging, pp. 340–348 (2001) 24. Corsini, M., Drelie Gelasca, E., Ebrahimi, T., Barni, M.: Watermarked 3-D mesh quality assessment. IEEE Trans. Multimedia 9(2), 247–256 (2007) 25. Lavoué, G.: A multiscale metric for 3D mesh visual quality assessment. Comput. Graph. Forum 30(5), 1427–1437 (2011) 26. Lavoué, G., Drelie Gelasca, E., Dupont, F., Baskurt, A., Ebrahimi, T.: Perceptually driven 3D distance metrics with application to watermarking. In: Proceedings of SPIE Electronic Imaging (2006) 27. Wang, Z., Bovik, A.-C., Sheikh, H.R., Simoncelli, E.P.: Image quality assessment: from error visibility to structural similarity. IEEE Trans. Image Process. 13(4), 600–612 (2004) 28. Alliez, P., Tayeb, S., Wormser, C.: 3D fast intersection and distance computation (AABB tree). In: CGAL User and Reference Manual (2012) 29. Wu, J.-H., Hu, S.-M., Tai, C.-L., Sun, J.-G.: An effective feature-preserving mesh simpliﬁcation scheme based on face constriction. In: Paciﬁc Conference on Computer Graphics and Applications, pp. 12–21 (2001) 30. Gelasca, E.-D., Ebrahimi, T.: Objective evaluation of the perceptual quality of 3D watermarking. In: IEEE International Conference on Image Processing, pp. 241–244 (2005) 31. Corsini, M., Gelasca, E.-D., Ebrahimi, T.: A multi-scale roughness metric for 3D watermarking quality assessment. In: Workshop on Image Analysis for Multimedia Interactive Services (2005) 32. Wang, K., Torkhani, F., Montanvert, A.: A fast roughness-based approach to the assessment of 3D mesh visual quality. Comput. Graph. 36(7), 808–818 (2012) 33. Vása, L., Rus, J.: Dihedral angle mesh error: a fast perception correlated distortion measure for ﬁxed connectivity triangle meshes. Comput. Graph. Forum 31(5), 1715–1724 (2012)  
   
  Fireworks Algorithm Based Image Registration Silviu-Ioan Bejinariu1(&), Hariton Costin1,2, Florin Rotaru1, Ramona Luca1, Cristina Diana Niţă1, and Camelia Lazăr1 1  
   
  Institute of Computer Science, Romanian Academy Iaşi Branch, Iasi, Romania {silviu.bejinariu,florin.rotaru, ramona.luca,cristina.nita, camelia.lazar}@iit.academiaromana-is.ro, [email protected]  2 Faculty of Medical Bioengineering, “Grigore T. Popa” University of Medicine and Pharmacy, Iasi, Romania  
   
  Abstract. In the Image Processing (IP) domain, optimization algorithms have to be applied in many cases. Nature-inspired heuristics allow obtaining near optimal solutions using lower computing resources. In this paper the Fireworks Algorithm (FWA) behavior is studied for Image Registration (IR) problems. The IR results accuracy is analyzed for different types of images, mainly in case of pixel based registration using the Normalized Mutual Information. FWA is compared to Particle Swarming (PSO), Cuckoo Search (CSA) and Genetic Algorithms (GA) in terms of results accuracy and number of objective function evaluations required to obtain the optimal geometric transform parameters. Because the pixel based IR may fail in case of images containing graphic drawings, a features based IR approach is proposed for this class of images. Comparing to other nature inspired algorithms, FWA performances are close to those of PSO and CSA in terms of accuracy. Considering the required computing time, that is determined by the number of cost function evaluations, FWA is little slower than PSO and much faster than CSA and GA. Keywords: Fireworks Algorithm  
   
   Optimization  Image registration  
   
  1 Introduction Image registration (IR) is the process of geometric overlaying or alignment of two or more images of the same scene for subsequent common processing [1]. The goal of an IR procedure is to approximate the parameters of the geometric transform to be applied to a source image such that it is aligned to a model image. The overlaying quality is evaluated using a similarity criterion which must be maximized using an optimization algorithm. In case of a large number of parameters, or of complex similarity measures, the optimal parameters may be difﬁcult to obtain. Based on the strategies of live beings to survive, ﬁnd food or avoid obstacles, or modeling other natural phenomena, the nature-inspired metaheuristics offer the possibility to obtain faster a near optimal solution [2]. © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_44  
   
  510  
   
  S.-I. Bejinariu et al.  
   
  A relatively new nature inspired algorithm is the Fireworks Algorithm (FWA) proposed in [3] and deeply analyzed in [4]. A detailed study and some enhancements of the operators (strategies) used in FWA are presented in [5]. Other versions of FWA are: an adaptive version of FWA proposed in [6] and a cooperative strategy among ﬁreworks in [7]. Multi-objective versions of FWA were also developed [8]. In most papers the algorithm’s performances are studied using benchmark functions. The IR issue was addressed in [9–11] using Bacterial Foraging Optimization and in [12] using Bat and Cuckoo Search algorithms. In [13] the behavior of Bacterial Foraging Optimization, Particle Swarming, Multi-swarming and Firefly algorithms in multi-threshold image segmentation was studied. In [14] single and multi-objective FWA convergence was analyzed using test functions. The paper is organized as follows. In the second section FWA is briefly described. The third section describes the IR problem and the experiments made using different types of images, including an analysis of an IR failure case. In the fourth section, the accuracy of FWA results is compared to that of the results obtained using the Particle Swarming, Cuckoo Search and Genetic Algorithms as optimization procedure. In the ﬁfth section, a features based IR approach is shortly described. It allows the registration of images that contain graphic drawings, that fails in case of pixel based registration. The last section concludes the paper.  
   
  2 Fireworks Algorithm The Fireworks Algorithm (FWA) belongs to the Swarm Intelligence algorithms category and it is inspired from the ﬁreworks explosion simulation [3, 4]. As in other swarming algorithms, the possible solutions are encoded as position of individuals that evolve in the problem domain. The evolution is simulated by selection of sparks resulted in the ﬁreworks explosion process. The objective to optimize is evaluated in all the reached positions and the best obtained position is considered as being the problem solution [14]. FWA was initially developed for single-objective optimization problems, in which the parameter value that minimize (or maximize) a ﬁtness function have to be determined: minx2S f ð xÞ  
   
  ð1Þ  
   
  where S is the problem domain (constraints). FWA is an iterative algorithm which starts with a set of individuals (ﬁreworks) randomly placed in the problem domain. For each iteration (epoch) of FWA, a variable number of descendants (sparks) is generated for each ﬁrework. The descendants are evaluated and some of them became ﬁreworks in the next evolution step  (epoch).  Let’s consider X ¼ fxi ; i ¼ 1; . . .N g a set of N ﬁreworks, and xi ¼ x1i ; . . .; xdi their positions in the problem domain, where d is the dimension of the problem.  
   
  Fireworks Algorithm Based Image Registration  
   
  511  
   
  The general structure of the algorithm is described below [4]:  
   
  Each step of the FWA loop involves strategies that are important for the algorithm’s performances. The ﬁreworks explosion which ensures the quality of the next ﬁreworks generation is characterized by strength, amplitude and displacement. The explosion strength refers to the number of sparks Si of each ﬁrework. It depends on the current ﬁrework quality, and it is computed as: fworst  f ðxi Þ þ e Si ¼ m  Pn 1 ðfworst  f ðxi ÞÞ þ e  
   
  ð2Þ  
   
  where m is the total number of sparks, fworst is the worst ﬁtness value of the current ﬁreworks set, f ðxi Þ is the ﬁtness value of the ith ﬁrework and e is a constant used to avoid zero-division operations. To keep the number of sparks in a reasonable interval, minimum and maximum values that depend on m are imposed for Si . The amplitude Ai of the ith ﬁrework sparks is used to avoid the convergence to local solutions. The amplitude is higher as the distance to the best ﬁrework increases and it is computed as: f ðxi Þ  fbest þ e Ai ¼ A  Pn 1 ðf ðxi Þ  fbest Þ þ e  
   
  ð3Þ  
   
  where A is the desired sum of amplitudes, fbest is the best ﬁtness value in the current ﬁreworks set. Two types of sparks are created in the ith ﬁrework explosion: regular and Gaussian. Regular sparks are obtained from the parent ﬁrework by adding a uniform random number in the interval ðAi ; Ai Þ to some randomly chosen coordinates. xki ¼ xki þ U  
   
  ð4Þ  
   
  where k are the randomly chosen coordinates and U is the uniform random value.  
   
  512  
   
  S.-I. Bejinariu et al.  
   
  The Gaussian sparks assure the diversity of the next ﬁreworks generation by altering some randomly chosen coordinates of some randomly chosen ﬁreworks by random numbers with Gaussian distribution: xki ¼ xki  g  
   
  ð5Þ  
   
  where k are the randomly chosen coordinates and g are random numbers. If the generated sparks are placed outside the problem domain they must be re-positioned inside. The ﬁtness function is evaluated in the all new sparks and the next generation ﬁreworks population is selected. The best, the worst and the other N  2 randomly chosen ﬁreworks replace the population of ﬁreworks.  
   
  3 FWA Based Image Registration Image registration is the process of geometric overlaying or alignment of two or more images of the same scene taken at different times, from different viewpoints, and/or by different sensors [1]. There are two different approaches of IR: pixel level and features level registration. In both cases, IR is an optimization procedure because it requires to approximate the parameters of a geometric transform which applied to a source image minimize a similarity measure computed between the transformed source image and a model image. In the FWA based IR the possible solutions are encoded as positions of the ﬁreworks and the objective to optimize is the Normalized Mutual Information (NMI). The ﬁreworks evolve in a multidimensional space whose dimension is equal to the number of parameters in the geometric transform to be approximated. In the next paragraphs the Normalized Cross-Correlation (NCC) is also used to evaluate the results, but it is not used as optimization criteria. The FWA based IR procedure was evaluated using the images available in the ‘Miscellaneous’ volume of USC-SIPI database [15]. All used images were resized to 256  256 resolution, and color depth was reduced to 256 gray levels if not already so. In the following paragraphs the results obtained using four model images from this database are presented. Two of these images contain photos (Fig. 1a and b), one contains graphics (Fig. 1c) and the last one is mixed (Fig. 1d).  
   
  a. ‘Lena’ model image b. ‘Peppers’ model image  
   
  c. ‘Ruler’ model image  
   
  Fig. 1. Original test images, from [15]  
   
  d. ‘Testpat’ model image  
   
  Fireworks Algorithm Based Image Registration  
   
  513  
   
  The source images were artiﬁcially generated by applying to model images an afﬁne transform with the following parameters: rotation by h ¼ 10 against the rotation center cx ¼ 30; cy ¼ 30 and scaling by the factor s ¼ 0:8. The computed inverse afﬁne transform has the following parameters: rotation by h0 ¼ 10 against the same center and scaling factor s0 ¼ 1:250. FWA was applied to register the source images (Fig. 2) to model images (Fig. 1). The parameters of the algorithm were chosen as follows: – – – – – –  
   
  ﬁtness function: NMI, number of epochs = 250, number of ﬁreworks = 5, maximum amplitude = 40, regular sparks factor = 10 and number of Gaussian sparks = 5.  
   
  These values of FWA parameters were chosen accordingly to those proposed in [4] and they were validated by our experiments. Because optimal value of NMI is unknown, there was no stop criterion other than the number of epochs. It must be noticed that the ﬁtness function evaluation requires to apply the approximated geometric transform that correspond to the ﬁrework position and then to compute the similarity measure between the model image and transformed source image. This evaluation is time consuming; in fact more than 90% of IR execution time is spent in the ﬁtness function evaluation [10].  
   
  a. ‘Lena’ source image b. ‘Peppers’ source image  
   
  c. ‘Ruler’ source image  
   
  d. ‘Testpat’ source image  
   
  Fig. 2. Source images obtained by applying the geometric transform to model images  
   
  Even if the number of individuals (ﬁreworks) and iteration (epochs) are reduced comparing to other nature-inspired IR procedures, the results are quite good. The ﬁnal results evaluation is performed using two different similarity measures: NMI and NCC. The columns named Expected contain the NMI/NCC values computed between the model image and source image transformed using the computed inverse transform. The columns named Approximated contain the NMI/NCC values computed between the model image and source image transformed using the approximated inverse transform. The column ‘#evals’ contains the total number of cost function evaluations, column ‘Best eval’ the number of the evaluation in which the best ﬁtness was reached and the last column contains the execution time in seconds – not so relevant while it depends on computer’s performances.  
   
  514  
   
  S.-I. Bejinariu et al.  
   
  By analyzing the values in Tables 1 and 2, the following conclusions can be drawn: – In most cases the approximated value of the similarity measure is greater than the expected value. This can be explained by the two geometric transforms applied to the image which means that pixels values were interpolated two times. – The parameters of the approximated inverse transform (Table 2) are very close to those of the computed inverse. – In case of ‘Ruler’ image the registration process failed. The cause is discussed below. – The best value was obtained enough late in the iterative process, which means that better solutions can be obtained by increasing the number of iterations. Regarding the number of epochs and number of ﬁreworks used in FWA it must be said that a reduced number of ﬁreworks (3 or 4) requires a considerably increase of the number of epochs in order to obtain similar results. By increasing the number of epochs and keeping constant the number of ﬁreworks (=5), the results are improved but not signiﬁcantly while the processing time greatly increases. – The application was tested on an Intel Core i3, 2.4 GHz, 6 GB RAM based computer. The execution time is presented for the case of parallel execution. Even if not present in the Table 1, the sequential execution time is about 30% greater with the observation that other applications were running in the same time.  
   
  Table 1. Results evaluation of IR process Image  
   
  NMI Expected Lena 1.3252 Peppers 1.3463 Ruler 1.1147 Testpat 1.5014  
   
  Approximated 1.3253 1.3466 1.0492 1.5014  
   
  NCC Expected 0.9765 0.9675 0.9699 0.9525  
   
  # evals Best eval Time (sec) Approximated 0.9766 0.9675 0.3511 0.9525  
   
  14369 14390 14109 14349  
   
  14062 14329 13867 14223  
   
  27.300 27.986 26.567 29.422  
   
  Table 2. Parameters of the approximated inverse transform h0  
   
  Image  
   
  c0x  
   
  c0y  
   
  s0  
   
  Lena Peppers Ruler Testpat  
   
  30.1959 30.0360 40.7941 29.9996  
   
  30.0245 −9.9944 1.2504 30.0073 −10.0032 1.2500 48.6515 −9.9937 1.2519 30.0161 −10.0012 1.2500  
   
  The registered images are depicted in Fig. 3. The failure of ‘Ruler’ image (which contains graphics) registration is also visible (Fig. 3c).  
   
  Fireworks Algorithm Based Image Registration  
   
  a. ‘Lena’ registered image  
   
  b. ‘Peppers’ registered c. ‘Ruler’ registered image image  
   
  515  
   
  d. ‘Testpat’ registered image  
   
  Fig. 3. Registered images obtained by applying the approximated inverse transform  
   
  3.1  
   
  IR Failure Analysis  
   
  As it was seen above, the IR of ‘Ruler’ image failed. Let’s analyze the histograms of the four images (Fig. 4). Only 5 levels of gray are used in the ‘Ruler’ image, most of them corresponding to the image background. By applying the afﬁne transform to the model, most pixels have the same or close values to those in the original, leading to small variations of the similarity measure. This is visible in Fig. 5 which contains for all images the variation of NMI depending on the rotation angle and scale factor, keeping the rotation center ﬁxed and equal to the values determined in the computed inverse transform. The peak of NMI surface is visible for all images, but the variation is steep close to the maximum value in case of ‘Ruler’ while the growth is smoother for the other images. It must be speciﬁed also that these surfaces have about 400 local maximum values in case of ‘Lena’ and ‘Peppers’, 122 local maximum in case of ‘Testpat’ and about 1040 maximum values in case of ‘Ruler’. Considering the fact that during evolution only 5 ﬁreworks are used, it is understandable why the algorithm converges to a local solution. In fact, because the initial positions are randomly chosen, for repeated executions of IR procedure on ‘Testpat’ image, in about 10% of cases the algorithm leads to the correct solution.  
   
  a. Histogram of ‘Lena’  
   
  b. Histogram of ‘Peppers’  
   
  c. Histogram of ‘Ruler’  
   
  d. Histogram of ‘Testpat’  
   
  Fig. 4. Histograms of the model images  
   
  516  
   
  S.-I. Bejinariu et al.  
   
  a. NMI variation – ‘Lena’  
   
  b. NMI variation – ‘Peppers’  
   
  c. NMI variation – ‘Ruler’  
   
  d. NMI variation – ‘Testpat’  
   
  Fig. 5. Normalized mutual information variation  
   
  The easiest solution to solve these failures is to change the algorithm’s parameters. The attempt to increase the number of iterations (epochs) to 500 or 1000 did not lead to the expected result, because it depends on the spatial distribution of the initial population. By increasing the number of ﬁreworks in the initial population to 10 or 15, the percent of cases in which the algorithm leads to the correct solution has increased to about 25%. In our opinion, both these parameters must be increased, even if this solution is not feasible because the execution time increases also. Another solution of this problem is the usage of features based IR. Some results are shortly described later in the ﬁfth section. 3.2  
   
  Image Registration of Noise Affected Images  
   
  The behavior of the FWA based IR procedure was studied also for noise affected images. The source images were warped using the same afﬁne transform described in the previous section and then they were degraded using Gaussian or Salt & Pepper noise. The degraded source images were registered to the original model images. Image degradation is evaluated using the Signal-To-Noise ratio (Table 3). The objective evaluation of IR results is presented in Tables 4 and 5 and the processed images are presented in Fig. 6. The conclusion that can be drawn is that the registration process is not affected by the degradation of images, but depends on the similarity measure used as objective function in the optimization. In fact this demonstrates that the procedure can be applied for multimodal images.  
   
  Fireworks Algorithm Based Image Registration  
   
  517  
   
  Table 3. SNR value for degraded source images Model image SNR (dB) S&P noise Gaussian noise Peppers 2.46 21.19 Testpat 2.72 21.72  
   
  Table 4. Evaluation of IR of degraded images Image  
   
  Noise  
   
  NMI Expected Peppers Gaussian 1.2081 S&P 1.1160 Testpat Gaussian 1.2526 S&P 1.1407  
   
  Computed 1.2081 1.1166 1.2533 1.1410  
   
  NCC Expected 0.9662 0.9069 0.9513 0.8921  
   
  Computed 0.9661 0.9070 0.9517 0.8919  
   
  # evals  
   
  Best eval  
   
  Time (sec)  
   
  14289 14491 14516 14408  
   
  13812 14390 14497 13962  
   
  29.890 33.291 24.258 26.801  
   
  Table 5. Computed parameters of the inverse transform Image Noise Peppers Gaussian S&P Testpat Gaussian S&P  
   
  cx 29.8557 30.0255 30.5535 29.9779  
   
  cy 29.9494 30.0632 30.0995 30.0260  
   
  Angle −10.0009 −10.0169 −10.0220 −9.9906  
   
  Scale 1.2498 1.2504 1.2513 1.2497  
   
  a. Source: ‘Peppers’ + Gaussian noise  
   
  b. Source: c. Source: ‘Peppers’ + S&P noise ‘Testpat’ + Gaussian noise  
   
  d. Source: ‘Testpat’ + S&P noise  
   
  e. Registered: ‘Peppers’ + Gaussian noise  
   
  f. Registered: g. Registered: ‘Peppers’ + S&P noise ‘Testpat’ + Gaussian noise  
   
  h. Registered: ‘Testpat’ + S&P noise  
   
  Fig. 6. IR results obtained using degraded source images  
   
  518  
   
  S.-I. Bejinariu et al.  
   
  4 FWA Versus Other Optimization Algorithms The accuracy of the image registration results is compared to that obtained using other optimization algorithms: Particle Swarming (PSO), Cuckoo Search (CSA) and Genetic Algorithm (GA). The PSO implementation described in [13] was customized for IR with the following parameters: number of particles – 100, number of iterations – 100, inertia weight – 0.729, local weight – 1.4945 and global weight – 1.4945. The weights are those proposed in [16]. Our experiments demonstrated that even small variations of these values decrease the results accuracy. The CSA based IR procedure [12] was used with the following parameters: number of nests – 25, number of iterations – 1000 and discovery rate – 0.25. For GA based IR an implementation based on real encoding (each chromosome is characterized by real values representing the geometric transform parameters) was used [17]. Discrete, average and simplex crossover operators were applied with different probabilities. The GA was applied as in [17] using the following parameters: number of generations – 500, number of chromosomes – 1500, probability of discrete crossover – 0.05, probability of average crossover – 0.15, probability of simplex crossover – 0.2 and mutation rate – 0.2. The IR procedure was applied using all these optimization algorithms on the same images as in the previous section. The obtained results are described in Table 6. Both NMI and NCC values are presented but NMI was used as objective function to be maximized. The maximum values of NMI are embossed for each image case. Table 6. Evaluation of IR results using FWA, PSO, CSA and GA as optimization algorithm Image Expected NMI NCC Lena 1.3252 0.9765 Peppers 1.3463 0.9675 Ruler 1.1147 0.9699 Testpat 1.5014 0.9525  
   
  FWA Computed NMI NCC 1.3253 0.9766 1.3466 0.9675 1.0492 0.3511 1.5014 0.9525  
   
  PSO Computed NMI NCC 1.3256 0.9766 1.3472 0.9676 1.0199 0.3184 1.5015 0.9525  
   
  CSA Computed NMI NCC 1.3257 0.9766 1.3472 0.9676 1.0535 0.8995 1.5017 0.9526  
   
  GA Computed NMI NCC 1.3244 0.9765 1.3455 0.9675 1.0408 0.2925 1.4907 0.9523  
   
  The same results are graphically presented for each test image in Fig. 7. The values presented in Fig. 7 have been rounded to three decimal digits. For this reason, in some graphs the values are equal but the corresponding bars have different heights. A brief analysis of these results leads to the following conclusions: – First of all, it must be noticed that in case of ‘Ruler’ test image the registration fails also in case of PSO, CSA and GA optimization, – All four optimization algorithms produce enough good results for three test images: ‘Lena’, ‘Peppers’ and ‘Testpat’. – CSA offers the best results for all four images. In fact, also for ‘Ruler’ test image, FWA, PSO and GA produce a result similar to that presented in Fig. 3c, while CSA  
   
  Fireworks Algorithm Based Image Registration  
   
  a. ‘Lena’ image  
   
  b. ‘Peppers’ image  
   
  c. ‘Ruler’ image  
   
  d. ‘Testpat’ image  
   
  519  
   
  Fig. 7. Evaluation of pixel based IR results obtained using FWA, PSO, CSA and GA for each test image  
   
  tends to approximate the inverse geometric transform. The ‘scale’ and ‘angle’ parameters are enough well approximated, only the rotation center coordinates are pretty much shifted from the expected values. It is possible that an increased number of iterations and/or an increased number of host nests allow CSA to obtain a better solution. – The results obtained by using GA in optimization are less accurate than the other three algorithms results. – The accuracy of results obtained by using PSO and FWA is good even if lower than CSA results accuracy. The PSO, CSA and GA based IR procedures were applied also for the images altered by Gaussian and Salt & Pepper noise with quite similar results. A complete analysis of the registration results have to consider also the processing time which is determined by the number of objective function evaluations. As it was already noticed in the previous section, in case of pixel based IR applications, more than 90% of the processing time is spent in these evaluations, so, reducing them may be important at least for real time applications. In Fig. 8, the average number of objective function evaluations is presented. On the other hand, the number of evaluations required to obtain the best solution is important given the fact that this class of algorithms usually obtain the best solution during the evolution but not necessary in the last iteration. As is depicted in Fig. 8, FWA and PSO use a lower number of cost function evaluations, while GA uses the greatest number while its results are less accurate. Concerning the number of cost function evaluations required to obtain the best solution,  
   
  520  
   
  S.-I. Bejinariu et al.  
   
  Fig. 8. Average number of objective function evaluations  
   
  it must be noticed that in case of FWA, PSO and CSA it is close to the total number of evaluations. This leads to the conclusion that more precise solutions can be obtained by increasing the number of iterations and/or individuals used in the evolutionary process. A different situation is encountered in case of GA. Its best solutions are obtained after about 8–9000 cost function evaluations, i.e. about one eight of the total number which is lower than in case of the other algorithms. This means that GA optimization represents a good choice if less accurate solutions are acceptable. As a conclusion, CSA can be used to obtain more precise solutions; GA can be used to faster obtain an acceptable solution; FWA and PSO is the proper choice if good solutions have to be also quickly obtained.  
   
  5 Pixel Based Versus Features Based IR We still have to ﬁnd a solution to register images that contain graphic drawings, like the ‘Ruler’ test image. A good solution is the usage of features based IR. In this case, distinctive and stable features (points, lines, contours, regions) have to be detected in both model and source images. A features based IR procedure using bio-inspired computing is presented in [17]. As features the key-points determined using the Scale Invariant Feature Transform (SIFT) [18] are used. To evaluate images similarity, the correspondences between features present in both images have to be identiﬁed. The Euclidean distances between SIFT descriptors are computed for all key-points pairs detected in the model and source images. For each key-point descriptor in the model image, the distances to the key-points descriptors in the source image are sorted in ascendant order. If the smallest distance is less than a speciﬁc percent (usually 30%) of the second distance then a match is established between the key-point in the model image and the key-point in the source image [17]. The registration procedures are similar excepting the objective function used in optimization. In case of features based IR the Euclidean distance between the positions of the common features in the two images is used for images similarity evaluation. It must be noticed also that in this case the geometric transform corresponding to each  
   
  Fireworks Algorithm Based Image Registration  
   
  521  
   
  possible solution have to be applied only for the key-points coordinates while in the pixel based IR, the entire source image have to be transformed. This explains why the features based IR is much faster than pixel based IR. In fact, increasing the number of iterations and/or individuals does not have a great impact on the processing time. However, features based IR has one great disadvantage. For multimodal or some noise affected images the correspondences between stable features in the two images can’t be established. Trying to register images that contain graphic drawings (‘Ruler’ image), the four optimization algorithms were applied for features based IR using the SIFT key-points. A number of 2607 stable features were determined in the model image and 2525 stable features were determined in the source image. From these only for 60 pairs of key-points the correspondence was established and they were used in registration. The image registration succeeded for all algorithms. As depicted in Fig. 9, the best registration accuracy is obtained when FWA was used as optimization algorithm but also the others produce enough good results. Concerning the number of objective function evaluations it is similar to that of pixel based IR, because the parameters chosen for the optimization algorithms were the same. Anyway this is less important because the IR is very fast. As comparison, the duration of IR procedure applied for the ‘Lena’ image and FWA usage in optimization, on a system equipped with an Intel Core i5 3.1 GHz processor and 4 GB RAM, is shown in Table 7.  
   
  Fig. 9. Evaluation of features based IR results using FWA, PSO, CSA and GA for ‘Ruler’ test image Table 7. IR duration (seconds) for ‘Lena’ image and FWA optimization Pixel based IR Features based IR Parallel 14.72 0.04 Sequential 20.13 0.05  
   
  The features based IR was applied also for the images degraded using Gaussian and Salt & Pepper noise. In the ﬁrst case the features based IR succeeded as well even if fewer correspondences were found in the two images. In the second case, the  
   
  522  
   
  S.-I. Bejinariu et al.  
   
  registration failed because no correspondences were established between the features detected in the two images.  
   
  6 Conclusions In this paper, the behavior of the Fireworks optimization algorithm for image registration problems is analyzed. Both pixel based and features based image registration were addressed for different types of images: pictures, graphics and a combination of these. In most cases the optimization algorithm is chosen and its parameters are tuned depending on the problem to be solved. FWA is compared to other nature inspired evolutionary algorithms: Particle Swarming, Cuckoo Search and Genetic algorithms. Concerning the pixel based IR, for which the Normalized Mutual Information was used as objective function, FWA may be a choice if enough good registration results have to be obtained in a reasonable execution time because the accuracy of its results is almost as good as for PSO and CSA algorithms and better than those of GA usage. Regarding the number of objective function evaluations that is proportional to the execution time, in the studied cases FWA is almost as fast as PSO is and much faster than CSA and GA. Similar results were obtained for images degraded by noise. The pixel based registration may fail if the images to be registered contain graphics. For this reason a features based IR approach is also analyzed. It is based on the SIFT features and FWA offers more accurate results than PSO, CSA and GA optimization algorithms. The features based IR has the disadvantage that it might fail for multi-modal or noise affected images, because the correspondences between the stable features detected in the two images can’t be found. The results presented in this paper were obtained using FWA, PSO, CSA and GA implementations in C++ [9–14]. The parallel implementation uses the computing power of multi-core processors and was developed using the parallel computing support of the Microsoft Visual Studio 2015 framework. The OpenCV open-source library was used for images manipulation. The graphs presented in Fig. 5 were drawn using a Matlab application. This research will be continued by the analysis of other nature-inspired optimization algorithms and their usage in image processing applications.  
   
  References 1. Zitova, B., Flusser, J.: Image registration methods: a survey. Image Vis. Comput. 21, 977– 1000 (2003). Elsevier 2. Yang, X.-S.: Nature-Inspired Optimization Algorithms. Elsevier Inc., Amsterdam (2014) 3. Tan, Y., Zhu, Y.: Fireworks algorithm for optimization. In: Tan, Y., Shi, Y., Tan, K.C. (eds.) ICSI 2010, Part I. LNCS, vol. 6145, pp. 355–364 (2010) 4. Tan, Y.: Fireworks Algorithm A Novel Swarm Intelligence Optimization Method. Springer, Heidelberg (2015)  
   
  Fireworks Algorithm Based Image Registration  
   
  523  
   
  5. Zheng, S., Janecek, A., Tan, Y.: Enhanced ﬁreworks algorithm. In: Proceedings of 2013 IEEE Congress on Evolutionary Computation, Cancún, México, pp. 2069–2077 (2013) 6. Li, J., Zheng, S., Tan, Y.: Adaptive ﬁreworks algorithm. In: Proceedings of 2014 IEEE Congress on Evolutionary Computation (CEC), pp. 3214–3221 (2014) 7. Zheng, S., Li, J., Janecek, A., Tan, Y.: A cooperative framework for ﬁreworks algorithm. In: IEEE/ACM Transactions on Computational Biology and Bioinformatics, pp. 1–13 (2015) 8. Liu, L., Zheng, S., Tan, Y.: S-metric based multi-objective ﬁreworks algorithm. In: 2015 IEEE Congress on Evolutionary Computation (CEC), pp. 1257–1264 (2015) 9. Costin, H., Bejinariu, S.I.: Medical image registration by means of a bio-inspired optimization strategy. Comput. Sci. J. Moldova 20, 2(59), 178–202 (2012) 10. Bejinariu, S.-I.: Image registration using bacterial foraging optimization algorithm on multi-core processors. In: 4th International Symposium on Electrical and Electronics Engineering (ISEEE), Galaţi, România (2013) 11. Bejinariu, S.-I., Costin, H., Rotaru, F., Luca, R., Niţă, C.: Social behavior in bacterial foraging optimization algorithm for image registration. In: Proceedings of the 18th International Conference on System Theory, Control and Computing, Sinaia, Romania, pp. 330–334 (2014) 12. Bejinariu, S.-I., Costin, H., Rotaru, F., Luca, R., Nita, C.D.: Image processing by means of some bio-inspired optimization algorithms. In: Proceedings of the IEEE 5th International Conference on E-Health and Bioengineering – “EHB 2015”, Iasi, Romania, pp. 1–4 (2015) 13. Bejinariu, S.-I., Costin, H., Rotaru, F., Luca, R., Nita, C.D.: Automatic multi-threshold image segmentation using metaheuristic algorithms. In: 2015 International Symposium on Signals, Circuits and Systems (ISSCS), Iasi, Romania, pp. 1–4 (2015) 14. Bejinariu, S.-I., Costin, H., Rotaru, F., Luca, R., Nita, C.D.: Fireworks algorithm based single and multi-objective optimization. Paper Submitted to Buletinul Institutului Politehnic din Iasi, Sectia Automatica si Calculatoare (2016) 15. University of Southern California, USC-SIPI Image Database. http://sipi.usc.edu/database/ database.php?volume=misc. Accessed 15 Mar 2016 16. Pedersen, M.E.H.: Good parameters for particle swarm optimization. Hvass Laboratories, Technical report no. HL100 (2010) 17. Bejinariu, S.-I., Costin, H., Rotaru, F., Luca, R., Niţă, C., Lazăr, C.: Parallel processing and bio-inspired computing for biomedical image registration. Comput. Sci. J. Moldova 22, 2(65), 253–277 (2014). Invited Article 18. Lowe, D.: Distinctive image features from scale-invariant keypoints. Int. J. Comput. Vis. 60(2), 91–110 (2004)  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion (wavREPro) Hedi Amri1(B) , Malek Gargouri1 , Med Karim Abdmouleh1 , Ali Khalfallah1 , Bertrand David2 , and Med Salim Bouhlel1 1  
   
  Research Unit: Sciences and Technologies of Image and Telecommunications, Higher Institute of Biotechnology, University of Sfax, Sfax, Tunisia {hedi.amri,malek.gargouri}@setit.rnu.tn, [email protected]  , [email protected]  , [email protected]  2 LIRIS Laboratory, UMR 5205 CNRS Central School of Lyon, University of Lyon, 36, av Guy de Collongue, 69134, Lyon-Ecully Cedex, France [email protected]   
   
  Abstract. The large volume of medical images remains a major problem for their archiving and transmission. In this context, we propose a novel protocol wavREPro that aims to minimize the image size before its storage and then to enlarge it at reception. This process has been achieved by exploiting the Discrete Wavelet Transforms (DWT) namely Haar, Le Gall (5/3) and Daubechies (9/7) wavelets. These tools represent the image in the multi-resolution domain that follows the human psycho-visual system. Therefore, the reduced image is none other than the approximation of the image. Its magniﬁcation is carried out by either cancelling the details (wavREProZ) or estimating them (wavREProED) using the DWT−1 on the reduced image. Our experiments have been conducted on a PET (Positron Emission Tomography) medical image database and the results have been presented for the three well-known color spaces RGB, HSV and YCbCr. The reported results have promoted the wavREProZ application with the Haar wavelets on RGB images since it achieved maximum ﬁdelity between the original and reduced then enlarged images. The good performance of this approach encourages its adoption to display images on screens having diﬀerent sizes. Keywords: Telemedicine · Archiving · Transmission · Medical images · Discrete Wavelet Transforms · Image reduction · Image expansion  
   
  1  
   
  Introduction  
   
  The reduction and expansion of digital images are current, useful and even necessary operations in many applications related to the imaging domain especially in the medical ﬁeld [7,14]. In fact, the big size of medical images [4,24] make their transmission and archiving quite diﬃcult due to the limitation of both the hard drive capacity and the transfer rate [10]. The only possible solution to overcome this problem is to reduce the size of these ﬁles by compression techniques c Springer International Publishing AG 2018  V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8 45  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  525  
   
  such as JPEG [11], JPEG 2000 [34], Fractal coding methods [6], Region of Interest Coding Techniques [12,17], Lossless dynamic and adaptive compression [9], low-complexity compression [29] and genetic algorithms [33] and REPro (Reduction/Expansion Protocol) [2]. In this work, we are interested in REPro [11] that compresses images by reducing their deﬁnition (pixel number). In this context, various methods have been developed such as the decimation by square-square mesh [15], the decimation from a square mesh to a staggered mesh [28] and the decimation from a staggered mesh to a square mesh. On the other hand, the enlargement process is required to access to the image details. It can also be used to increase the resolution of the image in the same spatial support to improve the visual comfort of the viewer. In the literature, diﬀerent techniques have been utilized for enlarging color images [27] namely the zero-padding [26], the polynomial nearest neighbor [32], the linear, quadratic and cubic interpolations and the cardinal spline transformation [13]. In our research, a novel approach has been developed to reduce and enlarge PET (Positron Emission Tomography) images. We have exploited the image multiresolution representation using Discrete Wavelet Transforms (DWTs) [8, 16,19,25,30] in the reduction and expansion phases. This paper is organized as follows. Section 2 is reserved to the presentation of our new approach wavREPro and its two versions. In this part, we also present an overview about the diﬀerent used tools which are the DWTs and the image quality metrics. Section 3 presents our experimental results and their assessments. In the last section (Sect. 4), we summarize the main contributions of our work.  
   
  2 2.1  
   
  Proposed Approach Medical Context  
   
  Telemedicine is an eﬀective solution to remedy the lack of medical specialists and equipment. Indeed, thanks to this technology, it is possible to exchange information having diﬀerent sizes and natures between a tele-staﬀ. This fact requires the adaptation of the image size to the screen size mainly when displaying medical images [20]. However, these images are usually large which can slow the communication. Furthermore, to display these images, they must also be adapted to the resolution of the screens [31]. In this context, REPro permits the reduction of the image deﬁnition that speeds its transmission. On the other hand, this protocol can enlarge the transferred image to ensure more visual comfort or it may further reduce the image deﬁnition to be adaptable to the low resolutions of some display devices such as tablets and smart phones (Fig. 1). 2.2  
   
  Methodology  
   
  To reduce or to enlarge the image, we have chosen to transform the image to the multiresolution domain to beneﬁt from its simultaneous spatial and frequency locations. This process is carried out by the use of the Discrete Wavelet Transforms (Fig. 2).  
   
  526  
   
  H. Amri et al.  
   
  Fig. 1. Image transmission process using REPro  
   
  Fig. 2. Protocol wavREPro  
   
  Where “ori.Im” is the original image, DWT is the Discrete Wavelet Transforms, LUT is the Look-Up Table, RI is the reduced image, RILUT is the approximation space related to the applied DWT, REI is the reduced then enlarged image. 2.2.1 Used Wavelet Transforms Wavelets are interesting tools as they provide a simultaneous frequency and spatial locations of the image. This feature following the human psychovisual model allows wavelets to be exploited in various image processing applications such as compression (JPEG 2000), ﬁltering [3], segmentation [5] and watermarking [19]. To apply a DWT on an image, we simply utilized it on lines then on columns. The original image was ﬁrst decomposed into an approximation Ap0 and 3 detail sub images called HD0 , VD0 and DD0 which denoted Horizontal Details, Vertical Details and Diagonal details, respectively [23]. The recursive application of wavelets yielded the representation of the image in the multiresolution domain at level n as shown in Fig. 3. The level n denoted the number of iterations of the application of wavelets.  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  527  
   
  Fig. 3. Representation of an image decomposition: one level and two level  
   
  In this work, three well-known transforms were exploited. In fact, the Haar wavelet was used for its simple implementation [22]. Moreover, we utilized Le Gall 5/3 and Daubechies 9/7 wavelets due to their frequent usages in the JPEG 2000 compression standard. The equations of Haar, 5/3 et 9/7 DWTs are depicted in Eqs. 1, 2 and 3, respectively.  s[n] = 12 (s0 [n] + d0 [n]) (1) d[n] = 12 (s0 [n] − d0 [n])    d[n] = d0 [n] - 12 (s0 [n + 1] + s0 [n]) (2)   s[n] = s0 [n] + 14 (d[n] + d[n - 1]) + 12  1  ((s0 [n + 2] + s0 [n − 1]) − 9 (s0 [n + 1] + s0 [n])) + 12 d[n] = d0 [n] + 16   s[n] = s0 [n] + 14 (d[n] + d[n - 1]) + 12 (3) where s0 and d0 are the initial approximation and details and s and d are the new approximation and details. Figure 4 illustrated the image decompositions in one level and two level after the application of the 5/3 wavelet on an original color image (Fig. 4a).  
   
  Fig. 4. Image decomposition using the 5/3 wavelet: (a) original image, (b) decomposition in level 1, (c) decomposition in level 2  
   
  528  
   
  H. Amri et al.  
   
  2.2.2 The WavREPro Protocol The wavREPro protocol (or “Reduction/Expansion Protocol based on wavelets”) exploited the DWTs not only to reduce the image but also to enlarge it. Two versions of this protocol were proposed (Fig. 5). On the one hand, we obtained wavREProZ when the wavREPro protocol used Zero details. On the other hand, wavREProED represented wavREPro using enlarged details. These two approaches used the same reduction process that involved DWTs. This aimed to get the approximation on which we applied a Look-Up Table (LUT) [1] transform before its transmission to respect the image coding standards. We explain below the expansion process of wavREProZ and wavREProED.  
   
  Fig. 5. Image reduction by wavREPro  
   
  2.2.2.1 The wavREProZ Protocol When the user received the reduced image (RI), it applied on it a color palette (Look-Up Table: LUT). This table was based on linear functions to make the values in accordance with the approximation space related to the applied DWT. The resulting matrix was called RILUT. We associated to this matrix 3 zero matrices having the same dimensions as RILUT. These matrices were considered as matrices of Horizontal Details (HD = 0), Vertical Details (VD = 0) and Diagonal Details (DD = 0). Finally, DWT−1 was applied on the set {RILUT, HD = 0, VD = 0, DD = 0} to get the reduced then enlarged image using wavREProZ and we named it REI-wavZ (Fig. 6).  
   
  Fig. 6. Expansion of the reduced image using wavREProZ  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  529  
   
  Fig. 7. Decomposition of the reduced image using DWT  
   
  2.2.2.2 The wavREProED Protocol This protocol tried to ﬁnd the vertical (VD), horizontal (HD) and diagonal (DD) details lost in the reduction phase. This process was carried out in two phases. In fact, the DWT was applied on the reduced image as illustrated in Fig. 7. Then, the DWT−1 is carried out on each of the Horizontal Details HDR, Vertical Details VDR and Diagonal Details DDR of the reduced mage (RI). To compute one of these components, the other components should be cancelled as described in Fig. 8. Thus, to estimate a detail component, we have enlarged its counter-parts obtained from the application of the DWT on the reduced image while respecting the frequency location of these details.  
   
  Fig. 8. Computation of the diﬀerent details using wavREProED: (a) computation of HD, (b) computation of VD, (c) computation of DD  
   
  Finally, to get the image enlarged by the wavREProED protocol, we have adapted the reduced image RI to the approximation space related to the used DWT to obtain the same image RILUT used by wavREProZ. The magniﬁed image (REI-wavED) is obtained by applying the DWT−1 on the set {RILUT, HD, VD, DD} as illustrated in Fig. 9. 2.2.3 Image Quality Metrics The image quality metrics were considered in our experiments to assess the level of distortion introduced by the reduction-expansion process. In this work, we used the Peak Signal to Noise Ratio (PSNR) and the Structural Similarity Index Metric (SSIM) to get an objective evaluation of the performance of the proposed approaches.  
   
  530  
   
  H. Amri et al.  
   
  Fig. 9. Expansion of the reduced image using wavREProED  
   
  2.2.3.1 Structural SIMilarity The Structural SIMilarity (SSIM) index is a method for measuring the similarity between two images where we focus on the structure image ﬁdelity. The SSIM [18] is expressed by Eq. 4. SSIM (x, y) =  
   
  (2μx μy + C1 )(2σxy + C2 ) (μ2x + μ2y + C1 )(σx2 + σy2 + C2 )  
   
  (4)  
   
  C1 = (K1 L)2 , C2 = (K2 L)2 where μx and μx denote the average values of the images X and Y respectively, σx and σy are the standard deviations (the square root of variance) of X and Y σxy is the covariance of X and Y. L is the dynamic range of the pixel values (255 for the images encoded on 8 bits) and C1 and C2 are small positive constants (K1 and K2  1). At each pixel (i, j), a local SSIM (i, j) index is deﬁned by evaluating the average, the standard deviation and the covariance on a local neighbor around that pixel (i, j). The overall quality of the image is measured by the Means SSIM index (MSSIM) which is expressed by Eq. 5. M SSIM =  
   
  1  SSIM (i, j) M i j  
   
  (5)  
   
  where M is the total number of local SSIM indices. 2.2.3.2 Peak Signal Noise Ratio The PSNR quantiﬁes the image distortion in decibel (dB) [21]. It is a function of the Mean Square Error (MSE). Equations 6 and 7 describe the MSE and PSNR metrics, respectively. n  m    ∗ 2 Iij − Iij M SE =  
   
  i=1 j=1  
   
  (6)  
   
  nm 2  
   
  P SN R (I, I ∗ ) = 10 log 10(X max /M SE(I, I ∗ )) where I and I* are images having the same size n × m.  
   
  (7)  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  531  
   
  When a PSNR is upper than or equal to 30 dB, it reﬂects an acceptable image degradation. From 60 dB, it represents an imperceptible image distortion. 2.2.3.3 Selection Rate The quantiﬁcation of the distortion introduced by two methods on an image database was generally carried out according results provided by P SN Raverage and SSIMaverage . However, if the P SN Raverage of the ﬁrst approach is higher than that of the second method, this fact does not prove that the ﬁrst approach introduces less distortion on each image of the database. To get a more objective assessment, we introduced the concept of selection rate. Hence, the selection rate of the method 1 was simply the percentage of the images of the database where this method introduced less distortion compared to the second method. Considering this deﬁnition, we obtained selection rates based on PSNR and SSIM to evaluate the performances of the approaches on our image database.  
   
  3  
   
  Experiments and Discussion  
   
  We proposed to evaluate the performance of our two approaches wavREProZ and wavREproED and to analyze the impact of each color space (RGB, HSV, YCbCr) and each adopted wavelet on the reduction-expansion process. Our experiments were conducted on 30 PET images. Initially, we were interested in assessing the performance of each wavREPro version when the images were represented in the RGB color space. The reported results in Fig. 10 and Table 1 obviously showed that the adoption of the Haar wavelet in wavREPro yielded two diﬀerent performances n terms of PSNR and SSIM. Indeed, the use of this wavelet in the wavREProZ process, hence its name wavHaarZ, ensured the best degree of similarity between the original and reduced then enlarged images. However, the same wavelet caused the most image quality degradation when it was used in the wavREProED method, hence its name wavHaarED. In addition, we noted that PSNRs obtained after the application of 5/3 and 9/7 wavelets on PET images were very close (Fig. 10a). However, the results shown in Fig. 10b promoted the utilization of the 9/7 wavelet followed by the 5/3 wavelet in terms of SSIM. Thus, the Haar wavelet improved the performance of wavREProZ while it was preferable to use wavREProED with the 9/7 or 5/3 wavelets (Table 1). Where wav5/3Z and wav5/3ED denoted the 5/3 wavelets applied in wavREProZ and wavREProED, respectively. Similarly, wav9/7Z and wav9/7ED represented the 9/7 wavelets applied in wavREProZ and wavREProED, respectively. The results provided by Table 2 conﬁrmed the values of PSNR and SSIM. Indeed, wavHaarZ was selected as the best technique of reduction-expansion for all the PET images of the database when the color space was RGB.  
   
  532  
   
  H. Amri et al.  
   
  Fig. 10. Eﬀects of the wavREPro application on PET images represented in RGB color space: (a) Quality assessment of the RGB images in terms of PSNR, (b) Quality assessment of the RGB images in terms of SSIM  
   
  In order to evaluate the performances of wavREProZ and wavREProED and the impact of the choice of wavelets on the HSV (Hue Saturation Value) image quality, we converted the test images to this color space. Then, these images were reduced then enlarged. Finally, they were converted back to the RGB space. We exploited PSNR, SSIM and selection rates to illustrate the eﬀect of the reduction operation followed by the image magniﬁcation process. The results presented in Fig. 11 and Table 3 proved again that wavReproZ based on Haar wavelet transforms performed better in terms of PSNR and SSIM. Similarly to the results attained in the RGB color space, the Haar wavelet had the greatest performance when we adopted it in wavREProZ. But, contrary to the results provided in the RGB color space, wavREProED based on wavHaarED seemed more eﬃcient than wavREProED based on the 9/7 wavelets. Indeed, wavHaarED performed better than wav9/7ED for 20% of the database images in terms of PSNR and reached even 26.6% of this set in terms of SSIM (Table 4).  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  533  
   
  Table 1. Quality evaluation of the RGB images after the application of wavREPro. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED P SN Raverage 50.47 SSIMaverage  
   
  35.42  
   
  0.989  
   
  38.21  
   
  0.877  
   
  0.904  
   
  39.54 0.922  
   
  41.51 0.959  
   
  42.63 0.97  
   
  Table 2. Selection rates of wavelets applied on RGB images. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED PSNR 100%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  SSIM  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  100%  
   
  Fig. 11. Eﬀects of the wavREPro application on PET images represented in HSV color space: (a) Quality assessment of the HSV images in terms of PSNR, (b) Quality assessment of the HSV images in terms of SSIM  
   
  534  
   
  H. Amri et al.  
   
  Table 3. Quality evaluation of the HSV images after the application of wavREPro. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED P SN Raverage 44.30 SSIMaverage  
   
  42.85  
   
  0.985  
   
  28.62  
   
  0.971  
   
  0.858  
   
  31.46 0.883  
   
  29.84  
   
  32.51  
   
  0.915  
   
  0.935  
   
  Table 4. Selection rates of wavelets applied on HSV images. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED PSNR 80%  
   
  20%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  SSIM  
   
  26.67%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  73.33%  
   
  Fig. 12. Eﬀects of the wavREPro application on PET images represented in YCbCr color space: (a) Quality assessment of the YCbCr images in terms of PSNR, (b) Quality assessment of the YCbCr images in terms of SSIM  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  535  
   
  We also carried out our experiments on our test images that we converted to the YCbCr color space. Figure 12 illustrated the degree of resemblance between the original and reduced then enlarged images. The performances of the diﬀerent methods were summarized in Table 5. According to Fig. 11a, we clearly noticed that PSNRs are higher than 30 dB for all the applied methods. In other words, there was a good conservation of the content of all the images. Table 5. Quality evaluation of the YCbCr images after the application of wavREPro. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED P SN Raverage 38.50  
   
  35.39  
   
  39.67  
   
  41.20  
   
  42.54  
   
  43.38  
   
  SSIMaverage  
   
  0.891  
   
  0.940  
   
  0.945  
   
  0.966  
   
  0.973  
   
  0.913  
   
  On the other hand, we noted that PSNR and SSIM reached great values when wav9/7ED was adopted (Table 5). Moreover, the 5/3 wavelet provided the second best performance followed by the Haar wavelet. Therefore, wav9/7ED was obviously selected as the best technique since it ensured the most image content preservation (Table 6). Table 6. Selection rates of wavelets applied on YCbCr images. wavHaarZ wavHaarED wav5/3Z wav5/3ED wav9/7Z wav9/7ED PSNR 0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  100%  
   
  SSIM  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  0.0%  
   
  100%  
   
  0.0%  
   
  Finally, we noted that the Haar wavelet always gave the best results when it was included in wavREProZ whereas the 9/7 and 5/3 wavelets performed better when used in the wavREProED protocol. To highlight the impact of the space color choice on the wavREPro performance, we compared the best wavREPro approaches selected by each color space. This leaded us to compare the performances of wavHaarZ applied in RGB and HSV color spaces to those of wav9/7ED utilized in the YCbCr color space. Figure 13 and Tables 7 and 8 showed the performance assessments of methods in terms of PSNR and SSIM. We noted that RGB represented the best color space to adopt and that is why it was selected for all images (Fig. 13 and Tables 9 and 10).  
   
  536  
   
  H. Amri et al.  
   
  Fig. 13. Eﬀects of the wavREPro application on PET images: (a) Quality assessment of the images in terms of PSNR, (b) Quality assessment of the images in terms of SSIM  
   
  Table 7. Performance assessment of selected wavelets applied on TEP images in terms of P SN Raverage . wavHaarZ (RGB) wavHaarZ (HSV) Ond9/7ED (YCbCr) 50.47  
   
  44.30  
   
  43.38  
   
  Table 8. Performance assessment of selected wavelets applied on TEP images in terms of SSIMaverage . wavHaarZ (RGB) wavHaarZ (HSV) wav9/7ED (YCbCr) 0.989  
   
  0.985  
   
  0.973  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  537  
   
  Table 9. Selection of the best wavelet according to PSNR. wavHaarZ (RGB) wavHaarZ (HSV) wav9/7ED (YCbCr) 100%  
   
  0.0%  
   
  0.0%  
   
  Table 10. Selection of the best wavelet according to SSIM. wavHaarZ (RGB) wavHaarZ (HSV) Wav9/7ED (YCbCr) 100%  
   
  4  
   
  0.0%  
   
  0.0%  
   
  Conclusion  
   
  In this paper, we presented a new approach of reduction and enlargement called wavREPro that exploited the image representation in the multiresolution domain. This ﬁeld provided simultaneously the spatial and frequency locations of the image and followed the human psycho-visual model. The transition to this domain was achieved using the Discrete Wavelet Transforms. In this context, we used three types of DWTs namely Haar, Le Gall (5/3) and Daubechies (9/7) wavelets. These methods allowed the reduction of the image before its storage or transfer then its enlargement before its display on the screen. The minimized image was none other than the approximation that was the result of the DWT application on the image to transfer. To enlarge the image, we proposed two versions of wavREPro which added details to the obtained approximation and then applied the DWT−1 on the 4 components. The wavREPoZ version canceled details while the wavREProED version estimated the details of the image transformed to the multiresolution domain. The performances of these diﬀerent approaches were assessed in diﬀerent color spaces namely RGB, HSV and YCbCr. The obtained results promoted the use of the Haar wavelet, which canceled the details in the image magniﬁcation process. We also noted that it was appropriate to exploit the RGB space color for the application of wavREPro on PET images. In addition, it was obviously noted that the Haar wavelet was more eﬀective when used in wavREProZ while wavREProED achieved good results when the 5/3 and 9/7 wavelets were utilized. This work has been exploited to reduce images before their storage or transfer. In addition, our approach has ensured their adaption to the diﬀerent types of screens before their display. This can be carried out by resizing the image to ﬁt appropriately the screen size.  
   
  References 1. Abdmouleh, M.K., Khalfallah, A., Bouhlel, M.S.: A chaotic cryptosystem for color image with dynamic look-up table. In: Proceedings of the 7th International Conference on Image and Signal Processing (ICISP 2016), pp. 91–100. Springer International Publishing, Trois-Rivieres (2016)  
   
  538  
   
  H. Amri et al.  
   
  2. Amri, H., Hanna, F., Lapayre, J.C., Khalfallah, A., Bouhlel, M.S.: REPRO: a new reduction/expansion protocol to increase the performance of image transmission in medical telediagnosis platforms. Biomed. Eng.: Appl. Basis Commun. 27(6), 1550054 (2015) 3. Aramendi, E., Irusta, U., Ayala, U., Naas, H., Kramer-Johansen, J., Eftestol, T.: Filtering mechanical chest compression artefacts from out-of-hospital cardiac arrest data. Resuscitation 98, 41–47 (2016) 4. Aribi, W., Khalfallah, A., Bouhlel, M.S., Elkadri, N.: Evaluation of image fusion techniques in nuclear medicine. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 875–880 (2012) 5. Bai, X., Jin, J.S., Feng, D.: Segmentation-based multilayer diagnosis lossless medical image compression. In: Proceedings of the Pan-Sydney Area Workshop on Visual Information Processing, VIP 2005, pp. 9–14 (2004) 6. Bhavani, S., Thanushkodi, K.G.: Comparison of fractal coding methods for medical image compression. IET Image Process. 7(7), 686–693 (2013) 7. Bonnans, V., Humbert, P., Pazart, L., Marzani, F., Lapayre, J.C., Lang, C.: Collaborative platform for skin cancer screening and associated optical ﬁbered probe for diagnosis. In: Sin’Fran 2009, Singaporean-French IPAL Symposium, pp. 44–55 (2009) 8. Boudjelal, A., Messali, Z., Boubchir, L., Chetih, N.: Nonparametric Bayesian estimation structures in the wavelet domain of multiple noisy image copies. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 495–501 (2012) 9. Castiglione, A., Pizzolante, R., De Santis, A., Carpentieri, B., Castiglione, A., Palmieri, F.: Cloud-based adaptive compression and secure management services for 3D healthcare data. Future Gener. Comput. Syst. 43(44), 120–134 (2015) 10. Chaabouni, I., Fourati, W., Bouhlel, M.S.: Using ROI with ISOM compression to medical image. IJCVR 6(1/2), 65–76 (2016) 11. Ciznicki, M., Kurowski, K., Plaza, A.: Graphics processing unit implementation of JPEG2000 for hyperspectral image compression. J. Appl. Remote Sens. 6(1), 061507-1–061507-14 (2012) 12. Doukas, C., Maglogiannis, I.: Region of interest coding techniques for medical image compression. IEEE Eng. Med. Biol. Mag. 26(5), 29–35 (2007) 13. Fahmy, M.F., Fahmy, G., Fahmy, O.F.: B-spline wavelets for signal denoising and image compression. Signal Image Video Process. 5(2), 141–153 (2011) 14. Fuin, D., Garcia, E., Guyennet, H., Lapayre, J.C.: Collaborative interactions for medical e-Diagnosis. HPCN Int. J. High-Perform. Comput. Netw. 5(3), 189–197 (2008) 15. Gotchev, A.P., Egiazarian, K.O., Marchokov, G., Saramki, T.: A near least squares method for image decimation. ICIP 2, 929–932 (2003) 16. Hassen, W., Mbainaibeye, J., Olivier, C., Amiri, H.: New video encoder based on wavelet coeﬃcients and motion compensation. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 440–447 (2012) 17. Hernndez-Cabronero, M., Blanes, I., Pinho, A.J., Marcellin, M.W., Serra-Sagrist, J.: Progressive lossy-to-lossless compression of dna microarray images. IEEE Signal Process. Lett. 23(5), 698–702 (2016) 18. Joshi, Y.G., Loo, J., Shah, P., Rahman, S., Chang, Y.C.: A novel low complexity local hybrid pseudo-SSIM-SATD distortion metric towards perceptual rate control. In: 2013 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB), pp. 1–6 (2013)  
   
  Discrete Wavelet Transforms for PET Image Reduction/Expansion  
   
  539  
   
  19. Kammoun, F., Khalfallah, A., Bouhlel, M.S.: New scheme of digital watermarking using an adaptive embedding strength applied on multiresolution ﬁled by 9/7 wavelet. Int. J. Imaging Syst. Technol. 16(6), 249–257 (2006) 20. Kassab, R., Lapayre, J.C., Aupet, J.B., Marzani, F., Pieralli, C.: Scars collaborative telediagnosis platform using adaptive image ﬂow. Integr. Comput.-Aided Eng. ICAE 1(20), 3–14 (2013) 21. Amri, H., Khalfallah, A., Lapayre, J.C., Bouhlel, M.S.: Watermarking for improving the reduction-expansion process of medical images (WREPro). Int. J. Imaging Robot.TM 16(3), 124–139 (2016) 22. Khalfallah, A., Bouhlel, M.S.: The impact of the concept of the family relative signatures on the non-blind watermarking in the multiresolution domain using 9/7 and 5/3 wavelets. Int. J. Inf. Commun. Technol. 4(3–4), 111–118 (2011) 23. Khalfallah, A., Brahim, K., Olivier, C.: A new approach to encrypted semi-blend watermarking in multi resolution ﬁeld by 9/7 wavelet. In: IEEE International Conference of E-Medical Systems E-Medisys 2007. Frs, Morocco (2007) 24. Lazrag, H., Naceur, M.S.: Despeckling of intravascular ultrasound images using curvelet transform. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 365–369 (2012) 25. Lazrag, H., Naceur, M.S.: Wavelet ﬁlters analysis for speckle reduction in intravascular ultrasound images. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 375–379 (2012) 26. Liu, S., Wang, Q., Liu, G.: A versatile method of discrete convolution and FFT (DC-FFT) for contact analyses. Wear 243(1/2), 101–111 (2000) 27. Nini, B.: Projection based permutation of color images. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 460–467 (2012) 28. Petraglia, A., Pereira, J., Barugui, F.: Low-sensitivity IIR switched-capacitor decimation ﬁlters using delay lines with staggered T/H stages. IEEE Proc. - Circuits Devices Syst. 153(5), 193–198 (2006) 29. Pizzolante, R., Carpentieri, B., Castiglione, A.: A secure low complexity approach for compression and transmission of 3-D medical images. In: Proceedings of the 2013 Eighth International Conference on Broadband and Wireless Computing, Communication and Applications, BWCCA 2013, pp. 387–392. IEEE Computer Society (2013) 30. Saidani, T., Atri, M., Said, Y., Tourki, R.: Real time FPGA acceleration for discrete wavelet transform of the 5/3 ﬁlter for JPEG 2000. In: 2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), pp. 393–399 (2012) 31. Sanchez Santana, M.A., Aupet, J.B., Betbeder, M.L., Lapayre, J.C., Camarena, A.: A tool for telediagnosis of cardiovascular diseases in a collaborative and adaptive approach. J. Univers. Comput. Sci. JUCS 19(9), 1275–1294 (2013) 32. Schafer, R.W., Rabiner, L.R.: A digital signal processing approach to interpolation. Proc. IEEE 61(6), 692–702 (1973) 33. Shih, F.Y., Wu, Y.T.: Robust watermarking and compression for medical images based on genetic algorithms. Inf. Sci. 175(3), 200–216 (2005) 34. Wu, X., Li, Y., Liu, K., Wang, K., Wang, L.: Massive parallel implementation of JPEG2000 decoding algorithm with multi-GPUS. In: Proceedings of the SPIE, vol. 9124, pp. 91240S–91240S-6 (2014)  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform Anca Ignat1(&) and Mihaela Luca2 1  
   
  Faculty of Computer Science, University “Alexandru Ioan Cuza” of Iași, Iași, Romania [email protected]  2 Institute of Computer Science, Romanian Academy, Iaşi, Romania [email protected]   
   
  Abstract. Dual Tree Complex Wavelet Transform (DTCWT) is a practical tool offering the possibility of extracting characteristics from images, a transformation which has good directional selectivity, is approximately shift invariant and it is computationally efﬁcient. DTCWT may be employed in different stages of image processing, including multiscale texture featuring. We are measuring texture similarities on characteristics vectors by applying cosine, Pearson correlation coefﬁcient, entropy-based and histogram related distances and we tested these measures on slightly rotated samples from Brodatz texture album. Comparisons and observations are made on the methods that we employed. Keywords: Dual Tree Complex Wavelet Transform Similarity measures  Texture  
   
    
   
  Feature extraction  
   
    
   
  1 Introduction Understanding images is a complex process which implies training during long periods of time in order to use high amounts of accumulated knowledge. To recognize images similar to those that we are acquainted to, we are scaling them and situating them in environmental contexts, in order to place the objects from the image in an appropriate scenario. As human beings we are merely evaluating colors, textures, lines, shapes, shades and lights, materials and spatial positioning, while a computer needs a large variety of mathematical models attempting to represent the cognitive processes in order to obtain comparable results. Intelligent agent architectures aim to adapt to each special task apparently simple for human eye-brain chain which in fact is a very complex paradigm. Image features are extracted and decomposed in hierarchical stages, color and texture being characterized by complex mathematical methods. Texture characterization is important in many domains, among them being the medical imaging evaluation and interpretation, industrial applications, remote sensing, etc. [1–4]. With the actual amazing increase of the internet image databases it is essential in automatic object retrieval to have a good texture identiﬁcation procedure. The texture featuring and analysis with a relatively new mathematical tool, the Dual Tree Complex Wavelet Transform DTCWT [5, 6], is discussed in our paper. Note that the DTCWT is abbreviated with an italic C to differ from the Continuous Wavelet Transform. © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8_46  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  541  
   
  We used the classic Brodatz album with texture images [7] and some images from our experimental database. Texture features were computed using the six directional coefﬁcients provided by DTCWT applied on all these texture images and their rotated versions, as we will further explain. In order to identify a certain texture in an area of an image, we apply several distances (cosine, Pearson correlation coefﬁcient, entropy-based and histogram related) on the extracted features.  
   
  2 Disadvantages of Wavelet Transforms The main disadvantages of (real) wavelet transform [8, 9] are: oscillations around singularities (1), shift variance (2), aliasing (3) and the lack of directionality (4). These issues can be overcome by using Complex Wavelets. Yet, it is difﬁcult to compute complex wavelets satisfying the perfect reconstruction property. In [5, 6], Kingsbury introduced the Dual Tree Complex Wavelet Transform (DTCWT) which is a new way of computing complex wavelets with perfect reconstruction with a 2d:1 redundancy for d dimensional signals. Important aspects about computing DTCWT, its properties and possible applications were developed in [9–11].  
   
  3 Discussion on Dual Tree Complex Wavelet Transform The decimated Discrete Wavelet Transform [12] has two major inconveniences: shift variance (small shifts in the input signal can generate big variations in the wavelet coefﬁcients) and reduced directional selectivity (especially in diagonal directions). To overcome these limitations one can use complex wavelets. The difﬁculty in computing complex wavelets is given by the problem of designing perfectly reconstructed ﬁlter banks beyond the ﬁrst level of decomposition. The problem was solved by Kingsbury [5, 6]. He developed the Dual Tree Complex Wavelet Transform, which provides approximate shift invariance, good directional selectivity, uses short linear phase ﬁlters with perfect reconstruction and has efﬁcient computation costs (O(N) for 1D-signals). The toll to be paid for these properties is increased redundancy (2:1 for 1D-signals, 4:1 for 2D signals, 8:1 for 3D, and so on) but still it is much less than the undecimated wavelet transform. In order to obtain approximate shift invariance for the decimated DWT, one must double the sample rate at each level of decomposition; this is equivalent with having two parallel fully decimated trees and also the ﬁlters at level 1 must be delayed by one sample. After level 1, to reestablish the uniform interval sampling, one must work with odd length ﬁlter on one tree and even length ﬁlter on the other. In order to have a better symmetry between the trees odd and even ﬁlters must alternate when changing the decomposition level. The output obtained from the two parallel trees can be interpreted as the real and the imaginary parts of the complex wavelet coefﬁcients. In order to compute CWT for 2D signals, each level of decomposition contains two stages: one consists in ﬁltering the rows and the second stage is to ﬁlter the result along columns.  
   
  542  
   
  A. Ignat and M. Luca  
   
  When applied to digital images the DTCWT yields at each level of decomposition six bandpasses sub-images of complex coefﬁcients. These sub-images provide strong directional selectivity at angles ±15º, ±45º, and ±75º. For feature extraction the energy, the mean, the standard deviation, the entropy of the six complex directional coefﬁcients (or their amplitude) yielded by the DTCWT are usually employed: in [13, 14] they use energy and standard deviation, [15] works with the mean, the standard deviation of the amplitude of the sub-band images, and [16] employs the mean and the entropy. In [17] features were extracted using a threshold for counting the signiﬁcant elements of the DTCWT coefﬁcients. In [8, 18, 19], rotation invariant features were designed using DTCWT. In our paper, we study the influence of rotation and of changing the brightness of images (by applying a c transformation) over the DTCWT coefﬁcients. As features we use the histograms of the DTCWT directional sub-images. For comparisons, we employed ten similarity measures for probability density functions presented in [20] and for classiﬁcation we used the minimum-distance classiﬁer and SVM (Support Vector Machine) [21].  
   
  4 Texture Features Selected with DTCWT Due to the exponentially growing amount of digital images, each new aspect has to be taken into account to facilitate the automatic image classiﬁcation and clustering. In order to group the photos in classes depicting the same scene, it is possible to extract by means of segmentation some texture samples from each image. We might classify the image to a certain class by taking into account the information provided by the retrieved dominant textures. In order to identify textures, we extract feature vectors and we match the texture from the image with textures from a database. We tested some similarity measures in order to compare the textures of the test images with those from the database. The class in which we introduce the test image is the one that gives most matches. We study in this paper the effect of rotation on classiﬁcation process using DTCWT for feature extraction and we proposed some similarity measures. As an example, Fig. 1 is presenting an image from our town which contains as main textures bark, grass and pavement (Fig. 2). In Fig. 3 we have the same scene but it was taken by rotating the photo camera with an angle about 15–20°. We manually extracted three samples of textures from both of the images. The selected textures are depicted in Figs. 2 and 4. The samples represent the same three textures from both images (bark, grass, and pavement) but they are not cropped from the same spot in order to catch different illuminations of the scene. Alike visual detection of natural environments, we note that analysing the directions of important lines, shades, colours, we may detect, on different scales, different properties that help us to identify a texture. Because of its good directional selectivity, we considered the DTCWT as an appropriate tool for texture characterization. We have considered a database containing 12 grayscale texture images from the Brodatz album (Fig. 5). We uniformly preprocessed these images (the original and the rotated ones) in order to obtain a size of 64  64.  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  Fig. 1. Image of a sidewalk in Iasi, Romania  
   
  (a)  
   
  (b)  
   
  (c)  
   
  Fig. 2. (a), (b) Selected textures: bark, grass, pavement  
   
  Fig. 3. Rotated scene of the original image from Fig. 1  
   
  543  
   
  544  
   
  A. Ignat and M. Luca  
   
  Figure 6(a) and (b) are presenting the six directional DTCWT sub-band images Sj;1 for the texture samples from Fig. 4.  
   
  Fig. 4. Bark, grass, pavement samples from Fig. 3  
   
  Bark  
   
  Brick  
   
  Grass  
   
  Leather  
   
  Pigskin  
   
  Raffia  
   
  Sand  
   
  Straw  
   
  Water  
   
  Weave  
   
  Wood  
   
  Wool  
   
  Fig. 5. Brodatz textures database – 12 selected samples for our tests  
   
  For the DTCWT we used the following indexes for the six sub-images: j = 1 for +15º, j = 2 for +45º, j = 3 for +75º, j = 4 for −75º, j = 5 for −45º, and j = 6 for −15º. We tested different levels of wavelet decomposition (D = 1, 2, 3, 4) thus obtaining 2  6  D directional coefﬁcients. The provided sub-band images are complex: Wj;d ¼ Vj;d þ iUj;d ; j ¼ 1; 2; . . .; 6:  
   
  ð1Þ  
   
    The DTCWT provides the Vj;d ; Uj;d pairs for j = 1,…, 6, d = 1,…, D, along with the real lowpass image from the last decomposition   level. For our computations we employed only the amplitude Sj,d of the Vj;d ; Uj;d coefﬁcients, i.e.:   qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 2 þ U 2 ; j ¼ 1; . . .; 6; d ¼ 1; . . .; D Sj;d ¼ Wj;d  ¼ Vj;d j;d  
   
  ð2Þ  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  545  
   
  (a)  
   
  (b)  
   
  Fig. 6. (a) Selected textures: bark, grass, pavement 2 and the DTCWT amplitudes in the three directions: 15˚, 45˚, 75˚. (b) Selected textures: bark, grass, pavement 2 and the DTCWT amplitudes in the three directions: −15˚, −45˚, −75˚, d = 1  
   
  546  
   
  A. Ignat and M. Luca  
   
    We computed the Sj;d ; j ¼ 1; . . .; 6; d ¼ 1; . . .; D sub-band images for the normalized texture images (with intensity values in [0, 1]). We multiplied the Sj,d by 100, rounded to the nearest integer and computed the histogram, thus obtaining six 100–dimensional feature vectors for each wavelet decomposition level. In order to compare these histograms we tested some of the distances described in [20] (ﬁve from the v2 family, ﬁve from the Shannon’s entropy family, the cosine and the Pearson correlation coefﬁcient). We selected ﬁve that gave the best results. Let p and q be two histograms of size m = 100 we want to compare. We used the following distances in order to compare the histograms: dcos ðp; qÞ ¼ 1  cosðp; qÞ  
   
  ð3Þ  
   
  m P  
   
  pi qi i¼1 s ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ cosðp; qÞ ¼ m m P P p2i q2i i¼1  
   
  dcorr ðp; qÞ ¼ r ðp; qÞ ¼  
   
  ð4Þ  
   
  i¼1  
   
  1  r ðp; qÞ 2  
   
  ð5Þ  
   
  covðp; qÞ rp rq  
   
  ð6Þ  
   
  where by cov(p,q) we denoted the covariance of the random variables p, q, and rp, rq are the standard deviations of p and q respectively. From the Shannon’s entropy family we used Topsøe, Jeffreys and Jensen difference distances: dTop ðp; qÞ ¼  
   
  m  X i¼1  
   
  2pi 2qi þ qi log pi log ðpi þ qi Þ ðpi þ qi Þ  
   
  dJ ðp; qÞ ¼  
   
  dJd ðp; qÞ ¼  
   
  ð7Þ  
   
  m X pi ðpi  qi Þ log qi i¼1  
   
  m  X pi log pi þ qi log qi i¼1  
   
    
   
  2  
   
    
   
  pi þ qi pi þ qi log 2 2  
   
  ð8Þ  ð9Þ  
   
  and from the v2 family we employed the squared v2: dSqChi ðp; qÞ ¼  
   
  m X ð pi  qi Þ 2 i¼1  
   
  pi þ qi  
   
  ð10Þ  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  547  
   
  We employed these similarity measures in the following way: dhist ðX; Y Þ ¼  
   
  D X 6 X  
   
  d ðhistðSX;j;d Þ; histðSY;j;d ÞÞ  
   
  ð11Þ  
   
  d¼1 j¼1  
   
  where d* is one of the ﬁve distances described above. Figure 7 depicts the histograms of the DTCWT coefﬁcients in the direction of 75° (histograms of S3) for the Sand, Water and Wood textures. As can be seen, these histograms can be used as a separation measure between images.  
   
  Fig. 7. Histogram of the DTCWT coefﬁcients for the 75° direction for Sand, Water and Wood original textures  
   
  For testing the features and the classiﬁers we applied two types of transformations: a geometrical one (i.e. rotations with different rotation angles) and c intensity transforms. We used the following c transformation [22]: T ðr Þ ¼ r c :  
   
  ð12Þ  
   
  Using DTCWT, the above presented similarity measures and minimum distance classiﬁers or SVM we seek to retrieve for each transformed image the original texture that produced it.  
   
  5 Results and Discussions For the numerical tests we employed MATLAB. To compute the DTCWT we adapted [23] the software package from Professor Nick Kingsbury’s web page [24]. As mentioned above, we tested the extracted features and the classiﬁers on 12 textures selected from the Brodatz album ([7], Fig. 5). We consider as classiﬁers the minimum distance classiﬁer (using the distances previously introduced, i.e. (3), (5), (7)–(10)) and SVM. All the texture images are of size 64  64.  
   
  548  
   
  A. Ignat and M. Luca  
   
  Four types of classes representing the textures were considered. The ﬁrst type has classes containing only one texture, the original one. The rotated and the c transformed ones are used separately for tests. The last three types of classes contain more than one image. The original Brodatz album contains images of size 512  512. Using these images and resizing we computed rotated and c transformed textures of the same size (512  512). For each such texture we extracted 64 (88) non-overlapping sub-images of size 64  64. Each class that represents a texture is formed by putting together these 192 (364) images. We consider three situations: in the ﬁrst two cases we treat independently the rotated and the c transformed images and in the third one the classes contain a mixture of all types of images (base, rotated, c transformed). In the rotation case the class is formed only with rotated sub-images and those extracted from the original texture. In the c transformed situation the class is formed only with original and c transformed images. We formed the training set by choosing randomly 50% of the class content (50% of each type of image: original, rotated, c transformed), the other ones were employed for classiﬁcation purpose. We have rotated the texture images with the following angles: 5°, 10°, 15° and 30°. In Fig. 8 are depicted the Rafﬁa and the Wood textures and their rotated versions.  
   
  Raffia.05  
   
  Raffia.10  
   
  Raffia.15  
   
  Raffia.30  
   
  Wood.05  
   
  Wood.10  
   
  Wood.15  
   
  Wood.30  
   
  Fig. 8. Brodatz textures database – 2 rotated samples for tests  
   
  We applied also several c transformations to the original Brodatz. In Fig. 9. we show for Grass, Wood and Sand different c-transformed variants of these textures. In this paper, we considered values for c in [0.5, 2]. In the case of classes with only one element we used the following ﬁve distances: cosine, correlation, Topsøe, Jensen difference, and squared v2 . For the rotation angle of 5°, 10° and 15° we get 100% identiﬁcation rate for all ﬁve considered distances. For 30° rotated textures the cosine distance provides 3 errors, the correlation distance 4 errors, the other three distances have each 2 errors. The comparisons between the Rafﬁa and Wood rotated textures and the original ones using the ﬁve similarity measures described applied to the histogram of the DT sub-band images are shown in Tables 1, 2, 3 and 4. The misidentiﬁcations appear for the 30° rotation angle.  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  Grass  
   
  Grass γ=0.6  
   
  Grass γ=1.6  
   
  Grass γ=2  
   
  Wood  
   
  Wood γ=0.6 Wood γ=1.6  
   
  Wood γ=2  
   
  Sand  
   
  Sand γ=0.6  
   
  Sand γ=2  
   
  Sand γ=1.6  
   
  549  
   
  Fig. 9. c-transformed Brodatz textures – Grass, Wood and Sand Table 1. Cosine and correlation distances - rotated Rafﬁa images Rafﬁa.05 dcos dcorr Bark.00 0.295 0.170 Brick.00 0.333 0.181 Grass.00 0.328 0.183 Leather.00 0.155 0.081 Pigskin.00 0.160 0.085 Rafﬁa.00 0.045 0.021 Sand.00 0.143 0.076 Straw.00 0.181 0.099 Water.00 0.281 0.147 Weave.00 0.228 0.119 Wood.00 0.342 0.178 Wool.00 0.136 0.072  
   
  Rafﬁa.10 dcos dcorr 0.285 0.163 0.347 0.189 0.323 0.180 0.138 0.072 0.165 0.088 0.073 0.037 0.131 0.069 0.208 0.114 0.286 0.149 0.241 0.126 0.346 0.180 0.141 0.075  
   
  Rafﬁa.15 dcos dcorr 0.280 0.161 0.342 0.186 0.324 0.182 0.125 0.065 0.175 0.094 0.080 0.040 0.122 0.064 0.193 0.106 0.284 0.149 0.204 0.106 0.337 0.175 0.145 0.077  
   
  Rafﬁa.30 dcos dcorr 0.288 0.167 0.390 0.212 0.297 0.167 0.126 0.066 0.188 0.101 0.138 0.072 0.150 0.080 0.220 0.122 0.326 0.171 0.208 0.109 0.407 0.213 0.184 0.098  
   
  The cosine and the correlation distances make the same mistake (Leather) and the other three distances misidentiﬁes Rafﬁa with Sand. Both mistakes are understandable from the visual point of view taking into account that we use a directional instrument. The same thing happens with the Wood texture, i.e., the cosine and the correlation distances provide Weave as classiﬁcation result and the other three classify Wood as Water. We repeated the same classiﬁcation procedure as we used for the rotated textures for the c transformed ones. We get 100% identiﬁcation rate for c 2 ½0:6; 1:7. In Table 5 are the classiﬁcation results for Grass and Sand with c ¼ 0:6 and in Table 6 are the comparisons results for Grass and Wood with c ¼ 2.  
   
  550  
   
  A. Ignat and M. Luca Table 2. Topsøe, Jensen difference and squared v2 distances - rotated Rafﬁa images Rafﬁa.05 dJd dT Bark.00 12.7 6.4 Brick.00 29.0 14.5 Grass.00 18.6 9.3 Leather.00 12.0 6.0 Pigskin.00 9.8 4.9 Rafﬁa.00 1.5 0.7 Sand.00 6.9 3.5 Straw.00 18.2 9.1 Water.00 30.8 15.4 Weave.00 16.5 8.3 Wood.00 29.2 14.6 Wool.00 9.5 4.7  
   
  dSq 21.0 48.8 30.9 20.4 17.8 2.7 12.8 30.3 50.8 27.3 46.5 16.9  
   
  Rafﬁa.10 dT dJd 12.5 6.2 29.3 14.6 18.6 9.3 11.3 5.7 9.9 5.0 2.3 1.1 6.7 3.3 18.0 9.0 31.2 15.6 16.5 8.2 29.8 14.9 9.6 4.8  
   
  dSq 20.6 49.2 30.9 19.4 17.8 4.2 12.4 30.0 51.2 27.1 47.3 16.9  
   
  Rafﬁa.15 dT dJd 12.3 6.2 29.5 14.8 18.3 9.2 11.0 5.5 9.8 4.9 3.0 1.5 6.5 3.2 17.8 8.9 31.4 15.7 15.6 7.8 30.4 15.2 9.8 4.9  
   
  dSq 20.5 49.7 30.7 18.9 17.6 5.6 12.0 29.8 51.5 25.8 48.4 17.4  
   
  Rafﬁa.30 dT dJd 13.3 6.6 32.7 16.3 17.9 9.0 10.5 5.3 10.9 5.4 8.6 4.3 6.9 3.4 18.0 9.0 33.9 17.0 12.7 6.4 35.7 17.9 12.6 6.3  
   
  dSq 22.0 53.9 30.1 18.3 19.4 15.3 12.6 30.0 55.1 21.4 56.4 21.9  
   
  Table 3. Cosine and correlation distances - rotated Wood images Wood.05 dcos dcorr Bark.00 0.605 0.333 Brick.00 0.192 0.104 Grass.00 0.619 0.336 Leather.00 0.447 0.235 Pigskin.00 0.448 0.236 Rafﬁa.00 0.350 0.182 Sand.00 0.421 0.221 Straw.00 0.409 0.220 Water.00 0.140 0.070 Weave.00 0.318 0.164 Wood.00 0.045 0.020 Wool.00 0.390 0.205  
   
  Wood.10 dcos dcorr 0.609 0.336 0.190 0.102 0.624 0.339 0.437 0.230 0.430 0.227 0.346 0.180 0.421 0.222 0.400 0.214 0.129 0.065 0.320 0.165 0.053 0.024 0.384 0.203  
   
  Wood.15 dcos dcorr 0.590 0.326 0.203 0.110 0.616 0.336 0.425 0.224 0.406 0.214 0.336 0.175 0.400 0.211 0.385 0.207 0.112 0.056 0.306 0.158 0.082 0.040 0.361 0.191  
   
  Wood.30 dcos dcorr 0.509 0.283 0.272 0.146 0.544 0.297 0.350 0.185 0.335 0.177 0.353 0.185 0.329 0.174 0.355 0.192 0.174 0.088 0.232 0.119 0.239 0.123 0.339 0.180  
   
  The ﬁve distances behave in the same manner as for the rotated textures: the cosine and the correlation misidentify the same texture, and Topsøe, Jensen difference and squared v2 make the same mistake. We also studied the influence of histogram equalization of the texture images before computing the DTCWT. When we use histogram equalization, we obtain better results for the c-transformed images i.e. the interval with zero errors in the classiﬁcation process extends to c 2 ½0:05; 5:4. On the contrary when this procedure is performed on the rotated images the results are worse. In the case of histogram equalization for rotated textures classiﬁcation the results are: the cosine and correlation distances have 1 error each for the 5°, 10°, 15° rotation angles and 4 respectively 5 misidentiﬁcations for 30°.  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  551  
   
  Table 4. Topsøe, Jensen difference and squared v2 distances - rotated wood images Wood.05 dJd dT Bark.00 37.6 18.8 Brick.00 19.7 9.9 Grass.00 43.1 21.6 Leather.00 33.2 16.6 Pigskin.00 37.8 18.9 Rafﬁa.00 30.0 15.0 Sand.00 35.4 17.7 Straw.00 28.1 14.0 Water.00 12.8 6.4 Weave.00 40.1 20.1 Wood.00 1.9 0.9 Wool.00 30.4 15.2  
   
  dSq 59.3 34.0 68.1 52.9 59.7 47.6 56.2 45.8 22.1 63.2 3.4 48.5  
   
  Wood.10 dT dJd 37.9 19.0 20.0 10.0 43.7 21.8 33.1 16.5 37.1 18.6 30.3 15.2 35.3 17.6 28.8 14.4 12.4 6.2 40.0 20.0 2.9 1.5 30.0 15.0  
   
  dSq 59.8 34.2 68.9 52.7 58.7 48.0 56.0 46.8 21.4 63.0 5.3 47.9  
   
  Wood.15 dT dJd 37.9 19.0 19.8 9.9 44.0 22.0 33.1 16.5 36.1 18.1 30.3 15.2 34.8 17.4 29.3 14.6 11.8 5.9 38.9 19.5 4.5 2.3 29.5 14.7  
   
  dSq 60.2 33.8 69.8 53.1 57.3 48.2 55.4 47.8 20.3 61.5 8.2 47.2  
   
  Wood.30 dT dJd 33.5 16.7 25.8 12.9 39.9 20.0 27.8 13.9 26.4 13.2 31.8 15.9 26.3 13.1 28.4 14.2 19.3 9.7 27.7 13.8 22.8 11.4 24.7 12.3  
   
  dSq 53.5 42.5 63.9 45.5 42.5 51.4 42.7 45.7 32.1 44.8 36.1 40.3  
   
  Table 5. Grass and Sand gamma transformed images comparisons (c ¼ 0:6) Grass dcos Bark 0.183 Brick 0.572 Grass 0.082 Leather 0.193 Pigskin 0.268 Rafﬁa 0.287 Sand 0.251 Straw 0.240 Water 0.566 Weave 0.417 Wood 0.589 Wool 0.305  
   
  dcorr 0.112 0.318 0.047 0.109 0.148 0.159 0.141 0.136 0.310 0.231 0.318 0.170  
   
  dT 6.7 34.6 1.9 6.9 22.6 16.8 15.8 13.6 49.5 18.9 41.5 26.7  
   
  dJdiff 3.4 17.3 0.9 3.4 11.3 8.4 7.9 6.8 24.8 9.4 20.8 13.3  
   
  dSq 11.7 57.5 3.3 11.9 38.0 27.9 27.6 23.8 79.1 31.0 65.4 44.1  
   
  Sand dcos 0.338 0.289 0.399 0.202 0.138 0.135 0.118 0.223 0.207 0.180 0.364 0.114  
   
  dcorr 0.194 0.155 0.223 0.108 0.073 0.070 0.061 0.123 0.106 0.092 0.190 0.060  
   
  dT 18.5 23.4 28.6 17.9 3.6 11.1 4.0 21.6 22.3 13.1 35.5 3.9  
   
  dJdiff 9.3 11.7 14.3 9.0 1.8 5.6 2.0 10.8 11.1 6.5 17.8 1.9  
   
  dSq 31.5 39.1 48.8 31.2 6.3 20.7 7.4 36.4 36.5 22.1 57.2 6.8  
   
  The Topsøe, Jensen difference and squared v2 distances have 6 errors each for the 30° rotated textures and no misidentiﬁcation for the smaller rotation angles. For the cases when the classes have more than one texture we used as classiﬁers SVM and minimum distance with cosine, Jeffreys, Topsøe, Jensen difference, and squared v2. When the rotations and c-transformations were treated separately, each class in the training set has 64 elements, 32 from the original texture and 32 from the transformed one. The test set contains a total of 768 images, 64 from each texture. The rotation angles are the same as previously (h 2 f5 ; 10 ; 15 ; 30 g) and the values for c are in f0:5; 0:6; 0:8; 0:81 ; 0:61 ; 2g. We observe from Table 7 that as h increases usually the classiﬁcation results improve, one of the poorest results is for  
   
  552  
   
  A. Ignat and M. Luca Table 6. Grass and Wood gamma transformed images comparisons ( c ¼ 2) Grass dcos Bark 0.200 Brick 0.468 Grass 0.179 Leather 0.138 Pigskin 0.146 Rafﬁa 0.171 Sand 0.134 Straw 0.205 Water 0.418 Weave 0.310 Wood 0.494 Wool 0.184  
   
  dcorr 0.119 0.256 0.102 0.075 0.078 0.092 0.072 0.115 0.224 0.168 0.262 0.099  
   
  dT 7.1 30.7 8.6 5.1 10.3 8.3 5.3 13.3 36.5 11.9 34.5 13.4  
   
  dJdiff 3.5 15.4 4.3 2.5 5.1 4.2 2.7 6.7 18.2 6.0 17.2 6.7  
   
  dSq 11.7 51.5 15.4 9.1 17.9 14.3 9.7 23.1 58.9 19.9 54.4 22.7  
   
  Wood dcos 0.526 0.187 0.530 0.349 0.386 0.286 0.384 0.291 0.162 0.344 0.112 0.320  
   
  dcorr 0.293 0.104 0.288 0.183 0.205 0.150 0.204 0.156 0.085 0.180 0.057 0.170  
   
  dT 32.1 17.4 36.3 26.8 41.0 30.6 37.3 18.7 23.1 43.2 6.9 33.7  
   
  dJdiff 16.0 8.7 18.1 13.4 20.5 15.3 18.7 9.3 11.5 21.6 3.5 16.9  
   
  dSq 51.0 31.1 57.2 42.9 64.5 48.1 59.7 30.4 38.6 67.7 12.3 53.7  
   
  Table 7. Classiﬁcation results for rotated case  
   
  SVM Jeffreys Topsøe Jensen Squared v2 Cos  
   
  Rotation angles h ¼ 5 h ¼ 10 96.75% (25) 96.09% (30) 91.54% (65) 92.06% (61) 93.88% (47) 93.75% (48) 93.88% (47) 93.75% (48) 93.62% (49) 93.62% (49) 85.29% (113) 84.64% (118)  
   
  h ¼ 15 95.31% (36) 92.32% (59) 93.75% (48) 93.75% (48) 93.75% (48) 85.94% (108)  
   
  h ¼ 30 95.44% (35) 92.84% (55) 94.79% (40) 94.79% (40) 94.66% (41) 85.16% (114)  
   
  h ¼ 5 , the DTCWT provides better separation of textures if the rotation angle is greater than 10°. Best results are obtained with the SVM and the Topsøe, Jensen difference distances. When applying c transformations, we considered pairs ðg; 1=gÞ; g\1. As was expected as g approaches 1 the results are getting better. Comparing the results provided by each pair ðg; 1=gÞ; g\1 one remarks that we get better results for c values greater than 1 which provide better contrast than c < 1. Again, with the SVM one gets the best results and Topsøe, Jensen difference, and squared v2 distances come next, making the same number of mistakes (Table 8). We also analysed cases when all the textures were put together: ﬁrst, the original and the rotated textures using all angles, second the original and all the c-transformed images, and the third was when all the images representing a texture were present in class content. In the ﬁrst situation, each class has 160 elements and 1920 texture were tested. In the second case the classes have each 352 elements and 4224 textures were classiﬁed. In the last case, the classes contain 480 images each and 5760 texture were employed for classiﬁcation. The results are in Table 9.  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  553  
   
  Table 8. Classiﬁcation results for c transformation case c Transformations c = 0.5 c = 0.6 SVM Jeffreys Topsøe Jensen Squared v2 cos  
   
  95.96% 95.70% 96.62% 96.62% 96.35% 87.89%  
   
  (31) (33) (26) (26) (28) (93)  
   
  97.66% 96.62% 97.79% 97.79% 97.79% 91.54%  
   
  (18) (26) (17) (17) (17) (65)  
   
  c = 0.8  
   
  c = 0.8−1  
   
  c = 0.6−1  
   
  c=2  
   
  99.74% (2) 96.62% (26) 100% (0) 100% (0) 100% (0) 95.44% (35)  
   
  99.74% (2) 100% (0) 99.87% (1) 99.87% (1) 99.87% (1) 98.57% (11)  
   
  97.92% 97.14% 96.75% 96.75% 97.01% 94.01%  
   
  96.22% 95.31% 95.83% 95.83% 95.83% 91.78%  
   
  (16) (22) (25) (25) (23) (46)  
   
  (29) (36) (32) (32) (32) (63)  
   
  Table 9. Classiﬁcation results for rotations, c -transformed considered together SVM Jeffreys Topsøe Jensen Squared v2 cos  
   
  Rotations 97.19% (54) 95.21% (92) 95.99% (77) 95.99% (77) 96.41% (69) 90.42% (184)  
   
  c-transformed 99.55% (19) 99.12% (37) 99.12% (37) 99.12% (37) 99.17% (35) 96.97% (128)  
   
  All 98.23% 98.19% 98.72% 98.72% 98.82% 95.24%  
   
  (102) (104) (74) (74) (68) (274)  
   
  In this case the squared v2 minimum distance classiﬁer gives in average the best results and then the SVM. If we consider all the cases with classes represented by multiple textures, we computed the average classiﬁcation rate: the best results are obtained with SVM (with a total of 399 errors), then follows the squared v2 distance (460 errors), the Topsøe, Jensen difference distances make 472 errors each, Jeffreys yields 616 misidentiﬁcations and the cosine distance makes a total of 1352 errors. For the situation of class content with mixture of all types of images we computed for each texture the total number of misidentiﬁcations, the results are summarized in Table 10. It is surprising that a texture such as Brick which has good saliency, with Table 10. Number of misidentiﬁcations Rotations Bark 64 Brick 169 Grass 21 Leather 8 Pigskin 19 Rafﬁa 13 Sand 121 Straw 30 Water 0 Weave 51 Wood 3 Wool 54  
   
  c-transformed 85 27 56 19 5 2 26 25 0 24 0 24  
   
  All 161 146 61 33 23 6 113 21 0 76 4 52  
   
  554  
   
  A. Ignat and M. Luca  
   
  very distinct visual and directional characteristics has one of the highest misidentiﬁcation rate and the Water texture which visually is very similar with Sand or Pigskin has no errors in classiﬁcation. We tested the cosine, correlation, Topsøe, Jensen difference and squared v2 histogram similarity measures upon the six real world textures from Figs. 2 and 4. There are three classes of textures (bark, grass, and pavement) each class having two samples. We computed for all these textures the similarity measures to the other ﬁve images. In Table 11 we marked ‘T’ (true) when the minimum distance was achieved for the image in the same class and ‘F’ (false) otherwise. The DTCWT -based similarity measures provided the correct result in all the cases (the DTCWT column in Table 11). Table 11. Comparisons for real world images – distances applied to the histograms of the DTCWT coefﬁcients and of the images Cosine DTCWT Bark T Grass T Pavement T  
   
  Correlation Img DTCWT Img F T F T T T F T F  
   
  Topsøe DTCWT T T T  
   
  Jensen Img DTCWT F T T T T T  
   
  Squared v2 Img DTCWT Img F T F T T T T T T  
   
  We compare the classiﬁcation obtained applying the ﬁve distances to the histogram of the DTCWT coefﬁcients to the same classiﬁcation performed when computing the similarity of the histogram of the textures (the Img column in Table 11). We obtained the correct texture when comparing the histogram of the rotated textures with the not rotated ones, in almost all cases, as expected. The cosine and the correlation distances had 1 misidentiﬁcation each for the 30° case.  
   
  6 Conclusions In this paper, we studied texture identiﬁcation in digital images with a new method. We employed the Dual Tree Complex Wavelet Transform (DTCWT) for texture feature extraction and identiﬁcation using various similarity measures. The DTCWT provides a set of six complex selective directional coefﬁcients, for which we employed their magnitudes {Sj,d; j = 1,…,6, d = 1,..,D}. We computed the histograms of these coefﬁcients and classiﬁed 12 textures from the Brodatz album using SVM or minimum distance classiﬁers employing six similarity measures: cosine and Pearson correlation coefﬁcient, Jeffreys, Topsøe, Jensen difference and squared v2. Our main focus was on the influence of rotation and c-transformation on the capacity of texture recognition. We analysed several cases: classes with only one texture or with multiple textures, the rotations and c-transformations were treated separately or together. We also tested the proposed method on real world images with good identiﬁcation results. Our further research will concentrate on testing the influence of the image size, the noise and also on other types of image transformations (blur, shear, etc.) beside rotations and  
   
  Tips on Texture Evaluation with Dual Tree Complex Wavelet Transform  
   
  555  
   
  c-transformations on the capacity of the presented methods for texture identiﬁcation. These procedures will be tested also on image segmentation and indexing based on texture recognition.  
   
  References 1. Petrou, M., Sevilla, P.G.: Image Processing: Dealing With Texture. Wiley, England (2006) 2. Mirmehdi, M., Xie, X., Suri, J. (eds.) Handbook of Texture Analysis. Imperial College Press, London (2008) 3. Wang, X., Georganas, N.D., Petriu, E.M.: Fabric texture analysis using computer vision techniques. IEEE Trans. Instrum. Measur. 60(1), 44–56 (2011) 4. Basile, T.M.A., Caponetti, L., Castellano, G., Sforza, G.: A texture-based image processing approach for the description of human oocyte cytoplasm. IEEE Trans. Instrum. Measur. 59 (10), 2591–2601 (2010) 5. Kingsbury, N.G.: The dual-tree complex wavelet transform: a new technique for shift invariance and directional ﬁlters. In: Proceedings of the 8th IEEE DSP Workshop, Paper no. 86, Utah, 9–12 August 1998 6. Kingsbury, N.G.: The dual-tree complex wavelet transform: a new efﬁcient tool for image restoration and enhancement. In: Proceedings of the European Signal Processing Conference, Rhodes, September 1998, pp. 319–322 (1998) 7. Brodatz, P.: Textures: a photographic album for artists and designers, Dover, New York, USA (2014). http://www.ux.uis.no/*tranden/brodatz.html 8. Hill, P.R., Bull, D.R., Canagarajah, C.N.: Rotationally invariant texture features using the dual-tree complex wavelet transform. In: IEEE Proceedings of the International Conference on Image Processing (ICIP), Vancouver, Canada, vol. 3, pp. 901–904 (2000) 9. Selesnick, I.W., Baraniuk, R.G., Kingsbury, N.G.: The dual tree complex wavelet transform DTCWT. IEEE Sig. Process. Mag. 22(6), 123–151 (2005) 10. Kingsbury, N.G.: Complex wavelets for shift invariant analysis and ﬁltering of signals. J. Appl. Comput. Harmonic Anal. 3, 234–253 (2001) 11. Kingsbury, N.G.: Design of Q-shift complex wavelets for image processing using frequency domain energy minimization. In: Proceedings of the IEEE Conference on Image Processing, Barcelona, 15–17 September (2003). Paper 1199 12. Mallat, S.G.: A theory for multiresolution signal decomposition: the wavelet representation. IEEE Trans. Pattern Anal. Mach. Intell. 11(7), 674–693 (1989) 13. Hatipoglu, S., Mitra, S.K., Kingsbury, N.G.: Image texture description using complex wavelet transform. In: Proceedings of the IEEE International Conference on Image Processing, Vancouver, BC, Canada, September 2000, vol. 2, pp. 530–533 (2000) 14. Wang, H.-Z., He, X.-H., Zai, W.-J.: Texture image retrieval using dual-tree complex wavelet transform. In: Proceedings of the 2007 International Conference on Wavelet Analysis and Pattern Recognition, Beijing, China, 2–4 November 2007, pp. 230–234 (2007) 15. Mumtaz, A., Gilani, M.S.A., Hameed, K., Jameel, T.: Enhancing performance of image retrieval systems using dual tree complex wavelet transform and support vector machines. J. Comput. Inf. Technol. (CIT) 16(1), 57–68 (2008) 16. Celik, T., Tjahadi, T.: Multiscale texture classiﬁcation using dual-tree complex wavelet transform. Pattern Recogn. Lett. 30, 331–339 (2009) 17. Hatipoglu, S., Mitra, S.K., Kingsbury, N.: Texture classiﬁcation using dual-tree complex wavelet transform. IEEE Image Process. Appl. 465, 344–347 (1999)  
   
  556  
   
  A. Ignat and M. Luca  
   
  18. Lo, E.H.S., Pickering, M., Frater, M., Arnold, J.: Scale and rotation invariant texture features from the dual-tree complex wavelet transform. In: IEEE Proceedings of the International Conference on Image Processing (ICIP), 24–27 October, Singapore, vol. 1, pp. 227–230 (2004) 19. Chen, S., Shang, Y., Mao, B., Lian, Q.: Rotation invariant texture classiﬁcation algorithm based on DT-CWT and SVM. In: Liu, D., Fei, S., Hou, Z., Zhang, H., Sun, C. (eds.) Proceedings of the 4th International Symposium on Neural Networks Advances in Neural Networks ISNN 2007, pp. 454–460. Springer, Heidelberg (2007). 20. Cha, S.-H.: Comprehensive survey on distance/similarity measures between probability density functions. Int. J. Math. Models Methods Appl. Sci. 1(4), 300–307 (2007) 21. Xu, R., WunschII, D.C.: Clustering. IEEE Press/Wiley, Hoboken (2009) 22. Gonzales, R.C., Woods, R.E.: Digital Image Processing, 3rd ed. Chap. 3, pp. 132–137. Prentice Hall, Upper Saddle River (2008) 23. Costin (Luca), M., Ignat, A.: Pitfalls in using dual tree complex wavelet transform for texture featuring: a discussion. In: IEEE WISP 2011 - 7th IEEE International Symposium on Intelligent Signal Processing, Floriana, Malta, 19–21 September 2011, pp. 110–115 (2011) 24. Kingsbury’s, N.G.: http://www-sigproc.eng.cam.ac.uk/Main/NGK  
   
  Author Index  
   
  A Abdmouleh, Med Karim, 164, 524 Ahmed, Adeel, 216, 229, 253 Ahmed, Zaheer, 216, 229, 253 Aiordachioaie, Dorel, 430 Amri, Hedi, 164, 524 Arif, Muhammad, 216, 229, 253 Ashour, Amira S., 367, 375, 394 Azizi, Nabiha, 375 B Badkoobe, Marzieh, 189 Balas, Marius M., 12, 290 Balas, Sanda V., 367 Balas, Valentina Emilia, 78, 189, 316, 349 Banu, P.K. Nizar, 408 Barbu, Tudor, 423 Barbulescu, C., 47 Bărbuț, Alexandra, 308 Bărbuț, Liliana, 308 Beiu, Valeriu, 349 Bejinariu, Silviu-Ioan, 509 Ben Abdessalem Karaa, Wahiba, 394 Bold, Nicolae, 135 Boran, Robert A., 12 Bouhlel, Med Salim, 164, 497, 524 Bouhlel, Mohamed Salim, 474 C Chaki, Nabendu, 385 Cheriguene, Soraya, 375 Chiuchisan, Iulian, 339 Chiuchisan, Iuliana, 265, 327, 339, 349 Cornel, Barna, 385 Costin, Hariton, 509 Covasa, Mihai, 265 Crișan-Vida, Mihaela, 308  
   
  D David, Bertrand, 524 De Luise, D. López, 359 Dey, Nilanjan, 367, 375, 394 Dineva, Adrienn, 446, 455 Doloc, Cris, 265 Dombi, József, 446 Domșa, Ovidiu, 135 Domuschiev, I., 367 Dragan, Florin, 176 Dzitac, Simona, 60, 95, 107 E Elloumi, Nessrine, 497 Elnaggar, Ola E., 203 F Fayek, Magda B., 203 Filip, Ioan, 70, 176 G Gal, Andrei, 176 Gal-Nadasan, Emanuela, 298 Gal-Nadasan, Norbert, 298 Gargouri, Malek, 524 Geman, Oana, 265, 327, 339, 349 Glielmo, Luigi, 118 Gospodinov, M., 367 Gospodinova, E., 367 H Haghani, M., 316 Hemanth, D.J., 359 Holhjem, Øystein Hov, 118 Hosseinabadi, Ali Asghar Rahmani, 189  
   
  © Springer International Publishing AG 2018 V.E. Balas et al. (eds.), Soft Computing Applications, Advances in Intelligent Systems and Computing 633, DOI 10.1007/978-3-319-62521-8  
   
  557  
   
  558  
   
  Author Index  
   
  I Iannelli, Luigi, 118 Ignat, Anca, 540 Indumathi, G., 107 Isoc, Dorin, 18, 34  
   
  O Olariu, Iustin, 394, 408 Olariu, Teodora, 367, 375, 408 Own, Hala S., 408  
   
  J Jabbar, Muhammad, 216, 229, 253 Jaberi, O., 316 Jurcău, Daniel-Alexandru, 276  
   
  P Palmieri, Giovanni, 118 Park, J.S., 359 Parthasarathy, S., 60 Paul, Swagata, 385 Pérez, J., 359 Piuri, Vincenzo, 455 Poenaru, Dan V., 298 Popa-Andrei, Diana, 298 Popescu, Doru Anastasiu, 135 Prabhat, Purnendu, 487 Prostean, Octavian, 70  
   
  K Khajuria, Garvita, 487 Khalfallah, Ali, 164, 524 Kher, Vansha, 487 Kilyeni, St., 47 Kohli, Meena, 487 Kotta, Ülle, 78 Kumar, Ravish, 107 L Lazăr, Camelia, 509 Lolea, Marius, 95 Loukil Hadj Kacem, Habiba, 497 Loukil, Habiba, 474 Luca, Mihaela, 540 Luca, Ramona, 509 M Madan, Vinod K., 487 Maffei, Alessio, 118 Mannai, Monia, 394 Maraﬁoti, Giancarlo, 118 Mathisen, Geir, 118 Miclea, Razvan-Catalin, 3 Milici, Laurentiu-Dan, 265, 327, 339 Milici, Mariana-Rodica, 265, 327 Milici, Rodica-Mariana, 339 Mnerie, Corina A., 375 Mohanna, Farahnaz, 189 Mortazavi, S.A.R., 316 Mortazavi, S.M.J., 316 Muniyasamy, K., 60 N Niţă, Cristina Diana, 509  
   
  R Rahali, Mourad, 474 Ramadan, Rabie A., 203 Ramasamy, Srini, 78 Rizwan, Abdul Rasheed, 216, 253 Rohatinovici, Noemi, 385 Rostami, Ali Shokouhi, 189 Rotaru, Florin, 509 S Sandru, Florin, 3 Saravanakumar, G., 78 Sarkar, Bidyut Biman, 385 Shi, Fuqian, 375 Silea, Ioan, 3 Simo, A., 47 Sofrag, Adelin, 290 Soleimani, A., 316 Srinivasan, Seshadhri, 60, 78, 107, 118 Srivastava, Juhi R., 143 Stoicu-Tivadar, Lăcrămioara, 308 Stoicu-Tivadar, Vasile, 276, 298 Subathra, B., 60, 78 Sudarshan, T.S.B., 143 Sundarajan, N., 78 Szeidert, Iosif, 70  
   
  Author Index  
   
  559  
   
  T Tar, József K., 455 Toderean (Aldea), Roxana, 349 Tripathi, Shikha, 462  
   
  V Várkonyi-Kóczy, Annamária R., 455 Vasar, Cristian, 70 Vekkot, Susmitha, 462  
   
  U Ullah, Muhammad Sami, 229, 253  
   
  Z Zamani, A., 316  

 Report "Soft Computing Applications Proceedings of the 7th International Workshop Soft Computing Applications Sofa 2016 978-3-319-62521-8, 3319625217, 9783319625249, 3319625241, 978-3-319-62520-1"  
 ×    

 --- Select Reason ---  Pornographic  Defamatory  Illegal/Unlawful  Spam  Other Terms Of Service Violation  File a copyright complaint     

 Close  Submit    

    Contact information  
 Michael Browner   
   [email protected]    
   
   Address:   
 1918 St.Regis, Dorval, Quebec, H9P 1H6, Canada.   
   
 Support & Legal  
  O nas 
  Skontaktuj się z nami 
  Prawo autorskie 
  Polityka prywatności 
  Warunki 
  FAQs 
  Cookie Policy 
    
 Subscribe to our newsletter  
  Be the first to receive exclusive offers and the latest news on our products and services directly in your inbox.  
   Subscribe     

 Copyright © 2024 DOKUMEN.PUB. All rights reserved.        

 Unsere Partner sammeln Daten und verwenden Cookies zur Personalisierung und Messung von Anzeigen. Erfahren Sie, wie wir und unser Anzeigenpartner Google Daten sammeln und verwenden  .   Cookies zulassen    
    Call for papers data:Anmelden 
  Registrierung 
  Deutsch  English 
  Español 
  Português 
  Français 

     Dom 
  Najlepsze kategorie | CAREER & MONEY 
  PERSONAL GROWTH 
  POLITICS & CURRENT AFFAIRS 
  SCIENCE & TECH 
  HEALTH & FITNESS 
  LIFESTYLE 
  ENTERTAINMENT 
  BIOGRAPHIES & HISTORY 
  FICTION 
  Najlepsze historie 
  Najlepsze historie 
  Dodaj historię 
  Moje historie 

 Home 
  Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications (Studies in Fuzziness and Soft Computing, 258) 3642156053, 9783642156052 

 Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications (Studies in Fuzziness and Soft Computing, 258) 3642156053, 9783642156052   
 Dr. Jay Liebowitz Orkand Endowed Chair in Management and Technology University of Maryland University College Graduate S   
  208    91    8MB    
  English   Pages 492 [476]   Year 2010    
  Report DMCA / Copyright    
  DOWNLOAD FILE   
   
 Polecaj historie   

 Intelligent and Soft Computing Systems for Green Energy 1394166370, 9781394166374  
 INTELLIGENT AND SOFT COMPUTING SYSTEMS FOR GREEN ENERGY Written and edited by some of the world’s top experts in the fie  
  710    145    48MB    Read more   

 Evolutionary Computation in Economics and Finance (Studies in Fuzziness and Soft Computing, 100) 9783790825121, 9783790817843, 3790825123  
 After a decade's development, evolutionary computation (EC) proves to be a powerful tool kit for economic analysis.  
  197    113    44MB    Read more   

 Soft Computing: Fundamentals and Applications 9781842658635, 9781783320851  
 SOFT COMPUTING: Fundamentals and Applications starts with an introduction to soft computing, a family consists of many m  
  5,162    510    4MB    Read more   

 Fuzzy Graph Theory (Studies in Fuzziness and Soft Computing Book 363) 9783319714073, 9783639270952, 3319714074  
  
  184    45    9MB    Read more   

 Texture Spaces (Studies in Fuzziness and Soft Computing, 411) 3031397479, 9783031397479  
 This book provides a complete framework for the fundamental concepts and results of texture spaces and its applications.  
  154    85    2MB    Read more   

 Soft Computing: Theories and Applications : Proceedings of SoCTA 2019 (Advances in Intelligent Systems and Computing) [1st ed. 2020] 9811540314, 9789811540318  
 This book focuses on soft computing and how it can be applied to solve real-world problems arising in various domains, r  
  3,635    166    43MB    Read more   

 Monte Carlo Methods in Fuzzy Optimization (Studies in Fuzziness and Soft Computing, 222) 9783540762898, 3540762892  
 1. 1 Introduction The objective of this book is to introduce Monte Carlo methods to ?nd good approximate solutions to fu  
  169    33    4MB    Read more   

 Evolutionary Computation in Data Mining (Studies in Fuzziness and Soft Computing, 163) 9783540223702, 3540223703  
 Data mining (DM) consists of extracting interesting knowledge from re- world, large & complex data sets; and is the  
  141    106    Read more   

 Principles of Soft Computing Using Python Programming : Learn How to Deploy Soft Computing Models in Real World Applications 9781394173136  
 An accessible guide to the revolutionary techniques of Soft Computing. Soft computing is a computing approach designed  
  268    36    14MB    Read more   

 Foundations of Reasoning under Uncertainty (Studies in Fuzziness and Soft Computing, 249) 3642107265, 9783642107269  
 Uncertainty exists almost everywhere, except in the most idealized situations; it is not only an inevitable and ubiquito  
  140    83    Read more   

 Author / Uploaded 
  Jorge Casillas (editor) 
  Francisco J. Martínez López (editor) 

 Table of contents :  
  Title  
  Foreword  
  Preface  
  Contents  
  Essays  
  Marketing and Artificial Intelligence: Great Opportunities, Reluctant Partners  
  Introduction  
  Marketing Problem-Solving Modes  
  Marketing Problem-Solving Modes and Decision Support Technologies  
  The State of Artificial Intelligence (AI) in Marketing  
  Applications of AI in Marketing  
  Perspective  
  References  
  Data Mining and Scientific Knowledge: Some Cautions for Scholarly Researchers  
  Introduction  
  The Data Mining Method  
  Data Mining and Scientific Knowledge  
  Data Mining in a Practical Context  
  Discussion and Conclusions  
  References  
  Observations on Soft Computing in Marketing  
  References  
  Soft Computing Methods in Marketing: Phenomena and Management Problems  
  Introduction  
  Marketplace Phenomena  
  Management Problems  
  Summary  
  References  
  User-Generated Content: The “Voice of the Customer” in the 21st Century  
  Introduction  
  Marketing Scientists Should Care about UGC or Should They?  
  Marketing Scientists and Data Mining Experts Need Each Other Now More Than Ever  
  References  
  Fuzzy Networks  
  References  
  KDD: Applying in Marketing Practice Using Point of Sale Information  
  Introduction  
  The Store Layout  
  The Buying Association: A Way to Measure the Relationship among Products  
  Method and Results  
  Discussion  
  References  
  Marketing – Sales Interface and the Role of KDD  
  Marketing Versus Sales  
  A Call for Change  
  KDD as a Catalyst for Paradigmatic Change  
  References  
  Segmentation and Targeting  
  Applying Soft Cluster Analysis Techniques to Customer Interaction Information  
  Introduction  
  Literature Review  
  Background of Cluster Analysis  
  Applications in the Financial Services Industry and Customer Relationship Management  
  Business Context and Data Used for Analysis  
  Business Context  
  Synthetic Data Structure and Design  
  Synthetic Data Group Characteristics  
  Research Approach  
  Variable Selection  
  Data Validation  
  Data Standardization  
  Addressing Outliers  
  Decide Number of Clusters  
  Validate Clustering Results  
  Results  
  Variable Selection  
  Standardize Data  
  Decide Number of Clusters  
  Validate Clustering Results  
  Discussion and Analysis  
  Conclusion  
  References  
  Marketing Intelligent System for Customer Segmentation  
  Introduction  
  Components of Marketing Intelligent System  
  Operational Data  
  Derived Data  
  Customers’ Segmentation Using Partitioning Method  
  Interpretation of Intelligent Systems Outputs by Expert Systems  
  Marketing Intelligent Sytems for Customers Clustering Using Fuzzy C-Means Clustering  
  Experimental Results  
  Collaboration of Knowledge Based System and the Fuzzy C-Means Clustering Implementation Results  
  Conclusion  
  Practical Utilities for Marketing Management  
  References  
  Using Data Fusion to Enrich Customer Databases with Survey Data for Database Marketing  
  Introduction and Motivation  
  DataFusion  
  Data Fusion Concepts  
  Core Data Fusion Algorithms  
  Data Fusion Evaluation and Deployment  
  Case Study: Cross Selling Credit Cards  
  Internal Evaluation  
  External Evaluation  
  Case Discussion  
  A Process Model for a Fusion Factory  
  Conclusion  
  References  
  Collective Intelligence in Marketing  
  Introduction  
  Data Mining Technology in Marketing  
  Business Applications of Data Mining  
  Predicting Customer Preferences  
  Finding Similar Customers or Consumers  
  Applying Collective Intelligence in Marketing  
  Challenges of Applying Collective Intelligence in Marketing  
  Case Study: Keyword-Based Product Suggestions  
  Summary and Conclusions  
  References  
  Marketing Modelling  
  Predictive Modeling on Multiple Marketing Objectives Using Evolutionary Computation  
  Introduction  
  Background  
  Non-dominated Solutions  
  Genetic Search  
  Multi-objective Evolutionary Computation  
  Multi-objective Models Using Genetic Search  
  Model Representation  
  Genetic Search Operators  
  Multi-objective Models Using Pareto-Selection  
  Fitness Function  
  Performance Measures  
  Data and Multi-objective Model Performance  
  Data  
  Models along the Pareto-Frontier  
  Conclusions  
  References  
  Automatic Discovery of Potential Causal Structures in Marketing Databases Based on Fuzzy Association Rules  
  Introduction  
  Previous Considerations on the Adaptation of Marketing Data  
  Data Collection in Marketing  
  The Classical Approach to Deal with Marketing Data  
  Transformation of Marketing Scales into Fuzzy Semantic  
  Application of Machine Learning to the Marketing Data  
  Mining Association Rules  
  Association Rules: The Beginning  
  Association Rule Mining with Continuous Variables  
  Description of Fuzzy-CSar  
  Knowledge Representation  
  Multi-item Fuzzification  
  Process Organization  
  Problem Description and Methodology  
  Problem Description  
  Experimental Methodology  
  Analysis of the Results  
  Analysis of the Rules in the Objective Space  
  Analysis of the Utility of the Rules from the Marketing Expert Perspective  
  Conclusions and Further Work  
  References  
  Fuzzy–Evolutionary Modeling of Customer Behavior for Business Intelligence  
  Introduction  
  TheContext  
  Application Scenarios  
  Related Work  
  Data Mining  
  Fuzzy Rule-Based Systems  
  Fuzzy Sets  
  Operations on Fuzzy Sets  
  Fuzzy Propositions and Predicates  
  Fuzzy Rulebases  
  Evolutionary Algorithms  
  An Island-Based Evolutionary Algorithm for Fuzzy Rule-Base Optimization  
  Genetic Operators  
  Fitness  
  Selection and Overfitting Control  
  A Case Study on Customer Revenue Modeling  
  The Company  
  Aim of the Study  
  The Data  
  Discussion of the Results  
  Validation of the Model  
  Conclusions  
  References  
  Communication/Direct Marketing  
  An Evaluation Model for Selecting Integrated Marketing Communication Strategies for Customer Relationship Management  
  Introduction  
  Literature Review  
  Customer Relationship Management (CRM)  
  Customer Relational Benefit  
  Integrated Marketing Communication Strategy  
  Quality Function Deployment  
  Fuzzy Analytic Hierarchy Process  
  Construction of an Evaluation Model for Selecting IMC Strategy on CRM  
  Empirical Illustrations  
  The Hierarchy Construction of Customer Relational Benefit  
  The Relative Importance Weights of Categories and Attributes for Customer Relational Benefit  
  The Relationship Matrix between Customer Relational Benefit and IMC Strategy  
  The Completed Evaluation Model for Selecting IMC Strategy on CRM  
  Conclusion  
  Discussion and Implications  
  References  
  Direct Marketing Based on a Distributed Intelligent System  
  Introduction  
  Formation of Clusters to Boost Direct Marketing  
  Formal Presentation of Methods  
  The Analytical Hierarchy Process  
  Fuzzy C Means Clustering Algorithm  
  The Hybrid Approach to Process Customers Evaluations  
  The Multi-Agent System  
  Experimental Results  
  Clients’ Evaluation  
  Concluding Remarks  
  References  
  Direct Marketing Modeling Using Evolutionary Bayesian Network Learning Algorithm  
  Introduction  
  Background  
  Direct Marketing Modeling  
  Bayesian Networks  
  The Missing Value Problem  
  Basic SEM Algorithm  
  HEA  
  Learning Bayesian Networks from Incomplete Databases  
  The EBN Algorithm  
  The EM Procedure in EBN  
  The Initial Network Structure for G$_best$  
  Data Completing Procedure  
  HEA Search Procedure  
  Application in Direct Marketing Modeling  
  Methodology  
  Cross-Validation Results  
  Conclusion  
  References  
  Product  
  Designing Optimal Products: Algorithms and Systems  
  Introduction  
  The Optimal Product (Line) Design Problem  
  Choice Rule  
  Optimization Criteria  
  Number of Products to be Designed  
  Procedure Steps  
  Optimization Algorithm  
  Problem Formulation  
  Deterministic Choice Rules  
  Probabilistic Choice Rules  
  Optimization Algorithms Applied to the Problem  
  Greedy Heuristic  
  Interchange Heuristic  
  Divide and Conquer  
  Coordinate Ascent  
  Dynamic Programming  
  Beam Search  
  Nested Partitions  
  Genetic Algorithms  
  Lagrangian Relaxation with Branch and Bound  
  Comparison of the Algorithms  
  A Comparison of Genetic Algorithm to Simulated Annealing  
  Genetic Algorithm Implementation  
  Simulated Annealing Implementation  
  Monte Carlo Simulation  
  A Real World Case  
  Programs and Systems  
  DESOP-LINEOP  
  SIMOPT  
  GENESYS  
  MDSS  
  Advanced Simulation Module  
  Discussion  
  Conclusions  
  References  
  PRODLINE: Architecture of an Artificial Intelligence Based Marketing Decision Support System for PRODuct LINE Designs  
  Introduction  
  The Product Line Problem  
  Existing Approaches to Product Line Design Problem  
  Architecture of PRODLINE  
  Database  
  Model Base  
  PRODLINE: User Interaction  
  Inputs  
  Discussion and Future Directions  
  References  
  A Dempster-Shafer Theory Based Exposition of Probabilistic Reasoning in Consumer Choice  
  Introduction  
  Background  
  Dempster-Shafer Theory  
  Formulisation of DS/AHP and Consumer Choice  
  DS/AHP Analysis of Car Choice Problem  
  Future Trends  
  Conclusions  
  References  
  E-Commerce  
  Decision Making in Multiagent Web Services Based on Soft Computing  
  Introduction  
  Fundamentals for Web Services  
  E-Services and Web Services  
  Parties in Web Services  
  SESS: A Unified Multilayer Architecture for E-Services  
  First Layer: Infrastructure Services  
  Second Layer: Web Services  
  Third Layer: E-Services  
  SESS: A Service Centered System Architecture  
  Web Service Lifecycle  
  Introduction  
  Provider's Demand Driven Web Service Lifecycle  
  Requester's Demand Driven Web Service Lifecycle  
  Broker's Demand Driven Web Service Lifecycle  
  Summary of Demand Driven Web Service Lifecycle  
  Decision Making in Web Services  
  Decision Making  
  Decision Making in Web Services  
  Soft Computing for Web Services  
  WUDS: A Unified Decision Support System for Web Services  
  Agents within WUDS  
  WS Decision Supporter  
  Agents Workflowing in WUDS  
  Case Based Web Services  
  Introduction  
  Web Services vs. CBR  
  A Unified Treatment of Case Based Web Services  
  Conclusions and Future Work  
  References  
  Dynamic Price Forecasting in Simultaneous Online Art Auctions  
  Introduction  
  Simultaneous Online Auctions  
  Data Used in This Study  
  Bidder Competition in Simultaneous Online Auctions  
  Dynamic Price Forecasting  
  Model Formulation  
  Benchmark Models  
  Model Estimation and Evaluation  
  Results  
  Estimated Models  
  Forecasting Performance  
  Bidder Competition and Price Forecasting  
  Bidder Competition as Time-Varying Predictors  
  Bidder Competition as a Conditioning Variable  
  Conclusion and Future Direction  
  References  
  Analysing Incomplete Consumer Web Data Using the Classification and Ranking Belief Simplex (Probabilistic Reasoning and Evolutionary Computation)  
  Introduction  
  Background  
  Measuring Consumer Web Purchasing Attitudes and CaRBS Analyses  
  Conceptualisation and Operationalisation of Web Purchasing Involvement  
  Internet Survey Design  
  CaRBS Analysis of ‘Incomplete’ Web Experience Data Set  
  CaRBS Analysis of ‘Completed’ Web Experience Data Set  
  Future Trends  
  Conclusions  
  References  
  Author Index   
 Citation preview   
  Jorge Casillas and Francisco J. Martínez-López (Eds.) Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications  
   
  Studies in Fuzziness and Soft Computing, Volume 258 Editor-in-Chief Prof. Janusz Kacprzyk Systems Research Institute Polish Academy of Sciences ul. Newelska 6 01-447 Warsaw Poland E-mail: [email protected]  Further volumes of this series can be found on our homepage: springer.com Vol. 243. Rudolf Seising (Ed.) Views on Fuzzy Sets and Systems from Different Perspectives, 2009 ISBN 978-3-540-93801-9  
   
  Vol. 251. George A. Anastassiou Fuzzy Mathematics: Approximation Theory, 2010 ISBN 978-3-642-11219-5  
   
  Vol. 244. Xiaodong Liu and Witold Pedrycz Axiomatic Fuzzy Set Theory and Its Applications, 2009 ISBN 978-3-642-00401-8  
   
  Vol. 252. Cengiz Kahraman, Mesut Yavuz (Eds.) Production Engineering and Management under Fuzziness, 2010 ISBN 978-3-642-12051-0 Vol. 253. Badredine Arfi Linguistic Fuzzy Logic Methods in Social Sciences, 2010 ISBN 978-3-642-13342-8 Vol. 254. Weldon A. Lodwick, Janusz Kacprzyk (Eds.) Fuzzy Optimization, 2010 ISBN 978-3-642-13934-5 Vol. 255. Zongmin Ma, Li Yan (Eds.) Soft Computing in XML Data Management, 2010 ISBN 978-3-642-14009-9 Vol. 256. Robert Jeansoulin, Odile Papini, Henri Prade, and Steven Schockaert (Eds.) Methods for Handling Imperfect Spatial Information, 2010 ISBN 978-3-642-14754-8 Vol. 257. Salvatore Greco, Ricardo Alberto Marques Pereira, Massimo Squillante, Ronald R. Yager, and Janusz Kacprzyk (Eds.) Preferences and Decisions,2010 ISBN 978-3-642-15975-6  
   
  Vol. 245. Xuzhu Wang, Da Ruan, Etienne E. Kerre Mathematics of Fuzziness – Basic Issues, 2009 ISBN 978-3-540-78310-7 Vol. 246. Piedad Brox, Iluminada Castillo, Santiago Sánchez Solano Fuzzy Logic-Based Algorithms for Video De-Interlacing, 2010 ISBN 978-3-642-10694-1 Vol. 247. Michael Glykas Fuzzy Cognitive Maps, 2010 ISBN 978-3-642-03219-6 Vol. 248. Bing-Yuan Cao Optimal Models and Methods with Fuzzy Quantities, 2010 ISBN 978-3-642-10710-8 Vol. 249. Bernadette Bouchon-Meunier, Luis Magdalena, Manuel Ojeda-Aciego, José-Luis Verdegay, Ronald R. Yager (Eds.) Foundations of Reasoning under Uncertainty, 2010 ISBN 978-3-642-10726-9 Vol. 250. Xiaoxia Huang Portfolio Analysis, 2010 ISBN 978-3-642-11213-3  
   
  Vol. 258. Jorge Casillas and Francisco J. Martínez-López (Eds.) Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications, 2010 ISBN 978-3-642-15605-2  
   
  Jorge Casillas and Francisco J. Martínez-López (Eds.)  
   
  Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications  
   
  ABC  
   
  Editors Dr. Jorge Casillas Department of Computer Science and Artificial Intelligence Computer and Telecommunication Engineering School University of Granada Granada E-18071 Spain E-mail: [email protected]   
   
  Dr. Francisco J. Martínez-López Department of Marketing Business Faculty University of Granada Granada, Spain E-18.071 E-mail: [email protected]   
   
  ISBN 978-3-642-15605-2  
   
  e-ISBN 978-3-642-15606-9  
   
  and Department of Economics and Business – Marketing Group Open University of Catalonia Barcelona, Spain E-08.035 E-mail: [email protected]   
   
  DOI 10.1007/978-3-642-15606-9 Studies in Fuzziness and Soft Computing  
   
  ISSN 1434-9922  
   
  Library of Congress Control Number: 2010934965 c 2010 Springer-Verlag Berlin Heidelberg  This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilm or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law. The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. Typeset & Cover Design: Scientific Publishing Services Pvt. Ltd., Chennai, India. Printed on acid-free paper 987654321 springer.com  
   
  Foreword  
   
  Dr. Jay Liebowitz Orkand Endowed Chair in Management and Technology University of Maryland University College Graduate School of Management & Technology 3501 University Boulevard East Adelphi, Maryland 20783-8030 USA [email protected]   
   
  When I first heard the general topic of this book, Marketing Intelligent Systems or what I’ll refer to as Marketing Intelligence, it sounded quite intriguing. Certainly, the marketing field is laden with numeric and symbolic data, ripe for various types of mining—data, text, multimedia, and web mining. It’s an open laboratory for applying numerous forms of intelligentsia—neural networks, data mining, expert systems, intelligent agents, genetic algorithms, support vector machines, hidden Markov models, fuzzy logic, hybrid intelligent systems, and other techniques. I always felt that the marketing and finance domains are wonderful application areas for intelligent systems, and this book demonstrates the synergy between marketing and intelligent systems, especially soft computing. Interactive advertising is a complementary field to marketing where intelligent systems can play a role. I had the pleasure of working on a summer faculty fellowship with R/GA in New York City—they have been ranked as the top interactive advertising agency worldwide. I quickly learned that interactive advertising also takes advantage of data visualization and intelligent systems technologies to help inform the Chief Marketing Officer of various companies. Having improved ways to present information for strategic decision making through use of these technologies is a great benefit. A number of interactive advertising agencies have groups working on “data intelligence” in order to present different views of sales and other data in order to help their clients make better marketing decisions. Let’s explore the term “marketing intelligence”. The Marketing Intelligence & Planning journal, published by Emerald Publishers, “aims to provide a vehicle that will help marketing managers put research and plans into action.” In its aims and scope, the editors further explain, “Within that broad description lies a wealth of skills encompassing information-gathering, data interpretation, consumer psychology, technological resource knowledge, demographics and the marshalling of human and technical resources to create a powerful strategy.” Data interpretation seems to be at the intersection of “marketing” and “intelligence”. By applying advanced technologies, data can be interpreted and visualized in order to enhance the decision making ability of the marketing executives. Certainly, blogs and social networking sites are rich forums for applying mining techniques to look for hidden  
   
  VI  
   
  Foreword  
   
  patterns and relationships. These patterns may enrich the discovery process and allow different views, perhaps those unexpected, from those initially conceived. In Inderscience’s International Journal of Business Forecasting and Marketing Intelligence, the focus is on applying innovative intelligence methodologies, such as rule-based forecasting, fuzzy logic forecasting, and other intelligent system techniques, to improve forecasting and marketing decisions. In looking at the Winter 2010 Marketing Educator’s American Marketing Association Conference, there are a number of tracks presented where the use of intelligent systems could be helpful: Consumer behavior, global marketing, brand marketing, business-tobusiness marketing, research methods, marketing strategy, sales and customer relationship management, service science, retailing, and marketing & technology. Digital-centered marketing where one takes advantage of such digital marketing elements as mobile, viral, and social marketing channels is a growing field that can apply the synergies of marketing and intelligent systems. Positions for Directors of Marketing Intelligence are also appearing to be the champions of new marketing methods. Gartner Group reports, such as the August 2008 report on “Social Media Delivers Marketing Intelligence”, are further evidence of this evolving field. In a recent report of “hot topics” for college undergraduates to select as majors in the coming years, the fields of service science, sustainability, health informatics, and computational sciences were cited as the key emerging fields. Certainly, marketing intelligence can play a key role in the service science field, as well as perhaps some of the other fields noted. In May 2008, there was even a special issue on “Service Intelligence and Service Science” published in the Springer Service-Oriented Computing and Applications Journal. In July 2009, there was the 3rd International Workshop on Service Intelligence and Computing to look at the synergies between the service intelligence and service sciences fields. In the years ahead, advanced computational technologies will be applied to the service science domain to enhance marketing types of decisions. In 2006, I edited a book titled Strategic Intelligence: Business Intelligence, Competitive Intelligence, and Knowledge Management (Taylor & Francis). I defined strategic intelligence as the aggregation of the other types of intelligentsia to provide value-added information and knowledge toward making organizational strategic decisions. I see strategic intelligence as the intersection of business intelligence, competitive intelligence, and knowledge management, whereby business intelligence and knowledge management have a more internal focus and competitive intelligence has a greater external view. Marketing intelligence seems to contribute to both business and competitive intelligence—helping to identify hidden patterns and relationships of large masses of data and text and also assisting in developing a systematic program for collecting, analyzing, and managing external information relating to an organization’s decision making process. I believe that this book sheds important light on how marketing intelligence, through the use of complementary marketing and intelligent systems techniques, can add to the strategic intelligence of an organization. The chapters present both a marketing and soft computing/intelligent systems perspective, respectively. I commend the editors and authors towards filling the vacuum in providing a key reference text in the marketing intelligence field. Enjoy!  
   
  Preface  
   
  The development of ad hoc Knowledge Discovery in Databases (KDD) applications for the resolution of information and decision-taking problems in marketing is more necessary than ever. If we observe the evolution of so-called Marketing Management Support Systems (MkMSS) through time, it is easy to see how the new categories of systems which have appeared over the last two decades have led in that direction. In fact, during the eighties, the inflection point was set that marked a transition stage from what are known as Data-driven Systems to Knowledge-based Systems, i.e. MkMSS based on Artificial Intelligent (AI) methods. The popular Marketing Expert Systems were the first type in this MkMSS category. Then, other new types within this category appeared, such as Casebased Reasoning Marketing Systems, Systems for the Improvement of Creativity in Marketing, Marketing Systems based on Artificial Neural Networks, Fuzzy Rules, etc. Most of these systems have been recent proposals and, in any case, their application is still scarce in marketing practical and, specially, academic domains. Anyhow, we have noticed a clear greater interest and use of these Knowledge-based Systems among marketing professionals than among marketing academics. Indeed, we perceive a notable disconnection of the latter from these systems, who still base most of their analytical methods on techniques belonging to statistics. Doubtless, this fact contributes to these two dimensions of marketing—i.e. the professional and the academic—grow apart. During the years that we have been working on this research stream, we have realized the significant lack of papers, especially in marketing journals, which focus on developing ad hoc AI-based methods and tools to solve marketing problems. Obviously, this also implies a lack of involvement by marketing academics in this promising research stream in marketing. Among the reasons that can be argued to justify the residual use that marketing academics make of AI, we highlight a generalized ignorance of what some branches of the AI discipline (such as knowledge-based systems, machine learning, soft computing, search and optimization algorithms, etc.) can offer. Of course, we encourage marketing academics to show a strong determination to approximate AI to the marketing discipline. When we talk about approximation, we refer to going far beyond a superficial knowledge of what these AI concepts are. On the contrary, we believe that multidisciplinary research projects, formed by hybrid teams of marketing and artificial intelligence people, are more than necessary. In essence, the AI discipline has a notable number of good researchers who are interested in applying their proposals, where business in general, management  
   
  VIII  
   
  Preface  
   
  and, in particular, marketing are target areas for application. However, the quality of such applications necessarily depends on how well described the marketing problem to be solved is, as well as how well developed and applied the AI-based methods are. This means having the support and involvement of people belonging to marketing, the users of such applications. Considering the above, this editorial project has two strategic aims: 1.  
   
  2.  
   
  Contribute and encourage the worldwide take-off of what we have called Marketing Intelligent Systems. These are, in general, AI-based systems applied to aid decision-taking in marketing. Moreover, when we recently proposed this term of Marketing Intelligent Systems, we specifically related it to the development and application of intelligent systems based on Soft Computing and other machine-learning methods for marketing. This is the main scope of interest. Promote the idea of interdisciplinary research projects, with members belonging to AI and marketing, in order to develop better applications thanks to the collaboration of both disciplines.  
   
  This book volume presented here is a worthy start for these purposes. Next, we briefly comment on its structural parts. Prior to the presentation of the manuscripts selected after a competitive call for chapters, the first block of this book is dedicated to introducing diverse leading marketing academics’ reflections on the potential of Soft Computing and other AIbased methods for the marketing domain. Following these essays, the book is structured in five main parts, in order to articulate in a more congruent manner the rest of the chapters. In this regard, the reader should be aware of the fact that some of the chapters could be reasonably assigned to more than one part, though they have been finally grouped as follows. The first part deals with segmentation and targeting. Duran et al. analyze the use of different clustering techniques such as k-means, fuzzy c-means, genetic kmeans and neural-gas algorithms to identify common characteristics and segment customers. Next, Markic and Tomic investigate the integration of crisp and fuzzy clustering techniques with knowledge-based expert systems for customer segmentation. Thirdly, Van der Putten and Kok develop predictive data mining for behavioral targeting by data fusion and analyze different techniques such as neural networks, linear regression, k-nearest neighbor and naive Bayes to deal with targeting. Finally, Bruckhaus reviews collective intelligent techniques which allow marketing managers to discover and approach behaviors, preferences and ideas of groups of people. These techniques are useful for new insights into firms’ customer portfolios so they can be better identified and targeted. The second part contains several contributions grouped around marketing modeling. Bhattacharyya explores the use of multi-objective genetic programming to derive predictive models from a marketing-related dataset. Orriols-Puig et al. propose an unsupervised genetic learning approach based on fuzzy association rules to extract causal patterns from consumer behavior databases. Finally, Pereira  
   
  Preface  
   
  IX  
   
  and Tettamanzi introduce a distributed evolutionary algorithm to optimize fuzzy rule-based predictive models of various types of customer behavior. Next, there are two parts devoted to elements of the marketing-mix, specifically applications and solutions for Communication and Product policies. In the third part, Hsu et al. show how a fuzzy analytic hierarchy process helps to reduce imprecision and improve judgment when evaluating the preference of customer opinions about customer relationship management. López and López propose a distributed intelligent system based on multi-agent systems, an analytic hierarchy process and fuzzy c-means to analyze customers’ preferences for direct marketing. Wong also addresses direct marketing but using evolutionary algorithms that describe Bayesian networks from incomplete databases. The fourth part consists of two chapters directly related to Product policy, plus a third dealing with a problem of consumer’s choice based on diverse criteria, mainly functional characteristics of products, though this contribution also has implications for strategic and other marketing-mix areas. Genetic algorithms have proved to be effective in optimizing product line design, according to both Tsafarakis-Matsatsinis and Balakrishnan et al. in their chapters. A dynamic programming algorithm is also used in the second case to seed the genetic algorithm with promising initial solutions. In Beynon et al.’s chapter, probabilistic reasoning is hybridized with analytic hierarchy processes to approach the problem of consumer judgment and the grouping of the preference criteria that drive their product/brand choices. The final part is a set of contributions grouped under e-commerce applications. Sun et al. propose a multiagent system based on case-based reasoning and fuzzy logic for web service composition and recommendation. Dass et al. investigate the use of functional data analysis for the dynamic forecasting of price prediction in simultaneous online auctions. Finally, Beynon and Page deploy probabilistic reasoning and differential evolution to deal with incomplete data for measuring consumer web purchasing attitudes. This book is useful for technicians who apply intelligent systems to marketing, as well as for those marketing academics and professionals interested in the application of advanced intelligent systems. Synthetically, it is especially recommended for the following groups: • • • •  
   
  Computer Science engineers working on intelligent systems applications, especially Soft-Computing-based Intelligent Systems. Marketers and business managers of firms working with complex information systems. Computer Science and Marketing academics, in particular those investigating synergies between the AI and Marketing. PhD students studying intelligent systems applications and advanced analytical methods for marketing.  
   
  X  
   
  Preface  
   
  Finally, we wish to thank Springer and in particular Prof. J. Kacprzyk, for having given us the opportunity to make real this fascinating and challenging dream. We are also honored and privileged to have received help and encouragement from several notable world marketing academics; we thank you for your support, smart ideas and thoughts. Likewise, we offer our most sincere acknowledgment and gratitude to all the contributors for their rigor and generosity in producing such high quality papers. Last but not least, we especially thank the team of reviewers for their great work.  
   
  March 2010  
   
  Granada (Spain) Jorge Casillas and Francisco J. Martínez-López University of Granada, Spain  
   
  Contents  
   
  Essays Marketing and Artiﬁcial Intelligence: Great Opportunities, Reluctant Partners . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Berend Wierenga  
   
  1  
   
  Data Mining and Scientiﬁc Knowledge: Some Cautions for Scholarly Researchers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Nick Lee, Gordon Greenley  
   
  9  
   
  Observations on Soft Computing in Marketing . . . . . . . . . . . . . . . David W. Stewart  
   
  17  
   
  Soft Computing Methods in Marketing: Phenomena and Management Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . John Roberts  
   
  21  
   
  User-Generated Content: The “Voice of the Customer” in the 21st Century . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Eric T. Bradlow  
   
  27  
   
  Fuzzy Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dawn Iacobucci KDD: Applying in Marketing Practice Using Point of Sale Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Adilson Borges, Barry J. Babin Marketing – Sales Interface and the Role of KDD . . . . . . . . . . . Greg W. Marshall  
   
  31  
   
  35 43  
   
  XII  
   
  Contents  
   
  Segmentation and Targeting Applying Soft Cluster Analysis Techniques to Customer Interaction Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Randall E. Duran, Li Zhang, Tom Hayhurst Marketing Intelligent System for Customer Segmentation . . . Brano Markic, Drazena Tomic  
   
  49 79  
   
  Using Data Fusion to Enrich Customer Databases with Survey Data for Database Marketing . . . . . . . . . . . . . . . . . . . . . . . . 113 Peter van der Putten, Joost N. Kok Collective Intelligence in Marketing . . . . . . . . . . . . . . . . . . . . . . . . . 131 Tilmann Bruckhaus  
   
  Marketing Modelling Predictive Modeling on Multiple Marketing Objectives Using Evolutionary Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155 Siddhartha Bhattacharyya Automatic Discovery of Potential Causal Structures in Marketing Databases Based on Fuzzy Association Rules . . . . . 181 Albert Orriols-Puig, Jorge Casillas, Francisco J. Mart´ınez-L´ opez Fuzzy–Evolutionary Modeling of Customer Behavior for Business Intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207 C´elia da Costa Pereira, Andrea G.B. Tettamanzi  
   
  Communication/Direct Marketing An Evaluation Model for Selecting Integrated Marketing Communication Strategies for Customer Relationship Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227 Tsuen-Ho Hsu, Yen-Ting Helena Chiu, Jia-Wei Tang Direct Marketing Based on a Distributed Intelligent System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255 Virgilio L´ opez Morales, Omar L´ opez Ortega Direct Marketing Modeling Using Evolutionary Bayesian Network Learning Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273 Man Leung Wong  
   
  Contents  
   
  XIII  
   
  Product Designing Optimal Products: Algorithms and Systems . . . . . . . 295 Stelios Tsafarakis, Nikolaos Matsatsinis PRODLINE: Architecture of an Artiﬁcial Intelligence Based Marketing Decision Support System for PRODuct LINE Designs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337 P.V. (Sundar) Balakrishnan, Varghese S. Jacob, Hao Xia A Dempster-Shafer Theory Based Exposition of Probabilistic Reasoning in Consumer Choice . . . . . . . . . . . . . . . . 365 Malcolm J. Beynon, Luiz Moutinho, Cleopatra Veloutsou  
   
  E-Commerce Decision Making in Multiagent Web Services Based on Soft Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389 Zhaohao Sun, Minhong Wang, Dong Dong Dynamic Price Forecasting in Simultaneous Online Art Auctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417 Mayukh Dass, Wolfgang Jank, Galit Shmueli Analysing Incomplete Consumer Web Data Using the Classiﬁcation and Ranking Belief Simplex (Probabilistic Reasoning and Evolutionary Computation) . . . . . . . . . . . . . . . . . . 447 Malcolm J. Beynon, Kelly Page Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 475  
   
  Marketing and Artificial Intelligence: Great Opportunities, Reluctant Partners Berend Wierenga Professor of Marketing Rotterdam School of Management, Erasmus University e-mail: [email protected]   
   
  1 Introduction Marketing managers make decisions about products, brands, advertising, promotions, price, and distribution channels, based on deep knowledge about customers. The outcomes of marketing decisions are dependent on the behavior of other actors such as competitors, suppliers and resellers. Furthermore, uncertain factors such as the overall economy, the state of the financial sector and (international) political developments play an important role. Marketing decision making not only refers to tactical marketing mix instruments (the well-known 4Ps), but also to strategic issues, such as product development and innovation and long term decisions with respect to positioning, segmentation, expansion, and growth. This short description illustrates that marketing is a complex field of decision making. Some marketing problems are relatively well-structured (especially the more tactical marketing mix problems), but there are also many weakly-structured or even ill-structured problems. Many marketing phenomena can be expressed in numbers, for example sales (in units or dollars), market share, price, advertising expenditures, number of resellers, retention/churn, customer value, etc. Such variables can be computed and their mutual relationships can be quantified. However, there are also many qualitative problems in marketing, especially the more strategic ones. Therefore, besides computation, marketing decision making also involves a large degree of judgment and intuition in which the knowledge, expertise, and experience of professionals play an important role. It is clear that marketing decision making is a combination of analysis and judgment. As we will see below, the analytical part of marketing decision making is well served with a rich collection of sophisticated mathematical models and procedures for estimation and optimization that support marketing decision making. However, this is much less the case for the judgmental part where knowledge and expertise play an important role. The question is whether the acquisition and use of knowledge and expertise by marketing decision makers and their application to actual marketing problems can also benefit from appropriate decision support technologies. In this book on marketing intelligent systems, it is logical to ask what the field of Artificial Intelligence can contribute here. Artificial Intelligence (AI) deals J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 1–8. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  2  
   
  B. Wierenga  
   
  with human intelligence and how this can be represented in computers. Important topics in AI are knowledge, knowledge representation, reasoning, learning, expertise, heuristic search, and pattern recognition. All these elements are relevant in the daily life of marketing decision makers who constantly use their knowledge, expertise and intuition to solve marketing problems. Therefore, potentially AI can make an important contribution to marketing decision making. However, so far this potential has only been realized to a very limited extent. This contribution takes a closer look at the opportunities for AI in marketing, takes stock of what has been achieved so far, and discusses perspectives for the future.  
   
  2 Marketing Problem-Solving Modes We start with a discussion about marketing problem-solving modes. These are specific ways of making marketing decisions. Basically, decision making is dependent on three factors: the marketing problem, the decision maker, and the decision environment. This results in four different marketing problem-solving modes: Optimizing, Reasoning, Analogizing, and Creating (ORAC) (Wierenga and Van Bruggen 1997; 2000). The ORAC model is depicted in Figure 1 and shows the full continuum of how marketing decision makers deal with problems. At the one extreme we have hard calculation (“clocks of mind”), and at the other we have free flows of thought, mental processes without a clear goal (“clouds of mind’). We briefly discuss the four marketing problem-solving modes.  
   
  O  
   
  =  
   
  Optimizing  
   
  R  
   
  =  
   
  Reasoning  
   
  A  
   
  =  
   
  Analogizing  
   
  C  
   
  =  
   
  Creating  
   
  Clocks of Mind ↑ . . . ↓ Clouds of Mind  
   
  Fig. 1 The ORAC model of marketing problem-solving modes (Wierenga and van Bruggen 1997; 2000)  
   
  Optimizing implies that there is an objectively best solution that can be reached by proper use of the marketing instruments. This is only possible if we have precise insight in the mechanism behind the variable that we want to optimize (e.g. sales, market share or profit). Once this mechanism is captured in a mathematical model, the best values for the marketing instruments (dependent on the objective function) can be found by applying optimization or simulation. An example of optimizing is deciding on the best media plan (i.e. the allocation over media such as TV, press, internet) for an advertising campaign, once the advertising budget and the relevant reach and costs data of the media are known.  
   
  Marketing and Artificial Intelligence: Great Opportunities, Reluctant Partners  
   
  3  
   
  Reasoning means that a marketer has a representation (mental model) of certain marketing phenomena in mind, and uses this as a basis for making inferences and drawing conclusions. For example, the decision maker may have a mental model of the factors that determine the market share of his brand. Suppose that this is relatively low in one particular geographical area. The manager might then reason (if ….then…) that this can be due to several possible causes, (i) deviant preferences of consumers; (ii) low efforts of salespeople; or (iii) relatively strong competition (Goldstein 2001). Market research can help to verify each of these possible causes and will result in decisions about possible actions (e.g. change the taste of the product; increase the salesforce). The outcomes of market research may also lead to the updating of managers’ mental models. Analogizing takes place when marketing decision makers, confronted with a problem, recall a similar problem that previously occurred and was solved in a satisfactory way. Decision makers often organize their experiences in the form of “stories”. New cases are easily interpreted using existing stories, and solutions are found quickly, often automatically. This type of analogical reasoning occurs very often in marketing. For example, when a new product is introduced, experiences with earlier product introductions act as points of reference. Creating occurs when the decision maker searches for novel and effective ideas and solutions. This means mapping and exploring the problem’s conceptual space and involves divergent thinking. In marketing, creating is a very important marketing problem-solving mode. Marketers are always looking for innovative product ideas, catchy advertising themes and imaginative sales promotion campaigns.  
   
  3 Marketing Problem-Solving Modes and Decision Support Technologies Over time a rich collection of decision aids have become available that can support marketing managers to improve the effectiveness and efficiency of their decisions. The complete set is referred to as marketing management support systems (MMSS). (Wierenga and van Bruggen 2000). Figure 2 shows how the decision support technologies used in these MMSS are related to the marketing problemsolving modes. The mapping to marketing problem-solving modes is not exactly one-to-one, but Figure 2 shows the overall tendencies. Marketing management support systems can be divided in two categories, datadriven and knowledge-driven. Marketing data have become available abundantly over the last few decades (e.g. scanner data; internet data) and data-driven decision support technologies are very prominent in marketing. They are particularly important for optimizing and reasoning. Methods from operations research (OR) and econometrics play an important role here. For example, OR methods can be used to optimally allocate the advertising budget over advertising media and econometric analysis can help to statistically determine the factors that affect market share. As we have just seen, the latter information is useful for reasoning about possible marketing actions, and for the updating of managers’ mental models.  
   
  4  
   
  B. Wierenga  
   
  Marketing ProblemSolving Modes Optimizing  
   
  Decision Support Technologies Data-driven • • •  
   
  Operations Research (OR) Econometric Modeling Predictive Modeling/NN  
   
  Reasoning Knowledge-driven • Analogizing  
   
  • •  
   
  Knowledge-Based Systems/ Expert Systems Analogical Reasoning/ Case-Based Reasoning Creativity Support Systems  
   
  Creating  
   
  Fig. 2 Marketing problem-solving modes and decision support technologies  
   
  Predictive modeling techniques used in Customer Relationship Management (CRM) and direct marketing are also data-driven. (Neural nets-NN is a predictive modeling technique that has its roots in AI). Knowledge-driven decision support technologies are particularly useful for marketing problem-solving modes that deal with weakly structured problems, parts (i.e. the qualitative element) of reasoning, analogizing, and creating. Knowledge-based systems (KBS) and expert systems (ES) are important examples. The latter, in particular, can also be used for reasoning about the factors behind particular marketing phenomena, for example the success of new products, or the effect of an advertising campaign. Decision support technologies based on analogical reasoning, such as case-based reasoning (CBR) have great potential for the analogizing and creating modes. This is also a potential application area for creativity support systems (Garfield 2008).  
   
  4 The State of Artificial Intelligence (AI) in Marketing Figure 2 shows that the potential for knowledge-driven decision support technologies in marketing is high. Contributions from AI are possible for three of the four marketing problem-solving modes. However, reality does not reflect this. To date, data-driven approaches, mostly a combination of operations research and econometric methods are dominant in marketing management support systems. It is safe to say that data-driven, quantitative models (i.e. the upper-right corner of Figure 2) make up over 80% of all the work in decision support systems for marketing at  
   
  Marketing and Artificial Intelligence: Great Opportunities, Reluctant Partners  
   
  5  
   
  this moment. Compared to this, the role of artificial intelligence in marketing is minor1. The number of publications about AI approaches in marketing literature is limited and the same holds true for the presence of marketing in AI literature. In 1958 Simon and Newell wrote that “the very core of managerial activity is the exercise of judgment and intuition” and that “large areas of managerial activity have hardly been touched by operations and management science”. In the same paper (in Operations Research) they foresaw the day that it would be possible “to handle with appropriate analytical tools the problems that we now tackle with judgment and guess”. Strangely enough, it does not seem that judgment and intuition in marketing have benefitted a lot from the progress in AI since the late fifties. It is true that AI techniques are used in marketing (as we will see below), but only to a limited degree. There are several (possible) reasons for the limited use of AI in marketing. • Modern marketing management as a field emerged in the late 1950s. At that time, operations research and econometrics were already established fields. In fact, they played a key role in the development of the area of marketing models (Wierenga 2008), which is one of the three academic pillars of contemporary marketing (the other pillars are consumer behavior and managerial marketing). Artificial intelligence as a field was only just emerging at that time. • OR and econometrics are fields with well-defined sets of techniques and algorithms, with clear purposes and application goals. They mostly come with userfriendly computer programs that marketers can directly implement for their problems. However, AI is a heterogeneous, maybe even eclectic, set of approaches, which often takes considerable effort to implement. Moreover, most marketing academics are not trained in the concepts and theories of AI. • The results of applications of OR and econometrics can usually be quantified, for example as the increase in number of sales or in dollars of profit. AI techniques, however, are mostly applied to weakly-structured problems and it is often difficult to measure how much better a solution is due to the use of AI, for example a new product design or a new advertising campaign. Marketers seem to be better at ease with rigorous results than with soft computing. There may also be reasons on the side of AI. • There seems to be little attention for marketing problems in AI. A recent poster of the “The AI Landscape” (Leake 2008) shows many (potential) applications of AI, ranging from education, logistics, surgery, security, to art, music, and entertainment, but fails to mention marketing, advertising, selling, promotions or other marketing-related fields.  
   
  1  
   
  Here we refer to the explicit use of AI in marketing. Of course, AI principles may be imbedded in marketing-related procedures such as search algorithms for the Internet).  
   
  6  
   
  B. Wierenga  
   
  • Perhaps the progress in AI has been less than was foreseen in 1958. In general, there has been a tendency of over-optimism in AI (a point in case is prediction about when a computer would be the world’s chess champion). The promised analytical tools to tackle judgmental marketing problems may come later than expected.  
   
  4.1 Applications of AI in Marketing The main applications of AI in marketing so far are expert systems, neural nets, and case-based reasoning. We discuss them briefly. 4.1.1 Expert Systems In the late eighties, marketing knowledge emerged as a major topic, together with the notion that it can be captured and subsequently applied by using knowledgebased systems. In marketing, this created a wave of interest in expert systems. They were developed for several domains of marketing (McCann and Gallagher 1990). For example: systems (i) to find the most suitable type of sales promotion; (ii) to recommend the execution of advertisements (positioning, message, presenter); (iii) to screen new product ideas, and (iv) to automate the interpretation of scanner data, including writing reports. Around that time, over twenty expert systems were published in marketing literature (Wierenga & van Bruggen 2000 Chapter 5).An example of a system specially developed for a particular marketing function is BRANDFRAME (developed by Wierenga, Dalebout, and Dutta 2000; see also Wierenga and van Bruggen 2001). This system supports a brand manager, which is a typical marketing job. In BRANDFRAME the situation of the (focal) brand is specified in terms of its attributes, competing brands, retail channels, targets and budgets. When new marketing information comes in, for example from panel data companies such as Nielsen and IRI, BRANDFRAME analyzes this data and recommends the marketing mix instruments (for example: lower the price; start a sales promotion campaign). It is also possible to design marketing programs in BRANDFRAME, for example for advertising or sales promotion campaigns. The system uses frame-based knowledge representation, combined with a rulebased reasoning system. In recent years, marketing literature has reported few further developments in marketing expert systems. 4.1.2 Neural Networks and Predictive Modeling Around 2000, customer relationship management (CRM) became an important topic in marketing. An essential element of CRM (which is closely related to direct marketing) is the customer database which contains information about each individual customer. This information may refer to socio-economic characteristics (age, gender, education, income), earlier interactions with the customer (e.g. offers made and responses to these offers, complaints, service), and information about the purchase history of the customer (i.e. how much purchased and when). This data can be used to predict the response of customers to a new offer or to predict customer retention/churn. Such  
   
  Marketing and Artificial Intelligence: Great Opportunities, Reluctant Partners  
   
  7  
   
  predictions are very useful, for example for selecting the most promising prospects for a mailing or for selecting customers in need of special attention because they have a high likelihood of leaving the company. A large set of techniques is available for predictive modeling. Prominent techniques are neural networks (NN) and classification and regression trees (CART), both with their roots in artificial intelligence. However, also more classical statistical techniques are used such as discriminant analysis and (logit) regression (Malthouse and Blattberg 2005; Neslin et al 2006). CRM is a quickly growing area of marketing. Companies want to achieve maximum return on the often huge investments in customer databases. Therefore, further sophistication of predictive modeling techniques for future customer behavior is very important. Fortunately, this volume contains several contributions on this topic. 4.1.3 Analogical Reasoning and Case-Based Reasoning (CBR) Analogical reasoning plays an important role in human perception and decision making. When confronted with a new problem, people seek similarities with earlier situations and use previous solutions as the starting point for dealing with the problem at hand. This is especially the case in weakly structured areas, where there is no clear set of variables that explain the relevant phenomena or define a precise objective. In marketing we have many such problems, for example in product development, sales promotions, and advertising. Goldstein (2001) found that product managers organize what they learn from analyzing scanner data into a set of stories about brands and their environments. Analogical reasoning is also the principle behind the field of case-based reasoning (CBR) in Artificial Intelligence. A CBR system comprises a set of previous cases from the domain under study and a set of search criteria for retrieving cases for situations that are similar (or analogous) to the target problem. Applications of CBR can be found in domains such as architecture, engineering, law, and medicine. By their nature, many marketing problems have a perfect fit with CBR. Several applications have already emerged, for example CBR systems for promotion planning and for forecasting retail sales (see Wierenga & van Bruggen 2000, Chapter 6). A recent application uses CBR as a decision support technology for designing creative sales promotion campaigns (Althuizen and Wierenga 2009). We believe that analogical reasoning is a fruitful area for synergy between marketing and AI.  
   
  4.2 Perspective Although there is some adoption of AI approaches in marketing, the two areas are almost completely disjoint. This is surprising and also a shame, because the nature of many marketing problems makes them very suitable for AI techniques. There is a real need for decision technologies that support the solution of weakly-structured marketing problems. Van Bruggen and Wierenga (2001) found that most of the existing MMSS support the marketing problem-solving mode of optimizing, but that they are often applied in decision situations for which they are less suitable (i.e. where the marketing problem-solving modes of reasoning, analogizing orcreating are applicable). Their study also showed that a bad fit between the  
   
  8  
   
  B. Wierenga  
   
  marketing-problem-solving mode and the applied decision support technology results in significantly less impact of the support system. It would be fortunate if further progress in AI can help marketing to deal with the more judgmental problems of its field. Reducing the distance between marketing and AI also has an important pay-off for AI. Marketing is a unique combination of quantitative and qualitative problems, which gives AI the opportunity to demonstrate its power in areas where operations research and econometrics cannot reach. Marketing is also a field where innovation and creativity play an important role. This should appeal to the imaginative AI people. Hopefully the current volume will be instrumental in bringing marketing and AI closer together.  
   
  References Althuizen, N.A.P., Wierenga, B.: Deploying Analogical Reasoning as a Decision Support Technology for Creatively Solving Managerial Design Problems. Working paper. Rotterdam School of Management, Erasmus University (2009) Garfield, M.J.: Creativity Support Systems. In: Burnstein, F., Holsapple, C.W. (eds.) Handbook on Decision Support Systems. Variations, vol. 2, pp. 745–758. Springer, New York (2008) Goldstein, D.K.: Product Manager’s Use of Scanner Data: a Story of Organizational Learning. In: Desphandé, R. (ed.) Using Market Knowledge, pp. 191–216. Sage, Thousand Oaks (2001) Leake, D.B.: AI Magazine Poster: The AI Landscape. AI Magazine 29(2), 3 Malthouse, E.C., Blattberg, R.C.: Can we predict customer lifetime value? Journal of Interactive Marketing 19(1), 2–16 (2005) Mc Cann, J.M., Gallagher, J.P.: Expert Systems for Scanner Data Environments. Kluwer Academic Publishers, Boston (1990) Neslin, S.A., Gupta, S., Kamakura, W., Lu, J., Mason, C.H.: Defection Detection: Measuring and Understanding the Predictive Accuracy of Customer Churn Models. Journal of Marketing Research 43, 204–211 (2006) Simon, H.A., Newell, A.: Heuristic Problem Solving: the Next Advance in Operations Research. Operations Research 6, 1–10 (1958) Van Bruggen, G.H., Wierenga, B.: Matching Management Support Systems and Managerial Problem-Solving Modes: The Key to Effective Decision Support. European Management Journal 19(3), 228–238 (2001) Wierenga, B. (ed.): Handbook of Marketing Decision Models, p. 630. Springer Science + Business Media, New York (2008) Wierenga, B., van Bruggen, G.H.: The Integration of Marketing Problem-Solving Modes and Marketing Management Support Systems. Journal of Marketing 61(3), 21–37 (1997) Wierenga, B., van Bruggen, G.H.: Marketing Management Support Systems: Principles, Tools, and Implementaiton, p. 341. Kluwer Academic Publishers, Boston (2000) Wierenga, B., Van Bruggen, G.H.: Developing a Customized Decision Support System for Brand Managers. Interfaces 31(3) Part 2(2), 128–145 (2001) Wierenga, B., Dalebout, A., Dutta, S.: BRANDFRAME: A Marketing Management Support System for the Brand Manager. In: Wierenga, B., van Bruggen, G. (eds.) Marketing Management Support Systems: Principles, Tools, and Implementation, pp. 231–262. Kluwer Academic Publishers, Boston (2000)  
   
  Data Mining and Scientific Knowledge: Some Cautions for Scholarly Researchers Nick Lee1 and Gordon Greenley2 1 Professor of Marketing and Organizational Research and Marketing Research Group Convenor Aston Business School, Birmingham, UK Co-Editor: European Journal of Marketing 2 Professor of Marketing and Marketing Subject Group Convenor Aston Business School, Birmingham, UK Co-Editor: European Journal of Marketing  
   
  1 Introduction Recent years have seen the emergence of data analytic techniques requiring for their practical use previously unimaginable raw computational power. Such techniques include neural network analysis, genetic algorithms, classification and regression trees, v-fold cross-validation clustering and suchlike. Many of these methods are what could be called ‘learning’ algorithms, which can be used for prediction, classification, association, and clustering of data based on previouslyestimated features of a data set. In other words, they are ‘trained’ on a data set with both predictors and target variables, and the model estimated is then used on future data which does not contain measured values of the target variable. Or in clustering methods, an iterative algorithm looks to generate clusters which are as homogenous within and as heterogeneous between as possible. Such analytic methods can be used on data collected with the express purposes of testing hypotheses. However, it is when such methods are employed on large sets of data, without a priori theoretical hypotheses or expectations, that they are known as data mining. In fact, it appears that such is the explosion in use of such methods, and in particular their use in commercial contexts such as customer relationship management or consumer profiling, that it is the methods themselves which are considered to be ‘data mining’ methods. However, it should be made clear at the outset of this essay that it is the use that they are put to which should be termed ‘data mining’, not the tools themselves (Larose 2005). This is despite the naming of software packages like ‘Statistica Data Miner’, which sell for sums at the higher end of 6-figures to commercial operations. In fact, a technique as ubiquitous as multiple regression can be used as a data mining tool if one wishes. It is the aim of this essay to place the recent exponential growth of the use of data mining methods into the context of scientific marketing and business research, and in particular to sound a note of caution for social scientific researchers about the over-use of a data-mining approach. In doing so, the fundamental nature J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 9–15. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  10  
   
  N. Lee and G. Greenley  
   
  of data mining is briefly outlined. Following this, data mining is discussed within a framework of scientific knowledge development and epistemology. Finally, the potential use of data mining in certain contexts is noted. We will conclude with some important points that business and marketing scholars should consider when considering the use of data mining approaches.  
   
  2 The Data Mining Method Data mining is one part of a wider methodology termed Knowledge Discovery in Databases (KDD). Within this process, the term data mining refers to the uncovering of new and unsuspected relationships in, and the discovery of new and useful knowledge from, databases (e.g. Adriaans and Zantinge, 1996; Hand et al, 2001). While it should be natural for the scholar to immediately consider the question of what exactly is knowledge, this will be dealt with in the next section. In a more practical context, scientists and businesspeople deal with large databases on a dayto-day basis. In many cases, they use the data to answer questions that they pose in a very structured way – such as ‘what is the difference between the mean level of job satisfaction across high and low-stress salespeople’ or ‘which customers bought brand x during August’. Such structured queries have been common practice for many years. The difference between the data mining approach and a normal structured interrogation of a data set is that, when data mining, one starts without such a structured question, but instead is interested in exploring the database for any potential ‘nuggets’ of interest. Another key point of interest is that – while this is not an essential component of a data-mining approach – most methods of data mining involve learning algorithms. Unlike traditional analysis of data, learning algorithms (such as genetic algorithms or neural networks) are able to be ‘trained’ to create rules which are able to describe a data set, that are then able to work on new data. While humans could of course train themselves to do this, the advantage of the learning algorithm is that it can work with far larger data sets, in far less time, than humans – as long as the data set contains at least some structure.  
   
  3 Data Mining and Scientific Knowledge The characteristics of the data mining approach introduced above have significant relevance to its use to generate scientific knowledge. Of course, as shall be seen subsequently, data mining has use in many contexts outside of science as well. However, as Editors of the European Journal of Marketing, a major journal dedicated to advances in marketing theory, it is their use in scientific knowledge development in marketing (and by extension more general business or social research) which is our primary concern in this essay1. Marketing has long debated 1  
   
  It is important to note that – while we were invited to write this essay as Editors of EJM – the opinions expressed here should not be taken to represent a formal editorial policy or direction for EJM in any manner.  
   
  Data Mining and Scientific Knowledge: Some Cautions for Scholarly Researchers  
   
  11  
   
  its status as a science (e.g. Buzzell, 1963, Hunt, 1983; 1990; 2003, Brown, 1995), with various scholars taking different viewpoints on both the nature of science itself, and whether marketing can be considered to be a science. Hunt’s (e.g. 1983) work is arguably the most articulate and significant corpus regarding this issue, and it is defensible to say that – working with the premise that one wants to class marketing as a science – Hunt’s delineation of the nature of science (e.g. 1983) can be taken as broadly coherent in the context of marketing research. Hunt defines three essential characteristics of a science (1983: pp. 18); “(1) a distinct subject matter, (2) the description and classification of the subject matter, and (3) the presumption that underlying the subject matter are uniformities and regularities which science seeks to discover”. Hunt also adds (pp. 18-19) that to be termed a science, a discipline must employ the scientific method; which he defines as a “set of procedures”. Like the nature of science itself, the scientific method has been subject to considerable debate and controversy over the last century (e.g. Feyerabend, 1993). One of the key areas of misunderstanding is whether the method refers to the practical techniques used for discovery, or the conceptual/theoretical method used to justify a discovery as knowledge (Lee and Lings 2008). Hunt (1983) points out that the scientific method is not dependent on the use of particular data collection methods, tools, or analysis techniques, since it is of course the case that different sciences use different tools as appropriate. Instead, the scientific method should more accurately be perceived as a method for justifying the knowledge claims uncovered by investigation (Lee and Lings 2008). In this sense, there are multiple (perhaps infinite) ways of discovery, and of making knowledge claims about the world, but at present only one scientific method of justifying those claims as actual knowledge. This method – termed more formally the hypothetico-deductive method – has proven to be the foundation of scientific research since its formal articulation by Karl Popper. Thus, in exploring the usefulness of data mining for scientific research, it is naturally necessary to do so in relation to where it may sit within a hypothetico-deductive approach to research. While a full explication of the hypothetico-deductive method is outside the scope of this short essay, it is the term deductive which is of most relevance to the present discussion. Of course, deduction refers to the creation of theory from logical argument, which may then be tested through empirical observation. While it is often characterized as a cycle of induction and deduction, the essence of the hypothetico-deductive method is the idea that one should create theoretical hypotheses through deductive reasoning, and then collect empirical data in an attempt to falsify those hypotheses. Certainly, one may begin the cycle by using inductive reasoning from some empirical observation or discovery, but until formal hypotheses are generated and subsequently tested, one should not claim to have created any scientific knowledge. The idea of falsification is of critical importance in this context. Current definitions of the nature of scientific research depend on the assumption that empirical data alone can never prove a hypothesis, but only disprove it. Thus, the hypothetico-deductive method can be seen as a way of systemizing the search for falsifying evidence about our hypotheses. This is in direct opposition to the pure empiricist or logical positivist position which was heretofore dominant in  
   
  12  
   
  N. Lee and G. Greenley  
   
  scientific research. Such approaches instead considered empirical observations not just to be sufficient proof alone, but in fact that all other types of evidence (e.g. rational thought and logical deduction) were of no use in knowledge generation. If one considers the hypothetico-deductive method to be the foundation of scientific research within marketing (cf. Hunt 1983), then the place of data mining is worthy of some discussion. Drawing from the nature of data mining as defined above, it would seem that data mining may have some use in a scientific knowledge creation process, but that this use would be limited. More specifically, the data mining approach is fundamentally an inductive one, in which a data set is interrogated in an exploratory fashion, in the hope of turning up something of interest. Surely, if one is working within a hypothetico-deductive paradigm of knowledge generation, any findings from a purely data mining study could never be considered as actual knowledge. Instead, such findings should be treated as knowledge claims, and used to help generate explicit theoretical hypotheses which can then be tested in newly-designed empirical studies, which collect new data. Only when these theoretical hypotheses fail to be falsified with additional empirical work can the knowledge claim then be considered as knowledge. It is certainly the case that the use of theory to help explain these empirical discoveries is also worthy of significant discussion. Or in other words whether purely empirical results from a data mining study only are enough to justify hypothesis generation and further testing. However, a full discussion of this is outside the present scope, given the short space available. Even so, our short answer to this question would be that the emergent inductive empirical relations would need theoretical deductive explanation as well, in order to justify them as testable hypotheses in a scientific context. In this sense, empirical data mining results are but a single strand of evidence or justification for a hypothesis, rather than sufficient alone. It is important to make clear however that this position refers to the data mining method, not to any particular technique or algorithm. Certainly, many algorithms commonly of use in data mining applications can and have been usefully employed in a deductive manner in scientific studies – such as multiple regression, principle components analysis, clustering, classification trees, and the like. However, the critical issue is not one of technique, but of the underlying epistemological position of the task employing the technique.  
   
  4 Data Mining in a Practical Context Notwithstanding the above, it is not the intention of this essay to decry the use of data mining approaches in general, since they are clearly of major potential use in both commercial and some scientific applications. Beginning with commercial applications, it is clear that marketing-focused firms can employ data mining methods to interrogate the huge customer databases which they routinely generate. Such work is common, and can include such tasks as market segmentation, customer profiling, and auditing. For example, it is well-known that Google utilizes data mining methods to predict which advertisements are best matched to which websites. Thus, without any actual knowledge (as we would term it) of why, Google can predict an advertisement’s likely success depending on how it is  
   
  Data Mining and Scientific Knowledge: Some Cautions for Scholarly Researchers  
   
  13  
   
  matched (Anderson 2008). Considering the terabytes of data Google collects constantly, such methods are likely to be the most effective way to predict success. Yet the question of whether raw prediction is actually scientific knowledge is moot in this and most other practical situations. As most business researchers know, few business organizations are particularly interested in explaining the theory of why things are related, but only in predicting what will happen if variables are changed. In other words, what ‘levers’ can be manipulated to improve performance? Data mining is an ideal tool for this task. However, raw data mining is also of significant use in many scientific fields outside of the business or social sciences. For example, sciences such as biochemistry work with massive data sets in many cases. In these situations, data mining can be usefully employed in uncovering relationships between for example genetic polymorphisms and the prevalence of disease. There is a significant difference between such scientific work and a typical business research study. In such biosciences, researchers often work within a very exploratory, or descriptive, context, and they also often work within contexts without large amounts of competing or unmeasured variables. For example, if one is working within a database of the human genome, then this is all the data. Conversely, if one is working within a database of customer characteristics, there may be many hundreds of unmeasured variables of interest, and any description of that database will be able to incorporate but a tiny subset of the possible explanatory variables. Even so – as is the case within neuroscientific research at present – purely exploratory or descriptive approaches (which data mining is useful for) must eventually be superseded by theory-driven hypothetico-deductive approaches (e.g. Senior and Russell, 2000).  
   
  5 Discussion and Conclusions The aim of this invited essay was to explore the implications and uses of data mining in the context of scientific knowledge generation for marketing and business research. In doing so, we defined both data mining and scientific knowledge. Importantly, data mining was defined as a method of exploration, not as a set of particular tools or algorithms. Knowledge was defined as distinct from a knowledge claim, in that a knowledge claim had not been subject to a hypothetico-deductive attempt at falsification. The importance of this distinction is that in most cases one cannot claim data mining approaches as tools of knowledge generation in a scientific context. At best, they are highly useful for the generation of hypotheses from data sets, which may previously have been unexplored. In this way, it is interesting to draw parallels with qualitative research approaches such as grounded theory (e.g. Glaser and Strauss, 1967). Glaser’s approach to grounded theory instructs that no appreciation of prior theories should be made before either collecting or analyzing data, in order to ‘let the data speak’ (Glaser 1992). Any argument in favor of data mining as a knowledge generation tool must therefore look to such approaches as justification. However, it is our view that – while such methods can result in truly original findings which would be unlikely to emerge from any other method – those findings should always be considered preliminary knowledge claims until further confirmatory testing.  
   
  14  
   
  N. Lee and G. Greenley  
   
  This is because, without a priori theoretical expectations (i.e. hypotheses), one is always at risk of over-interpreting the data. In fact, many data mining techniques use the term ‘overfitting’ to refer to this situation (Larose, 2005). In such an instance, one’s findings are essentially an artifact of the data set, and may not bear relation to the rest of the world. In other words, the training set is explained increasingly exactly, but the results are increasingly less generalizable to other data. Of course, if your data set is all of the relevant data in the world (as is the case in some scientific contexts), this is not a problem. However in most situations, and particularly within the business and social research contexts, our data contains only a subset of the available data, in terms of both subjects and possible variables. Overfitting in this case results in findings which are likely to have low external validity. Thus, we urge business and social researchers to exercise caution in the application of data mining in scientific knowledge generation. Even so, this is not to say that we consider it to be of no use at all. Just as many other exploratory techniques are of use in the hypothetico-deductive cycle, data mining may provide extremely valuable results in the context of the knowledge generation process as a whole. However, researchers would be well advised to avoid presenting the findings of pure data mining as anything other than preliminary or exploratory research (although of course this may be of significant use in many cases). Although we did not specifically discuss it here, we would also urge researchers to make sure they are knowledgeable in the appropriate use of various data mining algorithms, rather than using them as a ‘black box’ between their data and results. Such an approach runs the risk of being characterized as ‘data-driven’ and therefore should be given little time at top-level journals. In this way, we also urge editors and reviewers at journals to think carefully about the actual contribution of such studies, despite their often complex and impressive technical content. In conclusion, it is our view that explanatory theory is the key contribution of scientific research, and this should not be forgotten. Theory allows us to explain situations and contexts beyond our data, in contrast to pure prediction, which may have no real explanatory value whatsoever. While it may be of interest in many situations, it should not be characterized as scientific knowledge.  
   
  References Adriaans, P., Zantinge, D.: Data Mining. Addison-Wesley, Harlow, England (1996) Anderson, C.: The End of Science: The Data Deluge Makes the Scientific Method Obsolete. In: WIRED, vol. 16 (7), pp. 108–109 (2008) Buzzell, R.D.: Is Marketing a Science? Harvard Business Review 41(1), 32–40 (1963) Brown, S.: Postmodern Marketing, Thompson, London (1995) Feyerabend, P.K.: Against Method, 3rd edn. Verso, London (1993) Glaser, B.G.: Basics of Grounded Theory Analysis. Sociology Press, Mill Valley (1992) Glaser, B.G., Strauss, A.L.: The Discovery of Grounded Theory: Strategies for Qualitative Research. Aldine, Chicago (1967) Hand, D., Mannila, H., Smyth, P.: Principles of Data Mining. MIT Press, Cambridge (2001)  
   
  Data Mining and Scientific Knowledge: Some Cautions for Scholarly Researchers  
   
  15  
   
  Hunt, S.D.: Marketing Theory: The Philosophy of Marketing Science. Irwin, Homewood, IL (1983) Hunt, S.D.: Controversy in Marketing Theory: For Reason, Realism, Truth and Objectivity. M.E. Sharpe, Armonk (2003) Hunt, S.D.: Truth in Marketing Theory and Research. Journal of Marketing 54, 1–15 (1990) Lee, N., Lings, I.: Doing Business Research. Sage, London (2008) Senior, C., Russell, T.: Cognitive neuroscience for the 21st century. Trends in Cognitive Science 4, 444–445 (2000)  
   
  Observations on Soft Computing in Marketing David W. Stewart Dean of and Professor of Management and Marketing, A. Gary Anderson Graduate School of Management, University of California, Riverside, California, USA  
   
  Marketing managers make use of a variety of computer-based systems to aid decision- making. Some of these models would be considered “hard” models in the sense that they are based on quantitative data, usually historical data related to some type of market response and some empirically derived functional form of the relationships among actions in the market and market response (Hanssens, Parsons and Schultz 2008). Such models have been widely employed to decisions involving pricing and promotion, advertising scheduling and response, product design, and sales call scheduling, among others (Lilien and Rangaswamy 2006). These models, while very useful, require very rich data, as well strong assumptions about the generalizability of historical data to future events. These are assumptions likely to be less and less valid in an increasingly volatile world that includes regular introduction of new means of communications and product/service distribution, as well as new product and service innovations. Quantitative models in marketing are also limited by two other factors. First, it is often not possible to obtain certain types of data that would be desirable for making marketing decision - for example, experimental data on customer response to different product characteristics, advertising levels, product prices, etc. Although some data may be available from interviews, test market experiments, and the like, it is often necessary to supplement them with the judgment of experienced marketing managers. The second limitation is related to the complexity of many marketing factors, many of which are unquantifiable. The decision environment may simply to be too complex to develop a quantitative model that captures all of the relevant parameters. As a result of these limitations marketers have sought to build models that not include hard quantitative components, but also soft models that incorporate managerial judgment. These models are not “expert systems” in the classic sense of the term because they do not capture a set of replicable rules that would be characteristic of the use of artificial intelligence (Giarratano and Riley 2004, Little and Lodish 1981). Rather, decision calculus attempts to capture the subjective judgments, and hence, the experience of a decision maker within the context of a predictive model. For at least four decades the marketing literature has documented the development and commercial use of models that incorporate the judgments of experienced managers. Models have been published which assist managers in making decisions about a wide range of marketing variables, including prices, couponing J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 17–19. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  18  
   
  D.W. Stewart  
   
  efforts, advertising spending, media selection, and sales force scheduling. Many of these systems require that managerial expertise be used to set parameters and even to specify model forms. The way in which these models use judgmental data, the nature of their construction, and the purposes to which they are put differ in important ways from those of the typical expert system. Montgomery and Weinberg (1973) describe the typical decision calculus modeling exercise as: • •  
   
  • •  
   
  Managers first verbalize their implicit model of the situation or issue of interest, specifying factors that influence a criterion variable of interest and the relationships of factors to one another and to the criterion variable; This verbal model is translated to a formal mathematical model. In most applications the response function has two components, a current component and a delayed (or lagged) component. Lilien and Kotler (1983) provide a useful overview of typical forms these models take in marketing applications; Parameters associated with the mathematical model are estimated; and An interactive procedure is implemented that allows managers to examine the influence of variations of particular factors on the criterion. By examining the model outputs obtained by changing model inputs, managers can examine alternative decisions and determine the sensitivity of the criterion to changes in particular input factors;  
   
  Obviously, the development of a useful decision support tool is a primary benefit of model building involving decision calculus. Little and Lodish (1981) argue that numerous additional benefits also accrue from the model building exercise. Among these additional benefits are: • • • •  
   
  Model building facilitates the collection of data; It makes assumptions explicit; It identifies areas of disagreement and the nature of that disagreement; and It helps identify needs for information that have a high payoff potential.  
   
  Decision calculus models have a great deal in common with soft computer, though soft computing clearly brings a broader array of tools and methods to the task of informing decision-making. Soft computing also takes advantage of the enormous increase in computational power and the new techniques in biological computation that have emerged since the development of decision calculus models (Abraham, Das, and Roy 2007). Nevertheless, there is a common philosophical and methodological history that unites these different types of models. The underlying notion is that complex problems can be solved at a molar level as an alternative computational models that seek to fit quantitative models at a more micro level. Although it has demonstrate its utility in a host of venues, soft computing has yet to demonstrate its utility in solving practical marketing problems. It seems only a matter of time before it does so given the complex data sets now available to marketing organizations. It is also likely that these tools will carry benefits similar to those already demonstrated for decision calculus models in marketing.  
   
  Observations on Soft Computing in Marketing  
   
  19  
   
  References Abraham, A., Das, S., Roy, S.: Swarm Intelligence Algorithms for Data Clustering. In: Maimon, O., Rokach, L. (eds.) Soft Computing for Knowledge Discovery and Data Mining, pp. 279–313. Springer, New York (2007) Giarratano, J.C., Riley, G.: Expert Systems, Principles and Programming, 4th edn. PWS Publishing, New York (2004) Hanssens, D.M., Parsons, L.J., Schultz, R.L.: Market Response Models: Econometric and Time Series Analysis, 2nd edn. Springer, New York (2008) Lilien, G., Kotler, P.: Marketing Decision Making: A Model-building Approach. Harper and Row, New York (1983) Lilien, G.L., Rangaswamy, A.: Marketing Decision Support Models. In: Grover, R., Vriens, M. (eds.) The Handbook of Marketing Research, pp. 230–254. Sage, Thousand Oaks (2006) Little, J.D.C., Lodish, L.M.: Judgment-based marketing decision models: Problems and possible solutions/commentary on Judgment-Based Marketing Decision Models. Journal of Marketing 45(4), 13–40 (1981) Montgomery, D., Weinberg, C.: Modeling Marketing Phenomena: A Managerial Perspective. Journal of Contemporary Business (Autumn), 17–43 (1973)  
   
  Soft Computing Methods in Marketing: Phenomena and Management Problems John Roberts Professor of Marketing College of Business and Economics, Australian National University (Australia) and London Business School (UK) e-mail: [email protected]   
   
  1 Introduction Soft computing techniques gained popularity in the 1990s for highly complex problems in science and engineering (e.g., Jang et al. 1997). Since then, they have slowly been making their way into management disciplines (Mitra et al. 2002). In order to understand the potential of these methods in marketing, it is useful to have a framework with which to analyze how analytical methods can provide insight to marketing problems.  
   
  Marketing actions Brands and the marketing mix that supports them  
   
  Customer linking  
   
  Customer management including acquisition, retention and maximization  
   
  Marketplace phenomena Customer behavior, including beliefs, needs, preferences and actions Market environment including competition, channels, collaborators, and climate  
   
  Market feedback Market information: marketing research and intelligence Market analysis and insight  
   
  Market sensing  
   
  Fig. 1 A Model of the Market Decision Making Process  
   
  J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 21–26. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  22  
   
  J. Roberts  
   
  Marketing may be regarded as harnessing the resources of the organization to address the needs of its target customers, given the marketplace environment in which it competes (the top arrow in Figure 1). George Day calls this process “customer linking” (Day 1994). Actions in the top right box can be analyzed either from an internal perspective in terms of the products and services of the organization and the marketing mix that supports them, or externally in terms of its customers: how it attracts, retains and maximizes the value it provides to and captures from them. However, in order to focus the organization’s actions, an understanding of the environment is necessary, and feedback from the marketplace helps the manager better target her actions to where they will be most effective (the bottom arrows in Figure 1). Day calls this function “market sensing.” Market sensing has the dual elements of gathering data from the market and transforming those data into insights for action, by using suitable analytical tools. Soft computing tools form one weapon in the marketing analyst’s toolkit to provide that insight. In understanding the potential (and limitations) of soft computing tools, it is useful to analyze this environment. This chapter specifically examines the management actions for which the suite of techniques is well-suited, and the phenomena on which it can throw insight (the two top boxes in Figure 1). Details of the techniques of soft computing that belong to the bottom box are covered elsewhere in this volume.  
   
  2 Marketplace Phenomena Soft computing has particular strengths in the case of large databases and complex phenomena. To understand where these are most likely to occur it is useful to decompose the consumer decision. One traditional method of analyzing consumer decisions is by use of Lavidge and Steiner (1961)’s Hierarchy of Effects model (also known as the demand funnel and a variety of other names). This model is illustrated in Figure 2: One major driver of complexity of models (in terms of number of observations, parameters, and interactions between variables) is that of heterogeneity. When we have to allow for differences between individual consumers (or a large number of groups of consumers), the tractability of traditional models is likely to come under threat. In marketing, in reference to Figure 2, we do see situations where consumers vary in their proclivity to enter the category (need arousal). Both the diffusion of innovation and hazard rate literatures address this problem (for example, see Roberts and Lattin 2000). Similarly, Fotheringham (1988) has used a fuzzy set approach to modeling consideration set membership in the information search stage to probabilistically describe whether a brand will be evoked. Next, it is in the modeling of beliefs (perceptions), preferences, and choice that probabilistic representations of consumer decision processes have really come into their own, with Hierarchical Bayes now used as a standard approach to modeling consumer differences (see, Rossi and Allenby 2003 for a review). Finally, as we move from the acquisition stages to the retention and value maximization ones, customer satisfaction models have used a variety of soft computing techniques to identify individual or segment-level threats and opportunities.  
   
  Soft Computing Methods in Marketing: Phenomena and Management Problems  
   
  Need Arousal  
   
  Information search  
   
  23  
   
  Awareness  
   
  Consideration  
   
  Perceptions Evaluation Preference Purchase  
   
  Post purchase  
   
  Fig. 2 Lavidge and Steiner (1961)’s Hierarchy of Effects Model  
   
  While soft computing has much to recommend it in each stage of the hierarchy of effects, where it has the most to offer is when these complexities are compounded. That is, while we can encounter large scale problems in each of these areas, it is the convolution of these large scale problems that particularly lends itself to the approach. Typical examples of such multi-level problems include the following: •  
   
  •  
   
  •  
   
  Multidimensional consumer differences. We may have to segment on more than one basis (either within or between the levels of Figure 2). For example, within levels we may need to segment on the application to which the consumer is putting a service and her socio-economic profile. Between levels we may have to segment on the susceptibility of a consumer to an innovation at the need arousal level and the firm’s competitive capability at the purchase level. Multiple consumer purchases. The consumer may make multiple purchases within the category (suggesting a need to study share of wallet) or across categories (requiring estimation of cross-selling potential across multiple products). Interactions between consumers. Consumer networks may be critical, necessitating a study of order of magnitude of n2 with respect to customers, rather than just n (where n is the number of customers).  
   
  24  
   
  •  
   
  J. Roberts  
   
  Interactions between members of the market environment. Interactions between members of the channel, collaborators, competitors, and other groups (such as government regulators) may further compound the complexity of the problem.  
   
  3 Management Problems While multidimensional differences may exist at the level of the consumer or in the climate, they may not require complex models on the part of the manager to understand that variance. Before advocating a move to complex computing and modeling approaches, we must understand where just looking at the mean of distributions of heterogeneity is not going to lead to appropriate decisions, relative to a study of the entire distribution (or some middle approach such as looking at variances). Sometimes demand side factors alone may lead to a requirement to study the distribution of consumer tastes. The fallacy of averages in marketing is often illustrated by the fact that some people like iced tea, while others like hot tea. The fallacy of averages would suggest (incorrectly) that generally people like their tea lukewarm. In other situations, it is the context of managerial decision making in Figure 1 that makes complexity in the marketplace phenomena intractable to simplification and the use of means. The most obvious example of when modeling averages is problematic is when asymmetric loss functions exist: the benefit to the manager of upside error is not equal to the loss of downside. This will occur in a variety of situations. With lumpy investment decisions based on forecasts of consumer demand, over- and under-forecasts are likely to lead to very different consequences. Over-estimating demand is likely to lead to idle equipment and capital, while under-estimation will cause foregone contribution and possible customer dissatisfaction. Risk aversion on the part of the manager is another factor that will lead to asymmetric loss functions (Wehrung and Maccrimmon 1986). Finally, the presence of multiple decisions will lead to a requirement to study the whole distribution of customer outcomes, not just the mean. For example, in the ready to eat cereal and snacks market, Kellogg’s website lists 29 sub-brands1. Obviously, there are major interactions between these various sub-brands, and category optimization across them is an extremely complex problem. It is impossible to address without reference to the total distribution of beliefs, preferences and behaviors. Averages will not enable to answers to such portfolio management problems.  
   
  4 Summary Soft computing techniques have a number of advantages. Primarily, their ability to handle complex phenomena means that restrictive and potentially unrealistic assumptions do not need to be imposed on marketing problems. Balanced against 1  
   
  http://www2.kelloggs.com/brand/brand.aspx?brand=2  
   
  Soft Computing Methods in Marketing: Phenomena and Management Problems  
   
  25  
   
  this advantage is the loss of simplicity and parsimony, and this may incur associated costs of a loss of transparency and robustness. The mix of situations that favor soft computing techniques is increasing for a variety of reasons which may be understood by reference to Figure 1. Perhaps the primary drivers are trends in the market feedback tools available. Digital data capture means that large data sets are becoming available, enabling the modeling (and estimation) of consumer behavior in considerably finer detail than was previously possible. Computing power has obviously increased, and Moore’s law now enables calculations that would have been impossible, excessively onerous, or time intractable to be readily available. However, developments in both marketplace phenomena and managerial actions have also increased the potential application of soft computing approaches. Markets have become increasingly fragmented with the advent of highly targeted media and mass customization of products. For example, the U.K.’s largest retailer, Tesco, addresses over four million segments (Humby et al. 2008). In the top left box of Figure 1, managers have become increasingly sophisticated, with many firms employing sophisticated data mining techniques to address their customers. The emergence of specialist consulting and software firms (such as salesforce.com, dunhumby, and SAP) to support them has accelerated adoption in this area. Digitization has also increased the ability of the manager to experiment with a variety of strategies, leading to much richer mental models of the market, favoring the use of soft computing methods. Soft computing has the ability to lead us along paths that, as Keynes said, are more likely to be “vaguely right” rather than “precisely wrong” (e.g., Chick 1998). It is important that the migration path towards its use does not come at the cost of transparency or credibility. One way to ensure that this does not occur is to apply the techniques to environments that need the explanatory power they afford, and which influence management decisions for which the distribution of outcomes is critical, as well as the mean.  
   
  References Chick, V.: On Knowing One’s Place: The Role of Formalism in Economics. The Economic Journal 108(451), 1859–1869 (1998) Day, G.S.: The Capabilities of Market-Driven Organizations. Journal of Marketing 58(4), 37–52 (1994) Stewart, F.A.: Consumer Store Choice and Choice Set Definition. Marketing Science 7(3) (Summer), 299–310 (1988) Humby, C., Hunt, T., Phillips, T.: Scoring Points: How Tesco Continues to Win Customer Loyalty. Kogan Page, London (2008) Jang, J.-S.R., Sun, C.-T., Mizutani, E.: Neuro-Fuzzy and Soft Computing-A Computational Approach to Learning and Machine Intelligence. Matlab Curriculum Series, Boston (1997) Lavidge, R.J., Steiner, G.A.: A Model for Predictive Measurements of Advertising Effectiveness. Journal of Marketing 25(6), 59–62 (1961)  
   
  26  
   
  J. Roberts  
   
  Mitra, S., Pal, S.K., Mitra, P.: Data Mining in Soft Computing Framework: A Survey. IEEE Transactions On Neural Networks 13(1), 3–14 (2002) Roberts, J.H., Lattin, J.M.: Disaggregate Level Diffusion Models. In: Mahajan, V., Muller, E., Wind, Y. (eds.) New Product Diffusion Models, pp. 207–236. Kluwer Academic Publishers, Norwell (2000) Rossi, P.E., Greg, M.: Bayesian Statistics and Marketing. Marketing Science 22(3), 304–328 (Summer, 2003) Wehrung, D., Maccrimmon, K.R.: Taking Risks. The Free Press, New York (1986)  
   
  User-Generated Content: The “Voice of the Customer” in the 21st Century* Eric T. Bradlow K.P. Chao Professor, Professor of Marketing, Statistics, and Education, Editor-in-Chief of Marketing Science, and Co-Director of the Wharton Interactive Media Initiative, University of Pennsylvania, Pennsylvania, USA  
   
  1 Introduction It doesn’t take an academic paper to point out the prominence that companies like Facebook, MySpace, YouTube, etc. have had on our popular culture today. Many see it as an efficient communication mechanism (Web 2.0 if you will) in comparison to email and static content postings which now, remarkably only 15 years later after the internet ‘launch’, some people see as “old school”. In some sense, Andy Warhol’s prediction of “15 minutes fame” for each and any one of us can now be “self-generated” through our own hard work and user-generated content. Thus, with all of this impact (societally) as backdrop, where does it leave many of us, as academics? The answer, and I hope this essay provides some impetus for that, is not on the sidelines. As a good sign, recently a joint call for funded research proposals between the Wharton Interactive Media Initiative (WIMI, www.whartoninteractive.com) and the Marketing Science Institute (MSI, www.msi.org) on the impact and modeling of user-generated content (UGC) generated an overwhelming response with over 50 submissions. Even better news was that these submissions were broad in their scope. As a non-random sampling of ideas generated, consider the following. •  
   
  •  
   
  *  
   
  What is the impact of UGC on customer satisfaction and stock prices? Is there information contained in UGC that can help predict supra-normal returns? This can be considered, if you will, an update to the work of Fornell and colleagues (e.g. Anderson et. al, 1994), but now one based on UGC. How does the quantity and valence of UGC impact the diffusion (Bass, 1969) of new products? Note, that while the “scraping” of quantity information for the ‘amount’ of UGC may be somewhat simple, the valence of that information (‘quality’) is less so. While this may make the  
   
  Financial support for this work was provided by the Wharton Interactive Media Initiative (www.whartoninteractive.com).  
   
  J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 27–29. springerlink.com © Springer-Verlag Berlin Heidelberg 2010  
   
  28  
   
  E.T. Bradlow  
   
  •  
   
  timid shy away, this is one example of an opportunity where data mining and marketing scientists can partner together. Conjoint Analysis (Green and Rao, 1971) has long been a mainstay of marketing researchers as a method to understand consumer preferences for product features. But, how does one know that one has the right attributes in the first place – i.e. the classic “garbage in garbage out”? In a recent paper, Lee and Bradlow (2009) utilize feature extraction and clustering techniques to discover attributes that may be left off via standard focus group or managerial judgment methods.  
   
  While these three examples are different in spirit, they all share a common theme, what can really be extracted from UGC that would aid decision-makers? In the next section, I discuss some thoughts, supportively encouraging and otherwise.  
   
  2 Marketing Scientists Should Care about UGC or Should They? Forecasting is big business. The ability to predict consumer’s actions in the future allows marketing interventions such as targeted pricing (Rossi et al, 1996), target promotions (Shaffer and Zhang, 2002), and the like. The promise that UGC can improve these marketing levers is certainly one reason that firms are investing heavily in data warehouses that can store this information and without this does UGC really have a “business future”? While it might seem tautological that UGC can help predict “who wants what” and “when”, it becomes less obvious when one conditions on past behavioral measures such as purchasing, visitation, etc… (Moe and Fader, 2004). In addition, what is the cost of keeping UGC at the individual-level? Thus, a new stream of research on data minimization methods, i.e. What is the least amount of information that needs to be kept for accurate forecasting? (Musalem et. al, 2006 and Fader et al, 2009) will soon, I believe, be at the forefront of managerial importance. Fear, created by the loss of not keeping something that may somehow, someday be useful, will be replaced by the guiding principles of parsimony and sufficiency (in the statistical sense and otherwise). Or, let us consider another example of UGC, viral spreading through social networks (Stephen and Lehmann, 2009). Does having content that users provide, knowing who their friends are, and how and to what extent they are sharing that information provide increased ability for targeted advertising? Does it provide the ability to predict “customer engagement” which can include pageviews, number of visits (Sismeiro and Bucklin, 2004), use of applications (now very popular on websites) and a firm’s ability to monetize it? These are open empirical questions which marketing scientists likely can not answer alone because of the widespread data collection that is necessary. We conclude next with a call for Data Mining and Marketing Science to converge.  
   
  User-Generated Content: The “Voice of the Customer” in the 21st Century  
   
  29  
   
  3 Marketing Scientists and Data Mining Experts Need Each Other Now More Than Ever With all of the data that is abundant today, theory is now needed more than ever. Yes, I will say it again, theory is need now more than ever despite the belief of some that the massive amounts of data available today might make “brute empiricism” a solution to many problems. Without theory, all we are left with is exploration and sometimes massively unguided at that. Through the partnering of data mining/KDD experts in data collection and theory, and marketing scientists who can help link that data and theory to practice, UGC presents the next great horizon for “practical empiricism”. While the lowest hanging fruit might be including UGC covariates as predictors in models of behavior, hopefully our scientific efforts will move beyond that towards an understanding of its endogenous formation (the whys of people’s creation of it) and also an understanding of when it is truly insightful.  
   
  References Anderson, E.W., Fornell, C., Lehmann, D.R.: Customer Satisfaction, Market Share, and Profitability: Findings from Sweden. Journal of Marketing 58(3), 53–66 (1994) Bass, F.M.: A New Product Growth Model for Consumer Durables. Management Science 15, 215–227 (1969) Fader, P.S., Zheng, Z., Padmanabhan, B.: Inferring Competitive Measures from Aggregate Data: Information Sharing Using Stochastic Models, Wharton School Working Paper (2009) Green, P.E., Rao, V.R.: Conjoint measurement for quantifying judgmental data. Journal of Marketing Research 8, 355–363 (1971) Griffin, A., Hauser, J.R.: The Voice of the Customer. Marketing Science 12(1), 1–27 (Winter 1993) Lee, T.Y., Bradlow, E.T.: Automatic Construction of Conjoint Attributes and Levels From Online Customer Reviews, Wharton School Working Paper (2009) Moe, W.W., Fader, P.S.: Dynamic Conversion Behavior at E-Commerce Sites. Management Science 50(3), 326–335 (2004) Musalem, A., Bradlow, E.T., Raju, J.: Bayesian Estimation of Random-Coefficients Choice Models using Aggregate Data. Journal of Applied Econometrics (2006) (to appear) Rossi, P.E., McCulloch, R.E., Allenby, G.M.: The Value of Purchase History Data in Target Marketing. Marketing Science 15, 321–340 (1996) Shaffer, G., Zhang, Z.J.: Competitive One-to-One Promotions. Management Science 48(9), 1143–1160 (2002) Sismeiro, C., Bucklin, R.E.: Modeling Purchase Behavior at an E-Commerce Web Site: A Task Completion Approach. Journal of Marketing Research, 306–323 (August 2004) Stephen, A.T., Lehmann, D.R.: Is Anyone Listening? Modeling the Impact of Word-ofMouth at the Individual Level, Columbia University Working Paper (2009)  
   
  Fuzzy Networks Dawn Iacobucci E. Bronson Ingram Professor in Marketing, Owen Graduate School of Management, Vanderbilt University, Nashville, TN, USA  
   
  Knowledge discovery and fuzzy logic have great potential for social network models. Networks are currently extraordinarily popular, and while it’s fun to work in an area that people find interesting, there is such a thing as a topic being too popular. Networks are too popular in the sense that they are not widely understood by users, hence they are thought to be the new, new thing, capable of answering all questions, from “Will my brand’s presence on Facebook help its equity?” to “ Will a network bring peace to the Middle East?” Fuzzy logic should help new users proceed from naïve enthusiasm to thoughtful application, because fuzzification embraces approximation; huge questions cannot be answered with simple, precise estimates, but a fuzzy approach can put the inquirer in the rough vicinity of an answer (Martínez-López and Casillas, 2008). This essay considers three popular uses of networks: word-of-mouth, brand communities, and recommendation agents, and the application of fuzziness in each realm. The first of these, word-of-mouth, has long been recognized as a powerful marketing force. Marketers routinely consider the diffusion of a new product or idea into and throughout the marketplace using models that posit the mechanism of customers informing each other. Those who adopt early are thought to influence the choices of those who adopt later. Hence, currently, the marketing question that seems to be the “holy grail” takes this form, “How can networks help me identify my influential customers?” This question is remarkably easy to answer via social network techniques. Actors in the network are assessed for their volume and strength of interconnections. Actors that are more interconnected with others are said to be “central” compared to more “peripheral” in the network. Depending on what the network ties reflect, centrality may manifest an actor’s importance, power, communication access, and the like. In a word-of-mouth network such as those sought in diffusion studies, these central players are the very essence of an influential opinion leader. There are several criteria to assess centrality, and as a result, indices abound (Knoke and Yang, 2007). For example, some measures reflect the sheer number of connections, or their weighted strengths or frequencies of connections. Other indices capture the extent to which actors are key in bridging multiple parts of the network map. Still other centrality measures reflect a sense of closeness among the network players, as in the number of steps between pairs of actors, or their “degrees of separation.” Nevertheless, the centrality indices share the property J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 31–34. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  32  
   
  D. Iacobucci  
   
  that each captures the extent to which an actor has more connections to others, or stronger, or more frequently activated ties to others. These ties may be primarily inbound, and then the actor is said to be popular. The ties may be predominately outward bound, and then the actor is said to be expansive (e.g., extroverted). So where does fuzziness come in? Marketers understand that just because a customer engages in high activity, whether they claim many friends on a mobile phone plan, or are a frequent blogger, or actively recruit many friends on their Facebook page, it does not necessarily translate into their being an influential. But for all practical purposes, isn’t this status “close”? If someone posts to a blog, and some readers dismiss the posting as being uninformed, the marketer may be disappointed that this blogger isn’t as influential as first thought. Yet given their blogging volume and sheer statistical incidence, would it not likely be the case that their postings would impact some readers? Their blogging activity is presumably motivated by high customer involvement, thus may convey credibility, or at least passion. Thus, managing brand perceptions in the eyes of these frequent posters, frequent frienders, or frequent callers would be a social marketing activity whose result would be sufficiently close to the strategic aims of identifying and leveraging the influential customer. It is close enough. Brand communities are a contemporary marketing and social network phenomenon. Brand communities exist in real life and frequently online. People gather to share and learn and simply enjoy like-minded others. Some scholars claim they comprise a marketing or business strategy. I disagree. Marketing managers can try to launch such a community, and they can certainly insert marketing materials (brands, services, information) into the community in the hopes of effective persuasion. However, most authentic brand communities are grass-roots efforts, created by the love of a common element. For example, Harley riders got together long before some marketer coined the term, “brand community.” Marketing managers of brands that create such buzz and fondness can only hope to leverage the resulting community. Marketing managers of brands that create a collective yawn could persevere to eternity and not be successful in creating a community. When brand communities do exist, marketing phenomena such as diffusion can occur relatively quickly for two reasons. First, while the brand community can be rather large and its membership absolutely informal (e.g., no list of such actors exists), the community is still better defined and smaller to manage than the amorphous set of customers sought in the first application (of finding influentials among all customers). The marketer needs simply to be present at the auto / bike / beer / quilting event or website, and the community itself will take care of the information management, if it perceives value in the market offering. In addition, brand communities are largely democratic. In social network parlance, this egalitarian status shows itself distinctively in highly reciprocal or mutual ties. The ties create a clique of relatively highly interconnected actors comprising a subgroup within the network. Unlike the hierarchical relations between an early adopter exerting influence over a later adopter, customer elements in brand communities share mutual respect and communication. In such structures, those actors who extend ties in great volume tend to also receive them proportionally frequently.  
   
  Fuzzy Networks  
   
  33  
   
  There is a lot to be learned from the patterns of social networks of brand communities—how do the Saturn and Harley communities compare? How do communities of brands whose customers are predominately women compare with those for men’s brands? How do Latin American constituted communities compare with networks for British brands and customers? And of course, is there a structural network distinction between communities of highly profitable brands and those that are less so?The very egalitarian nature of the brand community is related to the fuzziness principle for this social network phenomenon. Specifically, while it is true that members of a brand community are not created equal in terms of facility and likelihood of becoming a brand champion, it is not important. The marketing manager’s actions can be somewhat imprecise. If the marketer gets the brands and communications into the hands of the brand champion, diffusion will be rapid within the community. But even if the marketer misses, and the materials reach a proxy actor, doing so will eventually affect the same result, with the simple delay of the proxy communicating to the real community leaders. It is close enough. Finally, the third marketing phenomenon that can benefit from a fuzzy application of social networks is that of recommendation agents (Iacobucci, Arabie and Bodapati, 2000). Current data-based algorithms for suggesting new products to purchase or new hyperlinks to follow for related articles to read are based on clustering techniques. Social networks models can contribute to this pursuit in lending the concept and techniques of structural equivalence. Two actors are said to be structurally equivalent if they share the same pattern of ties to others. If we are willing to fuzz up this criterion, then two customers would be said to be stochastically equivalent if they share similar searches, purchases, or preference ratings. This third application is different from the first two in that they had been true social networks—the entities in a word-of-mouth network or in a brand community are predominately human, and the ties between these actors, social, be they communication links or ties of liking, respect, sharing, etc. The recommendation agency problem is contextualized in a mixed network of ties among entities that are human, electronic, tangible goods and brands and intangible services. The nonhuman actors may be said to be connected to the extent they are similar, bundled, complementary, etc. The human actors may be interconnected via the usual social ties, but may not be; the recommendation system in Amazon uses no friending patterns, but that in Netflix allows for others to make direct suggestions to people they know. For this phenomenon, like seeking influentials and seeding brand communities, fuzzy networks should suffice to yield good marketing results. Browsing book titles, music CDs, or movie DVDs in stores is easier than doing so online, yet a model-derived suggestion can put the customer in the ball-park of a new set of titles that may be of interest. Amazon’s statistics indicate that recommendations are not mindlessly embraced; e.g., the website offers indices such as, “After viewing this item, 45% of customers purchased it, whereas 23% of customers purchased this next item.” When one item is viewed, and another is suggested, the suggested item need not be embraced for the tool to be approximately useful. The suggested item puts the user down a new search path, restarting a nonrandom  
   
  34  
   
  D. Iacobucci  
   
  walk. The user begins with a goal, which may be achieved immediately upon initial search, or it may be more optimally achieved upon corrected iteration based on inputs of recommendations resulting in successive approximations. Thus, we see that the system’s recommendation need not be “spot on.” Rather, the system only needs to be close enough. The study of network structures is a huge enterprise, and the application of networks to marketing and business phenomena is only in its infancy. These three examples were meant to be illustrative, drawing on popular and contemporary uses with which most readers will be familiar. Other examples at the nexus of fuzzy and networks will also benefit from the advantages of both. What was highlighted with the three exemplar fuzzy networks was the good news—that the application of networks does not need to be super precise for there to be great benefits realized.  
   
  References Iacobucci, D., Arabie, P., Bodapati, A.: Recommendation Agents on the Internet. Journal of Interactive Marketing 14(3), 2–11 (2000) Knoke, D., Yang, S.: Social Network Analysis, 2nd edn. Sage, Thousand Oaks (2007) Martinez-Lopez, F.J., Casillas, J.: Marketing Intelligent Systems for Consumer Behavior Modeling by a Descriptive Induction Approach Based on Genetic Fuzzy Systems. Industrial Marketing Management Press (2008), doi:10.1016/j.indmarman.2008.02.003  
   
  KDD: Applying in Marketing Practice Using Point of Sale Information Adilson Borges1 and Barry J. Babin2 1  
   
  Reims Management School IRC Professor of Marketing Reims Cedex, France 2 Louisiana Tech University Reims Management School Max P. Watson, Jr. Professor of Business Chair, Department of Marketing and Analysis Louisiana Tech University, Ruston, LA, USA  
   
  1 Introduction The dramatic increase in computing power that has emerged over the past two to three decades has revolutionized decision making in most business domains. In particular, point of sale data has been recorded by retailers now since the time of scanner technology. However, the great volumes of data overwhelmed conventional computation routines until more recently. Although the basic principles of data mining can be found in automatic interaction detection routines dating back to the 1960s, the computational limitations of those days prevented a thorough analysis of all the possible combinations of variables. Today, KDD procedures are commonplace as data mining hardware and software provides power to search for patterns among practically any imaginable number of combinations. No longer do we talk about computer capacity in terms of megabytes, but more commonly, data storage is discussed in terms of terabytes (1000 gigabytes) or petabytes (1000 terabytes). Thus, although this may seem like an overwhelming amount of data and to be less theory driven than is appropriate for conventional multivariate data analysis procedures, it is clear that multivariate data analysis is applicable within soft computing and other data mining procedures (see Hair, Black, Babin and Anderson 2010). In particular, routines such as cluster analysis, multidimensional scaling, and factor analysis can be integrated into these routines to help establish patterns that can be validated and reduce the risk of identifying patterns based on randomly occurring generalizations. Retail management, like all marketing efforts, deals with decision making under conditions of uncertainty. This paper describes a KDD application from a retail setting. Managers constantly seek the best arrangement of products to maximize the value experience for consumers and maximize sales revenues for the retailer. Can KDD procedures assist in the store layout question? Here is a description of one attempt to do so. J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 35 – 41. © Springer-Verlag Berlin Heidelberg 2010 springerlink.com  
   
  36  
   
  A. Borges and B.J. Babin  
   
  This paper proposes a new grocery store layout based on the association among categories. We use the buying association measure to create a category correlation matrix and we apply the multidimensional scale technique to display the set of products in the store space. We will imply that the buying association, measured through the market basket analysis, is the best way to find product organization that are best suited to one stop shopping.  
   
  2 The Store Layout Increasing space productivity represents a powerful truism in retailing: customers buy more when products are merchandised better. By careful planning of the store layout, retailers can encourage customers to flow through more shopping areas, and see a wider variety of merchandise (Levy and Weitz, 1998). There are at least two layout approaches: the traditional grid layout and the consumption universe layout. The traditional approach consists in repeating the industrial logic implementation, which means putting products that share some functional characteristics or origins in the same area. So we will find the bakery area (with bread, cakes, biscuits, etc), the vegetable area (with carrots, beans, etc), and so on. This traditional approach has been improved by the use of cross-elasticities, which should measure use association. Retailers have changed some categories and put more complementary in use items together. If a consumer wants take photos at a family party, s/he needs at least the camera and the film. In these cases, both products are complementary, because consumers need both at same time to achieve a specific goal (Walters, 1991). The nature of the relationship among products could be twofold: the use association (UA) or the buying association (BA). UA is the relationship among two or more products that meet specific consumer need by their functional characteristics. We can classify the relationship among different categories by their uses: the products can be substitutes, independent and complementary (Henderson and Quandt, 1958 ; Walter, 1991). The BA is the relationship established by consumers through their transaction acts and it will be verified in the market basket. While UA is not a necessary condition for BA, because UA depends much more on the products functional characteristics, BA depends on buying and re-buying cycles as well as on store marketing efforts. Despite improvements, the store remains organized in “product categories” as defined by the manufacturers or category buyers. This approach is company oriented and it fails to respond to the needs of the time pressured consumer. Some retailers are trying to move from this organization to something new, and are trying to become ¨consumer oriented¨ in their layout approach. Tesco has rethought their store layout with ¨plan-o-grams¨ to try to reflect local consumers needs (Shahidi, 2002). Other French retailers have used consumption universe layouts to make it easier for consumers to find their product in a more hedonic environment. This approach allows supermarkets to cluster products around meaningful purchase opportunities related to use association. Instead of finding coffee in the beverage section, cheese in fresh cheese, ham in the meat section, and cornflakes in  
   
  KDD: Applying in Marketing Practice Using Point of Sale Information  
   
  37  
   
  the cereal section, we could find all those products in the breakfast consumption universe. Other universes, such as the baby universe or tableware universe, propose the same scheme to cluster different product categories. It is too soon to foresee the financial results of such applications, but it shows, however, the retailer’s desire to improve in store product display. These new layout applications do not take the one stop shop phenomenon into account. In fact, this approach is based on the principle that conjoint use of products will unconditionally produce conjoint buying. The main problem with this rationale is that use association alone cannot be used to explain the associations carried out in the buying process (the market basket), because it fails to take buying time cycles into account. For example, bread and butter should be classified as occasional complements, and then they should be found in the same market basket (Walters, 1991). However, this could be not true, since the products have different buying and re-buying cycles. In that case, buying association may be weak, because bread is usually bought on a daily basis, and butter once every week or two. On the other hand, ‘independent products’ don’t have any use relationship, so they should not have any stable buying association. Meanwhile, Betancourt and Gautschi (1990) show that some products could be bought at the same time as a result of the store merchandising structure, store assortment, the marketing efforts and consumption cycles. So, the fact that two products are complementary is not a guarantee that those products will be present in the same market basket. In addition, some researchers have found that independent products have the same correlation intensity as complementary ones in the market baskets (Borges et alli, 2001). So, the store layout construction has to incorporate the market basket analysis to improve the one stop shopping experience. This allows retailers to cluster products around the consumer buying habits, and then to create a very strong appeal for today’s busy consumers.  
   
  3 The Buying Association: A Way to Measure the Relationship among Products The relationship between categories has always been articulated through their use, but this is not enough to explain conjoint presence in the market basket. These two kinds of relationships were clear for Balderston (1956), who presented it as (1) use complementary, if products are used together, and (2) buying complementary, if products are bought together. BA can be computed from supermarket tickets, and indicates real consumer behavior (it is not based on consumers’ declaration or intention). Loyalty cards and store scanners have produced a huge amount of data that is stored in data warehouses and analyzed by data mining techniques. Data Mining is regarded as the analysis step in the Knowledge Discovery in Databases (KDD) process, which is a "non-trivial process of extracting patterns from data that are useful, novel and comprehensive". In data mining, BA is considered as an association rule. This  
   
  38  
   
  A. Borges and B.J. Babin  
   
  association rule is composed of an antecedent and consequence set : A ⇒ B, where A is an antecedent and B a consequent; or A,B ⇒ C, where there are two antecedents and one consequence (Fayyad et alli, 1996). The BA is calculated by the following formula:  
   
  δ AB =  
   
  f ( AB) , f ( A)  
   
  (1)  
   
  where f(AB) represents the conjoint frequency of both products A and B and f(A) represents the product A frequency in the database. This equation is similar to the conditional probability that could be written as (A∩B)/A, given that A intersection B represents the market baskets where both products, A and B, are present at same time. The buying association represents the percentages of consumers that buy product A and who also buy product B. It shows the relationship strength between products, considering only the relationships carried out on buying behavior. This can be represented as a percentage: a BA of 35% between coffee and laundry is interpreted as 35% of consumers have bought coffee also bought laundry in the same shopping trip. In the same way that cross-elasticity is not symmetric, BA is also not symmetric. The BAFC can be different from BACF (this relationship depends mainly on the category penetration rates over the total sales). Mathematically: ∀ F>C, so (F∩C)/F < (F∩C)/C. So, if A frequency is different from B frequency, then the relationship among those products will always be asymmetric. For example, “F” represents the film and “C” the camera. Suppose the condition F>C is confirmed, then the film has a larger penetration in the market baskets than camera. If this condition is satisfied, then BAFC π dj ( f b ( x )) . Otherwise the models f a(x)and f b(x) are non-dominated with respect to each other. The set of models that are non-dominated by other models forms the nondominated or Pareto-optimal set of models. Several non-dominated models typically exist for multi-objective problems, especially when considering conflicting objectives. Here, high performance on one  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  159  
   
  objective corresponds to poor performance on the other. The set of non-dominated models along the Pareto-frontier represent different levels of tradeoff amongst the objectives. Solutions from traditional methods that optimize single objectives will typically be towards the extremities of the frontier. Adequately addressing multi-objectives requires consideration of solutions along the entire Pareto frontier, so that decision makers can examine different tradeoffs. Traditional methods attempt to find solutions distributed across the nondominated frontier by, for example, optimizing on an aggregated function of the objectives (Zeleny 1982) and varying the parameters to obtain individual solutions. Weighted combination of objectives into a single function to optimize will foster search towards a specific part of the tradeoff frontier. Linear weighted averages are often considered, with weights on the objectives based on desired tradeoffs or other domain knowledge. Without adequate prior understanding of the nature of tradeoffs and different solutions obtainable, considering such weighted combinations of objectives presents an unreliable and ad-hoc approach (Freitas 2004). This, however, remains the common approach to addressing multiple objectives in data mining. Other traditional approaches like hierarchical regressions also yield only a single solution, with the model-builder having little control over the tradeoff manifest in this solution. Evolutionary computation based approaches, with their population based search process, present effective mechanisms for searching along multiple objectives in parallel (Coello 2000, Coello et al. 2006, Deb 2001). Here, solutions along the entire Pareto frontier are simultaneously obtained, without any need for preference weighting on objectives. It thus readily provides decision-makers with a range of models exhibiting varying levels of tradeoff. Decision on a model to implement may then be taken after consideration of performance tradeoffs that different models along the Pareto frontier reveal.  
   
  2.2 Genetic Search Genetic algorithms provide a stochastic search procedure based on principles of natural genetics and survival of the fittest. They operate through a simulated evolution process on a population of structures that represent candidate solutions in the search space. Evolution occurs through (1) a selection mechanism that implements a survival of the fittest strategy, and (2) genetic recombination of the selected strings to produce ‘offspring’ for the next generation. The basic operation of a simple GA is illustrated in Figure 2, where each population carries N solutions. Each solution is evaluated against a fitness function (the search objective) that assigns a numeric fitness fi. The selection operation probabilistically chooses high fitness solutions into a ‘mating pool’ – solutions with higher than average fitness have a higher occurrence in the mating pool, while low fitness solutions may be eliminated from further consideration. Next, pairs of solutions from the mating pool are recombined to form new solutions (‘offspring’) for the next generation population. Crossover is a recombination operator where offspring are formed by combining parts of the ‘parent’ solutions.  
   
  160  
   
  S. Bhattacharyya  
   
  Selection  
   
  Recombination Crossover Mutation  
   
  Solution1 (f1)  
   
  Solution1  
   
  Solution2 (f2)  
   
  Solution2  
   
  Offspring2(1,4)  
   
  Solution3 (f3)  
   
  Solution2  
   
  Offspring3(2,7)  
   
  Solution4 (f4)  
   
  Solution4  
   
  Offspring4(2,7)  
   
  Offspring1(1,4)  
   
  ...  
   
  ...  
   
  ...  
   
  ...  
   
  ...  
   
  ...  
   
  SolutionN (fN)  
   
  SolutionX  
   
  OffspringN(x,y)  
   
  Generation t +1 Fig. 2 Genetic search –basic operation  
   
  For example, in Figure 2, crossover applied to Solution1 and Solution4 yields Offspring 1 and Offspring2. The mutation operator makes random changes to theoffspring and is applied with low probability. The population of new solutions is then again evaluated against the search objective in an iterative search procedure. Genetic search is known to be effective because of its ability to process and obtain good ‘building blocks’ – sub-structures in the solution -- that progressively yield better solutions, and from the implicit parallelism that arises from its simultaneous consideration of multiple solutions (see Goldberg (1989) for a detailed discussion.) GAs are considered suitable for application to complex search spaces not easily amenable to traditional techniques, and are noted to provide an effective tradeoff between exploitation of currently known solutions and a robust exploration of the entire search space. The selection scheme operationalizes exploitation and recombination effects exploration.  
   
  2.3 Multi-objective Evolutionary Computation Various multi-objective evolutionary algorithms (MOEA) have been proposed (Coello et al. 2006, Deb 2001). Key differences among these are in terms of selection and Pareto ranking, diversity preservation approaches, and use of secondary populations. In the vector-evaluated GA (Schaffer 1985), sub-populations are selected separately based on fitness along each of the different objectives; reproduction operators are then applied after shuffling all these sub-populations In Paretobased selection schemes, the selection of members for the new generation is based on some non-dominance criterion. Non-dominated solutions may be assigned equal selective pressure or population members can be ranked by the number of  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  161  
   
  solutions in the population that they are dominated by. Various approaches have been suggested for ranking population members based on non-dominance (see Coello et al. (2006), Deb (2001) for a full discussion). Genetic search typically converges to a single solution due to stochastic errors in selection. Fitness sharing (Goldberg and Richardson 1987), whereby population members in the same neighborhood have their fitness reduced through a sharing function, is used to foster search around multiple peaks in the fitness landscape and thus maintain diversity among population members. A sharing parameter determines the neighborhood distance within which such fitness adjustment occurs. In the multi-objective context, such techniques help maintain population members from across the Pareto frontier. Various sharing/niching techniques have been proposed to enhance Pareto-GAs by fostering wider sampling along the nondominated frontier (Coello 2000, Deb 2001, Veldhuizen and Lamont 2000). Performance of sharing is sensitive to sharing parameters, and guidelines for appropriate values have been suggested for some of the techniques. Among recent MOEA algorithms with noted strong performance are the nondominated sorting GA (Deb et al. 2002), the strength Pareto approach (Zitzler and Theile 1999), the Pareto archived evolutionary strategy (Knowles and Corne 2000), and the evolutionary local search algorithm (Menczer et al. 2000). Studies have reported comparisons between different MOEAs (Kollat and Reed 2005, Shaw et al. 1999, Veldhuizen and Lamont 1999), though as noted in Veldhuizen and Lamont (2000), there is no clear evidence favoring a specific ranking method or sharing approach. Another important aspect to MOEAs in practice is the use of a secondary population to store the non-dominated solutions found as genetic search progresses. This is necessary since non-dominated solutions in one generation can be lost in the stochastic search process. A basic approach can store all non-dominated solutions from each generation in the second population, which can be updated to remove dominated solutions. Alternately, solutions from this second population can be inserted periodically into the regular population to participate in the search (Veldhuizen and Lamont 2000). This is similar in concept to elitist selection in genetic search which preserves the current best solution into the next population. For Pareto-optimal solutions, the current non-dominated set can take up much of the next population; care thus needs to be taken to ensure adequate search. A number of papers in recent years report on application of MOEA to data mining problems. For classification, MOEAs have been suggested to simultaneously optimize accuracy as well as model compactness (Freitas et al. 2002; Kim, 2004; Dehuri and Mall, 2006; Pappa and Freitas, 2009). While most reported work considers objectives arising from traditional measures of data-mining performance, MOEAs can also directly try to optimize business objectives (Bhattacharyya 2000). MOEA has been applied to association rules mining considering support, interestingness and comprehensibility as different objectives (Ghosh and Nath, 2004; Kaya, 2006; Thilagam and Ananthanarayana, 2008). MOEAs have also been found useful for clustering (Handl and Knowles 2004, Kim et al. 2000, Murty et al. 2008), where different objectives can consider cluster cohesiveness, separation between clusters, minimal number of clusters, and minimal attributes used to describe clusters (Dehuri et al. 2008). A recent  
   
  162  
   
  S. Bhattacharyya  
   
  paper (Casillas and Martinez-Lopez 2009) obtains fuzzy rules predicting consumer behavior using MOEA, with error, rule set size and a measure of rule set interpretability as three objectives. Becerra et al. (2008) gives an overview on incorporating knowledge to facilitate search in MOEA through fitness function, search operators and initialization. Such mechanisms can be useful in improving the efficiency and efficacy of MOEAs in real-world applications.  
   
  3 Multi-objective Models Using Genetic Search This section describes the algorithm used to obtain multi-objective predictive models in this chapter, the fitness function formulation to incorporate business objectives for the marketing problem and dataset considered, and how performance of obtained models is evaluated.  
   
  3.1 Model Representation Solutions in a population can take a variety of representational forms, and in a data-mining context, the representation determines the nature of patterns that can be discerned from the data. Each population member can specify a weight vector on the predictor variables as in a linear regression; solutions then represent models of the form y = 1.67x1 + 11.6x2+ … Solutions can also represent a model expressed in symbolic rule form as in, for example, [(50K < Income =5.5K) OR ( …) …] => Buyer. Such representations can capture varied non-linear relationships in data. + *  
   
  *  
   
  +  
   
  exp *  
   
  X2 X1  
   
  *  
   
  X4  
   
  X1  
   
  X1  
   
  2.1 (2.1x1 + x2) exp(x1) + 0.7x1x4 Fig. 3 Non-linear representation of GP  
   
  0.7  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  163  
   
  The tree-structured representation of genetic programming (Koza 1993) allows arbitrary functional forms based on a set of functional primitives. Models here specify a function f (x) of the predictor variables that can be depicted as a parse tree, thus allowing arbitrarily complex functions based on a defined set of primitives. The functional primitives usable at different internal (non-terminal) nodes are defined through the Function Set, and terminal nodes are obtained from the Terminal Set. For the models reported in this paper, the function-set F = {+, -, *, /, exp, log} is used, and the terminal-set is T = {ℜ, x1, x2, ..., xn}, where ℜ denotes the set of real numbers (in a specified range) and xi the predictor variables in the data. Figure 3 provides an example of a GP tree-based model.  
   
  3.2 Genetic Search Operators Crossover and mutation form the two basic recombination operators. Crossover implements a mating scheme between pairs of “parents” to produce “offspring” that carry characteristics of both parents. Mutation is a random operator applied to insure against premature convergence of the population; mutation also maintains the possibility that any population representative can be ultimately generated. Appropriate implementations of the crossover and mutation operators are used based on model representation, and are detailed in various standard texts. For the tree-structured models used for the experiments reported here, regular GP crossover and mutation operators are used. Crossover exchanges randomly chosen subtrees of two parents to create two new offspring; Figure 4 shows an example. The tree mutation operator randomly changes a sub-tree. Regular GP attempts to learn numeric constants through the combination of numeric values (terminals in the tree) by function sets operators; as detailed in Evett and Fernandez (1998), this is often inadequate for obtaining accurate constants. Non-uniform mutation where the search gets focused with increasing generations is used here for learning numeric constants. Non-uniform mutation (Michalewicz, 1994): A numeric value sk at a terminal node is replaced by  
   
  ⎧sk + Δ (t , u − sk ) . sk′ = ⎨ ⎩ sk − Δ (t , sk − l ) Here, [u, l] represents the legal range of values for each element and a uniform random choice determines whether the increment or the decrement be applied. The mutation value Δ(t , x) returns a value in [0,x] that decreases with increasing t. Thus, with t as the number of generations of search, this operator seeks used wider search in the initial stages, but gradually focuses the search as the generations progress. The following implementation is used:  
   
  164  
   
  S. Bhattacharyya  
   
  +  
   
  *  
   
  *  
   
  exp +  
   
  X2 X1  
   
  *  
   
  X2  
   
  X1  
   
  X5  
   
  2  
   
  X3  
   
  Model A  
   
  Model B  
   
  +  
   
  *  
   
  *  
   
  exp *  
   
  X2  
   
  X5  
   
  X1  
   
  X1 2  
   
  +  
   
  X2  
   
  X3  
   
  Model D  
   
  Model C  
   
  Fig. 4 Crossover of models A and B to give two new models C and D  
   
  Δ(t , x ) = x (1 − r  
   
  t (1− ) b T  
   
  )  
   
  where r is uniformly generated in [0,1], T gives the total number of generations of search, and b is a parameter determining degree of non-uniformity (a value of b=2 was used for the experiments).  
   
  3.3 Multi-objective Models Using Pareto-Selection This study adopts the simple and elegant Pareto-based scheme of Louis and Rawlins (1993) to obtain the set of non-dominated solutions. This is a variant of binary tournament selection and operates as follows: a pair of solutions (parents) is randomly selected from the current population, and the recombination operators (crossover and mutation) applied in the usual manner to generate two new solutions (offspring). Then the Pareto-optimal set of parents and offspring is produced, and two solutions from this set are randomly selected for the new population. This  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  165  
   
  procedure is repeated to fill the entire population for the next generation. The process in general can be applied with tournament sizes greater than two also. This manner of selection is noted to naturally foster the development of niches exploring different regions of fitness tradeoffs (Louis and Rawlins 1993). We incorporate elitism into the Pareto selection process. Elitism, where the best solution is retained intact into the next generation, has been noted to be crucial for effective search. In a Pareto-GA context, a population will usually contain several non-dominated solutions. Elitism is incorporated by retaining the current population's non-dominated solutions into the next generation. Note that elitist selection here reduces the number of population members that actively participate in the search using the genetic recombination operators, and can thus impose a burden. The genetic learning procedure begins with a population of randomly generated models, and can be summarized as: While (not terminating-condition) { Evaluate-fitness of population members Determine the non-dominated set in the population Insert non-dominated set into the next generation While next-generation population is not full { Select two parents randomly from current population With probability pcross perform crossover on two parents to get two new offspring, With probability pmutate perform mutation on each offspring With probability pnumutate perform non-uniform mutation on each offspring Obtain the Pareto-optimal set of parents and offspring Select two solutions randomly from the Pareto-optimal set Insert selected solutions into next generation } } The search is terminated after a fixed number of iterations.  
   
  3.4 Fitness Function The fitness function specifies the search objective and provides a numerical figure-of-merit or utility measure for a solution in the population. A key advantage of GA/GP arises from the flexibility allowed in formulation of the fitness function. Unlike in many other techniques, there are no constraints of smoothness, continuity or linearity in the function – the only requirement is that the fitness function provide a numerical value indicating desirability of a solution; it may even be specified as a rule-set for model performance assessment. The flexibility in fitness function formulation allows the development of models tailored to specific business objectives. For predictive modeling tasks, the search objective is often framed around the dependent variable. For example, with  
   
  166  
   
  S. Bhattacharyya  
   
  a binary dependent variable measuring a buy/no-buy decision, customer churn, response to a solicitation, etc., the fitness function can be specified along traditional performance measures to maximize overall accuracy, correctly identify ‘responders’, etc. Considering the way models will be implemented and given budgetary or other constraints, the fitness function can also be defined to identify, say, 30% of individuals most likely to buy (Bhattacharyya 1999). Traditional objectives (and models developed using conventional approaches that seek to maximize overall likelihood, minimize errors, etc.) may not yield models that are best suited with respect to specific implementation considerations like these. For continuous dependent variables, too, the fitness function can be set to obtain a ‘profit’ model that seeks, for example, the most profitable customers for specific targetingdepths, or those with the highest frequency of response, etc. In the decile-maximization approach (Bhattacharyya 1999) that obtains models to maximize performance at specific targeting depths, fitness of models is estimated at a specified depth-of-file d (d is specified as a fraction of the total data e.g. d=0.1 for the top 10 percent or first decile, etc.). Given multiple objectives πi, fitness may be evaluated along each of the objectives as follows: Consider a data set D containing N observations: D = {(x, z)k, k=1,..N}, where x denotes the vector of predictors, and z = {zi, i=1,..n} gives the variables corresponding to n objectives. Then, considering a specific model f, model evaluation scores the observations as: yˆ k = f ( x k ) . Let the data ranked in descending order of model scores be denoted as yˆ ks , and the ranked observations up to the specified depth d be given by  
   
  Dd = { (x, z)k: yˆ ks , k=1,..,Nd}, where Nd = d.N gives the number of observations up to the depth d. Then, the model's fitness for the i-th objective is obtained as  
   
  π id =  
   
  ∑ (z ) i  
   
  k∈D d  
   
  k  
   
  .  
   
  Evaluating the fitness of a model involves obtaining values for each of the multiple objectives defining the problem. Alternately, to generally maximize lifts across all deciles, rather than focus on specific deciles, fitness functions can be defined to seek an optimal ordering of observations based on the dependent variables. This can be obtained by considering differences between the dependent variable values in score-ranked observation and in the optimal ordering of observations from high to low values of the dependent variables. This is the approach taken for the results presented in this chapter. The fitness evaluation may also be defined to guard against over-fit by, for example, utilizing resampling techniques, as found useful in Bhattacharyya (1999). It can also incorporate a preference for simpler models carrying fewer variables, or for models exhibiting desired tradeoffs amongst conflicting characteristics.  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  167  
   
  3.5 Performance Measures Given the context of the direct marketing dataset, we assess model performance on the cumulative lifts at different file-depths. This is preferred over traditional measures of performance like overall accuracy, error rate, etc. in direct marketing where models are often used to identify a subset of the total customers expected to maximize response to a solicitation, revenue generated, or other performance criterion. A decile analysis is typically used to evaluate model performance across file-depths. Here, customers are ranked in descending order of their respective model scores – higher scores indicating better performance – and separated into 10 equal groups. Table 1 shows a typical decile analysis, where performance is assessed on response. The first row indicates performance for the top 10% of individuals as identified by the model. The Cumulative Lifts at specific depths of file provide a measure of improvement over a random mailing, and are calculated as:  
   
  Cumulative Lift decile =  
   
  cumulative average performancedecile *100. overall average performance  
   
  Thus, in Table 1, a cumulative lift of 3.7 in the top decile indicates that the model in question is expected to provide a mailing response that is 3.7 times the response expected from a random mailing to 10% of the file. Where a dependent variable gives the revenue generated, a similar decile analysis can be used to evaluate the performance on cumulative revenue at different deciles. Performance of a model on the Response and Revenue objectives is indicated by the Response-Lift and Revenue-Lift at a considered decile - a model that captures more responders/revenue at the top deciles thus shows superior performance on the response/revenue objective. Note that individual lift values indicate performance on a single objective only, without regard for the other objective. As mentioned earlier, where the two objectives do not relate well, high performance of a model on one objective will correspond to poor performance on the other. In such situations, different levels of performance tradeoffs exist and are captured by the models along the Pareto frontier. Performance of a model on the Response and Revenue objectives is indicated by the Response-Lift and Revenue-Lift at a considered decile - a model that captures more responders/revenue at the top deciles thus shows superior performance on the response/revenue objective. Note that individual lift values indicate performance on a single objective only, without regard for the other objective. As mentioned earlier, where the two objectives do not relate well, high performance of a model on one objective will correspond to poor performance on the other. In such situations, different levels of performance tradeoffs exist and are captured by the models along the Pareto frontier. The determination of a specific model to implement can be based on various factors considered by a decision-maker - for instance, it may be desirable that performance on both objectives be above some minimal threshold level, and judgments may consider individual, subjective factors too. Given the application  
   
  168  
   
  S. Bhattacharyya Table 1 Sample Decile Analysis  
   
  Decile  
   
  Number of Customers  
   
  top 2 3 4 5 6 7 8 9 bottom Total  
   
  9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 90,000  
   
  Number of Responses 1332 936 648 324 144 72 72 36 20 16 3600  
   
  Cumulative Responses 2179 3932 4328 4439 4549 4634 4701 4770 4819 4874  
   
  Cumulative Response Rate (%) 14.8% 12.6% 10.8% 9.0% 7.52% 6.4% 5.6% 4.95% 4.43% 4.0%  
   
  Cumulative Response Lift 3.70 3.15 2.70 2.25 1.88 1.60 1.40 1.24 1.11 1.00  
   
  considered here, the overall modeling objective is taken as the maximization of the expected revenue that can be realized through identification of high-revenue customers. This can be estimated at a specific decile or file-depth d as follows (Bhattacharyya 2000): Let V denote the total revenue over all individuals in the data, and R the total number of responders. Consider Vd and Rd the cumulative total revenue and cumulative total number of responders respectively at decile d. Then, if N denotes the overall total customers in the data and Nd is the total customers up to the decile level d, the cumulative response and revenue lifts are: Response Lift = (Rd/Nd)/(R/N) and Revenue Lift = (Vd/Nd)/(V/N). The expected revenue up to the file-depth d is given by: (Average-response per customer)d*(Average revenue per customer)d = (Rd/Nd)*(Vd/Nd) = (ResponseLift * RevenueLift) * [(R/N) * (V/N)]. The product of Response Lift and Revenue Lift values then gives the cumulative lift on the expected-revenue as: [(Rd/Nd)*(Vd/Nd)] / [(R/N) * (V/N)]. This Product of Lifts thus provides a useful measure to evaluate the performance of models on expected revenue. This measure depends on both objectives, and models with high performance on only one objective may not perform well on Product of Lifts which indicates expected-revenue from a model at specified filedepths.  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  169  
   
  4 Data and Multi-objective Model Performance We examine the effectiveness of the multi-objective genetic search approach in handling multi-objective data-mining problems using a real-life dataset. This section describes the dataset used and presents the performance of different models along the Pareto frontier. For comparison, we also show the performance of least squares regression and logistic regression models on the same data.  
   
  4.1 Data The dataset pertains to direct mail solicitations from past donors for a non-profit organization1. It carries historical data on solicitations and donations from 10/86 through 6/95. All donors in the data received at least one solicitation in early 10/95 and the data carries the number and amount donations in the subsequent Fall, 1995 period. We consider the development of models to p redict response (at least one donation) and dollars in the later time period, given the history of prior solicitations and contributions. The dataset carries 99,200 cases, with each being defined through 77 attributes. The list of data attributes are given in Appendix A. Various transformations were conducted to obtain a modeling dataset. Solicitation codes in the data are specific to program type and date of solicitation. The data specifies these codes as one of four program types - A, B, C, or a miscellaneous group. The codes are resolved to obtain the total number of solicitations of different types for each observation in the data. Similarly, for contribution codes, we obtain the total number of contributions to different types. Contribution dollars for the different codes are also aggregated to get total contributions made for the different contribution types. Binary variables were created for each type to depict whether a solicitation and contribution for that type was ever made. Thus the following variables were derived for each of the four types: Number of solicitations of Type x Number of contributions of Type x Dollars of contribution to Type x Solicitation Type x (yes/no) Contribution Type x (yes/no) Date fields were converted to months-since in relation to a baseline of 10/1/1995.The following date related fields were retained for modeling: dates of first contribution, largest contribution, latest solicitation and latest contribution, change of address date. The State variable was transformed to retain only the 9 states found to have large concentration of customers, and these were converted to binary indicator variables. After preliminary examination, the Reinstatement Code, Rental Exclusion Code, 2nd Address Indicator variables were also retained in the modeling 1  
   
  The dataset is provided for academic use by the Direct Marketing Educational Foundation.  
   
  170  
   
  S. Bhattacharyya  
   
  dataset. Where more than two categories were specified, multiple binary variables were created. Certain additional fields were also created: Longevity: time period between first and latest contributions Ratio of Lifetime Contributions to Solicitations Average Lifetime Contribution Average Contribution per Solicitation The modeling dataset had 58 predictor variables, and two dependent variables for Response and Dollars in the later Fall 1995 period.  
   
  4.2 Models along the Pareto-Frontier Here we examine the performance of a set of GP models obtained using the genetic search procedure with Pareto-selection as described above2. For comparison, we also show the performance of an ordinary least squares regression model and a logistic regression model on the same data. Models were developed on a training dataset of 30,000 cases and performance of models is considered on the separate validation dataset comprising the remaining cases. For the genetic search, multiple initial runs with different random seeds were conducted and the non-dominated solutions from each were saved. A final run with initial population seeded using the saved non-dominated solutions was used to obtain the non-dominated solutions shown below. The fitness function was defined to optimize the ordering of dataset observations on the dependent variables so as to maximize lifts at the upper deciles.  
   
  Fig. 5 Non-dominated models 2  
   
  The models were obtained using the evolveDMTM software for data mining using evolutionary computation techniques. Details are available from the author.  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  171  
   
  The non-dominated models obtained are shown in Figure 5. Different models incorporating varying levels of tradeoff among the two objectives are seen. Models toward the upper-left show good performance on the Revenue objective, but perform poorly on Response. Conversely, models at the lower-right have good performance on Response but low Revenue performance. We consider different models along the Pareto frontier, as indicated by A, B… F in the figure. Since performance of models in the upper deciles is typically of interest, we examine the cumulative lifts of different models at the first, second and third deciles, corresponding to 10%, 20% and 30% file-depths. Tables 2a-2c give the performance of the different models at these deciles. Here, OLS represents the ordinary least squares regression on the continuous dependent variable for revenue, and LR is for the logistic regression model on the binary dependent variable for response. The graphs in Figure 6 plot the lifts of the different models on the two individual objectives, at different file-depths. The single objective OLS and LR models perform well on the respective revenue and response objectives that they are built to optimize on. As can be expected, performance of these models on the other objective is lower. The multi-objective models from the upper-left region of the Pareto-frontier are seen to perform better on Revenue Lift than the OLS model, and those from the lower-right perform better on Response Lift than the LR model. This is not surprising and shows that evolutionary search, using the nonlinear representation and seeking to maximize a fitness function that is more related to lift performance, is able to obtain better solutions than the traditional models. The multi-objective models from the middle region of the Pareto-frontier, exhibiting tradeoffs amongst the two objectives, are seen to perform well on the Product of Lifts measure. This arises from the conflicting objectives in the data, as evident in the Pareto-frontier obtained. All these models do not show better expected-revenue lifts than the OLS and LR models. At the top decile, the OLS model has higher performance than the multi-objective models A and B in the upper-left region of the Pareto-frontier, and the LR model does better than the models E and F which are from the lower-right region. It is interesting to observe that for this top decile, the LR model is not dominated on both objectives by any other model, and only model C dominates the OLS model. On product-of- lifts, the LR model does better than OLS, but models C and D exhibit the highest performance. At the second decile, it is the OLS model whose performance is non-dominated on both objectives by any of the other models. The LR model, however, displays a higher product-of-lifts. Performance of both OLS and LR is surpassed by models B, C and D from the middle region of the Pareto frontier. At the third decile, too, these three models outperform the others on product-of-lifts.  
   
  172  
   
  S. Bhattacharyya Table 2a Lifts for top decile  
   
  10% depth  
   
  Response Lift  
   
  Revenue Lift  
   
  Prod Lifts  
   
  A  
   
  1.42  
   
  2.67  
   
  3.79  
   
  B  
   
  1.49  
   
  2.70  
   
  4.02  
   
  C  
   
  1.97  
   
  2.58  
   
  5.09  
   
  D  
   
  2.21  
   
  2.43  
   
  5.38  
   
  E  
   
  2.29  
   
  2.04  
   
  4.68  
   
  F  
   
  2.42  
   
  1.85  
   
  4.47  
   
  OLS  
   
  1.61  
   
  2.46  
   
  3.97  
   
  LR  
   
  2.34  
   
  2.10  
   
  4.91  
   
  Table 2b Lifts for second decile  
   
  20% depth  
   
  Response Lift  
   
  Revenue Lift  
   
  Prod Lifts  
   
  A B C D E  
   
  1.37 1.42 1.82 1.92 1.99  
   
  2.08 2.09 2.01 1.94 1.81  
   
  2.85 2.97 3.67 3.73 3.61  
   
  F OLS  
   
  2.07 1.49  
   
  1.49 2.04  
   
  3.08 3.04  
   
  LR  
   
  1.91  
   
  1.72  
   
  3.29  
   
  Table 2c Lifts for third decile  
   
  30% depth A B C D E F OLS LR  
   
  Response Lift 1.33 1.38 1.61 1.78 1.82 1.91 1.38 1.69  
   
  Revenue Lift 1.82 1.80 1.77 1.71 1.62 1.29 1.79 1.46  
   
  Prod Lifts 2.42 2.50 2.83 3.04 2.95 2.47 2.48 2.48  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  Fig. 6 Lifts at different deciles  
   
  173  
   
  174  
   
  S. Bhattacharyya  
   
  5 Conclusions The Pareto-genetic search scheme used is seen to be effective at obtaining models with varying levels of tradeoff on multiple data-mining objectives. Models from the extremes of the tradeoff frontier are found to perform favorably in comparison with OLS and logistic regression models on the respective single objectives. The traditional OLS and logistic regression models - popular in industry use - perform well on the single criteria that they model. In the context of multiple objectives, however, they do not provide a decision-maker with different tradeoffs that the data may admit. With multiple models as obtained from the genetic search based approach here, selection of a specific model to implement, from amongst the nondominated set, can be made in consideration of a variety of factors of possible concern to a decision-maker. For the application and data in this study, considering expected-revenue as a criterion for judging overall model performance, the best of the multiple-objective models were seen to yield superior performance over the logistic regression and OLS models at different file-depths. With multiple objectives to consider, and a set of models with performance ranging along the Pareto frontier, the choice of a model to implement is an important next step. Where decision makers have a clear understanding of desired tradeoffs among objectives, the selection of ‘best’ model can be straightforward, especially where models are developed to optimize business objectives as in the case presented in this paper. For situations where the modeling objectives may not directly correspond with business criteria, observed tradeoffs on the modeling objectives may not present adequate information for a decision-makers choice of a model to implement. For such situations, further analyses on the Pareto optimal set of models may be required to provide decision-makers adequate insight into application performance tradeoffs of alternate models. The need for additional analyses also occurs where three or more objectives are considered, and visualization tools have been investigated to aid in decision-making (Kollat and Reed 2007). In marketing applications like the one presented in this paper, a combination of models can be useful to obtain the ‘best’ overall solution. With response and revenue/profit maximization, for example, as the two modeling objectives, a decision-maker may prefer a model with a certain tradeoff in profit and response likelihood at the upper deciles. From the potential customers identified through this model, one may also want to distinguish those indicated as high response potential by another model which exhibits high performance in the response objective; these individuals may be of interest for a different marketing treatment. In a similar manner, consideration of multiple models from the Pareto set can also be useful for identifying groups of customers that are best targeted with varying marketing approaches. Consideration of multiple models from the Pareto set in this way is under investigation. While traditional data-mining approaches usually obtain models built to objectives like maximum likelihood, minimal classification error, etc., the business problem can consider alternate criteria. In a direct marketing context, for example, managers may be concerned about the targeting depth that yields optimal returns, maximizing the number of responders within a certain budget, or identifying  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  175  
   
  responders that are also likely to generate high purchase revenue. As noted earlier, evolutionary computation allows the incorporation of such criteria into the fitness function and can thereby help build models that directly optimize business objectives of interest (Bhattacharyya 1999, 2000). Most EC based data mining work to date, however, have not taken advantage of this, and models are developed to general performance criteria. Incorporation of varied business criteria in fitness functions and their evaluation presents an important research opportunity. Consideration of multiple managerial objectives across different business problems using MOEA is also a promising area for future research. Many real-world problems addressed through marketing analytics and data mining can profitably utilize the multi-objective evolutionary search based approach presented here. In catalogue and retail sales, for example, models identifying potential buyers that also will not return purchased goods are useful; similarly, models that identify potential responders to mailings who are also likely to buy some specific product are often sought. Multiple and often conflicting objectives are also seen in the context of many cross-selling marketing campaigns. Problems in the telecommunications industry often seek to model customers' tenure in combination with usage - identifying people who have long tenure and high usage of services. Further application examples occur in the financial services industry, where models, for example, can seek customers who are likely to be approved for credit and who can also be expected not to make late payments or default on loans.  
   
  References Berry, M.J.A., Linoff, G.S.: Data Mining Techniques for Marketing, Sales and Customer Relationship Management. John Wiley & Sons, Chichester (2004) Becerra, R.L., Santana-Quintero, L.V., Coello, C.C.: Knowledge Incorporation in Multiobjective Evolutionary Algorithms. In: Ghosh, A., Dehuri, S., Ghosh, S. (eds.) MultiObjective Evolutionary Algorithms for Knowledge Discovery from Databases. Studies in Computational Intelligence, vol. 98, pp. 23–46. Springer, Heidelberg (2008) Bhattachryya, S.: Direct Marketing Performance Modeling using Genetic Algorithms. INFORMS Journal of Computing 11(13), 248–257 (1999) Bhattacharyya, S.: Evolutionary algorithms in data mining: Multi-objective performance modeling for direct marketing. In: Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Boston, Massachusetts, pp. 465–473 (2000) Casillas, J., Martínez-López, F.J.: Mining Uncertain Data with Multiobjective Genetic Fuzzy Systems to be Applied in Consumer Behaviour Modeling. Expert Systems with Applications 36(2), 1645–1659 (2009) Coello, C.C.: An Updated Survey of GA-Based Multiobjective Optimization Techniques. ACM Computing Surveys 32(2), 109–143 (2000) Coello, C.C., Lamont, G.B., Van Veldhuizen, D.A.: Evolutionary Algorithms for Solving Multi-Objective Problems (Genetic and Evolutionary Computation). Springer, New York (2006) De La Iglesia, B., Richards, G., Philpott, M.S., Rayward-Smith, V.J.: The Application and Effectiveness of a Multi-objective Metaheuristic Algorithm for Partial Classification. European Journal of Operational Research 169(3), 898–917 (2006)  
   
  176  
   
  S. Bhattacharyya  
   
  Deb, K.: Multi-Objective Optimization Using Evolutionary Algorithms. John Wiley & Sons, Inc., New York (2001) Deb, K., Pratap, A., Agrawal, S., Meyarivan, T.: A Fast and Elitist Multi-objective Genetic Algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation 6, 182–197 (2002) Dehuri, S., Ghosh, S., Ghosh, A.: Genetic Algorithm for Optimization of Multiple Objectives in Knowledge Discovery from Large Databases. In: Ghosh, A., Dehuri, S., Ghosh, S. (eds.) Multi-Objective Evolutionary Algorithms for Knowledge Discovery from Databases. Studies in Computational Intelligence, vol. 98, pp. 1–22. Springer, Heidelberg (2008) Dehuri, S., Jagadev, A.K., Ghosh, A., Mall, R.: Multi-objective Genetic Algorithm for Association Rule Mining using a Homogeneous Dedicated Cluster of Workstations. American Journal of Applied Sciences 88, 2086–2095 (2006) Dehuri, S., Mall, R.: Predictive and Comprehensible Rule Discovery using a Multiobjective Genetic Algorithm. Knowledge-Based Systems 19(6), 413–421 (2006) Evett, M., Fernandez, T.: Numeric Mutation Improves the Discovery of Numeric Constants in Genetic Program. In: Koza, J.R., et al. (eds.) Proceedings of the Third Annual Genetic Programming Conference, Wisconsin, Madison, Morgan Kaufmann, San Francisco (1998) Fonseca, C.M., Fleming, P.J.: An Overview of Evolutionary Algorithms in Multi-Objective Optimization. Evolutionary Computation 3(1), 1–16 (1995) Freitas, A.A.: A Critical Review of Multi-objective Optimization in Data Mining: a Position Paper. SIGKDD Explorations. Newsletter 6(2), 77–86 (2004) Freitas, A.A., Pappa, G.L., Kaestner, C.A.A.: Attribute Selection with a Multi-objective Genetic Algorithm. In: Proceedings of the 16th Brazilian Symposium on Artificial Intelligence, pp. 280–290. Springer, Heidelberg (2002) Ghosh, A., Nath, B.: Multi-objective Rule mining using Genetic Algorithms. Information Sciences 163(1-3), 123–133 (2004) Goldberg, D.E.: Genetic Algorithms in Search, Optimization and Machine Learning. Addison-Wesley, Reading (1989) Goldberg, D.E., Richardson, K.: Genetic algorithms with Sharing for Multi-modal Function Optimization. In: Proceedings of the 2nd International Conference on Genetic Algorithm, pp. 41–49 (1987) Hand, D.J.: Construction and Assessment of Classification Rules. John Wiley and Sons, Chichester (1997) Handl, J., Knowles, J.: Multiobjective Clustering with Automatic Determination of the Number of Clusters, Technical Report No. TR-COMPSYSBIO-2004-02, UMIST, Department of Chemistry (August 2004) Kaya, M.: Multi-objective Genetic Algorithm based Approaches for Mining Optimized Fuzzy Association Rules. Soft Computing: A Fusion of Foundations, Methodologies and Applications 10(7), 578–586 (2006) Kim, D.: Structural Risk Minimization on Decision Trees using an Evolutionary Multiobjective Algorithm. In: Keijzer, M., O’Reilly, U.-M., Lucas, S., Costa, E., Soule, T. (eds.) EuroGP 2004. LNCS, vol. 3003, pp. 338–348. Springer, Heidelberg (2004) Kim, Y., Street, N.W.: An Intelligent System for Customer Targeting: a Data Mining Approach. Decision Support Systems 37(2), 215–228 (2004)  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  177  
   
  Kim, Y., Street, W.N., Menczer, F.: Feature Selection in Unsupervised Learning via Evolutionary Search. In: Proc. 6th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD 2000), pp. 365–369 (2000) Knowles, J.D., Corne, D.W.: Approximating the Non-dominated Front using the Pareto Archived Evolution Strategy. Evolutionary Computation 8(2), 49–172 (2000) Kollat, J.B., Reed, P.M.: The value of online adaptive search: A performance comparison of NSGAII, ε-NSGAII and εMOEA. In: Coello, C.C., Aguirre, A.H., Zitzler, E. (eds.) EMO 2005. LNCS, vol. 3410, pp. 386–398. Springer, Heidelberg (2005) Kollat, J.B., Reed, P.M.: A framework for Visually Interactive Decision-making and Design using Evolutionary Multi-objective Optimization (VIDEO). Environmental Modelling & Software 22(12), 1691–1704 (2007) Koza, J.R.: Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press, Cambridge (1993) Louis, S.J., Rawlins, G.J.E.: Pareto-Optimality, GA-Easiness and Deception. In: Forrest, S. (ed.) Proceedings of the Fifth International Conference on Genetic Algorithms, pp. 118–123 (1993) Massand, B., Piatetsky-Shapiro, G.: A Comparison of Different Approaches for Maximizing the Business Payoffs of Prediction Models. In: Simoudis, E., Han, J.W., Fayyad, U. (eds.) Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, pp. 195–201 (1996) Menczer, F., Degeratu, M., Street, N.W.: Efficient and Scalable Pareto Optimization by Evolutionary Local Selection Algorithms. Evolutionary Computation 8(2), 223–247 (2000) Michalewicz, Z.: Genetic Algorithms + Data Structures = Evolution Programs, 2nd edn. Springer, Heidelberg (1994) Murty, M.N., Babaria, R., Bhattacharyya, C.: Clustering Based on Genetic Algorithms. In: Ghosh, A., Dehuri, S., Ghosh, S. (eds.) Multi-Objective Evolutionary Algorithms for Knowledge Discovery from Databases. Studies in Computational Intelligence, vol. 98, pp. 137–159. Springer, Heidelberg (2008) Pappa, G.L., Freitas, A.A.: Evolving Rule Induction algorithms with Multi-objective Grammar-based Genetic Programming. Knowledge and Information Systems 19(3), 283–309 (2009) Richardson, J.T., Palmer, M.R., Liepins, G., Hilliard, M.: Some Guidelines for Genetic Algorithms with Penalty Functions. In: Schaffer, J.D. (ed.) Proceedings of the Third International Conference on genetic Algorithms, pp. 191–197 (1989) Schaffer, J.D.: Multiple Objective Optimization with Vector Evaluated Genetic Algorithms. In: Genetic Algorithms and their Applications: Proceedings of the First International Conference on Genetic Algorithms, pp. 93–100. Lawrence Erlbaum, Mahwah (1985) Shaw, K.J., Nortcliffe, A.L., Thompson, M., Love, J., Fonseca, C.M., Fleming, P.J.: Assessing the Performance of Multiobjective Genetic Algorithms for Optimization of a Batch Process Scheduling Problem. In: Angeline, P. (ed.) Congress on Evolutionary Computation, pp. 37–45. IEEE Press, Piscataway (1999) Sikora, R., Piramuthu, S.: Efficient Genetic Algorithm Based Data Mining Using Feature Selection with Hausdorff Distance. Information Technology and Management 6(4), 315–331 (2005)  
   
  178  
   
  S. Bhattacharyya  
   
  Thilagam, P.S., Ananthanarayana, V.S.: Extraction and Optimization of Fuzzy Association Rules using Multi-objective Genetic Algorithm. Pattern Analysis and Applications 11(2), 159–168 (2008) Van Veldhuizen, D.A., Lamont, G.B.: Multiobjective Evolutionary Algorithm Test Suites. In: Carroll, J., Haddad, H., Oppenheim, D., Bryant, B., Lamont, G.B. (eds.) Proceedings of the 1999 ACM Symposium on Applied Computing, New York, pp. 351–357 (1999) Van Veldhuizen, D.A., Lamont, G.B.: Multiobjective Evolutionary Algorithms: Analyzing the State-of-Art. Evolutionary Computation 8(2), 125–147 (2000) Zhang, Y., Bhattacharyya, S.: Genetic Programming in Classifying Large-scale Data: an Ensemble Method. Information Sciences 163(1-3), 85–101 (2004) Zeleny, M.: Multiple Criteria Decision Making. McGraw-Hill, New York (1982) Zitzler, E., Thiele, L.: Multi-objective Evolutionary Algorithms: a Comparative Case study and Strength Pareto Approach. IEEE Transactions on Evolutionary Computation 3, 257–271 (1999)  
   
  Predictive Modeling on Multiple Marketing Objectives Using EC  
   
  Appendix Appendix A – Original Data set attributes ACCNTNMB, Donor ID TARGDOL Dollars of Fall 1995 Donations TARGRES Number of Fall 1995 Donations Contributions history: CNCOD1 to CNCOD10 Latest to 10th Latest Contribution Code CNDAT1 to CNDAT10 Latest to 10th Latest Contribution Date CNDOL1 to CNDOL10 Latest to 10th Latest Contribution CNTMLIF Times Contributed Lifetime CNTRLIF Dollars Contribution Lifetime CONLARG Largest Contribution CONTRFST First Contribution DATEFST First Contribution Date DATELRG Largest Contribution Date Solicitation history: SLCOD1 to SLCOD11 Latest to 11th Latest Solicitation Code SLDAT1 to SLDAT11 Latest to 11th Latest Solicitation Date SLTMLIF Times Solicitated Lifetime FIRMCOD Firm/Head HH code MEMBCODE Membership Code NOCLBCOD No Club Contact Code NONPRCOD No Premium Contact Code NORETCOD No Return Postage Code NOSUSCOD No Sustain Fund Code PREFCODE Preferred Contributor Code REINCODE Reinstatement Code REINDATE Reinstatement Date RENTCODE Rental Exclusion Code CHNGDATE Change of Address Date SECADRIN 2nd Address Indicator SEX Gender STATCODE State ZIPCODE ZIP Code  
   
  179  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases Based on Fuzzy Association Rules Albert Orriols-Puig1, Jorge Casillas2 , and Francisco J. Mart´ınez-L´opez3 1  
   
  2  
   
  3  
   
  Grup de Recerca en Sistemes Intelligents Enginyeria i Arquitectura La Salle (URL), 08022 Barcelona, Spain e-mail: [email protected]  CITIC-UGR (Research Center on Communication and Information Technology) Department of Computer Science and Artificial Intelligence University of Granada, 18071 Granada, Spain e-mail: [email protected]  Department of Marketing University of Granada, 18071 Granada, Spain and Universitat Oberta de Catalunya, 08035 Barcelona, Spain e-mail: [email protected]   
   
  Abstract. Marketing-oriented firms are especially concerned with modeling consumer behavior in order to improve their information and aid their decision processes on markets. For this purpose, marketing experts use complex models and apply statistical methodologies to infer conclusions from data. In the recent years, the application of machine learning has been identified as a promising approach to complement these classical techniques of analysis. In this chapter, we review some of the first approaches that undertake this idea. More specifically, we review the application of Fuzzy-CSar, a machine learning technique that evolves fuzzy association rules online, to a certain consumption problem analyzed. As a differentiating sign of identity from other methods, Fuzzy-CSar does not assume any aprioristic causality (so model) within the variables forming the consumer database. Instead, the system is responsible for extracting the strongest associations among variables, and so, the structure of the problem. Fuzzy-CSar is applied to the real-world marketing problem of modeling web consumers, with the aim of identifying interesting relationships among the variables of the model. In addition, the system is compared with a supervised learning technique, which is able to extract associations between a set of input variables and a pre-fixed output variable, expressly designed for this marketing problem. The results show that Fuzzy-CSar can provide interesting information for marketing experts that was not detected by the classical approach, and that the extraction of fuzzy association rules is an appealing alternative, in general, to refine or complement the modeling results obtained with the use of traditional methods of analysis applied for these purposes; in particular, we focus on, and take as a reference, the structural equation modeling.  
   
  J. Casillas & F.J. Mart´ınez-L´opez (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 181–206. c Springer-Verlag Berlin Heidelberg 2010 springerlink.com   
   
  182  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  1 Introduction Companies are constantly searching for suitable marketing opportunities to survive in increasingly turbulent and volatile markets. For this purpose, marketing experts are especially concerned with the creation and management of key information about the market [6]. In management and marketing disciplines, the use of models has been usual to drive the database analysis. Model-based analytical processes imply that a structure of relations among the elements (i.e., variables) of this previously known model be used to, by means of analytical methods of study, describe or predict the behavior of those relations. This analytical approach matches the procedure classically set by the scientific method; i.e., a researcher works with a set of hypotheses of expected relationships among variables, those hypotheses are empirically tested and, finally, some conclusions are extracted (e.g., see [20]). Basically, these are the core questions in marketing modeling, which are usually followed to drive the information search process in marketing databases with the aim of supporting marketing decisions. But, would it be plausible to work without models? Doubtless, models are very necessary, especially in the academic field, where the arsenal of statistical and, in general, analytical tools are usually applied with a theory-driven approach. However, mostly from the practitioners’ perspective, their usage may limit the added-value extracted from the data when applied to certain kind of decision problems in marketing. In particular, in non- or ill-structured problems, analysis based on the a priori information offered by a model, which may disregard important relationships due to the weak structure of the problem, may not be as effective as a decision maker would expect. Hence, though the support of models is helpful to address the search of information in marketing databases, there are situations, both in the practitioners’ and scholars’ arena, where the use of other non model-based solutions, either on their own or as a complementary tool to a information search process based on models, might produce profitable results. For instance, from an academic perspective, when analyzing the validity of a theoretical model, an additional approach to the traditional would be to adjust all the possible causal structures (models), reasonable or unreasonable, and then, theoretically analyze those configurations with better fitness. However, as causal (theoretic) structures of reference increase in complexity, the number of possible configurations is considerably higher [3], so the development of the said approach would be more difficult to accomplish. In this case, powerful analytical methods are necessary to undertake this task with efficiency. Time ago, some authors [7] pointed out that a process of search and analysis for all the possible configurations of causal models, in a certain marketing database, could be automatized using some Computation Science-based method. However, these authors also recognized that years of evolution would be necessary to be able to work with suitable procedures. Nowadays, the so-called knowledge-based marketing support systems offer an excellent framework to develop methods with this purpose (see [3]). In this regard, several authors have proposed to apply supervised machine learning methods, which are informed with little prior knowledge about the problem, resulting in the extraction of  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  183  
   
  key knowledge that was not detected by the classical analysis methodology (e.g., see [4, 17]). Continuing with these efforts, the application of unsupervised learning techniques which have no knowledge about the problem structure—letting the machine extract interesting, useful, and unknown knowledge about the market—appears as an appealing approach to these problems. The purpose of this chapter is to review the work done on the extraction of fuzzy association rules to discover new interesting knowledge from marketing databases. Specifically, we focus on a database that contains information about the consumer behavior. To achieve this, we apply Fuzzy-CSar, a learning classifier system (LCS) [11] that assumes no structure about the problem and evolves a diverse set of fuzzy association rules that describe interesting associations among problem variables. Fuzzy-CSar uses a fuzzy representation that enables the system to deal with the imprecision of the marketing data. The system is compared with an evolutionary multi-objective (EMO) approach that extracts fuzzy rules that define a particular prefixed output variable [17]. The results highlight that fuzzy association rules permit extracting key knowledge that was discovered neither by the classical approach nor by the EMO approach. The chapter is organized as follows. Section 2 describes the type of data usually found in marketing databases, with especial attention to the particularities of the kind of variables (i.e. constructs) forming complex causal models in marketing, explains the classical marketing analysis approach in more detail, and motivates the use of machine learning to tackle these problems. Section 3 provides the basic concepts of association rules, and Sect. 4 describes Fuzzy-CSar. Section 5 presents the experimental methodology, and Sect. 6 analyzes the results. Finally, Sect. 7 concludes and presents future work lines.  
   
  2 Previous Considerations on the Adaptation of Marketing Data A common practice in marketing modeling, and consumer behavior modeling in particular (field where the method proposed here is applied to), when working with complex models (i.e., with multiple relations of dependent and independent variables), is specifying such models to be empirically analyzed by structural equation modeling [17]; other types of causal models, so statistical estimation methods, are also used, though we focus our research on the most difficult case to solve of the complex models. These models are compounded by elements (constructs) which are inferred from imprecise data, i.e., the indicators or variables related to every element of the model. As follows, we explicate these types of problems, specifically focusing on the type of data that is made available for analysis. Then, we outline some significant aspects related to this structural modeling methodology when applied to a consumer behavior model and motivate the use of machine learning techniques to obtain new interesting information. Then, we explain how marketing data can be transformed into fuzzy semantics, and finally, we discuss different strategies to let machine learning techniques deal with the particularities of the marketing data.  
   
  184  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  2.1 Data Collection in Marketing Generally, when working with complex models for consumer behavior analysis, so with structural models, the elements of the model are divided into two categories: (1) unobserved/latent variables, also known as constructs, which are conceptually those whose measurement cannot be made directly with a single measure; and (2) observed variables or indicators, those related to every single measure (i.e., an item in a multi-item measurement scale) developed to be related to a construct. The underlying idea is that an observed variable is an imperfect measure of a construct, but a set of indicators related to a construct, considered altogether, may lead to a reliable measurement of said construct. Therefore, every construct in a model is usually related to a set of observed variables. This is currently the predominant measurement approach, known as the partial-interpretation philosophy [22]. Finally, there is an especial category of constructs known as second-order constructs. These are characterized by not having direct association with indicators in the measurement model, as an ordinary/first order construct has, but by being defined by a combination of first-order constructs related to them. Note that the overall structure of these data is unconventional. Thus, machine learning techniques need to be adapted to deal with them.  
   
  2.2 The Classical Approach to Deal with Marketing Data To extract key knowledge from a database (usually generated after a survey that administered questionnaires to a sample of the target population), marketing experts use the following approach, addressed as the classical approach of analysis in the rest of this chapter. First, the expert establishes a theoretical model, which denotes the relationships—and directions of these relationships—among the variables of the problem. Marketing experts base such models on diverse sources, where we highlight the theoretical basis, the a priori information of the market, and their own experience. Then, the models are used to establish a set of hypotheses that explain the relationship among constructs that have been connected in the structural model. Thereafter, a measurement model is set and statistical methods based on structural modeling methodologies are used to contrast these hypotheses. The conclusions extracted from the analysis may cause the marketing expert to refine the structural model and to apply again the same analysis procedure. While it has been shown that the classical approach may provide key knowledge of the consumer behavior analyzed, which may be used to support decision making [20], based on a conceptual/structural model to drive the search of information in the database, it may hamper the discovery of some key knowledge. To extract further interesting information, several authors have successfully applied machine learning techniques to these types of problems. For example, in [4], the authors used supervised learning techniques to model the consumer behavior in the Internet, resulting in new interesting knowledge not detected by the classical approach. This approach permitted extracting fuzzy rules that always predicted the same variable  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  185  
   
  in the consequent. In the present chapter, we take some of the ideas presented in [4] as starting point and extend them to build a system that extracts fuzzy association rules from consumer behavior databases, but with a different approach. In particular, we do not consider any a priori information about the system and expect that the system provides us with any relevant association among variables. Before proceeding with the description of this approach, the next subsections briefly present key questions related with the transformation of the original data (i.e. marketing measurement scales) into fuzzy semantic and finally discuss how a general learning system can be adapted to deal with the particularities of the marketing data.  
   
  2.3 Transformation of Marketing Scales into Fuzzy Semantic The machine learning stage could not work without transforming the original marketing data into fuzzy terms. Some notes are deserved to be commented in this regard. The transformation process differs depending on the type of marketing scale, subjacent to every variable of the marketing database. In order to simplify the problem, let us focus on the following traditional classification of measurement scales [23, 24]: nominal, ordinal, interval, and ratio. The transformation of these basic measurement scales into fuzzy variables is useful for all those cases where a measurement scale entails, as minimum, certain order. This premise would involve all the types of measurement scales, with the exception of the nominal. Next, we offer some general reflections for each of the four scales.  
   
  Nominal scales. The characteristics of this scale (e.g., consumer’s gender, nationality, etc.) just allow identifying and classifying into some of the categories of the scale. But, there is no relation of order or grade between the categories. Consequently, it does not have any sense applying the fuzzy reasoning, as nature of the scale’s categories is purely deterministic. This fact involves that these scales are considered as singleton fuzzy sets, a particular case of fuzzy sets; i.e., if certain consumer belongs to certain category, he/she has a membership degree of one to the fuzzy set related to that category, and zero to the others.  
   
  Ordinal scales. When the transformation of these types of scales is tackled, there is a main inconvenient: as they are non-metric/qualitative scales, there is just information about the consumer’s membership or non-membership to one of the categories in which the marketing variable was structured. This fact limits the possibilities to determine the extreme and central values of the fuzzy sets defining the linguistic variable associated with that marketing variable. Likewise, regardless the previous question, the marketing expert should solve the following dilemma: should or should not the linguistic variable explicitly consider the structure of categories defining the original marketing variable? In general, it is widely accepted the convenience of a linguistic variable synthesizes the information provided by the original scale, in order to improve the interpretation of relations among the elements of the model, as well as to draw on the potentials of fuzzy inference. However, a subsequent aggregation of original categories is difficult to  
   
  186  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  Very high  
   
  High  
   
  Medium-High  
   
  Medium-Low  
   
  Very low Low  
   
  implement due to the lack of information provided by an ordinal scale; i.e., references are needed, for instance the extremes and central points of the fuzzy sets obtained after the aggregation. On the other hand, there are studies which require the original categories of certain ordinal scale to be maintained, with the aim of analyzing, for instance, an eventual research question. Though, it is also true that there are other situations where the aggregation of categories, classes of the variable, can be done without any inconvenient for the research purposes. Therefore, based on the above reflections, there are two possibilities when transforming an ordinal scale into a linguistic variable: (1) maintaining the categories of the original scale or (2) aggregating such categories, so to obtain a linguistic variable with fewer terms than categories had the original ordinal scale. Diverse questions, mainly the problems that would have to be faced with the latter, make the first option to be more convenient. In Fig. 1 we show an example for the variable “Weekly use of the Web” (ordinal scale extracted from the database used in [20]), structured as follows: (1) x ≤ 1 hour; (2) 1 < x ≤ 5 hours; (3) 5 < x ≤ 10 hours; (4) 10 < x ≤ 20 hours; (5) 20 < x ≤ 40 hours; and (6) x > 40 hours.  
   
  Membership Degree  
   
  1  
   
  0.5  
   
  0 0.5  
   
  3  
   
  7.5  
   
  Class 1 Class 2 Class 3  
   
  1 5  
   
  15  
   
  10  
   
  30  
   
  20 Class 4  
   
  50  
   
  40 Class 5  
   
  Hours/week 60  
   
  Class 6  
   
  Fig. 1 Example of transformation of a marketing ordinal scale into a linguistic variable (classes of the original scale are maintained)  
   
  Interval scales. These scales are metric/quantitative, so they allow more possibilities when being transformed into linguistic variables. Notwithstanding, now we are going to focus our reflections on the particular case of the rating scales, as they are the scales habitually used to measure the items related to constructs. Two main questions should be tackled: the number of linguistic terms to use and the type of membership function more convenient to represent the behavior of the fuzzy sets. With respect to the former, though the particularities of each research has to be taken into account, considering the number of points commonly used by these types of scales (i.e. between five and eleven), it is convenient to work with a number  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  187  
   
  of fuzzy set between three and five. Likewise, as these scales generally measure the consumer’s opinion intensity on variables of interest for the certain research, we propose using, in general, the following labels or terms: low, medium/indifferent, and high when working with three fuzzy sets; and very low, low, medium/indifferent, high, and very high when working with five fuzzy sets. With respect to the second question, the membership function type, it is more convenient the transformation of scales using a triangular function. In particular, triangular functions must be necessarily used for the case of the extreme fuzzy sets defining a fuzzy variable related to certain rating scale. The main argument to support this is based on the characteristics of these scales. For instance, let us consider a seven-point semantic differential scale (1: Bad 7: Good), used to measure the consumer’s attitude toward a brand. We know that when consumer has a totally negative attitude, his/her valuation will be 1. However, if his/her valuation were 2, that would mean a low attitude, though not the lowest level linked to a valuation of 1. Therefore, the fuzzy set low should show a membership degree of 1 when the marketing scale value is 1, decreasing with a linear tendency to zero for the rest of numeric values associated with said set. This reasoning would be equally valid for the case of the fuzzy set high, though it would be a fuzzy set with a membership function linearly increasing till the highest value of 7 in the marketing scale. Finally, as it is logic, the superior limit of the fuzzy set low, as well as the inferior limit of the fuzzy set high, would match with that value of the marketing scale in which the fuzzy set medium takes a membership degree of 1. Therefore, it is also necessary to define the domain of such central fuzzy set of the variable. The procedure to define this set differs depending on whether we are dealing with forced or non-forced scales. For the case of non-forced scales, the solution is intuitive and straight. As the central point of the scale represents an intermediate or indifferent position, said point would be the central point of the fuzzy set, with membership degree of 1. However, the solution for the case of forced-scales would imply another solution, as there is no central point. This fact makes necessary the use of a trapezoidal functions to define the behavior of the central fuzzy set of the variable, in such a way that the central points would be always formed by an even number of points in the scale, i.e., the central points. Figure 2 illustrates a graphic representation of two fuzzy variables with three linguistic terms each, associated with two semantic differential (non-forced and forced) scales.  
   
  Ratio scales. These present less restrictions and inconvenient to be transformed into fuzzy variables than any of the other types already described. As these scales are truly continuous, with zero as the lowest value, the numbers of linguistic terms, the determination of the domains for the established set of fuzzy sets, and the membership functions to use are completely flexible. The only inconvenient for the marketing expert is how to fix the maximum value for the scales in order to define the domain of the last fuzzy set of the variable.  
   
  188  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  Fig. 2 Examples of membership functions for non-forced (seven-point) and forced (tenpoints) rating scales  
   
  2.4 Application of Machine Learning to the Marketing Data In general, two strategies could be used to let learners deal with the marketing data: (1) preprocessing the input data to render them tractable with a general learner or (2) adapting the learning technique to the particularities of the data. The former approach implies transforming the data into a simpler format. An intuitive approach would be to reduce the different items of a specific first-order construct to a single value (e.g., by averaging the values); a similar approach should be used to get an average value for second-order constructs. Another approach would be to expand any variable measured by multiple items to multiple variables measured by a single item and do not consider the existence of second-order constructs; then, the data set could be reduced by means of instance selection. Nevertheless, the underlying problem of data preprocessing is that relevant information may be lost in the transformation process. For this purpose, Casillas and Mart´ınez-L´opez [4] proposed a modification of the inference process of fuzzy rule-based systems to deal with this especial type of data, which was addressed as multi-item fuzzification. The idea of this approach is to use fuzzy operators to (1) aggregate by fuzzy unions (T-conorms) the information provided by the multiple items that define a single variable and (2) intersect (with T-norms) the partial information provided by the first-order variables that describe second-order variables. This mechanism, included in Fuzzy-CSar, is detailed in Sect. 4.2.  
   
  3 Mining Association Rules Association rule mining (ARM) [1] consists in extracting interesting patterns, associations, correlations, or causal structures among the variables in sets of usually unlabeled data. There has been and increasing interest in ARM in the recent years due to the existence of real-world applications in industry that generate large volumes of unlabeled data that have to be processed in order to extract novel and useful information for the company, which in turn may help guide the decision process of the business. This section briefly introduces ARM by first reviewing the initial approaches applied to data described by boolean variables and by then going to more recent approaches that can deal with numeric variables.  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  189  
   
  3.1 Association Rules: The Beginning Initial research on ARM was mainly motivated by the analysis of market basket data, which enabled companies to get a better understanding of the purchasing behavior of their customers. Therefore, association rules were first applied to problems featured by binary or boolean variables. The problem of ARM can be described as follows. Let T = {t1 ,t2 , ...,tn } be a set of transactions, where each transaction consists of a set of items I = {i1 , i2 , . . . , ik }. Let an itemset X be a collection of items I = {i1 , i2 , ..., im }. A frequent itemset is an itemset whose support (supp(X)) is greater than a threshold specified by the user (this threshold is typically addressed as minsupp in the literature). The support of the rules is computed as supp(X) =  
   
  |X(T )| . |T |  
   
  (1)  
   
  That is, the support is the number of transactions in the database which have the itemset X divided by the total number of transactions in the database. Then, an association rule R is an implication of the form X → Y , where both X and Y are itemsets and X ∩ Y = 0. / As previously mentioned, ARM aims at extracting interesting association rules. Although many different measures have been developed to measure the interest of association rules so far [15], there are two basic indicators of the quality of the rules: support (supp) and confidence (con f ). The support of a rule is defined as the ratio of the support of the union of antecedent and consequent to the number of transactions in the database, i.e., supp(R) =  
   
  supp(X ∪Y ) . |T |  
   
  (2)  
   
  The confidence is computed as the ratio of the support of the union of antecedent and consequent to the support of the antecedent, i.e., con f (R) =  
   
  supp(X ∪Y ) . supp(X)  
   
  (3)  
   
  Therefore, support indicates the frequency of occurring patterns, and confidence evaluates the strength of the implication denoted in the association rule. Many algorithms have been proposed to extract association rules since the first proposal in [1]. Agrawal et al. [2] presented the Apriori algorithm, one of the most influential algorithms that set the basis for further research in association rule mining. Apriori uses two different phases to extract all the possible association rules with minimum support and confidence: (1) identification of all frequent itemsets and (2) generation of association rules from these large itemsets. The first phase is based on an iterative process that builds k-length itemsets by combining all the (k-1)-length itemsets whose support is greater than or equal to the minimum support fixed by the used. The support of each new itemset is computed by scanning the database. The second phase takes each frequent itemset and generates rules that  
   
  190  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  contain some of the items in the antecedent of the rule and the remaining ones in the consequent of the rule. The confidence of each rule is computed by scanning the database for each rule, and only those with a minimum confidence are returned. As this process is time consuming, especially in large databases, new approaches that try to reduce the number of scans of the database have been proposed (e.g., see [9]).  
   
  3.2 Association Rule Mining with Continuous Variables The first approaches to ARM only focused on analyzing whether an item was present in a transaction or not, describing the problem with boolean variables. Nonetheless, real-world problems are typically featured by continuous attributes, and these attributes can contain many distinct values. While the support of particular values for these attributes tends to be low, the support of interval of values is much higher. This created the need for building algorithms that could deal with intervals of values, yielding two approaches to the problem: quantitative association rules and fuzzy association rules. Several authors proposed algorithms to deal with interval-based rules, which are typically addressed as quantitative association rules. In these algorithms, the aim was shifted to extracting rules in which variables are defined by intervals, such as “if experience ∈ [5-10] years then income ∈ [30 000 - 40 000]$.” One of the first methods that falls under this category can be found in [21], which, previously to extracting frequent itemsets, uses an equi-depth partitioning to define a set of intervals for each continuous attribute. The method creates a new variable for each interval, transforming therefore the problem into a binary problem. Then, an Apriori-like algorithm is applied to extract association rules from the transformed data. Although this approach and similar ones could deal with continuous variables, it was detected that these types of algorithms could either ignore or over-emphasize the items that lay near the boundary of intervals if the attributes were not properly partitioned. This was addressed as the sharp boundary problem. Two main approaches have been followed to tackle this problem. On the one hand, some authors have applied different clustering mechanisms to extract the best possible intervals from the data [16, 19, 25]. On the other hand, there have been some proposals that adjust these intervals during learning [18]. In parallel to these approaches, some authors faced the problem of sharp boundaries by incorporating fuzzy logics into ARM. In this case, variables were defined by fuzzy sets, allowing the system to extract rules such as “if experience is large then income is high,” where large and high are two linguistic terms represented by fuzzy sets. As variables were represented by fuzzy sets, the problem of the sharp boundary was overcome. Among others, one of the most significant approaches under this category was proposed in [12, 13, 14], which redefined support and confidence for fuzzy association rules and designed an algorithm that combined ideas of Apriori with concepts of fuzzy sets to extract association rules described by variables represented by linguistic terms.  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  191  
   
  Since the consumer behavior modeling problem addressed in this chapter is featured by continuous attributes, we employ a system that falls under this last category. Therefore, Fuzzy-CSar is a system that creates fuzzy association rules from the database and utilizes the typical definitions of support and confidence defined for fuzzy systems to evaluate the interestingness of rules. The details of the algorithm are further explained in the following section.  
   
  4 Description of Fuzzy-CSar Fuzzy-CSar is an ARM algorithm that follows a Michigan-style learning classifier system architecture [11] to extract fuzzy association rules from databases. Differently from most of the state-of-the-art algorithms in fuzzy ARM, Fuzzy-CSar (1) uses a fixed-size population to search for the most promising associations among variables, and so, does not necessarily create all the association rules with minimum support and confidence, (2) extracts association rules from streams of examples instead of from static databases, and, as a consequence, (3) does not scan repetitively the data base but incrementally learns from the stream of examples. The system uses an apportionment of credit technique to incrementally adjust the parameters of association rules and a genetic algorithm [8, 10] to discover new promising rules online. In addition, the system is provided with the multi-item fuzzification in order to deal with the particularities of the marketing data. In what follows, the system is described in some detail by first presenting the knowledge representation and the multi-item fuzzification and then explaining the learning organization.  
   
  4.1 Knowledge Representation Fuzzy-CSar evolves a population [P] of classifiers, where each classifier individually denotes an association among problem variables. Therefore, the solution to the problem is the whole population. Note thus that the population size fixes an upper bound on the number of interesting associations that can be found; that is, at maximum, the system will be able to discover as many interesting relationships as number of classifiers in the population. Each classifier consists of a fuzzy association rule and a set of parameters. The fuzzy association rule is represented as if xi is Ai and · · · and x j is Aj then xc is Ac , in which the antecedent contains a set of a input variables xi , . . . , x j (0 < a < , where  is the number of variables of the problem) and the consequent consists of a single variable xc which is not present in the antecedent. Thus, we allow rules to have an arbitrary number of variables in the antecedent, but we require that rules have always one variable in the consequent. Each variable is represented by a disjunction of linguistic terms or labels Ai = { Ai1 ∨ . . . ∨ Aini }. However, the number of linguistic terms per variable is limited in  
   
  192  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  order to avoid the creation of largely general rules that may provide poor information about the problem. That is, if no restriction were required, the system would tend to generate rules whose variables in the antecedent and consequent had all the possible linguistic terms, since they would cause the rule to match any possible input, and so, its support and confidence would be very high. To prevent the system from creating these rules, we allow the configuration of the maximum number of linguistic terms permitted per input variable (maxLabIn) and output variable (maxLabOut). In addition to the rule itself, each classifier has also six main parameters: (1) the support supp, an indicator of the occurring frequency of the rule; (2) the confidence con f , which denotes the strength of the implication; (3) the fitness F, which is computed as a power of the confidence, so reflecting the quality of the rule; (4) the experience exp, which counts the number of times that the antecedent of the rule has matched an input instance; (5) the numerosity num, which reckons the number of copies of the classifier in the population; and (6) the average size of the association sets as in which the classifier has participated. The function of the different parameters, as well as the process followed to create and evolve these rules, is further explained with the process organization of Fuzzy-CSar in Section 4.3. But before that, next section introduces the multi-item fuzzification included in the system to deal with the marketing data.  
   
  4.2 Multi-item Fuzzification In [17], the authors proposed the concept of multi-item fuzzification in order to deal with problems featured by unobserved variables described by multiple items and second-order constructs partially defined by first-order constructs. This procedure, which was incorporated into Fuzzy-CSar to deal with this kind of marketing data, considers both (1) how to compute the matching degree of a set of items with a variable and (2) how to calculate the matching of several first-order variables with a second-order variable. The first idea of the method is that each individual item provides partial information about the corresponding unobserved variable or first-order variable. Therefore, the authors proposed to compute the matching degree as the aggregation (T-conorm) of the information given by each item. Thence, the matching degree of a variable i with the vector of items xi = (xi1 , xi2 , . . . , xipi ) is  
   
  μAi (xi ) = maxhpii=1 μAi (xihi ).  
   
  (4)  
   
  In our experiments, we considered the maximum as the union operator. On the other hand, second-order variables are those defined by the intersection of the information provided by the corresponding first-order variables. For this reason, multi-item fuzzification calculates the matching degree of second-order variables as the T-norm of the matching degrees of each corresponding first-order variable. In our implementation, we used the minimum as T-norm.  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  193  
   
  4.3 Process Organization After explaining the classifier representation and the mechanism to compute the matching degree in the marketing data, now we are in position to review the learning organization of Fuzzy-CSar. Fuzzy-CSar incrementally tunes the parameters of the classifiers as new examples are received and periodically applies the GA to niches of classifiers in order to create new rules that denote promising associations. The process is explained as follows. At each learning iteration, Fuzzy-CSar receives an input example (e1 , e2 , . . ., e ) and takes the following actions. First, the system creates the match set [M] with all the classifiers in the population that match the input example with a degree larger than 0. If [M] contains less that θmna classifiers, the covering operator is triggered to create as many new matching classifiers as required to have θmna classifiers in [M]. Then, classifiers in [M] are organized in association set candidates. Each association set candidate is given a probability to be selected that is proportional to the average confidence of the classifiers that belong to this association set. The selected association set [A] goes through a subsumption process which aims at diminishing the number of rules that express similar associations among variables. Then, the parameters of all the classifiers in [M] are updated. At the end of the iteration, a GA is applied to [A] if the average time since its last application is greater than θGA . This process is repeatedly applied, therefore, updating the parameters of existing classifiers and creating new promising rules online. To fully comprehend the system process, five elements need further explanation: (1) the covering operator, (2) the procedure to create association set candidates, (3) the association set subsumption mechanism, (4) the parameter update procedure, and (5) the rule discovery by means of a GA. The subsequent subsections explicate each one of these elements in more detail. 4.3.1  
   
  Covering Operator  
   
  The covering operator is the responsible for providing the population with the initial classifiers which will be latter evaluated as new examples are received and evolved by the genetic algorithm. In order to create coherent rules, the operator generates rules that denote associations that are actually strong in the sampled example e from which covering has been activated. For this purpose, the covering operator uses the following procedure. Given the sampled input example e, covering creates a new classifier that contains some variables of the problem in the antecedent and the consequent of the rule and that matches e with maximum degree. That is, for each variable, the operator randomly decides (with probability 1 − P#) whether the variable has to be in the antecedent of the rule, with the constraints (1) that, at least, a variable has to be selected and (2) that, at most,  − 1 variables can be included in the antecedent. Then, one of the remaining variables is selected to be in the rule consequent. Each of these variables is initialized with the linguistic label that maximizes the matching degree with the corresponding input value. In addition, we introduce generalization by permitting the addition of any other linguistic term with  
   
  194  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  probability P# , with the restrictions that each variable in the antecedent and consequent respectively contains maxLabIn and maxLabOut linguistic terms at maximum. 4.3.2  
   
  Creation of Association Set Candidates  
   
  The system organizes the population rules in different niches that individually contain rules with similar associations with the aim of establishing a collaboration among niches and a competition of rules inside each niche. That is, the collaboration/competition scheme is produced by the niche-based genetic algorithm and the population-based deletion scheme, which are explained in subsection 4.3.5. The following explains the heuristic process employed to create these niches. The system relies on the idea that rules that have the same variable with the same or similar linguistic terms in the consequent must belong to the same niche, since probably they would denote similar associations among variables. Therefore, in order to create the different association set candidates, Fuzzy-CSar first sorts the rules of [M] ascendantly depending on the variable of the consequent. Given two rules r1 and r2 that have the same variable in the consequent, the system considers that r1 is smaller than r2 if 1 < 2 or (1 = 2 and u1 > u2 ), where 1 , u1 , 2 , and u2 are the position of first and the last linguistic term of the output variable of each rule respectively. Once [M] has been sorted, the association set candidates are built as follows. At the beginning, an association set candidate [A] is created and the first classifier in [M] is added to this association set candidate. Then, the following classifier k is added if it has the same variable in the consequent, and k is smaller than the minimum ui among all the classifiers in the current [A]. This process is repeated until finding the first classifier that does not satisfy this condition. In this case, a new association set candidate is created, and the same process is applied to add new classifiers to this association set. At the end, this process creates a non-fixed number of niches and distributes the rules through these niches. 4.3.3  
   
  Association Set Subsumption  
   
  The system explained thus far may generate similar rules that would coexist in the population. In order to avoid the maintenance of similar rules in the population, which would consume resources that may be useful to discover rules that denote different associations, Fuzzy-CSar incorporates a subsumption mechanism that searches for similar rules and only maintains the most general one. The subsumption procedure works as follows. Each rule in [A] is checked for subsumption with each other rule in [A]. A rule ri is a candidate subsumer of r j if it satisfies the following four conditions: (1) ri has higher confidence and it is experienced enough (that is, con f i > con f0 and expi > θexp , where con f0 and θexp are user-set parameters); (2) all the variables in the antecedent of ri are also present in the antecedent of r j (r j can have more variables in the antecedent than ri ); (3) both rules have the same variable in the consequent; and (4) ri is more general than  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  195  
   
  r j . A rule ri is more general than r j if all the input and the output variables of ri are also defined in r j , and ri has, at least, the same linguistic terms as r j for each one of its variables. 4.3.4  
   
  Parameter Update  
   
  At the end of each learning iteration, the parameters of all the classifiers that belong to the match set are adjusted according to the information provided by the sampled instance. First, the experience of the classifier is incremented. Second, the support of each rule is updated as suppt+1 =  
   
  suppt · (time − 1) + μA(x(e) ) · μB(y(e) ) , time  
   
  (5)  
   
  where time is the life time of the classifier, that is, the number of iterations that the classifier has been in the population, and μA(x(e) ) and μB(y(e) ) are the matching degrees of the antecedent and the consequent with x(e) and y(e) respectively. Note that this formula computes the support considering all the examples sampled to the system since the rule was created. Thereafter, the confidence is computed as con ft+1 = sum impt+1 /sum matt+1 , where sum impt+1 = sum impt + μA(x(e) ) · max{1 − μA(x(e) ), μB(y(e) )}, and  
   
  (6)  
   
  sum matt+1 = sum matt + μA(x ).  
   
  (7)  
   
  (e)  
   
  Initially, sum impt+1 = sum matt+1 = 0. That is, sum imp maintains the addition of the matching degree of each example sampled so far with the implication of the rule, and sum mat keeps the addition of the matching degrees of the antecedent of the rule with each example sampled since the rule creation. Next, the fitness of each rule in [M] is computed as a function of the confidence, i.e., F = con f ν , where ν permits controlling the pressure toward highly fit classifiers. Finally, the association set size estimate of all rules that belong to [A] is updated. Each rule maintains the average size of all the association sets in which it has participated. 4.3.5  
   
  Discovery Component  
   
  Fuzzy-CSar uses a niche-based GA to create new promising classifiers. The GA is triggered on [A] when the average time from its last application upon the classifiers in [A] exceeds the threshold θGA . The time elapsed between GA applications enables the system to adjust the parameters of the new classifiers before the next application of the GA. Once triggered, the GA selects two parents p1 and p2 from [A], where each classifier has a probability of being selected proportional to its fitness. The two parents are crossed with probability Pχ , generating two offspring ch1 and ch2 . Fuzzy-CSar  
   
  196  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  uses a uniform crossover operator that contemplates the restriction that any offspring has to have, at least, a variable in the rule’s antecedent. If crossover is not applied, the children are exact copies of the parents. The resulting offspring may go through three different types of mutation: (1) mutation of antecedent variables (with probability PI/R ), which randomly chooses whether a new antecedent variable has to be added to or one of the antecedent variables has to be removed from the rule; (2) mutation of the linguistic terms of the variable (with probability Pμ ), which selects one of the existing variables of the rule and mutates its value; and (3) mutation of the consequent variable (with probability PC ), which selects one of the variables of the antecedent and exchanges it with the variable of the consequent. Thereafter, the new offspring are introduced into the population. If the population is full, excess classifiers are deleted from [P] with probability directly proportional to their association set size estimate and inversely proportional its fitness. To sum up, Fuzzy-CSar is a population-based ARM that evaluates rules online as new examples are sampled to the system and that periodically applies a GA to create new promising rules. Note that the system does not require the user to determine the minimum support and minimum confidence of the rules. Instead of this, the system evolves a set of rules with maximum support and confidence, and the number of rules is limited by the population size. The rule activation based on matching prioritizes rules that match a larger number of training examples with respect to those that match a lower number of training examples. In addition, the confidence-based selection of [A] and the inside-niche competition established by the GA pressure toward the creation of rules with progressively higher confidence.  
   
  5 Problem Description and Methodology After motivating the use of ARM for modeling the user behavior and presenting a technique that is able to extract fuzzy association rules without specifying the minimum support and the minimum confidence of the rules, we now move on to the experimentation. This section first explains the details of the marketing problem analyzed in this chapter and presents previous structural models extracted from this problem by using classical marketing analysis techniques. Then, we detail the experimental methodology.  
   
  5.1 Problem Description The present work addresses the problem of modeling web consumers to extract key knowledge that enable marketing experts to create a compelling online environment for these users with the final goal of using this information to create a competitive advantage on the Internet. To tackle this problem, several authors have proposed causal models of the consumer experience on the Internet [5]. These models have mainly focused on the description of the state of flow during consumer navigation of the Web, that is, the cognitive state experienced during online navigation. Reaching  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  Skill  
   
  StartWeb  
   
  197  
   
  Control  
   
  SKILL/ CONTROL FLOW  
   
  Interaction Speed CHALL./ AROUSAL  
   
  Chall.  
   
  Exploratory  
   
  Behavior  
   
  Arousal  
   
  WebImportance  
   
  TELEPRES./ TIME DISTORTION  
   
  Focus  
   
  Telepresence  
   
  TimeDistortion  
   
  Fig. 3 Theoretical model of the user experience on the Internet  
   
  the state of flow comprises a “complete involvement of the user with his activity.” Therefore, marketing experts are especially concerned with the identification of the factors that lead the user to the state of maximum flow. In this chapter, we consider one of the most influential structural models as starting point, which was analytically developed by Novak et al. [20]. The structural model, illustrated in Fig. 3, consisted of nine first-order constructs: skill, control, interactive speed, importance, challenge, arousal, telepresence, time distortion, and exploratory behavior. In addition to these first-order variables, the model also contained three second-order constructs: skill/control, chall/arousal, and telepresence/time distortion, which are partially defined by first-order constructs. The model also considered the variable startWeb, which indicated for how long the user had been using the web. The data were obtained from a large sample Web-based consumer survey conducted in [20]. These surveys posed a set of questions or items that partially described each one of the nine first-order constructs. The user was asked to grade these questions with Likert nine-point rating scales that ranged from “strongly disagree” to “strongly agree.” The startWeb variable was measured with a six-ordinal rating scale that comprised different options of usage time. The analysis conducted in [20] identified that the following four constructs were the most important ones to determine the state of flow: (1) skill and control, (2) challenge and arousal, (3) telepresence and time distortion, and (4) interactive speed. The other constructs were found to be meaningless to define flow. However, it is  
   
  198  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  worth noting that the conclusions extracted by the classical approach depended on the initial causal model. Therefore, some key relationships may had not been discovered. In the following, we use the model-free system Fuzzy-CSar in order to identify associations among the variables of the problem with the aim of detecting any further relationship not captured by the causal model of Novak et al. The approach is not proposed as an alternative to the classical marketing analysis tools, but as a complement to these techniques. The next subsection details the experiments conducted.  
   
  5.2 Experimental Methodology The aim of the experiments was to study whether the application of machine learning techniques could result in the identification of not only the same but new important associations between variables with respect to those detected in the causal model of Novak et al. In addition, we also analyzed the benefits of association rule mining over other machine learning techniques for data prediction, i.e., techniques in which the target variable is predetermined. For this purpose, we included an EMO approach expressly designed for creating rules with a fixed variable in the consequent for the marketing problem [4]. The approach used a genetic cooperative competitive scheme to evolve a Pareto set of rules with maximum support and confidence. For more details on the algorithm, the reader is referred to [4]. Herein, we explain the three experiments conducted to analyze the added value provided by ARM.  
   
  Experiment 1. The first experiment aimed at studying whether Fuzzy-CSar could capture the same knowledge represented in the structural model of Novak et al. This model focused on predicting the variable flow. The analytical study detected that there were four relevant variables to determine the state of flow: (1) skill and control, (2) challenge and arousal, (3) telepresence and time distortion, and (4) interactive speed. The remaining variables were considered irrelevant. Thus, we applied Fuzzy-CSar to the data extracted from the questionnaires, but only considering these four variables and fixing the variable flow as the output variable of the association rules. As the output variable was fixed, we could also apply the aforementioned EMO approach in order to analyze whether Fuzzy-CSar could obtain similar rules to those created by a system specialized to optimize the support and confidence of the rules.  
   
  Experiment 2. Since the first experiment did not consider all the input variables, some important knowledge could be overlooked by no considering important interactions between these missing variables. To study this aspect, we ran Fuzzy-CSar on the data described by all the input variables and compared the results with those obtained from the first experiment. Again, the variable flow was fixed as the target variable of the association rules. In addition, we also run the EMO approach on  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  199  
   
  these data, extending the comparison of Fuzzy-CSar and the EMO approach started in the previous experiment.  
   
  Experiment 3. The two first experiments permitted the analysis of whether the machine learning techniques could extract similar knowledge to that provided by the structural model of Novak et al. and whether new important knowledge was discovered. Nevertheless, the two first experiments did not test the added value provided by extracting association rules online. Therefore, in the third experiment, we ran Fuzzy-CSar on the input data without forcing any variable in the consequent. Thus, the system was expected to evolve rules with different variables in the consequent, and so, to evolve the rules with maximum support and confidence. The aim of the experiment was to examine whether new interesting relationships, not captured by the structural model, could be discovered by Fuzzy-CSar. Note that, since the output variable was not fixed in this experiment, the EMO approach could not be ran. In all the experiments, Fuzzy-CSar was configured with a population size of 6 400 rules and the following parameters: P# = 0.5, Pχ = 0.8, {PI/B , Pμ , PC } = 0.1, θGA = 50, θexp = 1 000, con f0 = 0.95, ν = 1, δ = 0.1. All the variables, except for startWeb, used Ruspini’s strong fuzzy partitions with three linguistic terms. startWeb used six membership functions, each centered in one of the values that the variable could take. In all cases, maxLabIn = 2 and maxLabOut = 1. For the EMO approach, we employed the same configuration used by the authors [4]. That is, the system was configured to evolve a population of 100 individuals during 100 iterations, with crossover and mutation probabilities of 0.7 and 0.1 respectively. The variables used the same semantics as Fuzzy-CSar ones. Before proceeding to the analysis of the results, it is worth highlighting the underlying differences between Fuzzy-CSar and the EMO approach. As aforementioned, the first important difference is in the knowledge representation: FuzzyCSar creates fuzzy association rules where the output variable is not fixed and the EMO approach creates rules with a prefixed target variable. Therefore, FuzzyCSar, and ARM algorithms in general, could create rules that denote important associations among variables in a single run; on the other hand, the EMO approach has to fix the output variable at each run. The second important difference is the process organization and the goal of the method. Fuzzy-CSar aims at learning a set of association rules distributed through different niches according to the genotype of the rule; in addition, the learning is done online. The fitness-based insideniche selection and population-based deletion pressure toward obtaining rules with maximum confidence and support. Conversely, the EMO approach explicitly optimizes the rules with respect to their support and confidence, that is, it optimizes the Pareto front. Therefore, the EMO approach is more likely to evolve rules that maximize support and confidence, since it is specifically designed with this objective, while Fuzzy-CSar is more focused on evolving a diverse set of rules that have maximum confidence. Notwithstanding, we are interested in analyzing how our approach performs in comparison with a system which is specialized in optimizing the Pareto front.  
   
  200  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  6 Analysis of the Results This section examines the results of the three experiments from two perspectives. First, we study the results on the objective space by analyzing the rules of the Pareto set, that is, those rules for which there do not exist any other rule in the population that has both a higher support and a higher confidence than the given rule. With this analysis we consider the ability of Fuzzy-CSar to create different rules with high support and confidence that are distributed through the solution space and compare it with the EMO approach, but we do not study the utility of the rules from the point of view of the marketing expert. This analysis is conducted afterwards, where several rules that provide new interesting knowledge about the problem, not captured by the structural model, are illustrated.  
   
  6.1 Analysis of the Rules in the Objective Space Figure 4 shows the shape of the Pareto fronts evolved by Fuzzy-CSar and by the EMO approach in the first experiment, which considers only the four most relevant variables in the antecedent and forces flow to be in the consequent. The first row of Table 1 complements this information by reporting the average number of rules in the population of Fuzzy-CSar and the average number of rules in the Pareto set of Fuzzy-CSar and the EMO approach. In addition, to indicate the distribution of solutions in the Pareto set, the sum of the distance crowding between consecutive solutions in the Pareto front are also provided in parentheses.  
   
  EMO (Flow as consequent) Fuzzy-CSar (Flow as consequent)  
   
  1  
   
  Confidence  
   
  0.9  
   
  0.8  
   
  0.7  
   
  0.6 0  
   
  0.1  
   
  0.2  
   
  0.3  
   
  0.4  
   
  0.5  
   
  0.6  
   
  0.7  
   
  Support  
   
  Fig. 4 Average Pareto front obtained by Fuzzy-CSar and the EMO approach considering the 4 variables of the marketing data identified as the most important variables by the structural model and fixing the variable flow as target of the rules  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  201  
   
  EMO (Flow as consequent) Fuzzy-CSar (Flow as consequent) Fuzzy-CSar without fixed consequent Subset 'Flow' in Fuzzy-CSar without fixed consequent  
   
  Confidence  
   
  1  
   
  0.9  
   
  0.8  
   
  0.7  
   
  0.6 0  
   
  0.1  
   
  0.2  
   
  0.3  
   
  0.4  
   
  0.5  
   
  0.6  
   
  0.7  
   
  Support  
   
  Fig. 5 Average Pareto front obtained by Fuzzy-CSar and the EMO approach considering the 9 variables of the marketing data  
   
  Table 1 Average number of rules evolved by Fuzzy-CSar, average number of these rules that are in the Pareto set, and average number of rules in the Pareto sets obtained by the EMO approach. For the Pareto sets, the average crowding distance of the population is provided in parentheses.  
   
  Experiment 1 Experiment 2 Experiment 3  
   
  FCSar All FCSar Pareto EMO Pareto 479.2 76.3 (1.53 · 10−2 ) 82.6 (1.49 · 10−2 ) 1259.7 105.9 (1.07 · 10−2 ) 84.4 (1.49 · 10−2 ) 1752.5 468.3 (2.58 · 10−3 ) —  
   
  These results show the similarity of the results obtained with both methods. That is, both techniques discovered a similar number of solutions in the Pareto set, and these solutions were distributed uniformly through the objective space. The similarity of the results highlight the robustness of Fuzzy-CSar, which was able to generate Pareto fronts that were very close to those created by a competent technique which specifically optimized the Pareto front. In addition, the strongest rules obtained denote the same relationships provided by the structural model. Nonetheless, we put aside further discussion about the utility of the rules until the next section. Figure 5 together with the second row of Table 1 show the same information but for the second experiment, which considers any of the nine variables in the antecedent and forces flow to be in the consequent. These Pareto fronts are very similar to those obtained in the first experiment. Actually, the EMO approach can discover practically the same rules than those obtained with the first experiment. On the other hand, Fuzzy-CSar obtains a significantly larger number of rules in the Pareto set; as a consequence, the average crowding distance decreases, since  
   
  202  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  solutions in the Pareto set are closer to each other. Nonetheless, the shape of the Pareto sets is almost the same in both cases, which supports the hypothesis that the four variables identified as the most important ones by the models in [20] are indeed the most relevant ones to describe the flow construct. Finally, Fig. 5 together with the third row of Table 1 supply the results of FuzzyCSar for the third experiment, where any variable can be in the antecedent or in the consequent of the association rules. These results show the potential of our approach. In a single run, Fuzzy-CSar was able to evolve a set of rules with large confidence and support, resulting in a Pareto front that was clearly better than those of Fuzzy-CSar and the EMO approach when the flow construct was fixed in the rule consequent. To complement the results of the third experiment, the same figure plots the objective values of the rules of the Pareto front evolved by Fuzzy-CSar that predict the flow construct. Notice that, for large confidence, this Pareto front is close to the one evolved by the EMO approach and Fuzzy-CSar in previous experiments where flow was fixed in the consequent. On the other hand, the solutions in the Pareto front degrade as the confidence of the rules decreases. This behavior can be easily explained as follows. As the number of possible variables in the consequent increases, Fuzzy-CSar needs to maintain a larger number of rules that belong to different niches. In this case, the implicit niching system together with the niche-based GA and population-wise deletion operator of Fuzzy-CSar make pressure toward maintaining a diverse set of solutions. On the other hand, the GA also pressures toward evolving rules with maximum confidence. Therefore, the system maintains a diverse set of solutions with maximum confidence, which goes in detriment of solutions with smaller confidence, but larger support. Similar results could be obtained by the EMO approach by running nine different experiments, each one fixing a different variable in the consequent. This would yield nine Pareto sets, each one with rules that predict one of the nine variables. Then, these Pareto sets could be joined and processed to get the final Pareto set. Nevertheless, it is worth noting that Fuzzy-CSar provides a natural support for the extraction of interesting association rules with different variables in the consequent, evolving a set of distributed solutions in parallel, and maintaining only those with maximum confidence.  
   
  6.2 Analysis of the Utility of the Rules from the Marketing Expert Perspective After showing the competitiveness of Fuzzy-CSar with respect to the EMO approach, this section analyzes the importance of the knowledge provided by some of the rules discovered by Fuzzy-CSar. For this purpose, we show two particular examples of rules that provide key knowledge considered neither by the structural model [20] nor by the EMO approach [4].  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  203  
   
  Firstly, we selected a rule that predicted exploratory behavior, that is, R1 : IF importance is Medium and skill/control is {Small or Medium} and focusedAttention is {Small or Medium} and flow is {Small or Medium} THEN exploratoryBehavior is Medium [Supp.: 0.22; Conf.: 0.87].  
   
  The model proposed by Novak et al. considered that exploratory behavior was related to only telepresence/time distortion, that is, the degree of telepresence and the effect of losing the notion of time while browsing the web. However, rule R1 does not consider this relationship. Instead, it denotes that exploratory behavior is determined by importance, perceived skill/control, focused attention in the browsing process, and the state of flow. Thence, this rule indicates that intermediate values of the variables of the antecedent explicate, with confidence 0.87, states of moderate exploratory behaviors in the Web. The knowledge denoted by the rule may cause the marketing expert to consider other associations among variables that were not considered in the initial model. In particular, this relationship was initially considered in the causal model built in [20], but it was further discarded after a process of model refinement. Nonetheless, R1 is alerting of the importance and strength of this association. Secondly, we chose the following rule, which described focused attention: R2 : IF importance is {Small or Medium} and chall/arousal is {Small or Medium} and telepres/time distortion is Medium and exploratoryBehavior is {Medium or Large} THEN focused attention is Medium [Supp.: 0.21; Conf.: 0.84]  
   
  In Novak’s et al. model, focused attention was related to neither importance nor chall/arousal. However, rule R2 indicates that these two variables together with telepres/time distortion and exploratory behavior may determine moderate degrees of attention in the Web browsing. This information is especially interesting since it contradicts the causal model. This contradiction is reasonable if we consider the following. Differently from [20], Fuzzy-CSar does not assume any type of problem structure. Thence, Fuzzy-CSar can discover new relations among variables that may appear to be very useful and interesting. This may be the case of R2 , which implies that increasing the experience in the navigation process may influence, together with the other variables, the capacity of users to focus their attention on the Web. In summary, R2 proposes a new scenario that was not considered before, and marketing experts may analyze whether this new knowledge needs to be included in further revisions of the causal model. In addition to these particular examples, it is worth emphasizing that, in general, unsupervised learning techniques such as Fuzzy-CSar may be relevant tools in problems for which a priori information is unknown. In these cases, association rules may discover interesting, useful, and hidden associations among the variables forming a database that help marketing experts better understand a certain problem they are approaching to.  
   
  204  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  7 Conclusions and Further Work This chapter started by discussing the importance of the use of machine learning techniques to give support to classical methodologies for marketing analysis. Among the different techniques in machine learning, we identified ARM as one of the most appealing approaches since it enables the automatic identification of associations or relationships among variables from a data set. That is, differently from the classical approach, which requires that marketing experts work with a theoretical model, ARM does not require any type of a priori information about the problem. In order to show the added value that ARM could provide to marketing experts, we reviewed the application of Fuzzy-CSar, a general-purpose ARM technique that evolves a set of association rules online and that uses adapted inference mechanisms to deal with the particularities of the marketing data. Then, we applied it to the problem of modeling the user navigational process in online (the Web) environments; in particular, we were based on the Novak et al. [20] data and flow model to develop the experimental stage. Additionally, the system was compared to a predictive EMO approach that needed to fix the target variable of the evolved rules. The empirical results highlighted the added value of applying machine learning techniques to the marketing problem and, more specifically, of extracting association rules. That is, Fuzzy-CSar was able not only to generate rules that expressed the same knowledge as that contained in the theoretical (structural) marketing model of reference, but also to capture additional relationships among variables not previously considered in the theoretical background. We have shown how some of such uncovered relationships are very interesting from the analyzed marketing problem perspective. To sum up, these results suggest the suitability of ARM for marketing databases analysis. In particular, it has demonstrated to be helpful in consumer behavior modeling, especially as a complementary analytical tool to the traditional methods applied there. Anyhow, marketing researchers and practitioners, especially the formers, must not forget that the outcomes of these new, less orthodox, analytical methods are desirable to be interpreted and assimilated without forgetting to connect with the subjacent theoretical frameworks of the marketing issues they face. Acknowledgments. The authors would like to thank Ministerio de Educaci´on y Ciencia for its support under projects TIN2008-06681-CO6-01 and TIN2008-06681-CO6-05, Generalitat de Catalunya for its support under grant 2005SGR-00302, and Junta de Andaluc´ıa for its support under project P07-TIC-3185.  
   
  References 1. Agrawal, R., Imielinski, T., Swami, A.: Mining association rules between sets of items in large databases. In: Proceedings of the ACM SIGMOD International Conference on Management of Data, Washington D.C., May 1993, pp. 207–216 (1993)  
   
  Automatic Discovery of Potential Causal Structures in Marketing Databases  
   
  205  
   
  2. Agrawal, R., Srikant, R.: Fast algorithms for mining association rules in large databases. In: Bocca, J.B., Jarke, M., Zaniolo, C. (eds.) Proceedings of the 20th International Conference on Very Large Data Bases, VLDB, Santiago, Chile, September 1994, pp. 487–499 (1994) 3. Bollen, K.A.: Structural equations with latent variables. Wiley-Interscience, Hoboken (1989) (A division of John Wiley & Sons, Inc.) 4. Casillas, J., Mart´ınez-L´opez, F.J.: Mining uncertain data with multiobjective genetic fuzzy systems to be applied in consumer behaviour modelling. Expert Systems With Applications 36(2), 1645–1659 (2009) 5. Csikszentmihalyi, M.: Finding flow: The psychology of engagement with everyday life (1997) 6. Drejer, A.: Back to basics an beyond: Strategic management – an area where practice and theory are poorly related. Management Decision, 42(3/4), 508–520 7. Glymour, C., Scheines, R., Spirtes, P., Kelly, K.: Discovering causal structure. Academic Press, Orlando (1987) 8. Goldberg, D.E.: Genetic algorithms in search, optimization & machine learning, 1st edn. Addison Wesley, Reading (1989) 9. Han, J., Pei, J., Yin, Y., Mao, R.: Mining frequent patterns without candidate generation: A frequent-pattern tree approach. Data Mining and Knowledge Discovery 8(1), 53–87 (2004) 10. Holland, J.H.: Adaptation in natural and artificial systems. The University of Michigan Press, Ann Arbor (1975) 11. Holland, J.H., Reitman, J.S.: Cognitive systems based on adaptive algorithms. In: Waterman, D.A., Hayes-Roth, F. (eds.) Pattern-directed inference systems, pp. 313–329. Academic Press, San Diego (1978) 12. Hong, T.P., Kuo, C.S., Chi, S.C.: A fuzzy data mining algorithm for quantitative values. In: Proceedings International Conference on Knowledge-Based Intelligent Information Engineering Systems, pp. 480–483 (1999) 13. Hong, T.P., Kuo, C.S., Chi, S.C.: Mining association rules from quantitative data. Intelligent Data Analysis 3, 363–376 (1999) 14. Hong, T.P., Kuo, C.S., Chi, S.C.: Trade-off between computation time and number of rules for fuzzy mining from quantitative data. International Journal of Uncertainty, Fuzziness, and Knowledge-Based Systems 9(5), 587–604 (2001) 15. Lenca, P., Meyer, P., Vaillant, B., Lallich, S.: On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid. European Journal of Operational Research 184, 610–626 (2008) 16. Lent, B., Swami, A.N., Widom, J.: Clustering association rules. In: Procedings of the IEEE International Conference on Data Engineering, pp. 220–231 (1997) 17. Mart´ınez-L´opez, F.J., Casillas, J.: Marketing intelligent systems for consumer behaviour modelling by a descriptive induction approach based on genetic fuzzy systems. Industrial Marketing Management (2009), doi:10.1016/j.indmarman.2008.02.003 18. Mata, J., Alvarez, J.L., Riquelme, J.C.: An evolutionary algorithm to discover numeric association rules. In: SAC 2002, pp. 590–594. ACM, New York (2002) 19. Miller, R.J., Yang, Y.: Association rules over interval data. In: SIGMOD 1997: Proceedings of the 1997 ACM SIGMOD international conference on Management of data, pp. 452–461. ACM, New York (1997) 20. Novak, T., Hoffman, D., Yung, Y.: Measuring the customer experience in online environments: A structural modelling approach. Marketing Science 19(1), 22–42 (2000)  
   
  206  
   
  A. Orriols-Puig, J. Casillas, and F.J. Mart´ınez-L´opez  
   
  21. Srikant, R., Agrawal, R.: Mining quantitative association rules in large relational tables. In: Jagadish, H.V., Mumick, I.S. (eds.) Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, Montreal, Quebec, Canada, pp. 1–12 (1996) 22. Steenkamp, J., Baumgartner, H.: On the use of structural equation models for marketing modelling. International Journal of Research in Marketing 17, 195–202 (2000) 23. Stevens, S.S.: On the theory of scales of measurement. Science, 677–680 (1946) 24. Stevens, S.S.: Measurement, psychophysics and utility. John Wiley, New York (1959) 25. Wang, K., Tay, S.H.W., Liu, B.: Interestingness-based interval merger for numeric association rules. In: Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining, KDD, pp. 121–128. AAAI Press, Menlo Park (1998)  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior for Business Intelligence C´elia da Costa Pereira and Andrea G.B. Tettamanzi Universit` a degli Studi di Milano Dipartimento di Tecnologie dell’Informazione via Bramante 65, I-26013 Crema, Italy e-mail: {celia.pereira,andrea.tettamanzi}@unimi.it  
   
  Abstract. This chapter describes the application of evolutionary algorithms to induce predictive models of customer behavior in a business environment. Predictive models are expressed as fuzzy rule bases, which have the interesting property of being easy to interpret for a human expert, while providing satisfactory accuracy. The details of an island-based distributed evolutionary algorithm for fuzzy model induction are presented and a case study is used to illustrate the eﬀectiveness of the approach. Keywords: Business Intelligence, Data Mining, Modeling, Strategic Marketing, Forecast, Evolutionary Algorithms.  
   
  1 Introduction Companies face everyday problems related to uncertainty in organizational planning activities: accurate and timely knowledge means improved business performance. In this framework, business intelligence applications represent instruments for improving the decision making process within the company, by achieving a deeper understanding of market dynamics and customers’ behaviour. Particularly, in the ﬁelds of business and ﬁnance, the executives can improve their insight of market scenarios by foreseeing customers’ behaviour. This information allows to maximize revenues and manage costs through an increase in the eﬀectiveness and eﬃciency of all the strategies and processes which involve the customers. Predictions about customers’ intentions to purchase a product, about their loyalty rating, the gross operating margins or revenue they will generate, are fundamental for two reasons. Firstly, they are instrumental to an eﬀective planning of production volumes and speciﬁc promotional activities. Secondly, the comparison of projections to actual results allows to spot meaningful indicators, useful for improving performance. J. Casillas & F.J. Mart´ınez-L´ opez (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 207–225. c Springer-Verlag Berlin Heidelberg 2010 springerlink.com   
   
  208  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  This chapter describes a general approach to business intelligence, which exploits an evolutionary algorithm to design and optimize fuzzy-rule-based predictive models of various types of customer behavior. The chapter is organized as follows: Section 2 discusses the scenarios where evolutionary predictive modeling may be employed, and Section 3 gives an outline of the approach. The next sections introduce the main ingredients of the approach: Section 4 provides an introduction to fuzzy rule-based systems and Section 5 to evolutionary algorithms. Section 6 gives a detailed description of the approach, and Section 7 illustrates its eﬀectiveness by means of a real-world case study. Section 8 concludes.  
   
  2 The Context Traditional methods of customer analysis, like segmentation and market research, provide static knowledge about customers, which may become unreliable in time. A competitive advantage can be gained by adopting a data-mining approach whereby predictive models of customer behaviour are learned from historical data. Such knowledge is more ﬁne-grained, in that it allows to reason about an individual customer, not a segment; furthermore, by re-running the learning algorithm as newer data become available, such an approach may be made to take a continuous picture of the current situation, thus providing dynamic knowledge about customers. The described approach uses evolutionary algorithms (EAs) for model learning, and expresses models as fuzzy rule bases. EAs are known to be well-suited to tracking optima in dynamic optimization problems [5]. Fuzzy rule bases have the desirable characteristic of being intelligible, as they are expressed in a language typically used by human experts to express their knowledge.  
   
  2.1 Application Scenarios The system has been applied to a wide range of situations to achieve diﬀerent goals, including: • credit scoring in the banking sector [20]; • estimating the lifetime value of customers in the insurance sector [23]; • debt collection, i.e., predicting the probability of success of each of several alternative collection strategies in order to minimize cost and maximize eﬀectiveness of collection; • predicting customer response to new products, as a help to target advertisement campaigns or promotional activities in general; • predicting customer response to pricing and other marketing actions; • modeling of ﬁnancial time series for automated single-position day trading [7, 8].  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  209  
   
  • predicting the revenue and/or gross operating margins for each individual customer and each product, as an aid to optimizing production and sales force planning [24]. A case study on the last scenario is presented in Section 7. Once the range of revenue (or gross operating margin) in which a customer will be located in the next quarter has been foreseen, the manager can evaluate the capability of the selling force: for example, if all the customers followed by a group of sellers will generate the minimum hypothetical revenue, the considered sellers are not so eﬀective. In this case, the manager can compare diﬀerent groups on the basis of their respective expected results, even if their speciﬁc targets and environments are heterogeneous. Moreover, the obtained projections enable the company to target strategic marketing actions aimed at proposing new products to the customers that really have a predisposition for a speciﬁc kind of products and at increasing customers loyalty. Comparing the expected and actual results, a manager can have a detailed picture of the business process in order to promptly manage critical variables.  
   
  2.2 Related Work The idea of using fuzzy logic for expressing customer models or classiﬁcations and exploiting such information for personalizing marketing actions targeted to individual (potential) customers has been explored for at least a decade, with the ﬁrst proposals of fuzzy market segmentation [25] dating back to almost twenty years ago. For instance, the fuzzy modeling of client preferences has been applied to selecting the targets of direct marketing actions. This has been shown to provide advantages over the traditional practice of using statistical tools for target selection [21]. Other researchers have applied fuzzy logic to marketing by inducing a fuzzy classiﬁcation of individual customers that can be exploited to plan marketing campaigns [13]. This idea ﬁnds its natural application in e-commerce [26, 27]. A similar approach has been proposed for personalized advertisement [29], to determine which ad to display on a Web site, on the basis of the viewer’s characteristics. Some researchers have taken the further step of combining fuzzy logic with other soft computing methods, like neural networks, to build decision support systems that assist the user in developing marketing strategies [14]. A natural combination with other soft computing methods consists of using evolutionary algorithms to induce fuzzy classiﬁcation rules. This is the approach we describe in this chapter and other researchers have pursued with slightly diﬀerent techniques, notably Herrera and colleagues [10].  
   
  210  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  3 Data Mining In the area of business intelligence, data mining is a process aimed at discovering meaningful correlations, patterns, and trends between large amounts of data collected in a dataset. Once an objective of strategic marketing has been established, the system needs a wide dataset including as many data as possible not only to describe customers, but also to characterize their behaviour and tracing their actions. The model is determined by observing past behaviour of customers and extracting the relevant variables and correlations between data and rating (dependent variable) and it provides the company with projections based on the characteristics of each customer: a good knowledge of customers is the key for a successful marketing strategy. The described approach is based on the use of an EA which recognizes patterns within the dataset, by learning classiﬁers represented by sets of fuzzy rules. Using fuzzy rules makes it possible to get homogeneous predictions for diﬀerent clusters without imposing a traditional partition based on crisp thresholds, that often do not ﬁt the data, particularly in business applications. Fuzzy decision rules are useful in approximating non-linear functions because they have a good interpolative power and are intuitive and easily intelligible at the same time. Their characteristics allow the model to give an eﬀective representation of the reality and simultaneously avoid the “black-box” eﬀect of, e.g., neural networks. The output of the application is a set of rules written in plain consequential sentences. The intelligibility of the model and the high explanatory power of the obtained rules are useful for the ﬁrm, in fact the rules are easy to be interpreted and explained, so that an expert of the ﬁrm can clearly read and understand them. An easy understanding of a forecasting method is a fundamental characteristic, since otherwise the managers are reluctant to use forecasts [1]. Moreover, the proposed approach provides the managers with an information that is more transparent for the stakeholders and can easily be shared with them.  
   
  4 Fuzzy Rule-Based Systems This section provides a gentle introduction to fuzzy rule-based systems, with particular emphasis on the ﬂavor employed by the described approach. Fuzzy logic was initiated by Lotﬁ Zadeh with his seminal work on fuzzy sets [31]. Fuzzy set theory provides a mathematical framework for representing and treating vagueness, imprecision, lack of information, and partial truth. Very often, we lack complete information in solving real world problems. This can be due to several causes. First of all, human expertise is of a qualitative type, hard to translate into exact numbers and formulas. Our understanding of any process is largely based on imprecise, “approximate” reasoning.  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  211  
   
  However, imprecision does not prevent us from performing successfully very hard tasks, such as driving cars, improvising on a chord progression, or trading ﬁnancial instruments. Furthermore, the main vehicle of human expertise is natural language, which is in its own right ambiguous and vague, while at the same time being the most powerful communication tool ever invented.  
   
  4.1 Fuzzy Sets Fuzzy sets are a generalization of classical sets obtained by replacing the characteristic function of a set A, χA which takes up values in {0, 1} (χA (x) = 1 iﬀ x ∈ A, χA (x) = 0 otherwise) with a membership function μA , which can take up any value in [0, 1]. The value μA (x) is the membership degree of element x in A, i.e., the degree to which x belongs in A. A fuzzy set is completely deﬁned by its membership function. Therefore, it is useful to deﬁne a few terms describing various features of this function, summarized in Figure 1. Given a fuzzy set A, its core is the (conventional) set of all elements x such that μA (x) = 1; its support is the set of all x such that μA (x) > 0. A fuzzy set is normal if its core is nonempty. The set of all elements x of A such that μA (x) ≥ α, for a given α ∈ (0, 1], is called the α-cut of A, denoted Aα .  
   
  1 μA  
   
  α  
   
  0 core α-cut support  
   
  Fig. 1 Core, support, and α-cuts of a set A of the real line, having membership function μA  
   
  If a fuzzy set is completely deﬁned by its membership function, the question arises of how the shape of this function is determined. From an engineering point of view, the deﬁnition of the ranges, quantities, and entities relevant to a system is a crucial design step. In fuzzy systems all entities that come into play are deﬁned in terms of fuzzy sets, that is, of their membership functions. The determination of membership functions is then correctly viewed as a problem of design. As such, it can be left to the sensibility of a human expert or more objective techniques can be employed. Alternatively, optimal membership function assignment, of course relative to a number of design goals  
   
  212  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  that have to be clearly stated, such as robustness, system performance, etc., can be estimated by means of a machine learning or optimization method. In particular, evolutionary algorithms have been employed with success to this aim. This is the approach we follow in this chapter.  
   
  4.2 Operations on Fuzzy Sets The usual set-theoretic operations of union, intersection, and complement can be deﬁned as a generalization of their counterparts on classical sets by introducing two families of operators, called triangular norms and triangular co-norms. In practice, it is usual to employ the min norm for intersection and the max co-norm for union. Given two fuzzy sets A and B, and an element x, μA∪B (x) = max{μA (x), μB (x)};  
   
  (1)  
   
  μA∩B (x) = min{μA (x), μB (x)}; μA¯ (x) = 1 − μA (x).  
   
  (2) (3)  
   
  4.3 Fuzzy Propositions and Predicates In classical logic, a given proposition can fall in either of two sets: the set of all true propositions and the set of all false propositions, which is the complement of the former. In fuzzy logic, the set of true proposition and its complement, the set of false propositions, are fuzzy. The degree to which a given proposition P belongs to the set of true propositions is its degree of truth, T (P ). The logical connectives of negation, disjunction, and conjunction can be deﬁned for fuzzy logic based on its set-theoretic foundation, as follows: Negation T (¬P ) = 1 − T (P ); Disjunction T (P ∨ Q) = max{T (P ), T (Q)}; Conjunction T (P ∧ Q) = min{T (P ), T (Q)}.  
   
  (4) (5) (6)  
   
  Much in the same way, a one-to-one mapping can be established as well between fuzzy sets and fuzzy predicates. In classical logic, a predicate of an element of the universe of discourse deﬁnes the set of elements for which that predicate is true and its complement, the set of elements for which that predicate is not true. Once again, in fuzzy logic, these sets are fuzzy and the degree of truth of a predicate of an element is given by the degree to which that element is in the set associated with that predicate.  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  213  
   
  4.4 Fuzzy Rulebases A prominent role in the application of fuzzy logic to real-world problems is played by fuzzy rule-based systems. Fuzzy rule-based systems are systems of fuzzy rules that embody expert knowledge about a problem, and can be used to solve it by performing fuzzy inferences. The ingredients of a fuzzy rule-based systems are linguistic variables, fuzzy rules, and defuzziﬁcation methods. 4.4.1  
   
  Linguistic Variables  
   
  A linguistic variable [32] is deﬁned on a numerical interval and has linguistic values, whose semantics is deﬁned by their membership function. For example, a linguistic variable temperature might be deﬁned over the interval [−20◦ C, 50◦ C]; it could have linguistic values like cold, warm, and hot, whose meanings would be deﬁned by appropriate membership functions. 4.4.2  
   
  Fuzzy Rules  
   
  A fuzzy rule is a syntactic structure of the form IF antecedent THEN consequent,  
   
  (7)  
   
  where each antecedent and consequent are formulas in fuzzy logic. Fuzzy rules provide an alternative, compact, and powerful way of expressing functional dependencies between various elements of a system in a modular and, most importantly, intuitive fashion. As such, they have found broad application in practice, for example in the ﬁeld of control and diagnostic systems [19]. 4.4.3  
   
  Inference  
   
  The semantics of a fuzzy rule-based system is governed by the calculus of fuzzy rules [33]. In summary, all rules in a fuzzy rule base take part simultaneously in the inference process, each to an extent proportionate to the truth value associated with its antecedent. The result of an inference is represented by a fuzzy set for each of the dependent variables. The degree of membership for a value of a dependent variable in the associated fuzzy set gives a measure of its compatibility with the observed values of the independent variables. Given a system with n independent variables x1 , . . . , xn and m dependent variables y1 , . . . , ym , let R be a base of r fuzzy rules IF P1 (x1 , . . . , xn ) THEN Q1 (y1 , . . . , ym ), .. .. . . IF Pr (x1 , . . . , xn ) THEN Qr (y1 , . . . , ym ),  
   
  (8)  
   
  214  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  where P1 , . . . , Pr and Q1 , . . . Qr represent fuzzy predicates respectively on independent and dependent variables, and let τP denote the truth value of predicate P . Then the membership function describing the fuzzy set of values taken up by dependent variables y1 , . . . , ym of system R is given by τR (y1 , . . . , ym ; x1 , . . . , xn ) = sup1≤i≤r min{τQi (y1 , . . . , ym ), τPi (x1 , . . . , xn )}. 4.4.4  
   
  (9)  
   
  The Mamdani Model  
   
  The type of fuzzy rule-based system just described, making use of the min and max as the triangular norm and co-norm, is called the Mamdani model. A Mamdani system [15] has rules of the form IF x1 is A1 AND . . . AND xn is An THEN y is B,  
   
  (10)  
   
  where the Ai s and B are linguistic values (i.e., fuzzy sets) and each clause of the form “x is A” has the meaning that the value of variable x is in fuzzy set A. 4.4.5  
   
  Defuzziﬁcation Methods  
   
  There may be situations in which the output of a fuzzy inference needs to be a crisp number y ∗ instead of a fuzzy set R. Defuzziﬁcation is the conversion of a fuzzy quantity into a precise quantity. At least seven methods in the literature are popular for defuzzifying fuzzy outputs [12], which are appropriate for diﬀerent application contexts. The centroid method is the most prominent and physically appealing of all the defuzziﬁcation methods. It results in a crisp value  yμR (y)dy ∗ y =  , (11) μR (y)dy where the integration can be replaced by summation in discrete cases. The next section introduces evolutionary algorithms, a biologically inspired technique which we use to learn and optimize fuzzy rule bases.  
   
  5 Evolutionary Algorithms EAs are a broad class of stochastic optimization algorithms, inspired by biology and in particular by those biological processes that allow populations of organisms to adapt to their surrounding environment: genetic inheritance and survival of the ﬁttest. An EA maintains a population of candidate solutions for the problem at hand, and makes it evolve by iteratively applying a (usually quite small) set of stochastic operators, known as mutation, recombination, and selection.  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  215  
   
  Mutation randomly perturbs a candidate solution; recombination decomposes two distinct solutions and then randomly mixes their parts to form novel solutions; and selection replicates the most successful solutions found in a population at a rate proportional to their relative quality. The initial population may be either a random sample of the solution space or may be seeded with solutions found by simple local search procedures, if these are available. The resulting process tends to ﬁnd, given enough time, globally optimal solutions to the problem much in the same way as in nature populations of organisms tend to adapt to their surrounding environment. Books of reference and synthesis in the ﬁeld of EAs are [9, 3, 2]; recent advances are surveyed in [30]. Evolutionary algorithms have enjoyed an increasing popularity as reliable stochastic optimization, search and rule-discovering methods in the last few years. The original formulation by Holland and others in the seventies was a sequential one. That approach made it easier to reason about mathematical properties of the algorithms and was justiﬁed at the time by the lack of adequate software and hardware. However, it is clear that EAs oﬀer many natural opportunities for parallel implementation [17]. There are several possible parallel EA models, the most popular being the ﬁne-grained or grid [16], the coarse-grain or island [28], and the master-slave or ﬁtness parallelization [6] models. In the grid model, large populations of individuals are spatially distributed on a low-dimensional grid and individuals interact locally within a small neighborhood. In the master-slave model, a sequential EA is executed on what is called the master computer. The master is connected to several slave computers to which it sends individuals when they require evaluation. The slaves evaluate the individuals (ﬁtness evaluation makes up most of the computing time of an EA) and send the result back to the master. In the island model, the population is divided into smaller subpopulations which evolve independently and simultaneously according to a sequential EA. Periodic migrations of some selected individuals between islands allow to inject new diversity into converging subpopulations. Microprocessor-based multicomputers and workstation clusters are well suited for the implementation of this kind of parallel EA. Being coarse-grained, the island model is less demanding in terms of communication speed and bandwidth, which makes it a good candidate for a cluster implementation.  
   
  6 An Island-Based Evolutionary Algorithm for Fuzzy Rule-Base Optimization This section describes an island-based distributed evolutionary algorithm for the optimization of fuzzy rule bases. In particular, the discussion will focus on the specialized mutation and crossover operation, as well as on the ﬁtness function and ways to prevent overﬁtting.  
   
  216  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  The described approach incorporates an EA for the design and optimization of fuzzy rule-based systems that was originally developed to automatically learn fuzzy controllers [22, 18], then was adapted for data mining, [4] and is at the basis of MOLE, a general-purpose distributed engine for modeling and data mining based on EAs and fuzzy logic [24]. Each classiﬁer is described through a set of fuzzy rules. A rule is made by one or more antecedent clauses (“IF . . . ”) and a consequent clause (“THEN . . . ”). Clauses are represented by a pair of indices referring respectively to a variable and to one of its fuzzy sub-domains, i.e., a membership function. A MOLE classiﬁer is a rule base, whose rules comprise up to four antecedent and one consequent clause each. Input and output variables are partitioned into up to 16 distinct linguistic values each, described by as many membership functions. Membership functions for input variables are trapezoidal, while membership functions for the output variable are triangular. Classiﬁers are encoded in three main blocks: 1. a set of trapezoidal membership functions for each input variable; a trapezoid is represented by four ﬁxed-point numbers, each ﬁtting into a byte; 2. a set of symmetric triangular membership functions, represented as an area-center pair, for the output variable; 3. a set of rules, where a rule is represented as a list of up to four antecedent clauses (the IF part) and one consequent clause (the THEN part); a clause is represented by a pair of indices, referring respectively to a variable and to one of its membership functions. An island-based distributed EA is used to evolve classiﬁers. The sequential algorithm executed on every island is a standard generational replacement, elitist EA. Crossover and mutation are never applied to the best individual in the population.  
   
  6.1 Genetic Operators The recombination operator is designed to preserve the syntactic legality of classiﬁers. A new classiﬁer is obtained by combining the pieces of two parent classiﬁers. Each rule of the oﬀspring classiﬁer can be inherited from one of the parent programs with probability 1/2. When inherited, a rule takes with it to the oﬀspring classiﬁer all the referred domains with their membership functions. Other domains can be inherited from the parents, even if they are not used in the rule set of the child classiﬁer, to increase the size of the oﬀspring so that their size is roughly the average of its parents’ sizes. Like recombination, mutation produces only legal models, by applying small changes to the various syntactic parts of a fuzzy rulebase. Migration is responsible for the diﬀusion of genetic material between populations residing on diﬀerent islands. At each generation, with a small probability (the migration rate), a copy of the best individual of an island is  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  217  
   
  sent to all connected islands and as many of the worst individuals as the number of connected islands are replaced with an equal number of immigrants. A detailed description of the evolutionary algorithm and of its genetic operators can be found in [18].  
   
  6.2 Fitness Modeling can be thought of as an optimization problem, where we wish to ﬁnd the model M ∗ which maximizes some criterion which measure its accuracy in predicting yi = xim for all records i = 1, . . . , N in the training dataset. The most natural criteria for measuring model accuracy are: • the mean absolute error, err(M ) =  
   
  N 1  |yi − M (xi1 , . . . , xi,m−1 )|; N i=1  
   
  (12)  
   
  • the mean square error, N 1  (yi − M (xi1 , . . . , xi,m−1 ))2 . mse(M ) = N i=1  
   
  (13)  
   
  One big problem with using such criteria is that the dataset must be balanced, i.e., an equal number of representative for each possible value of the predictive attribute yi must be present, otherwise the underrepresented classes will end up being modeled with lesser accuracy. In other words, the optimal model would be very good at predicting representatives of highly represented classes, and quite poor at predicting individuals from other classes. To solve this problem, MOLE divides the range [ymin , ymax ] of the predictive variable into 256 bins. The bth bin, Xb , contains all the indices i such that yi − ymin = b. (14) 1 + 255 ymax − ymin For each bin b = 1, . . . , 256, it computes the mean absolute error for that bin errb (M ) =  
   
  1  |yi − M (xi1 , . . . , xi,m−1 )|,  
   
  Xb  
   
  (15)  
   
  i∈Xb  
   
  then the total absolute error as an  integral of the histogram of the absolute errors for all the bins, tae(M ) = b:Xb  =0 errb (M ). Now, the mean absolute error for every bin in the above summation counts just the same no matter how many records in the dataset belong to that bin. In other words, the level of representation of each bin (which, roughly speaking, corresponds to a class) has been factored out by the calculation of errb (M ). What we want  
   
  218  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  from a model is that it is accurate in predicting all classes, independently of their cardinality. 1 , in such a way The ﬁtness used by the EA is given by f (M ) = tae(M)+1 that a greater ﬁtness corresponds to a more accurate model.  
   
  6.3 Selection and Overﬁtting Control In order to avoid overﬁtting, the following mechanism is applied: the dataset is split into two subsets, namely the training set and the test set. The training set is used to compute the ﬁtness considered by selection, whereas the test set is used to compute a test ﬁtness. Now, for each island, the best model so far, M ∗ , is stored aside; at every generation, the best individual with respect to ﬁtness is obtained, Mbest = argmaxi f (Mi ). The test ﬁtness of Mbest , ftest (Mbest ), is computed and, together with f (Mbest ), it is used to determine an optimistic and a pessimistic estimate of the real quality of a model: for all model M , fopt (M ) = max{f (M ), ftest (M )}, and fpess (M ) = min{f (M ), ftest(M )}. Now, Mbest replaces M ∗ if and only if fpess (Mbest ) > fpess (M ∗ ), or, in case fpess (Mbest ) = fpess (M ∗ ), if fopt (Mbest ) > fopt (M ∗ ). Elitist linear ranking selection, with an adjustable selection pressure, is responsible for improvements from one generation to the next. Overall, the algorithm is elitist, in the sense that the best individual in the population is always passed on unchanged to the next generation, without undergoing crossover or mutation.  
   
  7 A Case Study on Customer Revenue Modeling The system has been applied to the predictive modeling of the revenue generated by customers of an Italian medium-sized manufacturing corporation operating in the ﬁeld of timber and its end products.  
   
  7.1 The Company Ever since 1927, the corporation we have targeted has been working proﬁciently and professionally in the industry of timber and its by-products both on the domestic and on the international market, becoming renowned for innovation, guarantee of quality, and careful customer care. Understanding the market has been their winning strategy to be dynamic and always proactive towards their clients, by oﬀering customized solutions in every sector and often anticipating their needs. Indeed, every market sector has  
   
  Fuzzy–Evolutionary Modeling of Customer Behavior  
   
  219  
   
  distinctive features and speciﬁc trends: the corporation’s products serve multiple purposes and are suited to diﬀerent uses. Their studies and continuous research on high technology and specialist materials, together with the expertise and the energy of their sales network have aﬀorded the ideal answer to many major ﬁrms which have chosen the corporation as their strategic partner. The company is a leader in manufacturing special plywood, assembled with pioneering and technological materials—all certiﬁed and guaranteed by the ISO 9001:2000 Company Quality System—and specializes in selling timber and semi-ﬁnished products coming from all over the world. The company manufactures two broad types of products, namely technical plywood and dimensional lumber. The company mainly sells its products to construction companies, shipyards (especially those building yachts, where high-quality timbers are demanded and appreciated), and retailers. For the purposes of this case study, the products marketed by the company may be divided into four homogeneous classes, by combining two orthogonal classiﬁcation criteria: • type of product: plywood vs. dimensional lumber; • distribution channel: direct sale to construction and shipbuilding companies vs. sale to distributors. The four homogeneous product classes are thus the following: 1. production lumber—dimensional lumber sold directly to manufacturing companies; 2. production plywood—plywood sold directly to manufacturing companies; 3. commercial lumber—dimensional lumber sold to distributors for the retail market; 4. commercial plywood—plywood sold to distributors for the retail market. The rationale for this four-way classiﬁcation is that each of the four resulting classes has its own speciﬁc customer requirements and channel of distribution, which is reﬂected by the internal organization of the marketing department and of the sales network of the corporation.  
   
  7.2 Aim of the Study In the Fall of 2005, a pilot test was performed to demonstrate the feasibility of an innovative approach to customers modeling in revenue segments. In order to reduce time and costs, the traditional statistical analysis of data was skipped. Classifying customers into revenue segments can be useful not only to plan the activities and forecast the overall returns for the next period, but also to identify characteristics which describe diﬀerent patterns of customers, to recognize strategic and occasional customers, to target commercial/marketing activities and so on.  
   
  220  
   
  C. da Costa Pereira and A.G.B. Tettamanzi  
   
  7.3 The Data The described approach was used to develop a predictive model to foresee the customers’ revenue segments for a quarter using historical data of the year before the analysis. Customers were classiﬁed into three quarterly revenue segments: 1st segment: revenue >50,000 euro/quarter; 2nd segment: revenue between 10,000 and 50,000 euro/quarter; 3rd segment: revenue 50,000 EUR/Q) 0.71 0.5 2 (10,000–50,000 EUR/Q) 0.54 0.5 3 ( 1, is called a weighted exponent, which is judiciously chosen. Observe matrix U being defined by an c × n membership matrix, where the element μi j ∈ [0, 1] is defined by a membership function for the jth data point x j belonging to group i, as:  
   
  μi j = {  
   
  1 i f ||x j − ci ||2 ≤ ||x j − ck ||2 , for each k = i, 0 , otherwise  
   
  (9)  
   
  The necessary conditions for Eq. (8) to reach a minimum can be found by forming a new objective function barJ as follows: ¯ c1 , c2 , . . . , cc , J(U,  
   
  λ1 , . . . , λn ) = = J(U, c1 , c2 , . . . , cc ) + ∑nj=1 λ j (∑ci=1 μi j − 1) = ∑ci=1 ∑nj=1 μimj di2j + ∑nj=1 λ j (∑ci=1 μi j − 1),  
   
  (10)  
   
  where λ j , j = 1 to n, are the Lagrange multipliers for the n constraints in Eq. (7). By ¯ c1 , c2 , . . . , cc , λ1 , . . . , λn ) with respect to all its input arguments, differentiating J(U, the necessary conditions for Eq. (8) to reach its minimum are ci = and  
   
  μi j =  
   
  ∑nj=1 μimj xi j , ∑nj=1 μimj 1  
   
  2 di j ∑ck=1 ( dk j ) m−1  
   
  (11)  
   
  ,  
   
  (12)  
   
  In the following, the clustering algorithm is stated. Algorithm 1 (Fuzzy C Means). Given the data set Z, choose the number of cluster 1 < c < N, the weighting exponent m > 1, a constant for a cost function minimum ε > 0, and a constant T h which is a termination tolerance threshold. Initialize the partition matrix U randomly, such that μi j (0) ∈ [0, 1]  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  261  
   
  Step 1. Compute clusters prototypes: Calculate c fuzzy cluster centers ci , i = 1 . . . , c using Eq. (11). Step 2. Compute the cost function According to Eq. (8). Stop if either it below the tolerance ε or its improvement over previous iteration is below the threshold T h. Step 3. Compute a new U using Eq. 12. Go to Step 2. End of the FC-Means algorithm  
   
  3.3 The Hybrid Approach to Process Customers Evaluations We describe the usage of Fuzzy C-Means and the AHP to process customers’ judgements. The combined usage of Fuzzy C-Means and the AHP to Direct Marketing is explained next. Let ξ = {e1 , e2 . · · · , en } be the set of clients’ evaluations, each of whom must compare the relative importance of a finite set of criteria C = {c1 , c2 , · · · , c p } on which products are judged. This results in:    1 ak12 . . . ak1p       k   a21 1 . . . ak2p  k PCM =  ,  . . . .  .. .. .. ..     ak ak . . . 1  p1 p2  
   
  (13)  
   
  where k = 1, 2, · · · , n is the kth client’s evaluation; akij is the relative importance of criterion i over criterion j as determined by client’s evaluation ek . When all the n Pairwise Comparison Matrices are formed, it remains to construct matrix PCMG that reflects the pattern associated with the totality of the clients’ evaluations. The algorithm to construct the Global Pairwise Comparison Matrix is as follows. 1. 2. 3. 4. 5. 6.  
   
  The cardinality p of set C is computed. A matrix PCMG of dimensions p × p is formed. The diagonal of matrix PCMG is filled with 1. Vector αi j is formed with entries akij , k = 1, 2, · · · , n. aG i j = FuzzyCMeans(αi j ) Method countIncidences is called for determining the quantity of evaluators inside each cluster. Cluster with the highest number of incidences is selected. Cluster centroid is obtained. 7. Repeat steps 4, 5, 6 ∀(i, j) = 1, 2, · · · , p; ∀(PCM k ), k = 1, 2, · · · , n  
   
  262  
   
  Thus,  
   
  V. López Morales and O. López Ortega  
   
   G   1 aG 12 . . . a1p      G   a21 1 . . . aG  G 2p  . PCM =   . . . .  .. .. .. ..     aG aG . . . 1  p1 p2  
   
  (14)  
   
  Equation (14) is the resultant Global Pairwise Comparison Matrix that serves as basis to execute the AHP once all the customers’s evaluations are processed. Next, we illustrate how a Multi-Agent System fully automates the processing of data. Specifically, the entire set of activities, from data gathering, processing and final calculation is performed by the distributed and intelligent multi-agent system.  
   
  4 The Multi-Agent System This section depicts the Multi-Agent System structure and dynamics. The MAS is fixed by the following agents, whose structure is shown in Fig. (1) by means of a deployment diagram: • • • •  
   
  A coordinator agent, A set of evaluator agents, A clustering agent, An AHP agent.  
   
  These agents altogether posses the following dynamics: 1. The coordinator agent acquires problem variables i.e. the set of criteria associated to the survey, the set of products to be evaluated, as well as the number of clients that will perform the evaluation. It leaves a message on the Evaluation Blackboard to inform each of the evaluator agents about the newly input survey. 2. Each of the evaluator agents assists in the evaluation of criteria and products, as each client provides his/her judgement. 3. The coordinator agent corroborates that every evaluator agent has completed its task, by querying the Evaluation Blackboard. 4. The coordinator agent informs clustering agent upon verification of data completeness. Then, clustering agent processes clients’s evaluation with Fuzzy CMeans to build clusters. 5. The clustering agent informs the coordinator agent upon completion of its assignment. 6. The coordinator agent request the AHP agent to compute the final prioritization of products by running the AHP. Then, it informs when the task is achieved. The previous list of activities is formally represented in the communication diagram of Figure (2). Those two types of diagrams are part of UML 2.0 [19].  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  263  
   
  :Decision Server 1  
   
  Decision Server  
   
  1 Data Base MySQL  
   
  *  
   
  Evaluator Node  
   
  Clustering Agent  
   
  Coordinator Agent  
   
  AHP Agent  
   
  Fig. 1 Structure of the Multi-Agent System  
   
  evaluator agent 3: consult problem parameters 4: insert PCMk  
   
  1  
   
  1  
   
  Evaluation Blackboard  
   
  DataBase Server 1: insert problem parameters 2: post message 5: validate evaluations  
   
  9: insert PCMg  
   
  11: request eigenvector 13: informs vector alpha  
   
  6: request clustering 8: informs vector alpha  
   
  clustering agent  
   
  AHP agent  
   
  coordinator agent 7: accept 10: informs task completion  
   
  12: accept 14: informs task completion  
   
  13: insert eigenvector  
   
  Fig. 2 Communication diagram of the Multi-Agent System  
   
  264  
   
  V. López Morales and O. López Ortega  
   
  The implementation of the MAS is done on the JADE platform [20]. JADE is a useful tool because it allows to promote intelligent behavior to a given agent, while providing a rich set of communication capabilities based on FIPA-ACL. Both, the Fuzzy C-Means clustering technique and the AHP were developed on Java so clustering agent and AHP agent, respectively, call the coding transparently. The MAS is a distributed architecture because each agent resides in its own processing unit, and communication is done over the TCP/IP protocol, for which JADE possesses powerful libraries. As it can be seen in Fig. (1), the coordinator agent communicates directly with both, the clustering agent and the AHP agent. It is not so regarding the evaluator agents. In this latter case, communication is done by posting messages on the Evaluation Blackboard. This Evaluation Blackboard is represented in Fig. (2) as an artifact. Such blackboard is actually a database implemented on MySQL, whose structure is shown in Fig. (3).  
   
  PCM-K problemID evaluatorID a.criteriaID b.criteriaID row column value PCM-G problemID a.criteriaID b.criteriaID row column value  
   
  Ev-Prob problemID evaluatorID sent status  
   
  Evaluator evaluatorID password  
   
  MatrixAlternativesK problemID evaluatorID criteriaID a.alternativeID b.alternativeID row column value  
   
  Alternative problemID alternativeID a_description Problem problemID numCriteria numAlternatives numEvaluators objective status  
   
  MatrixAlternativesG problemID criteriaID a.alternativeID b.alternativeID row column value  
   
  Criteria problemID criteriaID c_description  
   
  VectorW-G problemID alternativeID final_value  
   
  Fig. 3 IDEF1x model of the Evaluation Blackboard  
   
  Being the MAS a distributed architecture, it results a very useful tool for modern organizations because management and point sales are geographically separate entities. However, they must share the same information in order to achieve direct marketing. At this regard, management defines the set of criteria to evaluate products, what products must be evaluated, and the size of the population that will provide judgements. This is done at one physical location. The coordinator agent assists management directly.  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  265  
   
  On the other hand, actual salesmen or women are in touch with clients, yet they must adhere to the criteria fixed by management. The evaluator agent is running inside the computer used by the sales force, and gathers the criteria that was decided by management. There is one evaluator agent assisting every salesman or woman regardless their actual location. This is helpful to interview the clients they talk to. In this way, the clients opinions are fed to the central repository in real time. When the totality of opinions are input, the coordinator agent orders the clutering agent and the AHP agent to process clients’ data so management can visualize the manner in which a given market segment judges the company’s products. Such tasks are exemplified in section 5.  
   
  5 Experimental Results In this section we present a case-study to validate the combined Fuzzy C-Means AHP -MAS approach to direct marketing. The case study refers at determining what car model out of a list is best judged by a number of potential clients belonging to a specific market segment. To show the validity of the approach, we only provide data given by ten different clients, whom were asked to judge five different cars models on five different criteria. Management and salesmen or women were asked to employ the MAS. We present, step by step, the usage of the MAS and the final results.  
   
  Fig. 4 Coordinator Agent. Entering survey parameters  
   
  Let ξ = {e1 , e2 . · · · , e10 } be the set of clients, and C = {c1 , c2 , c3 , c4 , c5 } the set of criteria where: c1 = Design, c2 = Fuel Economy, c3 = Price, c4 = Engine Power, and c5 = Reliability. Five different alternatives are evaluated, which are labeled A1 = Jetta, A2 = Passat, A3 = Bora, A4 = Golf, and A5 = Lupo. Management, comfortably sitting in their headquarters, introduce the survey parameters in a Graphical User Interface associated to the coordinator agent. Firstly, they establish the ID associated with the problem, along with the number of criteria,  
   
  266  
   
  V. López Morales and O. López Ortega  
   
  alternatives and population size (total number of evaluators). Afterwards, they introduce the objective of the problem, description of criteria, and the products to be evaluated (Fig. 4). These parameters are stored in Table Problem of the Evaluation Blackboard previously described. Accordingly, Fig. (5) displays the final definition of the survey parameters.  
   
  Fig. 5 Coordinator Agent. Summary of survey parameters.  
   
  Once the problem parameters are introduced, the coordinator agent posts a message on the Evaluation Blackboard, which will be read by each of the evaluator agents on their own network location. Thus, each evaluator agent constantly verifies whether a new problem has been introduced. When a new survey is encountered (Fig. 6), its parameters are displayed so that the evaluator proceeds to determine the absolute importance of every criterion (Fig. 7). Here we would like to elaborate on this way of evaluation. According to empirical usage of the system, human evaluators complaint about the time consuming process and the inability to keep track of their own judgements when they were requested to pair-wise compare both, criteria and alternatives. They also expressed that the numbers they were facing lacked meaning at some point. Instead, all of them agreed that it is more intuitive to make an absolute judgement on a 1-10 scale, and automate the pairwise comparisons as part of the system. The construction of the pair-wise comparison matrix for criteria is transparent to the evaluator. It also guarantees consistency of the PCM. Consequently, this process yields a PCM matrix for each evaluator, which is stored in the table PCM-K of the Evaluation Blackboard. Upon completion of the entire set of evaluations, the coordinator agent informs the clustering agent that it must initiate the calculation of the clusters (Fig. 8).  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  267  
   
  Fig. 6 Evaluator Agent. Finding a new survey at Sales Point.  
   
  Then, clustering agent acknowledges receipt and proceeds to build clusters, and then stores the Global PCM in table PCM-G of the Evaluation Blackboard. A summary of the final results for this particular case are displayed in Fig. (9), while the details can be analyzed as presented in Fig. (10).  
   
  5.1 Clients’ Evaluation The actual judgements given by the clients are depicted in the following table. First, they were asked to evaluate on a scale from 0 to 10, how important is Design (c1 ), Fuel economy (c2 ), Price (c3 ), Engine power (c4 ), and Reliability (c5 ) at the moment of selecting a car. ci c1 c2 c3 c4 c5  
   
  e1 8 9 10 10 8  
   
  e2 9 8 10 9 8  
   
  e3 9 9 8 8 9  
   
  e4 9 7 9 7 8  
   
  ek e5 e6 10 7 6 8 7 10 8 6 7 6  
   
  e7 7 9 6 10 8  
   
  e8 6 9 10 6 10  
   
  e9 10 7 6 10 8  
   
  e10 7 8 8 6 7  
   
  268  
   
  V. López Morales and O. López Ortega  
   
  Fig. 7 Evaluator Agent. Criterion evaluation.  
   
  Fig. 8 Coordinator Agent informs Clustering Agent  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  269  
   
  Fig. 9 Summary of final results  
   
  Fig. 10 Details of final results  
   
  Once every client has established how important every criteria he/she considers to be in for purchasing a car, clients are asked to evaluate to what extend they think alternative cars comply to the evaluation criteria. In the following table we present only one example of how one client ranked the five different car models on each criteria.  
   
  270  
   
  e1 c1 c2 c3 c4 c5  
   
  V. López Morales and O. López Ortega  
   
  ai Jetta Passat Bora 8 10 10 9 4 5 7 4 6 8 10 9 9 10 10  
   
  Golf Lupo 8 6 8 10 7 10 8 5 8 8  
   
  According to the previous table, client number one considers that Jetta evaluates with an 8 for its design, a 9 for its fuel economy, 7 for the price, 8 for the engine power, and a 9 for the reliability. There is one instance of the previous table for every one of the clients that participate in the survey. The totality of the evaluations are stored in the the Evaluation Blackboard (Fig. 3). Once the target population evaluated (subjectively) the range of products, then the coordinator agent, running on the management node, validates that all the evaluations are complete. Shortly after, it requests that clustering agent and AHP agent achieve their own tasks by processing the raw data. Knowledge obtained by management is a final ranking, which determines what product appeals the most to the target market segment. In this case, A4 = Golf best balances the five features evaluated, as evidenced by ranking R = {A1 : 0.1674, A2 : 0.1428, A3 : 0.1582, A4 : 0.1684, A5 : 0.1681}.  
   
  6 Concluding Remarks We have presented an intelligent and distributed Multi-Agent System that incorporates the Analytical Hierarchy Process and the Fuzzy C-Means algorithm to enhance direct marketing. Particularly, the system is aimed at facilitating surveys and processing the large amounts of raw data that is generated. The results provided with the case-study are very promising, because it has been shown that management can establish direct contact with a large group of customers. Every individual, in turn, is left free to evaluate the company products according to his or her personal criteria. This is very valuable per se. Yet, the system also proved capable of processing the totality of the evaluations. With this, the perceptions of a market segment are deeply scrutinized by forming clusters. In this sense, the market segment is treated as a single unit because the perceptions of the majority are discovered. It is intended to improve the MAS we have presented here by including different soft-computing techniques, such as neural networks and Case-Based reasoning. These techniques will provide more facilities so that management can compare and analyze the market behavior. Acknowledgments. The authors would like to thank the anonymous reviewers because of their useful comments that improved this paper.  
   
  Direct Marketing Based on a Distributed Intelligent System  
   
  271  
   
  The work of Virgilio López Morales is partially supported by the PAI2006 - UAEH - 55A, SEP - SESIC - PROMEP - UAEH - PTC - 1004 and ANUIES - SEP - CONACyT/ECOS NORD, M02:M03, research grants.  
   
  References 1. Hanson, C.: What are the best methods for increasing diversity at a digital marketing company? DMNews 1(1) (January 26, 2009) 2. Tsai, J.: Marketing trends for 2009. Costumer Relationship Management Magazine 1(1) (January 2009) 3. Pijls, W., Potharst, R.: Number 2000-40-LIS in ERS. In: Classification and target group selection based upon frequent patterns. ERIM Report Series Research in Management, The Netherlands, 1–16 (2000) 4. Bult, J., Wansbeek, T.: Optimal selection for direct mail. Journal Marketing Science 14, 378–394 (1995) 5. Haughton, D., Oulabi, S.: Direct marketing modeling with Cart and CHAID. Journal of Direct Marketing 7, 16–26 (1993) 6. Zahavi, J., Levin, N.: Issues and problems in applying neuronal computing to target marketing. Journal of Direct Marketing 9(3), 33–45 (1995) 7. Zahavi, J., Levin, N.: Aplying neuronal computing to target marketing. Journal of Direct Marketing 11(1), 5–22 (1997) 8. Kaymak, U.: Fuzzy Target Selection Using RFM Variables. In: Proc. Of Joint 9th IFSA World Congress and 20th NAFIS Int. Conference, Vancouver, Canada, pp. 1038–1043 (2001) 9. Setnes, M., Kaymak, U.: Fuzzy Modeling of Client Preference from Large Data Sets: An Application to Target Selection in Direct Marketing. IEEE Transactions on Fuzzy Systems 9(1) (2001) 10. Sousa-João, M., Kaymak, U., Madeira, S.: A Comparative Study of Fuzzy Target Selection Methods in Direct Marketing. In: Proceedings, IEEE World Congress on Computational Intelligence, pp. 1251–1256 (2002) 11. Site, C.: Cyber Atlas On line,    12. Rayport, J., Sviokla, J.: Managing in the Marketspace. Harvard Business Review 1(1) (1994) 13. Bessen, J.: Riding the Marketing Information Wave. Harvard Business Review 1(1) (1993) 14. Bakos, Y.: Reducing Buyer Search Costs: Implications for Electronic Marketplaces. Management Science 43(12) (1997) 15. Balas, S.: Direct Marketer vs. Retailer: A Strategic Analysis of Competition and Market StructureMail vs. Mall. Marketing Science 17(3) (1998) 16. Saaty, T.L.: A scaling method for priorities in hierarchical structures. Journal of Mathematical Psychology 15(3), 234–281 (1977) 17. Roger Jang, C.T.S., Mizutani, E.: Neuro-fuzzy and Soft Computing. Prentice Hall, New York (1997) 18. Bezdek, J.C.: Pattern Recognition with Fuzzy Objective Function Algoritms. Plenum Press, New York (1981) 19. Bauer, B., Odell, J.: UML 2.0 and agents: how to build agent-based systems with the new UML standard. Engineering Applications of Artificial Intelligence 18, 141–157 (2005) 20. Fabio Bellifemine, G.C., Greenwood, D.: Developing Multi-Agent Systems with JADE. Addison Wesley, London (2007)  
   
  Direct Marketing Modeling Using Evolutionary Bayesian Network Learning Algorithm Man Leung Wong Department of Computing and Decision Sciences, Lingnan University, Tuen Mun, Hong Kong e-mail: [email protected]   
   
  Abstract. Direct marketing modeling identiﬁes eﬀective models for improving managerial decision making in marketing. This paper proposes a novel system for discovering models represented as Bayesian networks from incomplete databases in the presence of missing values. It combines an evolutionary algorithm with the traditional Expectation-Maximization(EM) algorithm to ﬁnd better network structures in each iteration round. A data completing method is also presented for the convenience of learning and evaluating the candidate networks. The new system can overcome the problem of getting stuck in sub-optimal solutions which occurs in most existing learning algorithms and the eﬃciency problem in some existing evolutionary algorithms. We apply it to a real-world direct marketing modeling problem, and compare the performance of the discovered Bayesian networks with other models obtained by other methods. In the comparison, the Bayesian networks learned by our system outperform other models. Keywords: Direct Marketing Modeling, Data Mining, Bayesian Networks, Evolutionary Algorithms.  
   
  1 Introduction The objective of the direct marketing modeling problem is to predict and rank potential buyers from the buying records of previous customers. The customer list will be ranked according to each customer’s likelihood of purchase. The decision makers can then select the portion of customer list to roll out. An advertising campaign including mailing of catalogs or brochure is targeted on the most promising prospects. Hence, if the prediction is accurate, it can help to enhance the response rate of the advertising campaign and increase the return of investment. In real-life applications, the databases containing the buying records of customers may contain missing values. Irrelevant records or trivial items with J. Casillas & F.J. Mart´ınez-L´ opez (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 273–294. c Springer-Verlag Berlin Heidelberg 2010 springerlink.com   
   
  274  
   
  M. Leung Wong  
   
  missing values can be simply discarded from the raw databases in the data preprocessing procedure. However, in most cases, the variables are related to each other and the deletion of incomplete records may lose important information. This will aﬀect performance dramatically especially if we want to discover some knowledge ”nuggets” from the databases and they happen to be contained in the incomplete records. Usually, people may alternatively replace the missing values with certain values, such as the mean or mode of the observed values of the same variable. Nevertheless, it may change the distribution of the original database. Bayesian networks are popular within the community of artiﬁcial intelligence and data mining due to their ability to support probabilistic reasoning from data with uncertainty. They can represent the co-related relationships among random variables and the conditional probabilities of each variable from a given data set. With a network structure at hand, people can conduct probabilistic inference to predict the outcome of some variables based on the values of other observed ones. Hence, Bayesian networks are widely used in many areas, such as diagnostic and classiﬁcation systems [1, 2, 3], information retrieval [4], troubleshooting, and so on. They are also suitable for reasoning with incomplete information. Many methods have been suggested to learn Bayesian network structures from complete databases without missing values, which can be classiﬁed into two main categories [5]: the dependency analysis method [6] and the scoreand-search approach [7, 8, 9]. For the former approach, the results of dependency tests are employed to construct a Bayesian network conforming to the ﬁndings. For the latter one, a scoring metric is adopted to evaluate candidate network structures while a search strategy is used to ﬁnd a network structure with the best score. Decomposable scoring metrics, such as MDL and BIC, are usually used to deal with the problem of time consuming score evaluation. When the network structure changes, we only need to re-evaluate the score of the corresponding nodes related to the changed edges, rather than the scores of the whole nodes. And stochastic search methods which employ evolutionary algorithms have been used in the latter approach for complete data, such as Genetic Algorithms [10, 11], Evolutionary Programming [12], and hybrid evolutionary algorithms [13]. Nevertheless, learning Bayesian networks from incomplete data is a diﬃcult problem in real-world applications. The parameter values and the scores of networks cannot be computed directly on the records having missing values. Moreover, the scoring metric cannot be decomposed directly. Thus, a local change in the network structure will lead to the re-evaluation of the score of the whole network, which is time-consuming considering the number of all possible networks and the complexity of the network structures. Furthermore, the patterns of the missing values also aﬀect the dealing methods. Missing values can appear in diﬀerent situations: Missing Completely At Random, or Not Ignorable [14]. In the ﬁrst situation, whether an observation is missing or not is independent of the actual states of the variables. So the incomplete  
   
  Direct Marketing Modeling  
   
  275  
   
  databases may be representative samples of the complete databases. However, in the second situation, the observations are missing to some speciﬁc states for some variables. Diﬀerent approaches should be adopted for diﬀerent situations, which again complicates the problem. Many researchers have been working on parameter learning and structure learning from incomplete data. For the former, several algorithms can be used to estimate or optimize the parameter values of the known Bayesian network structures, such as Gibbs sampling, EM [8], and Bound-and-Collapse (BC) method [15, 16]. For structure learning from incomplete data, the main issues are how to deﬁne a suitable scoring metric and how to search for Bayesian network structures eﬃciently and eﬀectively. Concerning the score evaluation for structure learning, some researchers proposed to calculate the expected values of the statistics to approximate the score of candidate networks. Friedman proposed a Bayesian Structural Expectation-Maximization (SEM) algorithm which alternates between the parameter optimization process and the model search process [17, 18]. The score of a Bayesian network is maximized by means of the maximization of the expected score. Pe˜ na et al. used the BC+EM method instead of the EM method in their BS-BC+EM algorithm for clustering [19, 20]. However, the search strategies adopted in most existing SEM algorithms may not be eﬀective and may make the algorithms ﬁnd sub-optimal solutions. Myers et al. employed a genetic algorithm to learn Bayesian networks from incomplete databases [21]. Both network structures and the missing values are encoded and evolved. The incomplete databases are completed by speciﬁc genetic operators during evolution. Nevertheless, it has the eﬃciency and convergence problems because of the enlarged search space and the strong randomness of the genetic operators for completing the missing values. In this study, we propose a new learning system that uses EM to handle incomplete databases with missing values and uses a hybrid evolutionary algorithm to search for good candidate Bayesian networks. The two procedures are iterated so that we can continue ﬁnding a better model while optimizing the parameters for a good model to complete the database with more accurate information. In order to reduce the time for statistics computation, the database is preprocessed into two parts : records with and without missing values. Instead of using the expected values of statistics as in most existing SEM algorithms, our system applies a data completing procedure to complete the database and thus decomposable scoring metrics can be used to evaluate the networks. The MDL scoring metric is employed in the search process to evaluate the ﬁtness of the candidate networks. We apply our system to a direct marketing modeling problem, which requires to rank the previous customers according to their probability of potential purchasing. The results show that the performance of the evolved Bayesian networks obtained by our system is better than the models learned by several other learning algorithms.  
   
  276  
   
  M. Leung Wong  
   
  The rest of this paper is organized as follows. In Section 2, we will present the backgrounds of direct marketing modeling, Bayesian networks, the missing value problem, and some Bayesian network learning algorithms. In Section 3, our new learning system for incomplete databases, EBN, will be described in details. In Section 4, we use our system to discover Bayesian networks from a real-life direct marketing database. We will conclude the paper in the last section.  
   
  2 Background 2.1 Direct Marketing Modeling Direct marketing concerns communication with prospects, so as to elicit response from them. In contrast to the mass marketing approach, direct marketing is targeted at a group of individuals that are potential buyers and are likely to respond. In retrospect, direct marketing emerged because of the prevalence of mail ordering in the nineteenth century [22]. As technology advances, marketing is no longer restricted to mailing but includes a variety of media. Nevertheless, the most important issue in the business remains to be the maximization of the proﬁtability, or ROI, of a marketing campaign. In a typical scenario, we often have a huge list of customers. The list could be records of existing customers or data bought from list brokers. But among the huge list, there are usually few real buyers which amount to only a few percents [23]. Since the budget of a campaign is limited, it is important to focus the eﬀort on the most promising prospects so that the response rate could be improved. Before computers became widely used, direct marketers often used simple heuristics to enhance the response rate. One straightforward approach is to use common sense to make the decision. In particular, we could match prospects by examining the demographics of the customers in the list. For example, in the life insurance industry, it is natural to target the advertising at those who are rich and aging. Another common approach to enhance the response rate is to conduct list testing by evaluating the response of samplings from the list. If a certain group of customers gives a high response rate, the actual campaign may be targeted at the customers similar to this group. A more systematic approach, which was developed in 1920s but is still being used today, is to diﬀerentiate potential buyers from non-buyers using the recency-frequency-monetary model (RFM) [22]. In essence, the proﬁtability of a customer is estimated by three factors including the recency of buying, the frequency of buying, and the amount of money spent. Hence, only individuals that are proﬁtable will be the targets of the campaign. With the advancement of computing and database technology, people seek for computational approaches to assist in decision making. From the data set that contains demographic details of customers, the objective is to develop a  
   
  Direct Marketing Modeling  
   
  277  
   
  response model and use the model to predict promising prospects. In certain sense, response models are similar to classiﬁers in the classiﬁcation problem. However, unlike the classiﬁer which makes a dichotomous decision (i.e. active or inactive respondents), the response model needs to score each customer in the data set with the likelihood of purchase. The customers are then ranked according to the score. A ranked list is desirable because it allows decision makers to select the portion of customer list to roll out [24]. For instance, out of the 200,000 customers on the list, we might wish to send out catalogs or brochures to the most promising 30% of customers so that the advertising campaign is cost-eﬀective (the 30% of the best customers to be mailed is referred to as the depth-of-ﬁle) [25]. Hence, one way to evaluate the response model is to look at its performance at diﬀerent depth-of-ﬁle. In the literature, there are various approaches proposed for building the response model. Here, we give a brief review in the following paragraphs. Earlier attempts often adopted a statistical analysis approach. Back in 1967, a company already used multiple regression analysis to build the response model. In 1968, the Automatic Interaction Detection (AID) system was developed which essentially uses tree analysis to divide consumers into diﬀerent segments [22]. Later, the system was modiﬁed and became the ChiSquared Automatic Interaction Detector (CHAID). One statistical analysis technique, which is still widely used today, is logistic regression. Essentially, the logistic regression model assumes that the logit (i.e. the logarithm of the odd ratios) of the dependent variable (active or inactive respondents) is a linear function of the independent variables (i.e. the attributes). Because the approach is popular, newly proposed models are often compared with the logistic regression model as the baseline comparison [25, 26, 27]. Zahavi and Levin [27] examined the possibility of learning a backpropagation neural network as the response model. However, due to a number of practical issues and that the empirical result did not improve over a logistic regression model, it seems that the neural network approach does not bring much beneﬁt. Because there are striking similarities between classiﬁcation and the direct marketing problem, it is straightforward to apply classiﬁcation algorithms to tackle the problem. As an example, Ling and Li [28] used a combination of two well-known classiﬁers, the na¨ıve Bayesian classiﬁer and C4.5, to construct the response model. Because scoring is necessary, they modiﬁed the C4.5 classiﬁer so that a prediction (i.e. active and inactive respondents) comes with a certainty factor. To combine the two classiﬁers, they applied ada-boosting [29] to both classiﬁers in learning. When they evaluated their response model across three diﬀerent real-life data sets, the result showed that their approach are eﬀective for solving the problem. Bhattacharyya formulated the direct marketing problem as a multiobjective optimization problem [25, 26]. He noted that the use of a single evaluation criterion, which is to measure the model’s accuracy, is often inadequate [26]. For practical concern, he suggested that the evaluation criterion  
   
  278  
   
  M. Leung Wong  
   
  needs to include the performance of the model at a given depth-of-ﬁle. In an early attempt, he proposed to use GAs to learn the weights of a linear response model while the evaluation function is a weighted average of the two evaluation criteria. When comparing the learnt model with the logit model on a real-life data set, the new approach indicates a superior performance [25]. Recently, he attempted to use genetic programming to learn a tree-structured symbolic rule form as the response model [26]. Instead of using a weighted average criterion function, his new approach searches for Pareto-optimal solutions. From the analysis, he found that the GP approach outperforms the GA approach and is eﬀective at obtaining solutions with diﬀerent levels of trade-oﬀs [26].  
   
  2.2 Bayesian Networks A Bayesian network, G, has a directed acyclic graph (DAG) structure. Each node in the graph corresponds to a discrete random variable in the domain. An edge, Y → X, on the graph, describes a parent and child relation in which Y is the parent and X is the child. All parents of X constitute the parent set of X which is denoted by ΠX . In addition to the graph, each node has a conditional probability table (CPT) specifying the probability of each possible state of the node given each possible combination of states of its parents. If a node contains no parent, the table gives the marginal probabilities of the node. Let U be the set of variables in the domain, U = {X1 ,. . . ,Xn }. Following Pearl’s notation [30], a conditional independence (CI) relation is denoted by I(X, Z, Y ) where X, Y , and Z are disjoint subsets of variables in U . Such notation says that X and Y are conditionally independent given the conditioning set, Z. Formally, a CI relation is deﬁned with: P (x | y, z) = P (x | z) whenever P (y, z) > 0  
   
  (1)  
   
  where x, y, and z are any value assignments to the set of variables X, Y , and Z respectively. A CI relation is characterized by its order, which is the number of variables in the conditioning set Z. By deﬁnition, the joint probability distribution of U can be expressed as:  P (X1 , . . . , Xn ) = P (Xi |ΠXi ) (2) i  
   
  For simplicity, we use Xi = k to specify that the i-th node takes the k-th possible state in its value domain, ΠXi = j to represent ΠXi being instantiated to the j-th combinational state, and Nijk to represent the counts of Xi = k and ΠXi = j appearing simultaneously in the data. The conditional probability p(Xi = k|ΠXi = j), also denoted as parameter θijk , can be calculated from complete data by:  
   
  Direct Marketing Modeling  
   
  279  
   
  Nijk θijk =  k Nijk  
   
  (3)  
   
  As mentioned before, there are two main categories of Bayesian network learning algorithms. The dependency analysis approach constructs a network by testing the validity of any independence assertion I(X, Z, Y ). If the assertion is supported by the data, edges cannot exist between X and Y on the graph [5, 6]. The validity of I(X, Z, Y ) is tested by performing a CI-test, in which statistical hypothesis testing procedure could be used. Suppose that the likelihood-ratio χ2 test is used and the χ2 statistics is calculated by: G2 = −2  
   
    
   
  P (x, y, z) ∗ log  
   
  x,y,z  
   
  P (x, y, z) P (y, z)P (x|z)  
   
  (4)  
   
  Checking the computed G2 against the χ2 distribution, we can obtain the pvalue [13]. If the p-value is less than a predeﬁned cutoﬀ value α, the assertion I(X, Z, Y ) is not valid; otherwise, it is valid and edges cannot exist between X and Y . The score-and-search approach uses a scoring metric to evaluate candidate networks [7]. Take the decomposable MDL scoring metric for example [9], the MDL score of network G with every node Ni in the domain U can be described as:  M DL(Ni , ΠNi ) (5) M DL(G) = Ni ∈U  
   
  The MDL score of a network is smaller than that of another network if the former network is better. With the scoring metric, the learning problem becomes a search problem. It should be noted that since the metric is nodedecomposable, it is only necessary to re-calculate the MDL scores of the modiﬁed nodes when the network structure is changed. However, the metric cannot be used directly if the databases have missing values.  
   
  2.3 The Missing Value Problem In real-world applications, the databases may contain incomplete records which have missing values. People may simply discard incomplete records, but relevant information may be deleted. Alternatively, they can complete the missing values with the information of the databases such as the mean values of other observed values of the variables. However, the distribution of the data may be changed. Advanced approaches including maximum likelihood estimation [14], Bayesian multiple imputation [31], machine learning [32], Bayesian networks [33, 34], k-nearest neighbour, regression [35, 36], and singular value decomposition [37] have been applied to complete the missing values in databases and microarray gene expression data sets. One advantage of Bayesian networks is that they support probabilistic reasoning from data with uncertainty. However, for learning Bayesian networks  
   
  280  
   
  M. Leung Wong  
   
  from incomplete databases, the parameter values and the scores of networks cannot be computed directly on the records having missing values. Moreover, the scoring metric cannot be decomposed directly. Thus, a local change in the network structure will lead to the re-evaluation of the score of the whole network. For parameter learning, existing methods either use diﬀerent inference algorithms to get the expected values of statistics or complete the missing values. Two commonly adopted methods are Gibbs sampling and EM [8]. Gibbs sampling tries to complete the database by inferring from the available information and then learns from the completed database [38]. On the other hand, EM calculates the expected values of the statistics via inference and then updates the parameter values using the previously calculated expected values [39, 40]. It will converge to a local maximum of the parameter values under certain conditions. Furthermore, EM usually converges faster than Gibbs sampling. Both Gibbs sampling and EM assume that the missing values appear randomly or follow a certain distribution. In order to encode prior knowledge of the pattern of missing data, Ramoni and Sebastinani proposed a new deterministic Bound-and-Collapse (BC) method that does not need to guess the pattern of missing data [15, 16, 41]. It ﬁrstly bounds the possible estimates consistent with the probability interval by computing the maximum and minimum estimates that would have been inferred from all possible completions of the database. Then the interval is collapsed to a unique value via a convex combination of the extreme estimates using information on the assumed pattern of missing data. For structure learning from incomplete databases, the score-and-search approach can still be employed. The main issues are how to deﬁne a suitable scoring metric and how to search for Bayesian networks eﬃciently and effectively. Many variants of Structural Expectation Maximization (SEM) were proposed for this kind of learning in the past few years [17, 18].  
   
  2.4 Basic SEM Algorithm The basic SEM algorithm cam learn Bayesian networks in the presence of missing values and hidden variables [17]. It alternates between two steps: an optimization for the Bayesian network parameters conducted by the EM algorithm, and a search for a better Bayesian network structure using a hill climbing strategy. The two steps iterate until the whole algorithm is stopped. The score of a Bayesian network is approximated by the expected value of statistics. Friedman extended his SEM to directly optimize the true Bayesian score of a network in [18]. The framework of the basic SEM algorithm can be described as follows: 1. let M1 be the initial Bayesian network structure. 2. for t=1,2,...  
   
  Direct Marketing Modeling  
   
  281  
   
  • Execute EM to approximate the maximum-likelihood parameters Θt for Mt . • Perform a greedy hill-climbing search over Bayesian network structures, evaluating each structure using approximated score Score(M ). • let Mt+1 be the Bayesian network structure with the best score. • If Score(Mt ) =Score(Mt+1 ) then return Mt and Θt .  
   
  2.5 HEA HEA is proposed by Wong and Leung for learning Bayesian networks from complete databases [13]. It employs the results of lower order CI-tests to reﬁne the search space and adopts a hybrid evolutionary algorithm to search for good network structures. Each individual in the population represents a candidate network which is encoded by a connection matrix. Besides, each individual has a cutoﬀ value α which is also subject to be evolved. At the beginning, for every pair of nodes (X,Y), the highest p-value returned by the lower order CI-tests is stored in a matrix Pv . If the p-value is greater than or equal to α, the conditional independence assertion I(X,Z,Y) is assumed to be valid, which implies that the nodes X and Y cannot have a direct edge between them. By changing the α values dynamically, the search space of each individual can be modiﬁed and each individual conducts its search in a diﬀerent search space. Four mutation operators are used in HEA. They add, delete, move, or reverse edges in the network structures either through a stochastic method or based on some knowledge. A novel merge operator is suggested to reuse previous search results. The MDL scoring metric is used for evaluating candidate networks. The cycle prevention method is adopted to prevent cycle formation in the network structures. The experimental results demonstrate that HEA has better performance on some benchmark data sets and real-world data sets than other state-ofthe-art algorithms [13].  
   
  3 Learning Bayesian Networks from Incomplete Databases 3.1 The EBN Algorithm Although HEA outperforms some existing approaches, it cannot deal with incomplete databases. Thus, we propose a novel evolutionary algorithm, called EBN (Evolutionary Bayesian Network learning method), that utilizes the efﬁcient and eﬀective global search ability of HEA and applies EM to handle missing values. Some strategies are also introduced to speed up EBN and to improve its performance. EBN is described in Fig. 1.  
   
  282  
   
  M. Leung Wong  
   
  In EBN, there are two special kinds of generations. SEM generation refers to one generation in the SEM framework (step 9 of Fig. 1) while HEA generation refers to the iteration in HEA search process (step 9(g) of Fig. 1). Firstly, the database is separated and stored into two parts in the data preprocess phase. The set of records having missing values is marked as H and the set of records without missing values is marked as O. Order-0 and order-1 CI tests are then conducted on O and the results are stored in the matrix Pv for reﬁning the search space of each individual in the following procedures. At the beginning of the SEM phase, for each individual, we check a randomly generated α value with the stored values in the matrix Pv to reﬁne its search space. It should be noted that the search space will not be reﬁned if O is not available. A DAG structure is then randomly constructed from the reﬁned search space for this individual. Thus, the initial population is generated (step 7 of Fig. 1). Through some speciﬁc strategies, an initial network structure is generated for the current best network which is denoted as Gbest . EBN will then be executed for a number of SEM generations until the stopping criteria are satisﬁed, that is, the maximum number of SEM generations is reached or the log-likelihood of Gbest does not change for a speciﬁed number of SEM generations (step 9 of Fig. 1). The log-likelihood of Gbest in the t-th SEM generation can be computed by:  [E(Nijk )log(θijk )] (6) ll(Gbest (t)) = i,j,k  
   
  Within each SEM generation, EM will be conducted ﬁrst to ﬁnd the best values for the parameters of Gbest (step 9(a) of Fig. 1). The missing values in H will be ﬁlled according to Gbest and its parameters (step 9(c) of Fig. 1). Combining the newly completed result of H with O, we get a new complete data set O . Then, the HEA search process will be executed on O for a certain number of HEA generations to ﬁnd a better network to replace Gbest . The MDL scoring metric is again employed in the search process to evaluate the ﬁtness of the candidate networks. The whole process will iterate until it stops. Some techniques are depicted in following subsections.  
   
  3.2 The EM Procedure in EBN EM is employed here for parameter estimation of the input Bayesian network. The procedure is described in Fig. 2. In order to facilitate the converge of the EM procedure, we choose Gbest as the input network. In step 1 of Fig. 2, the initial parameter values of Gbest are computed on data O∗. For the ﬁrst execution of EM in the ﬁrst SEM generation, O is used as O∗ (step 9(a) of Fig. 1). In the other SEM generations, O∗ is the completed data O from the previous SEM generation (step 9(a) of Fig. 1).  
   
  Direct Marketing Modeling  
   
  283  
   
  Data Preprocess 1. Store incomplete records together, mark the whole set as H. 2. Store other records together, mark the whole set as O. CI test Phase 3. If O is available a. Perform order-0 and order-1 CI tests on O. b. Store the highest p-value in the matrix Pv . else store negative values in the matrix Pv . SEM phase 4. Set t, the generation count, to 0. 5. Set tSEM , the SEM generation count, to 0. 6. Set tuc , the count of generations with unchanged log-likelihood, to 0. 7. For each individual Gi in the population P op(t) • Initialize the α value randomly, where 0 ≤ α ≤ 1. • Reﬁne the search space by checking the α value against the stored Pv value. • Inside the reduced search space, create a DAG randomly. 8. Generate the initial network structure for Gbest . 9. While tSEM is less than the maximum number of SEM generations or tuc is less than M AXuc , a. If tSEM = 0, execute EM(Gbest , O, H); else execute EM(Gbest , O , H). b. If the log-likelihood of Gbest does not change, increment tuc by 1; else set tuc to 0. c. Complete missing data in H using Gbest and its parameters, and get updated complete data O . d. Execute order-0 and order-1 CI-tests on O , and store the highest p-value in Pv . e. For each individual Gi in the population P op(t) • Reﬁne the search space by checking the α value against the Pv value. • Evaluate Gi using the MDL metric on O . f. Set tHEA, the HEA generation count in each SEM generation, to 0. g. While tHEA is less than the maximum number of HEA generations in each SEM generation , • execute HEA search phase. • increment tHEA and t by 1, respectively. h. Pick up the individual that has the lowest MDL score on O to replace Gbest . i. increment tSEM and t by 1, respectively. 10. Return the individual that has the lowest MDL score in any HEA generation of the last SEM generation as the output of the algorithm.  
   
  Fig. 1 EBN Algorithm  
   
  284  
   
  M. Leung Wong  
   
  EM contains two steps: the E-step and the M-step. In the E-step, the expected values of statistics of unobserved data (often called suﬃcient statistics) are estimated using probabilistic inference based on the input Gbest and its parameter assignments. For each node Xi and record l∗ , we can calculate the expected value of Nijk using the following equation:  E(Nijk ) = E(Nijk |l∗ ) (7) l∗  
   
  where  
   
  E(Nijk |l∗ ) = p(Xi = k, ΠXi = j|l∗ )  
   
  (8)  
   
  ∗  
   
  Let l represents the set of all other observed nodes in l . When both Xi and ΠXi are observed in l∗ , the expected value can be counted directly which is either 0 or 1. Otherwise, p(Xi = k, ΠXi = j|l∗ ) = p(Xi = k, ΠXi = j|l), and it can be calculated using any Bayesian inference algorithm [42]. In our experiments, the junction tree inference algorithm is adopted [43]. Since the database is preprocessed, we just need to run the E-step on H. Then, in the M-step, the parameters θijk are updated by E (Nijk ) θijk =   
   
  k E (Nijk )  
   
  (9)  
   
  where E (Nijk ) is the sum of the suﬃcient statistics calculated on H in the E-step and the statistics calculated on O which are evaluated and stored at the beginning. The two steps will iterate until the EM procedure stops. EM will terminate when either the value of the log-likelihood does not change in two successive iterations, or the maximum number of iterations is reached.  
   
  Procedure EM(Gbest , O∗, H) 1. If data O∗ is not empty, calculate the parameter values of Gbest on O∗; else the parameter values of Gbest are generated randomly. 2. Set t, the EM iteration count, to 0. 3. While not converged, • For every node Ni , – calculate the expected statistics on H; – update θijk using E  (Nijk ). • Calculate the log-likelihood of Gbest . • Increment t by 1. 4. Output Gbest and its parameters.  
   
  Fig. 2 Pseudo-code for the EM procedure  
   
  Direct Marketing Modeling  
   
  285  
   
  3.3 The Initial Network Structure for Gbest After executing the HEA search procedure, Gbest is updated by the best candidate network having the lowest MDL score in the population (step 9(h) of Fig. 1) and then the newly found Gbest is used in the EM procedure for the next SEM generation (step 9(a) of Fig. 1). However, we have to generate an initial network structure Gbest for the ﬁrst execution of the EM procedure for the ﬁrst SEM generation. The quality of this network structure is crucial, because EBN is conducted on the database whose missing values are ﬁlled by performing inference using Gbest and its parameters. In other words, the inference procedure may take a long time if Gbest is not good enough. In EBN, the initial network structure is obtained from a modiﬁed database. Considering the missing values in the original database as an additional state for each variable, we can get a new complete database. Then a network structure can be learned from the new complete database by HEA. The initial network structure Gbest induced by HEA will not be put into the initial population after the execution of the EM procedure for the ﬁrst SEM generation, so that the diversity of the population will not be destroyed at an early stage. The advantage of this method is that we can still ﬁnd a good network structure even when data O is not available.  
   
  3.4 Data Completing Procedure One of the main problems in learning Bayesian networks from incomplete databases is that the node-decomposable scoring metric cannot be used directly. In order to utilize HEA in EBN, we complete the missing data after each execution of the EM procedure so that the candidate networks can be evaluated eﬃciently on a complete database. When more than one node are unobserved in a record, we ﬁll the missing data according to the topological order of the current best network Gbest . For example, if node Xi and Xj are both unobserved in record l∗ and Xi → Xj exists in Gbest , we ﬁrst ﬁll the value of Xi and put it back into the junction tree, and then ﬁnd a value for Xj . A Bayesian inference algorithm is again employed to obtain the probabilities of all possible states of an unobserved node under the current observed data. We can simply pick up the state having the highest probability. Alternatively, we can select a state via a roulette wheel selection method. Suppose the value of node Xi is unobserved in current record l∗ , and Xi has k possible states in its value domain. We use {p1 , p2 ,...,pk } to represent the set of the probability of each of its state appearing under current observed data in l∗ respectively. In this approach, a random decimal r between 0 and 1 is generated, and then the m-th state will be chosen if m = 1, r ≤ p1 .  
   
  (10)  
   
  286  
   
  M. Leung Wong  
   
  or 1 < m ≤ k,  
   
  m−1   
   
  pi < r ≤  
   
  i=1  
   
  m   
   
  pi .  
   
  (11)  
   
  i=1  
   
  In EBN, we adopt the second completing approach so that the states with lower probabilities may also be selected.  
   
  3.5 HEA Search Procedure With a complete data O , HEA can be utilized to learn good Bayesian networks. The lower order CI-test will be conducted again on O and the highest p-values are stored in the matrix Pv , just as mentioned in subsection 2.5. Hence, each individual will reﬁne its search space according to the new results on the new data O . All the candidate networks are evaluated on O using the MDL scoring metric. In each HEA generation, the mutation operators and the merge operator will be applied on each individual to generate a new oﬀspring. The cycle prevention method is adopted to prevent cycle formation in the network structures. Individuals are then selected through a number of pairwise competitions over all the DAGs in the old population and the oﬀspring to form a new population for the next HEA generation. This process continues until the maximum number of HEA generations is reached. Finally, the best network with the lowest MDL score on O will be returned by the HEA search procedure.  
   
  4 Application in Direct Marketing Modeling In this section, we apply EBN in a real-world direct marketing modeling problem. We compare the performance of the Bayesian networks evolved by EBN (EBN models) with those obtained by LibB1 and Bayesware Discoverer2 from incomplete real-world data sets, as well as the performance of Bayesian neural network (BNN) [44], logistic regression (LR), na¨ıve Bayesian classiﬁer (NB) [45], and tree-augmented na¨ıve Bayesian network classiﬁer (TAN) [45]. We also present the performance of the Bayesian networks evolved by HEA using two missing values handling methods. They transform an incomplete data set into a completed one and employ HEA as search method for learning Bayesian networks from the new data set. In the ﬁrst method, denoted as HEA1, we simply replace missing values for each variable with the mode of the observed data of the variable (the state that has the largest number of observations). In the second method, denoted as HEA2, we consider the missing values as a new additional state for each variable, thus a new completed data set is generated. 1 2  
   
  LibB is available at http://compbio.cs.huji.ac.il/LibB/. A trial version of Bayesware Discoverer is available at http://www.bayesware.com/.  
   
  Direct Marketing Modeling  
   
  287  
   
  4.1 Methodology The response models are evaluated on a real-life direct marketing data set. It contains records of customers of a specialty catalog company, which mails catalogs to good customers on a regular basis. In this data set, there are 5,740 active respondents and 14,260 non-respondents. The response rate is 28.7%. Each customer is described by 361 attributes. We applied the forward selection criteria of logistic regression [46] to select nine relevant attributes out of the 361 attributes. Missing values are then introduced randomly into the data set. The percentages of the missing values in our experiments are 1%, 5%, and 10%, respectively. In our experiments, EBN, LibB and Bayesware Discoverer are executed directly on the data sets with missing values. For BNN, LR, NB, TAN and HEA1, we replace the missing values with the mean value or the mode for each variable. For HEA2, the missing values are treated as an additional new state for each variable. For EBN, the maximum number of iterations in EM is 10, the maximum number of HEA generations in each SEM generation is 100, the maximum number of SEM generations is 50, the population size is 50, tournament size is 7, and M AXuc is set to 10. For both HEA1 and HEA2, the maximum number of generations is set to 5000, the population size is 50, and the tournament size is 7. To compare the performance of diﬀerent response models, we use decile analysis which estimates the enhancement of the response rate for ranking at diﬀerent depth-of-ﬁle. Essentially, the descending sorted ranking list is equally divided into 10 deciles. Customers in the ﬁrst decile are the top ranked customers that are most likely to give response. Correspondingly, customers in the last decile are least likely to buy the speciﬁed products. A gains table will be constructed to describe the performance of the response model. In a gains table, we tabulate various statistics at each decile, including [47]: • Predicted Probability of Active: It is the average of the predicted probabilities of active respondents in the decile by the response model. • Percentage of Active: It is the percentage of active respondents in the decile. • Cumulative Percentage of Active: It is the cumulative percentage of active respondents from decile 0 to this decile. • Actives: It is the number of active respondents in this decile. • Percentage of Total Actives: It is the ratio of the number of active respondents in this decile to the number of all active respondents in the data set. • Cumulative Actives: It is the number of active respondents from decile 0 to this decile. • Cumulative Percentage of Total Actives: It is the ratio of the number of cumulative active respondents (from decile 0 to this decile) to the total number of active respondents in the data set.  
   
  288  
   
  M. Leung Wong  
   
  • Lift: It is calculated by dividing the percentage of active respondents by the response rate of the ﬁle. Intuitively, it estimates the enhancement by the response model in discriminating active respondents over a random approach for the current decile. • Cumulative Lift: It is calculated by dividing the cumulative percentage of active respondents by the response rate. This measure evaluates how good the response model is for a given depth-of-ﬁle over a random approach. It provides an important estimate of the performance of the model.  
   
  4.2 Cross-Validation Results In order to compare the robustness of the response models, we adopt a 10-fold cross-validation approach for performance estimation. A data set is randomly partitioned into 10 mutually exclusive and exhaustive folds. Each time, a diﬀerent fold is chosen as the test set and other nine folds are combined together as the training set. Response models are learned from the training set and evaluated on the corresponding test set. In Table 1, the average of the statistics of the EBN models for the 10 test sets of the data set with 1% missing values at each decile are tabulated. Numbers in the parentheses are the standard deviations. The EBN models have the cumulative lifts of 320.62 and 232.24 in the ﬁrst two deciles respectively, suggesting that by mailing to the top two deciles alone, the Bayesian networks generate over twice as many respondents as a random mailing without a model. For this data set, the average learning time of EBN is 49.1 seconds on a notebook computer with an Intel(R) Core(T M) 2 Duo 1.8GHz processor and 3 GB of main memory running Windows XP operating system. For the sake of comparison, the average of the cumulative lifts of the models learned by diﬀerent methods from data sets with diﬀerent percentages of missing values are summarized in Tables 2, 3, and 4, respectively. Numbers in the parentheses are the standard deviations. For each data set, the highest cumulative lift in each decile is highlighted in bold. The superscript + represents that the cumulative lift of the EBN models from the corresponding data set is signiﬁcant higher at 0.05 level than that of the models obtained by the corresponding methods. The superscript − represents that the cumulative lift of the EBN models is signiﬁcant lower at 0.05 level than that of the corresponding models. In Table 2, the average and the standard deviations of the cumulative lifts of the models learned by diﬀerent methods for the data set with 1% missing values are shown. In the ﬁrst two deciles, the networks learned by LibB have cumulative lifts of 211.19 and 185.59, respectively; and 213.04 and 189.43 respectively for Bayeseware Discoverer models. It can be observed that EBN models get the highest cumulative lifts in the ﬁrst three deciles, and the cumulative lifts of the EBN models in the ﬁrst two deciles are signiﬁcantly higher at 0.05 level than those of the other eight models.  
   
  Direct Marketing Modeling  
   
  289  
   
  In Table 3, the average and the standard deviations of the cumulative lifts for diﬀerent models learned from the data set with 5% missing values are shown. In the ﬁrst two deciles, the EBN models have the highest cumulative lifts of 320.27 and 224.07 respectively, and they are signiﬁcantly higher than those of the other eight methods at 0.05 level. The average learning time of EBN is 200.5 seconds for this data set. In Table 4, the average and the standard deviations of the cumulative lifts for diﬀerent models discovered from the data set with 10% missing values are shown. Again, it demonstrates that the discovered EBN models have the highest cumulative lifts in the ﬁrst two deciles, which are 320.18 and 212.88 respectively. The cumulative lifts of EBN models in the ﬁrst two deciles are signiﬁcantly higher at 0.05 level than those of the other eight methods. For this data set, the average learning time of EBN is 559.2 seconds. To summarize, the networks generated by EBN always have the highest cumulative lifts in the ﬁrst two deciles. Moreover, the cumulative lifts of the EBN models are signiﬁcantly higher at 0.05 level than those of the other models in the ﬁrst two deciles. Thus, we can conclude that EBN is very eﬀective in learning Bayesian networks from data sets with diﬀerent missing value percentages. Since an advertising campaign often involves huge investment, a Bayesian network which can categorize more prospects into the target list is valuable as it will enhance the response rate. From the experimental results, it seems that EBN are more eﬀective than the other methods.  
   
  Table 1 Gains Table of the EBN models for the 10 test sets of the data set with 1% missing values Decile Prob. of Active 0 44.61% (1.66%) 1 43.23% (0.82%) 2 42.92% (1.95%) 3 31.20% (1.72%) 4 24.61% (0.33%) 5 23.17% (0.37%) 6 22.69% (0.24%) 7 22.45% (0.55%) 8 17.12% (0.61%) 9 14.96% (0.87%)  
   
  % of Active 91.96% (6.41%) 41.37% (8.45%) 2.09% (7.63%) 30.30% (3.20%) 27.92% (3.55%) 58.26% (12.40%) 1.99% (6.05%) 4.30% (8.76%) 24.29% (4.65%) 5.66% (1.71%)  
   
  Cum. % of Active 91.96% (6.41%) 66.67% (5.55%) 45.14% (2.65%) 41.43% (1.91%) 38.73% (1.44%) 41.98% (1.99%) 36.27% (1.25%) 32.28% (1.19%) 31.39% (0.83%) 28.70% (0.71%)  
   
  Actives % of Total Actives 183.00 31.90% (12.75) (2.35%) 82.33 14.31% (16.81) (2.76%) 4.17 0.72% (15.19) (2.62%) 60.30 10.51% (6.37) (1.10%) 55.57 9.69% (7.07) (1.30%) 115.93 20.20% (24.67) (4.22%) 3.97 0.69% (12.05) (2.08%) 8.57 1.48% (17.43) (3.00%) 48.33 8.43% (9.25) (1.66%) 11.83 2.06% (3.58) (0.63%)  
   
  Cum. Cum. % of Actives Total Actives 183.00 31.90% (12.75) (2.35%) 265.33 46.22% (22.10) (3.54%) 269.50 46.94% (15.83) (2.24%) 329.80 57.45% (15.22) (1.94%) 385.37 67.14% (14.33) (1.85%) 501.30 87.33% (23.70) (3.47%) 505.27 88.02% (17.47) (1.92%) 513.83 89.50% (18.98) (1.89%) 562.17 97.94% (14.90) (0.63%) 574.00 100.00% (14.17) (0.00%)  
   
  Lift 320.62 (23.64) 143.86 (27.78) 7.26 (26.30) 105.60 (11.03) 97.40 (13.03) 202.99 (42.43) 6.90 (20.90) 14.91 (30.14) 84.74 (16.65) 19.75 (6.01)  
   
  Cum. Lift 320.62 (23.64) 232.24 (17.78) 157.25 (7.50) 144.33 (4.88) 134.95 (3.71) 146.29 (5.81) 126.38 (2.76) 112.44 (2.37) 109.36 (0.70) 100.00 (0.00)  
   
  290  
   
  M. Leung Wong  
   
  Table 2 Cumulative lifts of the networks learned by diﬀerent methods for the realworld data sets with 1% missing values. The statistics are obtained from the 10 test sets. Decile  
   
  EBN  
   
  LibB  
   
  Bayesware Discoverer  
   
  BNN  
   
  LR  
   
  NB  
   
  TAN  
   
  HEA1  
   
  HEA2  
   
  0  
   
  320.62 (23.64) 232.24 (17.78) 157.25 (7.50) 144.33 (4.88) 134.95 (3.71) 146.29 (5.81) 126.38 (2.76) 112.44 (2.37) 109.36 (0.70) 100.00 (0.00)  
   
  211.19+ (28.00) 185.59 + (17.44) 156.79 (7.08) 146.54 (5.56) 136.43 (6.92) 134.65+ (10.05) 119.16+ (4.11) 113.69 (3.87) 108.58 (2.03) 100.00 (0.00)  
   
  213.04+ (41.61) 189.43+ (14.53) 155.99 (7.46) 146.07 (7.90) 140.78 (12.08) 136.09+ (4.35) 119.63+ (1.82) 112.53 (1.84) 107.64+ (1.86) 100.00 (0.00)  
   
  200.11+ (11.00) 171.01+ (9.76) 156.56 (5.74) 144.26 (4.67) 135.60 (1.98) 127.33+ (2.15) 120.20+ (2.02) 113.80− (1.61) 107.71+ (0.98) 100.00 (0.00)  
   
  188.30+ (12.23) 168.80+ (9.73) 152.30+ (6.72) 141.40+ (3.13) 132.80+ (1.23) 125.80+ (2.86) 118.30+ (2.26) 112.50 (1.35) 106.60+ (1.07) 100.00 (0.00)  
   
  198.50+ (9.99) 169.70+ (7.15) 154.30 (4.45) 139.40+ (2.55) 131.20+ (1.75) 124.70+ (2.79) 116.70+ (1.64) 111.90 (1.45) 106.20+ (0.92) 100.00 (0.00)  
   
  195.80+ (6.41) 168.30+ (7.35) 150.90+ (4.89) 139.70+ (2.75) 132.50 (4.17) 124.10+ (2.69) 118.70+ (1.70) 113.40− (1.17) 106.20+ (1.03) 100.00 (0.00)  
   
  195.60+ (9.03) 169.80+ (8.65) 154.00 (5.54) 142.60 (5.23) 132.70+ (3.09) 126.40+ (2.88) 120.80+ (3.01) 113.10 (1.52) 106.20+ (1.14) 100.00 (0.00)  
   
  195.10+ (11.17) 170.10+ (6.79) 155.00 (5.83) 144.30 (3.80) 134.30 (3.02) 128.30+ (2.45) 118.80+ (1.48) 112.90− (0.57) 106.10+ (0.88) 100.00 (0.00)  
   
  1 2 3 4 5 6 7 8 9  
   
  Table 3 Cumulative lifts of the networks learned by diﬀerent methods for the realworld data sets with 5% missing values. The statistics are obtained from the 10 test sets. Decile  
   
  EBN  
   
  0  
   
  320.27 (22.43) 224.07 (16.29) 153.53 (6.98) 143.41 (5.83) 135.63 (3.67) 145.72 (5.51) 126.11 (2.86) 111.74 (2.05) 109.20 (1.11) 100.00 (0.00)  
   
  1 2 3 4 5 6 7 8 9  
   
  LibB  
   
  Bayesware Discoverer  
   
  BNN  
   
  217.63+ 246.59+ 199.37+ (47.64) (31.34) (10.33) 186.30+ 165.69+ 171.09+ (21.35) (19.94) (9.50) 155.28 152.60 155.97 (6.96) (7.80) (5.60) 145.15 143.24 143.21 (8.33) (6.71) (3.67) 136.75 144.16− 134.18 (6.21) (5.18) (2.61) 133.47+ 124.27+ 126.88+ (10.49) (3.38) (2.49) 118.90+ 118.10+ 120.07+ (4.94) (1.85) (2.29) 113.57− 113.09− 113.73− (3.69) (2.18) (1.48) 108.08+ 106.80+ 107.64+ (1.89) (1.56) (0.87) 100.00 100.00 100.00 (0.00) (0.00) (0.00)  
   
  LR  
   
  NB  
   
  TAN  
   
  HEA1  
   
  HEA2  
   
  188.50+ (11.45) 167.80+ (9.20) 151.40 (4.77) 140.40+ (2.67) 132.40+ (1.58) 125.60+ (2.67) 118.40+ (2.41) 112.40 (1.17) 106.60+ (0.97) 100.00 (0.00)  
   
  195.40+ (10.27) 170.30+ (6.33) 152.60 (4.14) 139.50+ (2.72) 130.50+ (1.27) 125.00+ (2.62) 117.00+ (1.70) 111.50 (1.35) 106.00+ (1.15) 100.00 (0.00)  
   
  197.80+ (9.84) 169.60+ (7.38) 151.50 (5.23) 139.90+ (2.85) 131.30+ (3.27) 123.60+ (1.65) 118.10+ (1.66) 112.50 (1.27) 106.10+ (1.10) 100.00 (0.00)  
   
  193.30+ (5.79) 167.90+ (6.82) 153.30 (4.47) 143.60 (3.89) 133.00+ (2.54) 126.30+ (2.95) 119.30+ (2.06) 112.70 (1.42) 106.20+ (1.23) 100.00 (0.00)  
   
  192.40+ (12.97) 169.90+ (7.58) 153.80 (5.85) 142.90 (4.51) 133.10+ (3.38) 128.10+ (3.21) 118.90+ (1.79) 113.20− (0.79) 105.90+ (0.88) 100.00 (0.00)  
   
  Direct Marketing Modeling  
   
  291  
   
  Table 4 Cumulative lifts of the networks learned by diﬀerent methods for the realworld data sets with 10% missing values. The statistics are obtained from the 10 test sets. Decile EBN 0 1 2 3 4 5 6 7 8 9  
   
  320.18 (24.36) 212.88 (15.96) 152.76 (5.65) 141.78 (4.40) 136.15 (5.39) 143.02 (6.50) 125.51 (3.20) 111.58 (2.08) 109.35 (0.91) 100.00 (0.00)  
   
  LibB  
   
  Bayesware Discoverer  
   
  BNN  
   
  LR  
   
  NB  
   
  TAN  
   
  HEA1  
   
  HEA2  
   
  239.06+ (64.44) 188.42+ (21.09) 153.36 (6.38) 142.46 (9.31) 134.86 (5.83) 134.62+ (10.86) 119.65+ (5.40) 112.61 (4.21) 108.97 (1.81) 100.00 (0.00)  
   
  196.86+ (18.50) 171.22+ (9.13) 152.20 (6.40) 139.63 (4.50) 131.55+ (4.84) 124.17+ (5.17) 117.23+ (2.73) 112.36 (1.85) 105.51+ (1.22) 100.00 (0.00)  
   
  195.71+ (13.60) 169.89+ (9.75) 154.32 (6.76) 142.28 (4.66) 133.14+ (3.55) 125.38+ (1.82) 119.27+ (2.25) 113.25− (1.28) 107.09+ (0.67) 100.00 (0.00)  
   
  185.10+ (12.56) 164.90+ (10.46) 149.30 (8.11) 138.90+ (3.57) 130.70+ (2.31) 123.60+ (2.01) 117.70+ (2.67) 111.90 (1.85) 106.40+ (0.84) 100.00 (0.00)  
   
  190.40+ (13.55) 167.70+ (6.29) 151.30 (3.95) 138.40+ (2.91) 128.60+ (1.78) 123.50+ (1.72) 116.10+ (2.33) 111.20 (1.81) 105.60+ (0.97) 100.00 (0.00)  
   
  194.90+ (11.43) 167.20+ (8.83) 151.30 (5.38) 139.40 (3.63) 129.80+ (4.16) 123.20+ (1.99) 117.30+ (1.42) 112.50− (1.27) 106.30+ (0.82) 100.00 (0.00)  
   
  194.10+ (9.87) 167.00+ (6.36) 152.40 (6.06) 139.90 (3.96) 132.30+ (2.67) 124.50+ (2.37) 118.30+ (2.26) 112.30 (1.25) 106.20+ (0.92) 100.00 (0.00)  
   
  195.80+ (9.27) 168.50+ (7.63) 153.00 (5.50) 141.00 (4.29) 132.40+ (3.86) 125.50+ (2.46) 118.40+ (1.84) 113.10− (0.88) 106.30+ (0.82) 100.00 (0.00)  
   
  5 Conclusion In this paper, we have described a new evolutionary algorithm called EBN that applies EM, a strategy for generating an initial network structure, and a data completing procedure to learn Bayesian networks from incomplete databases. To explore its interesting applications for real-life data mining problems, we have applied EBN to a real-world data set of direct marketing and compared the performance of the networks obtained by EBN with the models generated by other methods. The experimental results demonstrate that EBN outperforms other methods in the presence of missing values. The main advantage of EBN lies in the integration of EM and a hybrid evolutionary algorithm. While using EM and Bayesian inference to complete the missing values of a variable, the relationships of this variables with other variables are also considered instead of examining only the observed values of the variable. Thus better missing value imputations can be obtained. At the same time, the hybrid evolutionary algorithm facilitates the discovery of much better Bayesian network structures eﬀectively and eﬃciently. In this work, the missing values in the data sets are introduced randomly. In the future, studies will be conducted to facilitate EBN for incomplete data sets with other patterns of missing values.  
   
  292  
   
  M. Leung Wong  
   
  Acknowledgments. This work is supported by the Lingnan University Direct Grant DR04B8.  
   
  References 1. Jensen, F.V.: An Introduction to Bayesian Network. University of College London Press, London (1996) 2. Andreassen, S., Woldbye, M., Falck, B., Andersen, S.: MUNIN: A causal probabilistic network for interpretation of electromyographic ﬁndings. In: Proceedings of the Tenth International Joint Conference on Artiﬁcial Intelligence, pp. 366–372 (1987) 3. Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., Freeman, D.: Autoclass: A Bayesian classiﬁcation system. In: Proceedings of the Fifth International Workshop on Machine Learning, pp. 54–64 (1988) 4. Heckerman, D., Horvitz, E.: Inferring informational goals from free-text queries: A Bayesian approach. In: Cooper, G.F., Moral, S. (eds.) Proceedings of the Fourteenth Conference of Uncertainty in Artiﬁcial Intelligence, pp. 230–237. Morgan Kaufmann, Wisconsin (July 1998) 5. Cheng, J., Greiner, R., Kelly, J., Bell, D., Liu, W.: Learning Bayesian networks from data: An information-theory based approach. Artiﬁcial Intelligence 137, 43–90 (2002) 6. Spirtes, P., Glymour, C., Scheines, R.: Causation, Prediction, and Search, 2nd edn. MIT Press, MA (2000) 7. Cooper, G., Herskovits, E.: A Bayesian method for the induction of probabilistic networks from data. Machine Learning 9(4), 309–347 (1992) 8. Heckerman, D.: A tutorial on learning Bayesian networks. Microsoft Research Adv. Technol. Div., Redmond, WA, Tech. Rep. MSR-TR-95-06 (1995) 9. Lam, W., Bacchus, F.: Learning Bayesian belief networks-an approach based on the MDL principle. Computer Intelligence 10(4), 269–293 (1994) 10. Larra¨ naga, P., Poza, M., Yurramendi, Y., Murga, R., Kuijpers, C.: Structural learning of Bayesian network by genetic algorithms: A performance analysis of control parameters. IEEE Trans. Pattern Anal. Machine Intell. 18, 912–926 (1996) 11. Larra˜ naga, P., Kuijpers, C., Mura, R., Yurramendi, Y.: Learning Bayesian network structures by searching for the best ordering with genetic algorithms. IEEE Transactions on System, Man and Cybernetics 26(4), 487–493 (1996) 12. Wong, M.L., Lam, W., Leung, K.S.: Using evolutionary programming and minimum description length principle for data mining of Bayesian networks. IEEE Trans. Pattern Anal. Machine Intell. 21, 174–178 (1999) 13. Wong, M.L., Leung, K.S.: An eﬃcient data mining method for learning Bayesian networks using an evolutionary algorithm-based hybrid approach. IEEE Trans. Evolutionary Computation 8(4), 378–404 (2004) 14. Schafer, J.L., Graham, J.W.: Missing data: Our view of the state of art. Psychological Methods 7(2), 147–177 (2002) 15. Ramoni, M., Sebastinani, P.: Eﬃcient parameter learning in Bayesian networks from incomplete databases, Tech. Rep. KMI-TR-41 (1997) 16. Ramoni, M., Sebastinani, P.: The use of exogenous knowledge to learn Bayesian networks from incomplete databases, Tech. Rep. KMI-TR-44 (1997)  
   
  Direct Marketing Modeling  
   
  293  
   
  17. Friedman, N.: Learning belief networks in the presence of missing values and hidden variables. Machine Learning (1997) 18. Friedman, N.: The Bayesian Structural EM algorithm. In: Proceedings of the Fourteenth Conference on Uncertainty in Artiﬁcial Intelligence (1998) 19. Pe¨ na, J.M., Lozano, J.A., Larra¨ naga, P.: An improved Bayesian Structural EM algorithm for learning Bayesian networks for clustering. Pattern Recognition Letters, 779–786 (2000) 20. Pe¨ na, J.M., Lozano, J.A., Larra¨ naga, P.: Learning recursive Bayesian multinets for data clustering by means of constructive induction. Machine Learning, 63– 89 (2002) 21. Myers, J.W., Laskey, K.B., DeJong, K.A.: Learning Bayesian networks from incomplete data using evolutionary algorithms. In: Proceedings of the First Annual Conference on Genetic and Evolutionary Computation Conference 1999, pp. 458–465. Morgan Kauﬀman, Orlando (July 1999) 22. Petrison, L.A., Blattberg, R.C., Wang, P.: Database marketing: Past present, and future. Journal of Direct Marketing 11(4), 109–125 (1997) 23. Cabena, P., Hadjinian, P., Stadler, R., Verhees, J., Zansi, A.: Discovering Data Mining: From Concept to Implementation. Prentice-Hall Inc., Englewood Cliﬀs (1997) 24. Zahavi, J., Levin, N.: Issues and problems in applying neural computing to target marketing. Journal of Direct Marketing 11(4), 63–75 (1997) 25. Bhattacharyya, S.: Direct marketing response models using genetic algorithms. In: Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining, pp. 144–148 (1998) 26. Bhattacharyya, S.: Evolutionary algorithms in data mining: Multi-objective performance modeling for direct marketing. In: Proceedings of the Sixth International Conference on Knowledge Discovery and Data Mining, pp. 465–473 (August 2000) 27. Zahavi, J., Levin, N.: Applying neural computing to target marketing. Journal of Direct Marketing 11(4), 76–93 (1997) 28. Ling, C.X., Li, C.: Data mining for direct marketing: Problems and solutions. In: Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining, pp. 73–79 (1998) 29. Freund, Y., Schapire, R.E.: Experiments with a new boosting algorithm. In: Proceedings of the Thirteenth International Conference on Machine Learning, pp. 148–156 (1996) 30. Pearl, J.: Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Mateo (1988) 31. Rubin, D.B.: Multiple Imputation for nonresponse in Surveys. Wiley, Chichester (1987) 32. Lakshminarayan, K., Harp, S.A., Samad, T.: Imputation of missing data using machine learning techniques. In: Proceeding of the second International Conference on Knowledge Discovery and data Mining, pp. 140–146 (1996) 33. Zio, M.D., Scanu, M., Coppola, L., Luzi, O., Ponti, A.: Bayesian networks for imputation. Journal of the Royal Statistical Society (A) 167(2), 309–322 (2004) 34. Hruschka, E.R.J., Ebecken, N.F.F.: Missing values prediction with K2. Intelligent Data Analysis 6(6), 557–566 (2002) 35. Kim, H., Golub, G.H., Park, H.: Imputation of missing values in DNA microarray gene expression data. In: Proceedings of IEEE Computational Systems Bioinformatics Conference, pp. 572–573. IEEE Press, Los Alamitos (2004)  
   
  294  
   
  M. Leung Wong  
   
  36. Cai, Z., Heydari, M., Lin, G.: Microarray missing value imputation by iterated local least squares. In: Proceedings of the Fourth Asia-Paciﬁc Bioinformatics Conference, pp. 159–168 (2006) 37. Liu, L., Hawkins, D.M., Ghosh, S., Young, S.: Robust singular value decomposition analysis of microarray data. Proceedings of the National Academy of Sciences of the United States of America 100(23), 13167–13172 (2003) 38. Geman, S., Geman, D.: Stochastic relaxation, gibbs distributions and the bayesian restoration of images. IEEE Trans. Pattern Anal. Machine Intell. 6, 721–742 (1984) 39. Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society(B) 39(1), 1–38 (1977) 40. Lauritzen, S.L.: The EM algorithm for graphical association models with missing data. Computational Statistics and Data Analysis, 191–201 (1995) 41. Ramoni, M., Sebastiani, P.: Robust learning with missing data. Machine Learning 45, 147–170 (2001) 42. Lauritzen, S.L., Spiegelhalter, D.J.: Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society 50(2), 157–224 (1988) 43. Huang, C., Darwinche, A.: Inference in belief networks: a procedural guide. International Journal of Approximate Reasoning 15(3), 225–263 (1996) 44. Neal, R.M.: Bayesian Learning for Neural Networks. Springer, Heidelberg (1996) 45. Friedman, N., Geiger, D., Goldszmidt, M.: Bayesian network classiﬁers. Machine Learning 29, 131–163 (1997) 46. Agresti, A.: Categorical Data Analysis. Wiley, New York (2002) 47. Rud, O.P.: Data Mining Cookbook: Modeling Data for Marketing, Risk and Customer Relationship Management. Wiley, New York (2001)  
   
  Designing Optimal Products: Algorithms and Systems Stelios Tsafarakis and Nikolaos Matsatsinis Technical University of Crete, Department of Production and Management Engineering,Decision Support Systems Laboratory, Chania, Greece e-mail: [email protected]  [email protected]   
   
  Abstract. The high cost of a product failure makes it imperative for a company to assess the market penetration of a new product at its early design. In this context, the Optimal Product Line Design problem was formulated thirty five years ago, and remains a significant research topic in the area of quantitative marketing until today. In this chapter we provide a brief description of the problem, which belongs to the class of NP-hard problems, and review the optimization algorithms that have been applied to it. The performance of the algorithms is evaluated, and the best two approaches are applied to simulated data, as well as a real world scenario. Emphasis is placed on Genetic Algorithms, since the results of the study indicate them as the approach that better fits to the specific marketing problem. Finally, the relevant marketing systems that deal with the problem are presented, and their pros and cons are discussed.  
   
  1 Introduction Nowadays the economic environment where companies operate has become more competitive than ever. The globalization of the markets, the shorter product life cycles, and the rapid technology development, put high pressure on firms’ profitability. In order to survive under such circumstances a company must continuously launch new products or redesign its current ones. However, such procedures entail risk. A new product is costly and difficult to change, hence if it ends up as a commercial failure, the firm’s viability may be put in danger. Bad design constitutes one of the most frequent reasons for the failure of a new product (Kotler and Armstrong, 2008). In order to avoid such situations, managers try to design optimal products and assess their market penetration before their entrance to the production stage. This constitutes a wide area of research in quantitative marketing for over thirty years, known as the Optimal Product (Line) Design Problem. Here, each product consists of a number of attributes that take specific levels, and the consumer preferences regarding the various attribute levels are considered known. Taking as input these consumer preferences, optimization algorithms are used in order for optimal product profiles to be designed. Different objectives can be employed, such as the maximization of the products’ market share or J. Casillas & F.J. Martínez-López (Eds.): Marketing Intelligence Systems, STUDFUZZ 258, pp. 295–336. springerlink.com © Springer-Verlag Berlin Heidelberg 2010  
   
  296  
   
  S. Tsafarakis and N. Matsatsinis  
   
  the maximization of the company’s profit. In real world applications, as the number of attributes and levels increases, the number of candidate product profiles can grow uncontrollable large, making the managerial task for selecting the appropriate combination of attribute levels practically infeasible. Actually the optimal product line design problem has been proved to be NP-hard, which means that the complete solution space cannot be enumerated in polynomial time. In this context, a number of different heuristic approaches have been applied to solve the problem from 1974 until today. Some of the algorithms have been incorporated to intelligent marketing systems, which assist a manager in such problems of high complexity. Several papers have been published that present a specific algorithm and compare its performance with one or more other approaches. However, the comparison concerns only the approximation of the optimal solution, whereas marketing practitioners who work on real problems are interested in a number of other more qualitative issues. No study has been published that reviews the advantages and disadvantages of the algorithms that have been applied to the problem, while little work has been done regarding the evaluation of the relevant marketing systems. In this chapter, we aim at filling this gap by presenting an integrated work, which provides a detailed description of the product line design problem, reviews all the algorithms that have been applied to the problem along with the related marketing systems that incorporate them, and tries to draw valuable insights for the manager as well as the researcher. Emphasis is placed on the application of Genetic Algorithms to the problem, since it is the mostly used method in the literature, and constitutes the most advanced algorithm that has been incorporated into a marketing system. This work will help the marketing manager understand the problem, select the method that mostly fits to his requirements, and decide on whether he will use one of the existing marketing systems or he will need to develop a new system from the scratch, which will better satisfy his company’s requirements. A real world application is presented extensively, in order to support the manager in such a decision. Furthermore, this chapter provides a guide to the interested researchers, describing the optimization algorithms applied to the problem, comparing their performance, and pointing out the potential areas for future work. The rest of the chapter is organized into five sections as follows. Section 2 provides a brief description of the problem and its main properties. In Section 3, the different formulations of the problem are described. The optimization algorithms that have been applied to the problem are presented extensively in Section 4, and their pros and cons are evaluated. In Section 5 we compare the performance of Genetic Algorithms and Simulated Annealing, using a real data set as well as a Monte Carlo simulation. The relevant marketing systems and programs that have been developed are presented in Section 6, and some conclusions are drawn. Finally, Section 7 provides an overview of the main conclusions of the study, and suggests areas of future research.  
   
  2 The Optimal Product (Line) Design Problem The goal of the optimal product (line) design problem is the design of one (or more products), the introduction of which to the market will maximize a firm’s objective  
   
  Designing Optimal Products: Algorithms and Systems  
   
  297  
   
  (usually market share). This requires the proper modeling of customer preferences concerning the various product features. In particular, each product is represented as a bundle of attributes (features) which can take specific levels. A personal computer for example, consists of the attributes monitor, processor, hard disk, memory etc., the levels of which are illustrated in Table 1. Every individual has its own preferences; for example a civil engineer will probably choose a large monitor, whereas a mathematician may select a fast processor. Customer preferences are represented as values (called part-worths) for each attribute level. An example is given in Table 1. Table 1 Part-worths for each attribute level of a personal computer  
   
  Attributes  
   
  Monitor  
   
  Processor  
   
  Hard disk  
   
  Memory Mouse Camera  
   
  Levels 17’’ 19’’ 20’’ 24’’ Single-core 3,8 GHz Core-2 2,6 GHz Core-4 2Ghz 200 GB 500 GB 750 GB 1T 2 GB 4 GB 6 GB Cable Wireless Embedded No camera  
   
  Partworths Customer1 Customer2 0.8 0.1 0.2 0.3 0.3 0.4 0.5 0.9 0.1 0.2 0.3 0.3 0.9 0.5 0.4 0.2 0.6 0.3 0.7 0.5 0.4 0.8 0.2 0.1 0.4 0.3 0.9 0.4 0.3 0.1 0.4 0.9 0.3 0.8 0.2 0.2  
   
  Before making a choice among competing products, a consumer is assumed to implicitly assign a utility value to each, by evaluating all its attributes in a simultaneous compensative manner. On the basis of the above representation scheme, the utility value of a product is the sum of the part-worths of the corresponding attribute levels. The higher the product’s utility, the higher the probability to be chosen. Suppose that the two customers whose part-worths are presented in Table 1, have to select between PC1 (17’’, core-4 2GHz, HD 750 GB, 6 GB RAM, cable mouse, no camera) and PC2 (24’’, Single-core 3,8 GHz, HD 200 GB, 6 GB RAM, wireless mouse, embedded camera). Customer 1 will probably choose PC1 (utility=3.8) over PC2 (utility=2.5), whereas Customer 2 will probably choose PC2 (utility=3.4) over PC1 (utility=1.8). The utilities are converted to choice probabilities for each product through choice models, and are then aggregated across the whole customer base to provide hypothetical market shares. If we know the partworths for a population of consumers, we can simulate the introduction of  
   
  298  
   
  S. Tsafarakis and N. Matsatsinis  
   
  different product configurations (combinations of attribute levels) to the market and estimate conditional market shares. With the use of optimization algorithms we can find the product(s) that maximizes a firm’s market share, given the customer preferences and the configuration of the competitive products in the market. An example could be a new car manufacturer who is interested in introducing 3 new car models in different categories (Sport, SUV, Station Wagon) that will provide him with the highest possible volume sales. The customer preferences are usually revealed through market surveys, the results of which are entered into preference disaggregation methods like Conjoint Analysis, which estimate partworths for each individual. In the Optimal Product (line) Design problem the part-worths for each customer, as well as the competitive product profiles are considered known, and the aim is to find the product(s) configuration that maximizes a specific firm’s criterion. Next, we describe the different properties of the optimal product (line) design problem.  
   
  2.1 Choice Rule The choice rule (or choice model) is the underlying process by which a customer integrates information to choose a product from a set of competing products. Different choice rules have been developed with varying assumptions and purposes and they differ in the underlying logic structure that drives them (Manrai, 1995). The choice rule models the consumer’s purchasing pattern by relating preference to choice. It is a mathematical model which converts the product utilities that an individual assigns to the set of alternatives under consideration, to choice probabilities for each alternative. Choice rules can be either deterministic or probabilistic. The first choice or maximum utility is a deterministic rule, which assumes that the individual will always purchase the product with the highest utility. In this case the highest utility alternative receives probability of choice equal to 1, while the rest of the alternatives get a zero probability. Probabilistic rules on the other hand, assume that all alternatives receive a probability of choice in proportion to their utility value. Popular probabilistic choice models are: n  
   
  • •  
   
  the Bradley-Terry-Luce (1952; Luce, 1959), Pij=  
   
  ∑U  
   
  U ij  
   
  j =1  
   
  e  
   
  and the MultiNomial Logit (McFadden, 1974), Pij=  
   
  U ij  
   
  ij  
   
  ,  
   
  n  
   
  ∑e j =1  
   
  U ij  
   
  ,  
   
  where Pij is the probability that consumer i selects product j, Uij is the utility he assigns to product j, and n is the number of competing products. The first approaches applied to the problem employed the maximum utility rule, which is still widely used in product design applications due to its simple form. Its main limitation is that it tends to exaggerate the market share of popular alternatives while underestimating the unpopular ones. Probabilistic models have not received much attention in the specific problem, as they increase the algorithm’s complexity (the problem becomes non-linear). The kind of choice model used affects the problem formulation, as we will see in a later section.  
   
  Designing Optimal Products: Algorithms and Systems  
   
  299  
   
  2.2 Optimization Criteria The first criterion introduced was the maximization of a company’s market share, also known as share of choices (Shocker and Srinivasan, 1974), which remains the most frequently used objective until today. Later, two more criteria were presented, the buyer’s welfare (Green and Krieger, 1988) and the seller’s welfare (Green et al., 1981). In the former, no competition is assumed, and the aim is the maximization of the sum of the utilities that products under design offer to all customers. This is the least frequently used criterion, which mainly concerns product and services offered by public organizations. In the seller’s welfare, the goal is the maximization of a firm’s profit. This is the most complicated criterion since it requires the incorporation of the marginal return that the firm obtains from each attribute level into the objective function.  
   
  2.3 Number of Products to be Designed The optimal product design problem (one product to be designed) was first formulated by Zufryden (1977). Eight years later Green & Krieger (1985) introduced the optimal product line design problem (two or more products to be designed), which is the main focus of the specific research area today.  
   
  2.4 Procedure Steps The optimal product line design problem can be formulated either as a one-step or a two-step approach. In the latter, a reference set of candidate alternatives is first defined, and the items that optimize a certain criterion are selected next with the use of a specific algorithm (Green & Krieger, 1985). The problem here is to decide on the size of the reference set of products, and the way that it will be constructed in order to include all potential good solutions. Nowadays, the increase in computers’ speed, as well as the development of advanced optimization algorithms, has enabled the design of the items that comprise the line directly from part-worth data in a one-step approach (Green & Krieger, 1988).  
   
  2.5 Optimization Algorithm In real world applications, as the number of attributes and levels increases, the number of different product profiles raises exponentially, making the selection of the appropriate combination of attribute levels a very complex managerial task. For example in a product category with 7 attributes each taking 6 different levels, the number of possible product profiles is 279,936, while for designing a line of 3 products the number of candidate solutions is over a trillion. The exponential increase in the number of candidate solutions with the increase in the number of attributes and levels is illustrated in Table 2 (Alexouda, 2004), where K is the number of attributes, and J is the number of levels.  
   
  300  
   
  S. Tsafarakis and N. Matsatsinis  
   
  Kohli and Krishnamurti (1989) proved that the share of choices for the single product design problem is NP-hard, which means that the complete enumeration of the solution space is practically infeasible in tractable time. Kohli and Sukumar (1990) proved the same for the buyer’s welfare and the seller’s welfare, also for the single product design. In this context many different heuristic approaches have been applied to the problem from 1974 until today, the most significant of which are illustrated in Table 3. Table 2 The number of possible solutions (products and product lines) of different problem sizes (source: Alexouda, 2004)  
   
  Products in line 2 2 2 2 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3  
   
  K  
   
  J  
   
  3 4 4 5 3 4 4 5 5 5 5 6 6 6 7 7 7 8 8 8 5 5 5 6 6 6 7 7 7 8 8 8  
   
  4 3 4 3 4 3 4 3 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6 4 5 6  
   
  Number of possible products 64 81 256 243 64 81 256 243 1024 3125 7776 4096 15,625 46,656 16,384 78,125 279,936 65,536 390,625 1,679,616 1024 3125 7776 4096 15,625 46,656 16,384 78,125 279,936 65,536 390,625 1,679,616  
   
  Number of product lines  
   
  possible  
   
  2016 3240 32,640 29,403 41,664 85,320 2,763,520 2,362,041 523,776 4,881,250 30,229,200 8,386,560 122,062,500 1,088,367,840 134,209,536 3,051,718,750 39,181,942,080 2,147,450,880 76,293,750,000 1,410,554,113,920 178,433,024 5,081,381,250 78,333,933,600 11,444,858,880 635,660,812,500 16,925,571,069,120 732,873,539,584 79,469,807,968,750 3,656,119,258,074,240 46,910,348,656,640 9,934,031,168,750,000 789,728,812,499,209,000  
   
  Deterministic Deterministic  
   
  Nair, Thakur & Wen 1995  
   
  Deterministic, Probabilistic Probabilistic  
   
  Sudharshan, May & Gruca 1988 Green, Krieger & Zelnio 1989  
   
  Dobson & Kalish 1993  
   
  Deterministic  
   
  McBride & Zufryden 1988  
   
  Deterministic  
   
  Probabilistic  
   
  Green & Krieger 1988  
   
  Kohli & Sukumar 1990  
   
  Deterministic  
   
  Kohli & Krishnamusti 1987  
   
  Deterministic  
   
  Zufryden 1977 Deterministic, Probabilistic Deterministic  
   
  Deterministic  
   
  Shocker & Srinivasan 1974  
   
  Green, Carroll & Goldberg 1981 Green & Krieger 1985  
   
  Choice r ule  
   
  . Paper  
   
  One  
   
  Two  
   
  One  
   
  Two  
   
  Share Share, Profit, Buyers welfare Share, Profit, Buyers welfare Share, Profit  
   
  One  
   
  Two  
   
  One  
   
  Share  
   
  Share, Profit, Buyers welfare Share  
   
  One  
   
  Two  
   
  Share  
   
  Share  
   
  One  
   
  One  
   
  One  
   
  Steps  
   
  Share, Profit  
   
  Share  
   
  Share, Profit  
   
  Objective Gradient search, Grid search Mathematical programming Response Surface methods Greedy Heuristic, Interchange Heurist Dynamic Programming Divide & Conquer Mathematical programming Non linear programming Coordinate Ascent Dynamic Programming Greedy Heuristic Beam Search  
   
  Algor ithm  
   
  Table 3 Approaches applied to the optimal product (line) design problem  
   
  Line  
   
  Line  
   
  Line  
   
  Line  
   
  Line  
   
  Line  
   
  Line  
   
  Single  
   
  Line  
   
  Single  
   
  Single  
   
  Pr od ducts Single  
   
  PROSIT  
   
  DIFFSTRAT  
   
  SIMOPT  
   
  DESOP, LINEOP  
   
  QUALIN  
   
  ZIPMAP  
   
  Sysstem  
   
  Designing Optimal Products: Algorithms and Systems 301  
   
  Probabilistic  
   
  Deterministic  
   
  Steiner & Hruschka 2003  
   
  Alexouda 2004  
   
  Belloni, Freund, Selove & Simester 2008  
   
  Share  
   
  Profit  
   
  Share  
   
  Deterministic  
   
  Profit  
   
  Share  
   
  Probabilistic  
   
  Krieger & Green 2002  
   
  Share  
   
  Deterministic  
   
  Deterministic  
   
  Shi, Olafsson & Chen 2001  
   
  Profit  
   
  Share  
   
  Deterministic  
   
  Alexouda & Paparrizos 2001  
   
  Share, Buyers welfare Profit  
   
  Deterministic  
   
  Probabilistic  
   
  Chen & Hausman 2000  
   
  Balakrishnan, Gupta & Jacob 2004 Camm, Cochran, Curry & Kannan 2006  
   
  Deterministic  
   
  Balakrishnan & Jacob 1996  
   
  Table 3 (Cont.)  
   
  One  
   
  One  
   
  One  
   
  One  
   
  One  
   
  One  
   
  One  
   
  One  
   
  Two  
   
  One  
   
  Genetic algorithm Non linear programming Genetic algorithm Nested Partitions Greedy Heuristic Genetic algorithm Genetic algorithm Genetic algorithm Branch and Bound with Lagrangian relaxation Branch and Bound with Lagrangian relaxation Single  
   
  Line  
   
  Line  
   
  Line  
   
  Single  
   
  Line  
   
  Line  
   
  Line  
   
  Single  
   
  MDSS  
   
  MDSS  
   
  302 S. Tsafarakis and N. Matsatsinis  
   
  Designing Optimal Products: Algorithms and Systems  
   
  303  
   
  3 Problem Formulation The formulation of the problem depends on the employed choice rule and the selected optimization criterion.  
   
  3.1 Deterministic Choice Rules The most common approach found in the literature is the share of choices problem for the optimal product line design using the first choice rule. 3.1.1 Share of Choices Here, each individual is assumed to have an existing favorite product called status quo. The problem can be formulated as a 0-1 integer program, with the use of the following parameters (Kohli & Sukumar, 1990): Ω = {1,2,…, K} is the set of K attributes that comprise the product. Φκ = {1,2,…, Jκ} is the set of Jκ levels of attribute k. Ψ = {1,2,…M} is the set of products to be designed. θ = {1,2,…Ι} is the set of Ι customers. wijk= is the part-worth that customer i ∈ θ assigns to level j ∈ Φκ of attribute k ∈ Ω.  
   
  jki* = is the level of attribute k ∈ Ω of customer’s i ∈ θ status quo product. cijk = wijk - wij*k is the relative difference in the part-worth that customer i ∈ θ assigns between level j and level j* of attribute k ∈ Ω. Since the firm may already offer a number of products, we index as θ’ ⊂ θ the set of customers whose current status quo product is offered by a competitor. In this way the company aims at gaining the maximum possible number of clients from its competitors, without cannibalizing its existing product line. Three decision variables are also used: 1, if the level of product's m attribute k is j,  
   
  { x ={ x ={ xjkm =  
   
  0, otherwise  
   
  1, if product's m utility for customer i is less than his status quo,  
   
  im  
   
  0, otherwise  
   
  1, if customer i does not choose to switch from his status quo,  
   
  i  
   
  0, otherwise  
   
  In this context the share of choices problem in the product line design using a deterministic rule is formulated as follows:  
   
  304  
   
  S. Tsafarakis and N. Matsatsinis  
   
  ∑θ x  
   
  i  
   
  i∈ '  
   
  min  
   
  (1)  
   
  subject to  
   
  ∑x  
   
  j ∈Φ κ  
   
  =1  
   
  jkm  
   
  ∑ ∑c  
   
  ijk  
   
  k ∈Ω j ∈Φ κ  
   
  x jkm + yim > 0 ,  
   
  ∑x  
   
  im  
   
  xi -  
   
  k ∈ Ω, m ∈ Ψ,  
   
  ,  
   
  m∈Ψ  
   
  (2) i ∈ θ’, m ∈ Ψ,  
   
  ∀ i ∈ θ’  
   
  ≥ 1 – M,  
   
  xjkm, xim, xi = 0, 1 integer, i ∈ θ’, j ∈ Φκ, k ∈ Ω, m ∈ Ψ.  
   
  (3)  
   
  (4) (5)  
   
  Constraint (2) requires each product in the line to be assigned exactly one level of each attribute. Constraint (3) restricts xim to be 1 only if customer i prefers his status quo to product m. Constraint (4) forces xi to be 1 only if xim = 1 for all m ∈ Ψ, that is if customer i prefers his status quo to all products in the line. Constraint (5) represents the binary restrictions regarding the problem’s decision variables. The objective function (1) minimizes the number of instances for which xi = 1, and hence minimizes the number of customers who decide to be loyal to their status quo products (which is equivalent to maximizing the number of customers who switch from their status quo to a product from the company’s line). 3.1.2 Buyer’s Welfare In this case no status quo product is assumed for the customer (buyer), who will select the item from the offered line that maximizes his utility. The following decision variable is used: 1, if level j of attribute k appears in product m, and buyer i,  
   
  xijkm=  
   
  {  
   
  0, otherwise  
   
  The problem can be formulated as a 0-1 integer program as follows (Kohli & Sukumar, 1990):  
   
  ∑θ ∑ ∑ ∑ w i∈ m∈Ψk ∈Ω j∈Φ κ  
   
  max  
   
  x  
   
  ijk ijkm  
   
  (6)  
   
  subject to  
   
  ∑ ∑x  
   
  j∈Φ κ m∈Ψ  
   
  ∑x  
   
  j∈Φ κ  
   
  ijkm  
   
  ijkm  
   
  −  
   
  =1  
   
  i ∈ θ, k ∈ Ω,  
   
  ,  
   
  ∑x  
   
  j∈Φ κ '  
   
  ijk ' m  
   
  =0 ,  
   
  k’>k, k,k’ ∈ Ω, i ∈ θ, m ∈ Ψ,  
   
  (7) (8)  
   
  Designing Optimal Products: Algorithms and Systems  
   
  xijkm + xi’j’km ≤ 1,  
   
  i’>i, j’>j, i,i’ ∈ θ, j,j’ ∈ Φκ,k ∈ Ω, m ∈ Ψ,  
   
  xijkm = 0, 1 integer, i ∈ θ, j ∈ Φκ, k ∈ Ω, m ∈ Ψ  
   
  305  
   
  (9) (10)  
   
  Constraint (7) requires that, across products, only one level of an attribute be associated with a specific buyer. Constraint (8) requires that, across attributes, the level assigned to buyer i ∈ θ must correspond to the same product. Constraint (9) requires that for all buyers assigned to a specific product, the same level of an attribute must be specified. Together, these three constraints require that each buyer be assigned one of the products in the line. The objective function (6) selects the products (attribute levels combination) to maximize the total utility across buyers. 3.1.3 Seller’s Welfare Kohli & Sukumar (1990) provide a detailed description of the seller’s welfare problem, where the firm wants to maximize the marginal utility obtained by the introduction of a line of M new products. The seller may already offer some products in the market, and competition is represented through the existence of a current status quo product for each customer. If customer i ∈ θ selects a product in which level j ∈ Φκ of attribute k ∈ Ω appears, the seller is assumed to obtain a part-worth value uijk. The seller’s marginal return obtained from level j ∈ Φκ of attribute k ∈ Ω is: • •  
   
  dijk = uijk - uij*k, if customer i ∈ θ switches from a product offered by the seller dijk = uijk if customer i ∈ θ switches from a product offered by a competitor  
   
  The problem can be formulated as a 0-1 integer program as follows: max  
   
  ∑θ ∑∑ ∑ d  
   
  ijk  
   
  xijkm yi  
   
  i∈ m∈Ψ k∈Ω j∈Φκ  
   
  (11)  
   
  subject to  
   
  ∑∑ ∑w  
   
  m∈Ψ k ∈Ω j∈Φ κ  
   
  ijk  
   
  ( xijkm − xi ' jkm ) ≥ 0  
   
  , i  
   
  yi ∑∑ ∑ wijk xijkm ≥ y u m∈Ψ k∈Ω j∈Φκ  
   
  * i i  
   
  ≠ i’, i ∈ θ,  
   
  , i∈ θ  
   
  (12) (13)  
   
  yi = 0, 1 integer, and (7), (8), (9), (10). Constraints (7)-(10) require, as in the buyer’s welfare problem, that a specific product is assigned to each customer, and that each product in the line be assigned exactly one level of each attribute. Constraint (12) requires that each customer is assigned to the product that maximizes his utility. Constraint (13) requires that the seller obtains a return from customer i only if the utility of the new item assigned * to the customer is higher than the utility of the ui of his status quo product. The objective function (11) selects the products to maximize the seller’s total return from the products in the line.  
   
  306  
   
  S. Tsafarakis and N. Matsatsinis  
   
  3.2 Probabilistic Choice Rules When probabilistic choice rules are used, the market is assumed to consist of Ν competitive products with known configurations, including the M candidate items for the firm’s line: Ξ = {1,2,…Ν} is the set of products that comprise the market. 3.2.1 Share of Choices As before Ψ ⊂ Ξ is the set of products to be designed. Customers do not have a status quo product, and do not deterministically choose the highest utility product. Instead, we assume that each of the Ν alternatives has a certain probability to be selected, which is calculated with the use of a probabilistic choice model. Using BTL for example, the probability that customer i will choose product m is estimated as follows: Pim =  
   
  ∑U  
   
  U im  
   
  n∈Ξ  
   
  in  
   
  i ∈ θ, m ∈ Ψ, n ∈ Ξ,  
   
  ,  
   
  (14)  
   
  where Uim the utility that customer i assigns to product m (sum of its part-worths):  
   
  uim = ∑  
   
  ∑w  
   
  ijk  
   
  k ∈Ω j∈Φ κ  
   
  x jkm  
   
  , i ∈ θ, j ∈ Φκ, k ∈ Ω, m ∈ Ψ.  
   
  In this context the problem is formulated as the following non-linear program: max  
   
  ∑∑ P  
   
  m∈Ψ i∈θ  
   
  im  
   
  (15)  
   
  subject to  
   
  xjkm = 0, 1 integer, and (2). The objective function (15) maximizes the market share of the m products (probability to be purchased) of the company’s line. 3.2.2 Seller’s Welfare Green and Krieger (1992) presented the seller’s welfare problem, in an application of the SIMOPT program to pharmaceutical products. In order for the company’s profit to be maximized, variable (depending on attribute levels) and fixed costs for each product must be included in the objective function. The variable cost per unit for a product m is given by the following linear additive function:  
   
  cm(var) = ∑  
   
  ∑c  
   
  k ∈Ω j∈Φ κ  
   
  (var) jk  
   
  x jkm  
   
  , j ∈ Φκ, k ∈ Ω, m ∈ Ψ,  
   
  where  
   
  c (var) jk  
   
  the variable cost of attribute’s k level j for the seller.  
   
  Designing Optimal Products: Algorithms and Systems  
   
  307  
   
  A similar function is used for the fixed cost of product m:  
   
  cm( fix ) = ∑  
   
  ∑c  
   
  k ∈Ω j∈Φ κ  
   
  ( fix ) jk  
   
  x jkm  
   
  , j ∈ Φκ, k ∈ Ω, m ∈ Ψ.  
   
  If pm denotes item’s m price, the problem is formulated as the following non-linear program: ⎡  
   
  ∑ ⎢⎣( p  
   
  max m∈Ψ subject to  
   
  m  
   
  ( fix ) ⎤ − c (var) jk )∑ Pim I − cm ⎥ i∈θ ⎦  
   
  (16)  
   
  xjkm = 0, 1 integer, and (2). The objective function (16) maximizes the total seller’s profit obtained from the introduction of a line of M products.  
   
  4 Optimization Algorithms Applied to the Problem In this section we review and evaluate the most important algorithms that have been applied to the optimal product line design problem.  
   
  4.1 Greedy Heuristic Introduced by Green & Krieger (1985), this heuristic proceeds in two steps. At the first step a “good” set of reference products is created. The second step begins by choosing the best alternative among the candidate products. Then, the second alternative is selected from the reference set, which optimizes the objective function provided that the first product is already included in the market. The procedure iterates by adding one product at a time until the desired number of products in the line has been reached. In another paper, Green and Krieger (1987) describe the “best in heuristic” for developing the set of reference products. Initially the product profile that maximizes the utility u1max of customer 1 is found through complete enumeration of the attribute levels. If customer’s 2 utility for customer’s 1 best product is within a user specified fraction ε of u2max, then customer’s 2 best product is not added to the set; otherwise it is. As the method proceeds through the group of customers, all of the products currently on the set are tested to see if any are within ε of ukmax for customer k, and the previous rule is applied. The process is usually repeated through randomized ordering of the customers, and different values of ε, depending on the desired size of the set. Local optimality is not guaranteed, as it depends on the first product added to the line.  
   
  4.2 Interchange Heuristic In the same paper, Green and Krieger (1985) introduced another method where initially, a product line is randomly selected and its value is estimated. Next, each  
   
  308  
   
  S. Tsafarakis and N. Matsatsinis  
   
  alternative from the reference set is checked to see whether there exists a product in the line, the replacement of which by the specific alternative will improve the line’s value. If this condition holds, the alternative is added, and the product that is removed is the one that results in the maximum improvement of the line’s value. The process is repeated until no further improvement is possible. The authors recommend the use of the solution provided by the Greedy Heuristic, as the initial product line. The Interchange Heuristic guarantees local optimality, where the local neighborhood includes all solutions that differ from the existing by one product.  
   
  4.3 Divide and Conquer In this approach, developed by Green and Krieger (1988), the set of attributes K that comprise the product line is divided into two equal subsets K1 and K2. First, the levels of attributes belonging to K1 that are good approximations of the optimal solution are estimated. The authors suggest averaging the part-worths within each level of each attribute, and selecting for each attribute the level with the highest average. In each iteration, the values of the attributes belonging to the one subset are held fixed, while the values of the other subset are optimized through an exhaustive search. If the search space is too large for completely enumerating half of the attributes, the set of attributes can be divided into more subgroups, at the risk of finding a worst solution. Local optimality is guaranteed, where the local neighborhood depends on the number of subsets.  
   
  4.4 Coordinate Ascent Green et al. (1989), propose a heuristic that can be considered as a Coordinate Ascent implementation. A product line is initially formed at random and evaluated. The algorithm then iterates through each product attribute in a random order, and assesses each possible level. The altering of an attribute’s level is acceptable if it improves the solution’s quality. Only a single attribute change is assessed at a time (one opt version), and the algorithm terminates when no further improvement is possible. Local optimality is guaranteed, with the local neighborhood including all solutions that differ from the existing one by a single attribute.  
   
  4.5 Dynamic Programming Kohli and Krishnamusti (1987), and Kohli and Sukumar (1990) use a dynamic programming heuristic for solving the optimal product and product line design problems respectively. Here, the product (line) is built one attribute at a time. Initially, for each level of attribute B, the best level of attribute A is identified, forming in this way a number of partial product profiles, equal to attribute’s B number of levels. Next, for each level of attribute C, the best partial profile (consisting of attributes A and B) that was built in the previous step is identified. The method proceeds until all product(s) attributes have been considered. Finally, the product  
   
  Designing Optimal Products: Algorithms and Systems  
   
  309  
   
  (line) that optimizes the desired criterion is selected among the full profiles constructed. The quality of the final solution is highly dependant to the order in which the attributes are considered, thus multiple runs of the heuristic using different attribute orderings are recommended. No local optimality is guaranteed.  
   
  4.6 Beam Search Nair et al. (1995) solved the product line design problem using Beam Search. BS is a breadth-first process with no backtracking, where at any level of the search only the b (Bean Width) most promising nodes are further explored in the search tree. The method begins with K relative part-worth matrices C(k) (with elements cij = wij - wij* ), and initializes work matrices A1(•) based on C. At each stage l (layer), matrices E1(•) of combined levels are formed, by combining two matrices Al(•) at a time in the given order. Then, the b most promising combinations of levels are selected to form columns in new matrices Al+1(•) in the next layer, where it remains approximately half of the number of matrices in the previous layer. In this way, unpromising attribute levels are iteratively pruned, until a single work matrix remains. This final matrix consists of b columns, each containing a full product profile. These are the candidate alternatives for the first product in the line. For the first of the b alternatives, the data set is reduced by removing the customers who prefer this product over their status quo. The previous process is repeated for finding one second-product in the line, and iterated until M products are build that form a complete product line. The same procedure is repeated, until b complete product lines are designed, from which the one that gives the best value in the objective function is selected. The final solution depends on the way of pairing the different attribute combinations at each layer. The authors suggest a bestworst pairing, which gives better results than the random one. No local optimality is guaranteed.  
   
  4.7 Nested Partitions In the Nested Partitions implementation (Shi et al., 2001), a region is defined by a partial product line profile, for example all products that contain a specific attribute level. In each iteration a subset of the feasible region is considered the most promising, which is further partitioned into a fixed number of subregions, by determining the level of one more attribute, and aggregating what remains of the feasible region into one surrounding region. In each iteration therefore, the feasible region is covered by disjoint subregions. The surrounding region and each of the subregions are sampled using a random sampling scheme, through which random levels are assigned to the remaining attributes. The randomly selected product profiles are evaluated, in order for an index to be estimated that determines which region becomes the most promising in the next iteration. This region is then nested within the last one. If the surrounding region is found to be more promising than any of the regions under consideration, the method backtracks to a larger region using a fixed backtracking rule. NP combines global search through partitioning and sampling, and local search through calculation of the promising index. The  
   
  310  
   
  S. Tsafarakis and N. Matsatsinis  
   
  method can incorporate other heuristics to improve its performance. The authors tried a Greedy Heuristic, as well as a Dynamic Programming into the sampling step, and a Genetic Algorithm into the selection of the promising region. The results of their study indicate that the incorporation of each of the three heuristics is beneficial, with GA giving the best performance.  
   
  4.8 Genetic Algorithms Genetic Algorithms are optimization techniques that were first introduced by Holland (1975). They are based on the principle of “natural selection” proposed by Darwin a long time ago, and constitute a special case of Evolutionary Programming algorithms. In accordance with Biology science, GAs represent each solution as a chromosome that consists of genes (variables), which can take a number of values called alleles. A typical GA works as illustrated in Figure 1. Initially a set of chromosomes (population) is generated. If prior knowledge about the problem exists, we use it to create possible “good” chromosomes; else the initial population is generated at random. Next, the problem’s objective function is applied to every chromosome of the population, in order for its fitness (performance) to be evaluated. The chromosomes that will be reproduced to the next generation are then selected according to their fitness score, that is, the higher the chromosome’s fitness the higher the probability that it will be copied to the subsequent generation. Reproduction ensures that the chromosomes with the best performance will survive to the future generations, a process called “survival of the fittest”, so that high quality solutions will not be lost or altered. A mating procedure follows, where two parents are chosen to produce two offspring with a probability pc, through the application of a crossover operator. The logic behind crossover is that a chromosome may contain some “good” features (genes) that are highly valued. If two chromosomes (parents) exchange their good features then there is a great possibility that they will produce chromosomes (offspring) that will combine their good features, thus creating higher performance solutions. The expectation is that from generation to generation, crossover will produce new higher quality chromosomes. Subsequently, each of the newly formed chromosomes is selected with a probability pm to be mutated. Here one of its genes is chosen randomly and its value is altered to a new one randomly generated. Mutation produces new chromosomes that would never be created through crossover. In this way, entirely new solutions are produced in each generation, enabling the algorithm to search new paths and escape from possible local minima. Whereas reproduction reduces the diversity of the population, mutation maintains a certain degree of heterogeneity of solutions, which is necessary to avoid premature convergence of the evolutionary process. However, mutation rates must be kept low, in order to prevent the disturbance of the search process that would lead to some kind of random search (Steiner and Hruschka, 2003). Finally, if the convergence criterion has been met, the algorithm stops and the best solution so far is returned; else it continues from the population’s evaluation step.  
   
  Designing Optimal Products: Algorithms and Systems  
   
  311  
   
  Initial population Mutation Evaluation Crossover  
   
  Reproduction  
   
  no  
   
  Convergence criterion met?  
   
  yes Return best solution Fig. 1 Genetic Algorithm flowchart  
   
  4.8.1 Type of Problems Solved GAs were first applied to the optimal product design problem by Balakrishnan and Jacob (1996), who dealt with the share of choices and the buyer’s welfare problem, by employing the first choice rule. The authors provide a number of advantages that leaded them to use this approach. The search is implemented from a set of points (equal to the size of the population) rather than a single point, increasing in this way the method’s exploratory capability. GAs do not require additional knowledge, such as the differentiability of the function; instead they use the objective function directly. GAs do not work with the parameters themselves but with a direct encoding of them, which make them especially suited for discontinuous, high-dimensional, and multimodal problem domains, like the optimal product design. Later, Alexouda and Paparrizos (2001) applied GAs to the seller’s welfare problem for the optimal product line design, while Alexouda (2004), as well as Balakrishnan et al. (2004) dealt with the share of choices problem. All three approaches employed the first choice rule. The only approach that uses probabilistic choice rules is that of Steiner and Hruschka (2003), who dealt with the seller’s welfare problem. 4.8.2 Problem Representation Except for Balakrishnan et al. (2004), all other approaches adopted a binary representation scheme. In Balakrishnan and Jacob (1996), each product is represented by a  
   
  312  
   
  S. Tsafarakis and N. Matsatsinis  
   
  chromosome, which is divided into K substrings that correspond to the product’s attributes. Each substring consists of Jκ (the number of attribute’s k levels) genes that  
   
  ∑j  
   
  k  
   
  take values (alleles) 0 or 1. Hence the length of a chromosome is P= k∈Ω . A value of 1 denotes the presence of the specific level in the corresponding attribute, and a value of 0 its absence. This representation has the restriction that exactly one gene must take the value of 1 in each substring. Lets for instance assume that a personal computer consists of the attributes processor (Single-core 3,8 GHz, Core-2 2,6 GHz, Core-4 2Ghz), monitor (17’’, 19’’, 20’’, 24’’), and hard disk (200 GB, 500 GB, 750 GB). Then a Core-2 2,6 GHz with 20’’ monitor and 750 GB hard disk will be represented by the chromosome C={010 0010 001}. In Alexouda and Paparrizos (2001), Steiner and Hruschka (2003), and Alexouda (2004), a chromosome corresponds to a line of products. Each chromosome is composed of M*K substrings that represent the product’s attributes, each consisting of Jκ genes that take values 0 or 1. As before, a value of 1 denotes the presence of the specific level in the corresponding attribute, and a value of 0 its absence. The restriction that exactly one gene must take the value of 1 in  
   
  ∑j  
   
  k  
   
  each substring also holds here. The length of each chromosome is P=M k∈Ω . Referring to the personal computer example, the chromosome D={010 0010 001|100 0001 010} represents a line of two products; a Core-2 2,6 GHz with 20’’ monitor and 750 GB hard disk, and a single-core 3,8 GHz with 24’’ monitor and 500 GB hard disk. Balakrishnan et al. (2004) use an integer representation, where a chromosome corresponds to a line of products, a gene to an attribute, and the gene’s values to attribute levels. Hence, each chromosome is of length M*K, and is divided into M substrings, each representing a product in the line. Within each substring, gene k can take Jκ different values. The line of the two products described by chromosome D above, is represented in this case by chromosome E={233|142}. Here, the authors raise an issue concerning the principal of minimal redundancy, according to which each member of the space being searched should be represented by one chromosome only (Radcliffe, 1991). The integer representation scheme does not adhere to this principle, since the same line of products can be represented by M! different chromosomes. The previous PC product line, for instance, can also be represented by the chromosome E’={142|233} (the two products exchange their positions). This could cause inefficiencies in the search process, as the crossover between two identical products (E and E’) may result in two completely different sets of offspring. On the other hand, it may prove to be an advantage, as more members of the search space will probably be explored. In order to alleviate this concern, they adopt an alternative representation scheme where the substrings (products) in a chromosome are arranged in lexicographic order. That is, product 111 is before 112 which is before 121 etc. In this encoding, called sorted representation, the chromosome E would not exist. They tested both the sorted and the unsorted representations. 4.8.3 Genetic Algorithm’s Parameters Balakrishnan and Jacob (1996) represented the problem with the use of matrices. The GA population (number of chromosomes) has a size of N, and is stored in the matrix POPN*P. Customers’ preferences (part-worths for each attribute level) are  
   
  Designing Optimal Products: Algorithms and Systems  
   
  313  
   
  maintained in the matrix BETAI*P. The utilities that each of the I customers assigns to each of the N products (represented by chromosomes) are estimated in each generation, and stored in the matrix PRODUTIL= BETA*POPT. For the share of choices problem the utility of each customer’s status quo product is maintained in the matrix STATQUO. The chromosome n is evaluated through the comparison of the n-th column in PRODUTIL with the corresponding in STATQUO. The fitness of the chromosome is the number of times that PRODUTIL(i,n)>STATQUO(i,n), i=1…I, that is the number of customers that prefer the new product to their status quo. For the buyer’s welfare problem the fitness of the chromosome n is the sum of elements of the n-th column in PRODUTIL, that is the aggregate utility value for the whole set of customers. 4.8.3.1 Initialization of the population All five approaches initialize the GA population in a totally random manner. Furthermore, Alexouda and Paparrizos (2001), Alexouda (2004), and Balakrishnan et al. (2004), also assess the performance of a hybrid strategy in respect to the initialization of the population. Before running the GA, a Beam Search heuristic is applied and the best solution found is seeded into the genetic algorithm’s initial population, while the remaining N-1 chromosomes are randomly generated. The population size is set to 100 (Balakrishnan and Jacob, 1996), 150 (Alexouda and Paparrizos, 2001; Steiner and Hruschka, 2003), 180 (Alexouda, 2004), or 400 (Balakrishnan et al., 2004). 4.8.3.2 Reproduction Except for Steiner and Hruschka (2003), all other approaches adopt an elitist strategy for the process of reproduction, where the F fittest chromosomes are copied intact into the next generation. Such an approach ensures that the best chromosomes will survive to the subsequent generations. The value of F ranges from 4N/10 (Alexouda and Paparrizos, 2001; Alexouda, 2004), to N/2 (Balakrishnan and Jacob, 1996; Balakrishnan et al., 2004). Steiner and Hruschka (2003) employ a binary tournament selection procedure, where N/2 pairs of chromosomes are randomly selected with replacement, and from each pair only the chromosome with the higher fitness value survives to the succeeding generation. This is a semirandom process, which ensures that the chromosomes with higher fitness values have more probabilities to survive. 4.8.3.3 Crossover In the approaches that adopt a binary representation scheme, the unit of interest in the crossover procedure is the substring, in order for feasible solutions to be produced. In Steiner and Hruschka (2003) for example, who use one-point crossover with probability pc=0.9 and random selection of the cross site, the crossover of the two parents A = {010 0010 001|100 0001 010} and B = {100 0100 010|010 0010 100}, after the second substring will generate the two offspring  
   
  314  
   
  S. Tsafarakis and N. Matsatsinis  
   
  A’ = {010 0010 010|010 0010 100} B’ = {100 0100 001|100 0001 010}.  
   
  and  
   
  Except for the above approach, the other ones employ a uniform crossover with the probability pc taking the values 0.4 (Alexouda and Paparrizos, 2001), 0.45 (Alexouda, 2004) and 0.5 (Balakrishnan and Jacob, 1996). In the approach that employs an integer representation scheme, the unit of interest in crossover is the gene. If for instance, the two parents S={122|323} T={141|421},  
   
  and  
   
  exchange their second and sixth genes, this will generate the offspring S’={142|321} T’={121|423}.  
   
  and  
   
  When the sorted representation is used, the offspring are sorted in lexicographic order after the crossover operation. According to Radcliffe (1991), a forma specifies at certain chromosome’s positions (called defining positions) particular values that all its instances must contain. That is, if a chromosome η is an instance of a forma β, then η and β both contain the same values at the specified positions. Chromosomes S and T, for example, both belong to the forma: β = 1** *2*, where the * denotes a “don’t care” value. The principle of respect defines that the crossover of two chromosomes that belong to same forma must produce offspring also belonging to the same forma. Whereas in the unsorted representation the crossover is “respectful”, the property does not hold in the sorted representation, due to the ordering of the attributes after the crossover. 4.8.3.4 Mutation Except for the one with the integer representation scheme, in all other approaches the mutation operator is applied at the substring level. Chromosomes are randomly selected (without replacement) with a probability pm (mutation rate). An attribute (substring) of the selected chromosome is randomly picked and its level is altered. If, for instance, chromosome A is chosen to be mutated at the second substring, a potential mutated chromosome will be A’’={010 1000 001|100 0001 010}. In Balakrishnan et al. (2004), the mutation takes place at the gene level, while two different mutation operators are used. Except for the standard mutation operator, a hybridized one is employed, which uses as a mutator chromosome the best solution found by the Beam Search heuristic. Whenever a chromosome is selected for mutation, a gene is randomly selected and its value is either randomly changed using the standard mutation operator, or altered to the value contained in the specific attribute of the mutator chromosome. In this way the good attribute values of the BS best solution will be copied to the GA population. On the other hand, this may result in premature convergence to the alleles of the mutator string. In order to  
   
  Designing Optimal Products: Algorithms and Systems  
   
  315  
   
  avoid this, the two mutator operators have equal probability to be applied. The mutation rate takes a wide range of values: 0.05 (Steiner and Hruschka, 2003), 0.1 (Alexouda, 2004), 0.2 (Alexouda and Paparrizos, 2001), 0.3 (Balakrishnan and Jacob, 1996), or 0.4 (Balakrishnan et al., 2004). 4.8.3.5 Stopping criterion From the reproduced chromosomes, plus the offspring plus the mutated chromosomes, only the N fittest are maintained to the next generation, and the algorithm iterates until a stopping criterion is met. Balakrishnan and Jacob (1996), Steiner and Hruschka, (2003), and Balakrishnan et al. (2004) employ a moving average rule, where the algorithm terminates when the percentage change in the average fitness of the best three chromosomes over the five previous generations is less than 0.2% (convergence rate). In the other two approaches the procedure terminates when the best solution does not improve in the last 10 (Alexouda and Paparrizos, 2001), or 20 (Alexouda, 2004) generations. 4.8.4 Performance Evaluation 4.8.4.1 Genetic Algorithm vs. Dynamic Programming Balakrishnan and Jacob (1996) compared the results of their approach and the Dynamic Programming approach (Kohli and Krishnamusti, 1987) with the complete enumeration solutions in 192 data sets, in both the share of choices and buyer’s welfare problems. A full factorial experimental design was generated using the factors and levels presented in Table 4. Table 4 Factors and levels used in the experiment  
   
  Factor Number of attributes Number of attribute levels Number of customers  
   
  Levels 4 2 100  
   
  6 3 200  
   
  8 4 300  
   
  5 400  
   
  The part-worths were randomly generated following a normal distribution, and normalized within each customer to sum to 1. Random was also the generation of each customer’s status quo product. Four replications were performed in each case resulting in a total of 192 data sets. In the share of choices problem, the average best solution provided by GA was 99.13% of the optimal product profile found by complete enumeration, while the same value for the DP was 96.67%. GA also achieved a tighter standard deviation (0.016) than that of DP (0.031). In the buyer’s welfare problem the respective values were 99.92% for the GA with 0.0028 std, and 98.76% for the DP with 0.0165 std. The number of times that the optimal solution was found (hit rate) was 123 for the GA and 51 for the DP in the share of choices, and 175 for the GA and 82 for the DP in the buyer’s welfare. The performance of GA was also compared with that of DP in two larger problems of  
   
  316  
   
  S. Tsafarakis and N. Matsatsinis  
   
  sizes 326,592 and 870,912, where an exhaustive search was infeasible in tractable time. The data sets consisted of 200 customers, and 9 attributes that take (9,8,7,6,2,2,3,3,3) or (9,8,8,7,6,2,2,3,3) levels, while ten replications for each data set were performed. GA showed a better, worse, and equal performance compared to DP in 11, 3, and 6 data sets for the share of choices, and in 8, 3, and 9 data sets respectively for the buyer’s welfare. 4.8.4.2 Genetic Algorithm vs. Greedy Heuristic Steiner and Hruschka (2003) compared the results of their approach and the Greedy Heuristic approach (Green and Krieger 1985) with the complete enumeration solutions, in the seller’s welfare problem. A factorial experimental design was generated using the factors and levels presented in Table 5. Table 5 Factors and levels used in the experiment  
   
  Factor Number of attributes Number of attribute levels Number of products in the line Number of competing firms  
   
  Levels 3 2 2 1  
   
  4 3 3 2  
   
  5 4 4 3  
   
  From the 81 different cases a subset of 69 was considered. Four replications were performed under each case, resulting in a total of 276 problems solved, where customer part-worths, attribute level costs, and competitive products configuration were randomly generated. The value of the solution found by GA was never less than 96.66% of the optimal (minimum performance ratio), while the corresponding value for the GH was 87.22%. The optimal solution was found in 234 cases by the GA, and in 202 cases by the GH, which corresponds to a hit ratio of 84.78% and 73.19% respectively. The solution found by GA was strictly better than that found by GH in 66 cases, and strictly worse in only 25. 4.8.4.3 Genetic Algorithm vs. Beam Search Alexouda and Paparrizos (2001), Alexouda (2004), and Balakrishnan et al. (2004) compared the performance of GA with that of BS, which was considered the state of the art approach of the time. The first two approaches make a comparison of the two methods with a full search method in the seller’s welfare and share of choices problems respectively. Eight small problems were solved using different values for the number of products in the line (2, 3), number of attributes (3, 4, 5, 6, 7, 8), and number of levels (3, 4, 5, 6). Ten replications were performed in each case, while the number of customers was kept constant to 100. The results are shown in Table 6.  
   
  Designing Optimal Products: Algorithms and Systems  
   
  317  
   
  Table 6 Results of the comparison of the two methods  
   
  Seller’s welfare 73.75% 41.25% 53.75% 12.50% 0.9958 0.9806  
   
  GA found optimal BS found optimal GA outperforms BS BS outperforms GA GA/optimal BS/optimal  
   
  Share of choices 77.50% 45% 33.75% 12.50% 0.9951 0.9882  
   
  Furthermore, they compared the performance of a GA with completely random initialization (GA1), a GA where the initial population is seeded with the best BS solution (GA2), and a BS heuristic, in problems with larger sizes where complete enumeration is unfeasible. The number of customers was set to either 100 or 150 (Table 7). Table 7 Results of the comparison of the three methods  
   
  GA1 outperforms BS BS outperforms GA1 GA2 outperforms BS GA1 outperforms GA2 GA2 outperforms GA1 GA1/ BS GA2/ BS  
   
  Seller’s welfare I=100 I=150 93.88% 93.33% 6.11% 5.83% 86.66% 80.83% 1.0962 1.0794 1.0853 1.0702  
   
  Share of choices I=100 I=150 47.92% 53.33% 33.33% 31.25% 40% 43.33% 31.67% 35% 45.83 43.33% -  
   
  Balakrishnan et al. (2004) defined eight different types of GA and hybrid GA procedures (Table 8). Table 8 Genetic Algorithm techniques defined  
   
  Type GASM GASSM GAHM GASHM GASMBS GASSMBS GAHMBS GASHMBS  
   
  Representation Unsorted Sorted Unsorted Sorted Unsorted Sorted Unsorted Sorted  
   
  Integration with BS Hybrid Mutation Seed with BS No No No No Yes No Yes No No Yes No Yes Yes Yes Yes Yes  
   
  318  
   
  S. Tsafarakis and N. Matsatsinis  
   
  A 2x2 full factorial experimental design was employed using the factors number of products in the line (4 or 7), and number of attributes (7 or 9), with respective attribute levels (6 3 7 4 5 3 3) and (7 3 5 5 6 3 3 7 5), while the number of customers was 200. Two replications were performed in each case. The values of GA parameters are illustrated in Table 9. Table 9 Values of the Genetic Algorithm parameters  
   
  Parameter Mutation rate Population size Number of attributes to crossover (N=4, K=7) Number of attributes to crossover (N=4, K=9) Number of attributes to crossover (N=7, K=7) Number of attributes to crossover (N=7, K=9) Number of generations  
   
  Value 0.04 400 10 17 12 21 500  
   
  After experimentation it was found that a mutation rate less than 0.04 resulted in a premature convergence to suboptimal solutions, while higher values did not offered a substantial improvement. In addition, higher number of attributes to crossover was more beneficial in problems with smaller number of products in the line, as compared to problems with larger product lines. The results are presented in Table 10. Table 10 Results of the comparison of the 10 methods  
   
  Method GASM GASSM GAHM GASHM GASMBS GASSMBS GAHMBS GASHMBS BS CPLEX  
   
  Best solution found (percentage of cases) 12.5% 12.5% 12.5% 12.5% 25% 0 0 0 0 50%  
   
  Average approximation of best solution 94.44% 94.21% 94.16% 94.15% 94% 93.35% 92.82% 92.32% 89.53% 82.68%  
   
  Another full factorial design (2x2x2) was employed, in order to asses the impact of the number of products in line (4 or 7), the number of attributes (7 or 9), and the presence or absence of attribute importance, to the following variables of interest:  
   
  Designing Optimal Products: Algorithms and Systems  
   
  • • •  
   
  • • • •  
   
  319  
   
  The best GA solution. The ratio of the best GA solution to the best BS solution. The number of unique chromosomes in the final population: o With the best fitness. o With fitness within the 5% of the best solution. o With fitness between the 5% and 10% of the best solution. The worst chromosome in the final population. The average fitness in the final population. The standard deviation of chromosomes’ fitness in the final population. The number of generation at which the best solution was found.  
   
  Two product lines are considered different when at least one product exists in the one but not in the other, while two products are considered to be different if they differ in the level of at least one attribute. Ten replications were performed in each case resulting in a total of 80 data sets. The eight GA instances, as well as the BS heuristic, were run 10 times for each data set, hence 6400 different GA runs were performed. The results showed that GA techniques performed better or equally well as compared to BS in the 6140 cases (95.93%), performed strictly better in 5300 (82.81%), and underperformed in 260 (4.07%). The best GA solution reached a maximum difference of 12.75% with that of the BS, and was on average 2.6% better. The maximum difference reached when the BS solution was better was 6.1%. The hybridized GA methods always produced solutions at least as good as the BS solution, and in the 80.2 % of cases produced strictly better solutions. An interesting finding is that GA techniques which employ the unsorted representation, the standard mutation, and do not seed initial population with the best BS solution, showed the best average performance. A possible reason is the fact that the sorted representation scheme does not adhere to the principle of respect regarding the crossover operation. In addition, the incorporation of the best BS solution into the initial GA population, as well as the hybrid mutation operator probably make the algorithm converge to an area of solutions around the seeded BS solution, which in some cases may be suboptimal. Some loss in diversity of the final population may also be exhibited, as the integrated techniques displayed the worst results in respect to the number of unique chromosomes in the final population. Furthermore, integrated techniques suffer from premature convergence, as they tend to produce the best solution earlier, and result in the lowest standard deviation of chromosomes’ fitness in the final population. Particularly, GA techniques without any hybridization (GASM, GASSM) provided final solutions at least as good as that of the hybridization techniques in 52.37% of cases on average, and strictly better on 35.12%. This indicates that the integration with the BS heuristic does not improve the quality of the solution. The number of products and number of attributes significantly affect (p 0.3161 = m31({L}), suggests the respondent R31 is more associated with a high level of web experience, which is the incorrect segmentation in its case.  
   
  460  
   
  M.J. Beynon and K. Page  
   
  The results concerning another respondent R167 (known to have low level of web experience) are given in Table 5, with regard to the respective response BOEs m167,i(⋅). Table 5 Response values and response BOEs for the respondent R167, from CaRBS analysis of incomplete web experience data set Survey question R167 (actual) R167 (standardised) m167,i({H}) m167,i({L}) m167,i({H, L})  
   
  P1 3 −0.4761 0.0000 0.3360 0.6640  
   
  P2 0.0000 0.0000 1.0000  
   
  P3 0.0000 0.0000 1.0000  
   
  P4 6 1.7983 0.2962 0.0000 0.7038  
   
  P5 0.0000 0.0000 1.0000  
   
  Survey question R167 (actual) R167 (standardised) m167,i({H}) m167,i({L}) m167,i({H, L})  
   
  P6 2 −2.1006 0.0000 0.3924 0.6076  
   
  P7 5 0.6307 0.0000 0.0000 1.0000  
   
  P8 0.0000 0.0000 1.0000  
   
  P9 6 0.7596 0.3088 0.0000 0.6912  
   
  P10 6 0.9686 0.0000 0.0000 1.0000  
   
  In Table 5, a number of the response values, from the respondent R167, are shown to be missing (denoted with ‘-’), namely the survey questions, P2, P3, P5 and P8. For each of these questions, their respective response BOEs offer only total ignorance (as stated earlier). Also assigned total ignorance are the response BOEs associated with the survey questions, P7 and P10, not because the value were missing, but that the concomitant control variable values have meant only total ignorance is assigned to them. The remaining response BOEs offer more than only ignorance to either m167,i({H}) or m167,i({L}), which from their combination, produce the respondent BOE m167(⋅), found to be, m167({H}) = 0.2986, m167({L}) = 0.4184 and m167({H, L}) = 0.2830. This respondent BOE, with m167({H}) = 0.2986 < 0.4184 = m167({L}), suggests the respondent R167 is more associated with low level of web experience, which is the correct segmentation in this case. The results concerning individual respondents, and their low or high level of web experience segmentation, are next graphically considered, see Figure 3, with response and respondent BOEs shown for four respondents, as simplex coordinates in simplex plots (simplex plot is the standard domain with CaRBS (see Figure 1c) - with each vertex identifying where there would be certainty in their segmentation to having low (L) or high (H) web experience, or ignorance (H, L), a vertical dashed line discerns between where there is majority belief of segmentation to L or H. Figure 3 shows the evidence from survey question responses and final predicted segmentation of the respondents, R31 (3a), R167 (3b), R216 (3c) and R280 (3d). In each simplex plot shown, the grey shaded sub-domain of a simplex plot, at the top, defines where the respective response BOEs are able to exist (individually considered low level measurements whereby a level of ignorance is present in each response BOE - through the bounds on the Bi control variables, see Figure 1).  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  461  
   
  Fig. 3 Simplex plot based segmentation evidence of individual respondents, R31 (3a), R167 (3b), R216 (3c) and R280 (3d), from CaRBS analysis of incomplete web experience data set  
   
  With respondent R31 (Figure 3a - known to have low web experience), the ten circles in the shaded domain are the response BOEs representing the evidence from their responses to the survey questions P1, P2, …, P10 (labels for m31,Pi(⋅) see Table 4), with the lower circle shown the final respondent BOE m31(⋅), found from the combination of the m31,i(⋅) (compare with example in Figure 1). The discussion of this series of results on the respondent R31 follows the discussion surrounding Table 4, given previously. For example, the combination of the evidence in the response BOEs produces the respondent BOE m31(⋅), shown to be to the right of the vertical dashed line in Figure 3a, indicating their predicted segmentation to being high experienced, incorrect in this case. The results for the respondent R167 (Figure 3b) similarly follow that surrounding the details reported in Table 5. Two further respondents are considered in Figure 3, using the simplex plot representation, namely R216 and R280, which are known to both have high levels of web experience. The results for the respondent r280 (Figure 3c), show evidence from their responses to the survey questions supporting its low (P1, P4 and P8) and high (P5 and P9) web experience segmentation, resulting in a respondent BOE  
   
  462  
   
  M.J. Beynon and K. Page  
   
  offering weak evidence towards high level of web experience (correct segmentation). The results for the respondent r280 (Figure 3d), show strong supporting evidence from the majority of responses to the ten survey questions, with the implication being a very strong segmentation to them having high web experience, noticeably more certain in its predicted segmentation than for the other three respondents described. The process of positioning the segmentation of a respondent, in a simplex plot, on their predicted level of web experience, can be undertaken for each of the 300 respondents considered, see Figure 4.  
   
  Fig. 4 Simplex plot based representation of segmentation of respondents with low (4a) and high (4b) levels of web experience, from CaRBS analysis of incomplete web experience data set  
   
  The simplex plots in Figure 4, contain the simplex coordinates, denoted by circles and crosses, representing the presented respondent BOEs of known low (4a) and high (4b) web experienced respondents, respectively. The different heights of the simplex coordinates (circles and crosses) in the simplex plots indicate variation in the levels of ignorance associated with the respondents’ segmentations. One reason for the variation in the level of ignorance in a respondent’s segmentation is the level of incompleteness in their responses to the questions considered, as well as conflicting responses. At the limit, in Figure 4a, there is a simplex coordinate at the {H, L} vertex, showing a respondent BOE for a respondent has only total ignorance in its predicted segmentation, due to a large number of missing values present amongst their responses, and total ignorance assigned to the responses they actually made. The overall accuracy of this segmentation is based on whether the simplex coordinates representing respondent BOEs are on the correct side of the vertical dashed lines (low and high web experience to the left and right respectively). In summary, a total of 214 out of 300 (71.133%) respondents’ have correct predicted segmentation (118 of 171 (69.006%) low and 96 of 129 (74.419%) high). Throughout the descriptions of the predicted segmentation of the four respondents described in Figure 3, the evidence from their responses to the ten survey  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  463  
   
  questions varied amongst the respondents. This variation potentially exists in the evidential relevance (quality) of the responses to the survey questions from all the respondents. The next results presented concern the relevance, discerning power, of each survey question used in segmenting the respondents’ web experience. They have implications for how a website, or online retail presence is designed and communicated to differing segments of the target market categorized by high and low web usage. For example, if the item “purchasing and booking goods on the web is rather complicated” is reported as more important for users with low usage experience, targeting this segment of web users with specific communications to help educate and inform them about the booking process, could increase their overall satisfaction and positive attitudes with purchasing online. This information could also be used to inform web designers and marketing personnel on recommendations for improvement for effective transactional web design. As such the quality and accuracy of the data being analysed about not only a consumers perceptions, but also their web experience (i.e., unbiased), is of paramount importance to ensure correct and accurate results upon which electronic marketing decisions are made. The elucidation of this relevance uses the average response BOEs defined previously, which accrue the level of evidence from survey questions to certain equivalence classes of respondents (known to have low and high web experience in this case), and as BOEs, they can be graphically reported using simplex plots, see Figure 5 (with only the grey shaded sub-domain shown - where response BOEs exist).  
   
  Fig. 5 Relevance of each survey question to the segmentation of respondents, from CaRBS analysis of incomplete web experience data set  
   
  In Figure 5, each simplex coordinate labelled ‘?L’ and ‘?H’ represents the average response BOEs associated with survey question P?, from known low and high web experienced respondents, respectively. For example, the average response BOE represented by 9H is found from the average of the response BOEs for survey question P9 of respondents with known high web experience (not  
   
  464  
   
  M.J. Beynon and K. Page  
   
  including missing values). The further down the simplex plot sub-domain the ?L and ?H points appear the more relevance of the survey question (less ignorance) to the segmentation of low and high web experienced respondents, and the increased horizontal distance between respective points denotes the lesser ambiguity the survey question offers in the segmentation. In the results in Figure 5, it follows, the survey questions, P1, P6 and P9 (also P8 to a lesser extent), are indicated to have the more relevance (than the others), based on the responses of the respondents, since they are lowest down the simplex plot sub-domain. In terms of ambiguity, the horizontal distance between the 9L and 9H simplex coordinates ,associated with the survey question P9, identify its limited associated ambiguity in what the survey question suggests with respect to low and high web experienced respondents, when compared with the other survey questions. Further interpretation can be given on the other survey questions considered, even for question P10, a rating an individuals of overall interest in the web for shopping, which from Figure 5, has little relevance to this study due to its position (10L and 10H) near the {H, L} vertex (large level of ignorance associated with it). This relevance could be attributed to the contextual nature of web purchase, in that interest could be moderated by product category, age or even gender, allowing for further segmentation.  
   
  5.2 CaRBS Analysis of ‘Completed’ Web Experience Data Set This sub-section undertakes a further CaRBS analysis on the web experience data set, but here the missing values in the incomplete web experience data set, are now externally managed using mean imputation (Huisman 2000). It follows, all the respondents are retained in the data set (unlike when case deletion is employed), now termed a completed web experience data set, with the missing values replaced by the mean of the present values of the respective survey question. To again configure a CaRBS system, to optimally segment the respondents to having low or high web experience, through the respondents’ survey question response values, they were again standardized prior to the employment of TDE, allowing consistent domains over the control variables incumbent in CaRBS, set as; –2 ≤ ki ≤ 2, –1 ≤ θi ≤ 1, 0 ≤ Ai < 1 and Bi = 0.4 (see Beynon 2005b). With standardized response values considered, and employing mean imputation, the missing values were now assigned the value 0.0000, since standardized data has mean zero (and unit standard deviation). The TDE method was again employed to configure a CaRBS system, based on the previously defined TDE-based parameters, and run five times, each time converging to an optimum value, the best out of the five runs being OB = 0.3689. Like in the CaRBS analysis of the incomplete web experience data set, this value is noticeably above the lower bound, and is actually slightly lower than the previously found OB value (0.702). This OB value would suggest an improved level of segmentation has been achieved by the completing of the incomplete web experience dates set (using mean imputation). The resultant control variables, ki, θi and Ai (Bi = 0.4), found from the best TDE run are reported in Table 6.  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  465  
   
  Table 6 Control variables values associated with the configuration of CaRBS system, in the analysis of completed web experience data set Parameter ki  
   
  θi Ai Parameter ki  
   
  θi Ai  
   
  P1 2.0000 −0.1204 0.6714  
   
  P2 −2.0000 0.1453 0.6873  
   
  P3 2.0000 −1.0000 0.8902  
   
  P4 2.0000 0.4895 0.7288  
   
  P5 2.0000 −0.1262 0.5628  
   
  P6 2.0000 0.2410 0.3818  
   
  P7 2.0000 0.2939 0.6623  
   
  P8 2.0000 −0.4040 0.7801  
   
  P9 2.0000 0.1092 0.2265  
   
  P10 −2.0000 0.6070 0.9820  
   
  The results in Table 6, concerning ki, again show the same values and directions of association of the evidential contribution of the survey questions. The interesting feature here, is that the values found for the other control variables, θi and Ai, are mostly dissimilar to those found in the previous analysis (see Table 3). This is the first evidence on the impact of the external management of missing values, namely that the control variables found are different, so the configured CaRBS system here is different to that found in the previous analysis. Further evidence on this impact is shown by considering, in detail, the two respondents, R31 and R167, first considered in the previous analysis. Considering the respondent R31, the construction of the response BOE associated with the question P1 is again described. For the respondent R31, P1 = 2.000, when standardised, it is v = −1.1891 (see Table 7 presented later), then; cfP1(−1.1891) =  
   
  1 1 = = 0.1055, 1 + 8.4765 1 + e − 2.0000( −1.1891+ 0.1204)  
   
  using the control variables in Table 6. This confidence value is used in the expressions making up the triplet of mass values in the response BOE m31,P1(⋅), namely; m31,P1({H}), m31,P1({L}) and m31,P1({H, L}), found to be; 0.4 0.6714 × 0.4 0.1055 − = 0.1285 − 0.8173 1 − 0.6714 1 − 0.6714 = −0.6888 < 0.0000 so = 0.0000, −0.4 m31,P1({L}) = 0.1055 + 0.4 = −0.1285 + 0.4 = 0.2715, 1 − 0.6714 m31,P1({H, L}) = 1 − 0.0000 − 0.2715 = 0.7285.  
   
  m31,P1({H}) =  
   
  For the respondent R31, this response BOE is representative of all the associated response BOEs m31,i(⋅), presented in Table 7 (using their standardised response values).  
   
  466  
   
  M.J. Beynon and K. Page  
   
  Table 7 Response values and response BOEs for the respondent R31, from CaRBS analysis of completed web experience data set Parameter R31 (actual) R31 (standardised) m31,i({H}) m31,i({L}) m31,i({H, L})  
   
  P1 2 −1.1891 0.0000 0.2715 0.7285  
   
  P2 7 2.1122 0.0000 0.3754 0.6246  
   
  P3 4 −0.3316 0.0000 0.0000 1.0000  
   
  P4 4 0.1691 0.0000 0.0000 1.0000  
   
  P5 7 2.0537 0.3885 0.0000 0.6115  
   
  Parameter R31 (actual) R31 (standardised) m31,i({H}) m31,i({L}) m31,i({H, L})  
   
  P6 6 1.3385 0.3352 0.0000 0.6648  
   
  P7 5 0.6307 0.0000 0.0000 1.0000  
   
  P8 2 −1.2187 0.0000 0.1018 0.8982  
   
  P9 6 0.7596 0.2893 0.0000 0.7107  
   
  P10 7 1.5592 0.0000 0.0000 1.0000  
   
  A consequence of the response BOEs shown in Table 7, through their combination, is the resultant respondent BOE, termed m31(⋅), and found to be: m31({H}) = 0.5014, m31({L}) = 0.2949 and m31({H, L}) = 0.2037. This respondent BOE shows predominant association to high level of web experience, which is the incorrect segmentation in its case. Most interesting in these results concerning the respondent R31, is what changes there is in its segmentation to that found in the previous analysis (when the missing values in the data set were not managed in any way - retained as missing). In terms of the respondent BOE, there is little difference in these BOEs between when the incomplete and completed web experience data sets were considered (there are limited differences in the individual response BOEs - compare the details presented in Table 4 and Table 7). A further set of results are given with respect to the respondent R167, see Table 8. Table 8 Response values and response BOEs for the respondent R167, from CaRBS analysis of completed web experience data set Parameter R167 (actual) R167 (standardised) m167,i({H}) m167,i({L}) m167,i({H, L})  
   
  P1 3 −0.4761 0.0000 0.0000 1.0000  
   
  P2 0.0000 0.0000 0.0000 1.0000  
   
  P3 0.0000 0.0000 0.0000 1.0000  
   
  P4 6 1.7983 0.2997 0.0000 0.7003  
   
  P5 0.0000 0.0000 0.0000 1.0000  
   
  Parameter R167 (actual) R167 (standardised) m167,i({H}) m167,i({L}) m167,i({H, L})  
   
  P6 2 −2.1006 0.0000 0.3941 0.6059  
   
  P7 5 0.6307 0.0000 0.0000 1.0000  
   
  P8 0.0000 0.0000 0.0000 1.0000  
   
  P9 6 0.7597 0.2893 0.0000 0.7107  
   
  P10 6 0.9686 0.0000 0.0000 1.0000  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  467  
   
  Using the response BOEs reported in Table 8, the resultant respondent BOE, termed m167(⋅), and found to be; m167({H}) = 0.3795, m167({L}) = 0.2445 and m167({H, L}) = 0.3760. This respondent BOE suggests association to high level of web experience, an incorrect segmentation in this case. The results here are in contrast to the findings from the analysis of the incomplete web experience data set, where a correct segmentation was found. These findings on the respondent R167 demonstrate clearly the potential negative impact of externally managing the presence of missing values in a data set (in any way). Comparing the results in Tables 5 and 8, on the response BOEs used in constructing the respective respondent BOEs (from their combination), there is an impacting difference in the response BOEs m167,P1(⋅) found. That is, in the analysis of the completed data set, the response BOE m167,P1(⋅) offers only total ignorance, instead of the evidence towards their low level of web experience as offered by m167,P1(⋅) in the analysis of the incomplete data set. A visual representation of the evidential support of the response BOEs and subsequent respondent BOEs are given in Figure 6, for the four respondents, R31 (6a), R167 (6b), R216 (6c) and R280 (6d).  
   
  Fig. 6 Simplex plot based segmentation evidence of individual respondents, R 31 (6a), R 167 (6b), R 216 (6c) and R280 (6d), from CaRBS analysis of completed web experience data set  
   
  468  
   
  M.J. Beynon and K. Page  
   
  The primary benefit of these simplex plots here, is in the ability to compare the segmentation results of these respondents with their segmentation in the previous analysis (see Figure 3). For the respondent R31, as mentioned previously, there is limited change in the resultant respondent BOE, but some minor positional changes of the simplex coordinates representing the response BOEs. For the respondent R167, the difference in the two analyses is more impacting than for R31, where the positional change of the respondent BOE m167(⋅) now to the right of the vertical dashed line is shown in Figure 6b, instead of being the left in Figure 3b. Inspection of the response BOEs, associated with the respondent R167, shows the lack of evidential contribution now by their response to survey question P1 compared to in the previous analysis. The other two respondents R 216 (6c) and R280 (6c), have similar results from both analyses, in terms of the positions of the respective respondent BOEs, but further inspection does show changes in the evidential contributions of the response BOEs. The process of positioning the segmentation of a respondent, in a simplex plot, on their predicted level of web experience, can be again undertaken for each of the 300 respondents considered, see Figure 7.  
   
  Fig. 7 Simplex plot based representation of segmentation of respondents with low (7a) and high (7b) levels of web experience, from CaRBS analysis of completed web experience data set  
   
  In Figure 7, the respondent BOEs are shown as circles and crosses (simplex coordinates), depending on whether the respondents’ are known to have low or high levels of web experience. While the spread of the simplex coordinates shown appears similar to those reported in Figure 4 (from the CaRBS analysis of the incomplete web experience data set), there are changes. One noticeable change, is the non-presence of a simplex coordinate at the {H, L} vertex in Figure 7a, as there was in Figure 4a. This is due to the replacement of the missing response values of this respondent, which has meant some evidence has been assigned to its response BOEs, and so its movement away from the top vertex. The overall accuracy of this segmentation is again based on whether the simplex coordinates representing respondent BOEs are on the correct side of the  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  469  
   
  vertical dashed lines (low and high web experience to the left and right, respectively). In summary, a total of 214 out of 300 (71.133%) respondents’ have correct predicted segmentation (119 of 171 (69.591%) low and 95 of 129 (73.643%) high). The overall segmentation accuracy is the same as in the CaRBS analysis of the incomplete web experience data set, but the separate accuracies of the low and high web experienced respondents do differ slightly. To consider the relevance of the individual questions, the average response BOEs defined previously are again used, graphically reported in simplex plots in Figure 8 (grey shaded sub-domain shown only again).  
   
  Fig. 8 Relevance of each survey question to the segmentation of respondents, from CaRBS analysis of completed web experience data set  
   
  The relevance results reported in Figure 8 indicate the survey questions, P6 and P9, are noticeably more relevant than the other survey questions (their positions lower down the simplex plot sub-domain shown). When comparing with the same results in Figure 5, from the CaRBS analysis of the incomplete web experience data set, the relevancies of the two survey questions, P1 and P8, have changed noticeably. The changes in the relevancies of the survey questions, P1 and P8, between the two CaRBS analyses demonstrates most clearly the impact of managing the missing values present in a data set. Within the marketing context, here we can see that items P6 and P9 suffer less relevance inference from the presence of missing data than the other, previously found P1 and P8 more relevant items.  
   
  6 Future Trends The potential future trends that can be considered, from this chapter, is the recognition that there is the possibility that the external management of missing values in incomplete data set can impact negatively on the inference that subsequent analysis allows. The use of the CaRBS technique on the original incomplete and a completed version of the web experience data set, through the comparison of the results,  
   
  470  
   
  M.J. Beynon and K. Page  
   
  clearly shows the variation in inference that could be the consequence of the management of missing values. It of course requires the existence of techniques, like CaRBS, that enable the analysis of incomplete data sets that a change of mind set towards the presence of missing values can take place in the future.  
   
  7 Conclusions One of the most critical issues in model formulation and marketing analytics is the treatment of missing data, and subsequently, their management in marketing intelligent systems, causing problems through the loss of statistical power and quality in parameter estimates. As such, the standard/traditional solutions, in the marketing literature, have been their external management. The CaRBS technique employed throughout this chapter offers a novel analysis approach, with its inclusion of the notion of ignorance in the evidence and final segmentation of the respondents to their association with having low or high web experience. A feature of the utilisation of the CaRBS technique is its ability to analyse incomplete data, in the case of the web experience data set, missing responses by respondents to certain survey questions. This is an important development, through the use of the soft computing associated methodology Dempster-Shafer theory in the CaRBS technique, since there has been limited ability to analyse such incomplete data sets, without having to externally manage the missing values present in some way. Indeed, this is a clear example of how soft computing approaches, in general, can offer new incites in how to undertake the pertinent analysis of marketing data, and creation of intelligent marketing intelligent systems. The whole point of conducting segmentation analyses in marketing is to be able to provide marketers with useful information about why some segments are similar whilst others differ (Hansen 2005). However, with the presence of incomplete data (with missing values), the ability to develop reliable segment profiles with confidence decreases. By using a technique that enables researchers to analyse the relevance (quality) of the data, or level of bias in the dataset at either individual (respondent) level or variable item (question) level, it enables them to strategically discern the quality of the dataset for more informed and correct interpretation. This allows for more accurate marketing insight generation upon which strategic marketing decisions are made. This chapter has discussed and applied the use of a technique for the realistic analysis of incomplete data collected through an Internet survey about on consumer attitudes towards online shopping and past usage experience to aid reliable and valid segmentation analysis.  
   
  References Babin, B.J., Darden, W.R., Griffin, M.: Work and/or fun: Measuring hedonic and utilitarian shopping value. Journal of Consumer Research 20, 644–656 (1994) Ballantine, P.W.: Effects of Interactivity and Product Information on Consumer Satisfaction in an Online Retailing Setting. International Journal of Retailing and Distribution Management 33(6), 461–471 (2005)  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  471  
   
  Bellenger, D.N., Korgaonkar, P.K.: Profiling the Recreational Shopper. Journal of Retailing 56, 77–91 (1980) Beynon, M.J.: A Novel Technique of Object Ranking and Classification under Ignorance: An Application to the Corporate Failure Risk Problem. European Journal of Operational Research 167, 493–517 (2005a) Beynon, M.J.: A Novel Approach to the Credit Rating Problem: Object Classification Under Ignorance. International Journal of Intelligent Systems in Accounting, Finance and Management 13, 113–130 (2005b) Beynon, M.J.: Optimising Object Classification: Uncertain Reasoning based Analysis using CaRBS Systematic Search Algorithms. In: Vrakas, D., Vlahavas, I. (eds.) Artificial Intelligence for Advanced Problem Solving, pp. 234–253. IDEA Group Inc., PA (2008) Brengman, M., Geuens, M., Weijters, B., et al.: Segmenting Internet Shoppers Based On Their Web-Usage-Related Lifestyle: A Cross-Cultural Validation. Journal of Business Research 58(1), 79–88 (2005) Chang, S.: Internet segmentation: state-of-the-art marketing applications. Journal of Segmentation Marketing 2(1), 19–34 (1998) Chen, Z.: Data Mining and Uncertain Reasoning: An Integrated Approach. John Wiley, New York (2001) Christian, L.M., Dillman, D.A., Smyth, J.D.: Helping Respondents Get it Right the First Time: The Influence of Words, Symbols, and Graphics in Web Surveys. Public Opinion Quarterly 71(1), 113–125 (2007) Davis, F.D., Bagozzi, R.P., Warshaw, P.R.: User acceptance of computer technology: A comparison of two theoretical models. Management Science 35(8), 982–1003 (1989) Dempster, A.P.: Upper and lower probabilities induced by a multiple valued mapping. Ann. Math. Statistics 38, 325–339 (1967) Diaz, A.N., Hammond, K., McWilliam, G.: A Study of Web Use and Attitudes Amongst Novices, Moderate Users and Heavy Users. In: Paper presented at the 25th EMAC Conference Proceedings (1997) Dillman, D.A., Christian, L.M.: Survey Mode as a Source of Instability in Responses Across Surveys. Field Methods 17, 30–52 (2005) Donthu, N., Garcia, A.: The Internet Shopper. Journal of Advertising Research, 52–58 (May/June 1999) ESOMAR, Global MR Trends ESOMAR Report (2006), (September 5, 2009), http://www.esomar.org/web/publication/paper.php?page=1&id=1 416&keyword=industry%20trends Experian, Online to Rescue Britain’s Retail Sector from Recession, Experian Report Accessed (June 24, 2009), https://www.paypal-press.co.uk/Content/ Detail.asp?ReleaseID=169&NewsAreaID=2 Fan, H.-Y., Lampinen, J.A.: Trigonometric Mutation Operation to Differential Evolution. Journal of Global Optimization 27, 105–129 (2003) Forrester, European Online Retail Consumer (December 20, 2004), http://www.forrester.com/ER/Press/Release/0,1769,973,00.html (retrieved September 20, 2005) Forsythe, S., Liu, C., Shannon, D., et al.: Development of a Scale to Measure the Perceived Benefits and Risks of Online Shopping. Journal of Interactive Marketing 20(2), 55–75 (2006) Francis, J.E.: Internet Retailing Quality: One Size Does Not Fit All. Managing Service Quality 17(3), 341–355 (2007)  
   
  472  
   
  M.J. Beynon and K. Page  
   
  Handzic, M., Low, G.C.: The role of experience in user perceptions of information technology: An empirical examination. South African Computer Journal 24, 194–200 (1999) Hansen, T.: Consumer Adoption of Online Grocery Buying: A Discriminant Analysis. International Journal of Retail and Distribution Management 33, 101–121 (2005) Huang, X., Zhu, Q.: A pseudo-nearest-neighbour approach for missing data on Gaussian random data sets. Pattern Recognition Letters 23, 613–1622 (2002) Huisman, M.: Imputation of Missing Item Responses: Some Simple Techniques. Quality & Quantity 34, 331–351 (2000) Jain, K., Srinivasan, N.: An Empirical Assessment of Multiple Operationalisation of Involvement. In: Paper presented at the Advances in Consumer Research, Provo, UT (1990) Korgaonkar, P.K., Wolin, L.D.: A Multivariate Analysis of Web Usage. Journal of Advertising Research, 53–68 (March/April 1999) Koslowsky, S.: The case of missing data. Journal of Database Marketing 9(4), 312–318 (2002) Lee, G.-G., Lin, H.-F.: Customer Perceptions of e-Service Quality in Online Shopping. International Journal of Retailing and Distribution Management 33(2), 161–176 (2005) Liao, Z., Tow-Cheung, M.: Internet-based E-shopping and consumer attitudes: An empirical study. Information and Management 38, 299–306 (2001) Lucas, C., Araabi, B.N.: Generalisation of the Dempster-Shafer Theory: A Fuzzy-Valued Measure. IEEE Transactions on Fuzzy Systems 7(3), 255–270 (1999) McQuarrie, E.F., Munson, J.M.: The Zaichkowsky Personal Involvement Inventory: Modification and Extension. In: Paper presented at the Advances in Consumer Research, Provo, UT (1986) Manfreda, K.L., Bosnjak, M., Berzelak, J., et al.: Web Surveys versus Other Survey Modes: A Meta-analysis Comparing Response Rates. International Journal of Marketing Research 50(1), 79–104 (2008) Mantores, R.L.: De Approximate Reasoning Models. Ellis Horwood, West Sussex (1990) Mittal, B.: Measuring Purchase-Decision Involvement. Psychology & Marketing 6, 147–162 (Summer 1989) Moore, G.C., Benbasat, I.: Development of an instrument to measure the perceptions of adopting an information technology innovation. Information Systems Research 2(3), 192–222 (1991) Page-Thomas, K.L., Moss, G., Chelly, D., et al.: The provision of service delivery information prior to purchase: A missed opportunity. International Journal of Retailing & Distribution Management 34(4/5), 258–277 (2006) Page, K.L.: World Wide Web Perceptions and Use: Investigating the Role of Web Knowledge. Unpublished Doctoral Dissertation, UNSW, Sydney (2003) Pyle, D.: Data Preparation for Data Mining. Morgan Kaufmann, Los altos (1999) Roesmer, C.: Nonstandard Analysis and Dempster-Shafer Theory. International Journal of Intelligent Systems 15, 117–127 (2000) Rohm, A.J., Swaminathan, V.: A typology of online shoppers based on shopping motivations. Journal of Business Research 57(7), 748–757 (2004) Roth, P.: Missing Data: A Conceptual Review for Applied Psychologists. Personnel Psychology 47, 537–560 (1994) Safranek, R.J., Gottschlich, S., Kak, A.C.: Evidence Accumulation Using Binary Frames of Discernment for Verification Vision. IEEE Transactions on Robotics and Automation 6, 405–417 (1990)  
   
  Analysing Incomplete Consumer Web Data Using the CaRBS  
   
  473  
   
  Schafer, J.L., Graham, J.W.: Missing Data: Our View of the State of the Art. Psychological Methods 7(2), 147–177 (2002) Shafer, G.A.: Mathematical theory of Evidence. Princeton University Press, Princeton (1976) Slama, M.E., Tashchian, A.: Selected Socioeconomic and Demographic Characteristics Associated with Purchasing Involvement. Journal of Marketing 49, 72–82 (Winter 1985) Smith, C.: Casting the Net: Surveying an Internet population. Journal of Computer Mediated Communication 3(1) (1997) Smith, M.F., Carsky, M.L.: Grocery Shopping Behaviour. Journal of Retailing and Consumer Services 3(3), 73–80 (1996) Storn, R., Price, K.: Differential Evolution - A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces. Journal of Global Optimisation 11, 341–359 (1997) Swoboda, B.S.: Conditions of Consumer Information Seeking: Theoretical Foundations and Empirical Results of Using Interactive Multimedia Systems. The International Review of Retail, Distribution, and Consumer Research 8(4), 361–381 (1998) Taylor, S., Todd, P.: Assessing IT usage: The role of prior experience. MIS Quarterly 19, 561–570 (1995) Yang, J.-B., Liu, J., Wang, J., et al.: Belief Rule-Base Inference Methodology Using the Evidential Reasoning Approach—RIMER. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 36(2), 266–285 (2006) Zadeh, L.A.: Fuzzy Logic and Approximate Reasoning (In Memory of Grigore Moisel). Synthese 30, 407–428 (1975)  
   
  Author Index  
   
  Babin, Barry J. 35 Balakrishnan, P.V. (Sundar) 337 Beynon, Malcolm J. 365, 447 Bhattacharyya, Siddhartha 155 Borges, Adilson 35 Bradlow, Eric T. 27 Bruckhaus, Tilmann 131 Casillas, Jorge 181 Chiu, Yen-Ting Helena  
   
  Hayhurst, Tom Hsu, Tsuen-Ho Iacobucci, Dawn  
   
  227  
   
  Roberts, John  
   
  Lee, Nick  
   
  9 49 227  
   
  21  
   
  Tang, Jia-Wei 227 Tettamanzi, Andrea G.B. Tomic, Drazena 79 Tsafarakis, Stelios 295  
   
  31  
   
  Veloutsou, Cleopatra  
   
  365  
   
  Wang, Minhong 389 Wierenga, Berend 1 Wong, Man Leung 273  
   
  113  
   
  9  
   
  Markic, Brano 79 Marshall, Greg W. 43 Mart´ınez-L´ opez, Francisco J.  
   
  181 255  
   
  Shmueli, Galit 417 Stewart, David W. 17 Sun, Zhaohao 389  
   
  Jacob, Varghese S. 337 Jank, Wolfgang 417 Kok, Joost N.  
   
  Orriols-Puig, Albert Ortega, Omar L´ opez  
   
  Page, Kelly 447 Pereira, C´elia da Costa 207 Putten, Peter van der 113  
   
  Dass, Mayukh 417 Dong, Dong 389 Duran, Randall E. 49 Greenley, Gordon  
   
  Matsatsinis, Nikolaos 295 Morales, Virgilio L´ opez 255 Moutinho, Luiz 365  
   
  181  
   
  Xia, Hao  
   
  337  
   
  Zhang, Li  
   
  49  
   
  207  

 Report "Marketing Intelligent Systems Using Soft Computing: Managerial and Research Applications (Studies in Fuzziness and Soft Computing, 258) 3642156053, 9783642156052"  
 ×    

 --- Select Reason ---  Pornographic  Defamatory  Illegal/Unlawful  Spam  Other Terms Of Service Violation  File a copyright complaint     

 Close  Submit    

    Contact information  
 Michael Browner   
   [email protected]    
   
   Address:   
 1918 St.Regis, Dorval, Quebec, H9P 1H6, Canada.   
   
 Support & Legal  
  O nas 
  Skontaktuj się z nami 
  Prawo autorskie 
  Polityka prywatności 
  Warunki 
  FAQs 
  Cookie Policy 
    
 Subscribe to our newsletter  
  Be the first to receive exclusive offers and the latest news on our products and services directly in your inbox.  
   Subscribe     

 Copyright © 2024 DOKUMEN.PUB. All rights reserved.        

 Unsere Partner sammeln Daten und verwenden Cookies zur Personalisierung und Messung von Anzeigen. Erfahren Sie, wie wir und unser Anzeigenpartner Google Daten sammeln und verwenden  .   Cookies zulassen    
    Important dates data

40. Conference SOUPS_0:
Skip to main content    
   USENIX supports diversity, equity, and inclusion and condemns hate and discrimination  .  

 About 
  Conferences | Upcoming 
  By Name 
  Calls for Papers 
  Grants 
  Sponsorship 
  Best Papers 
  Test of Time Awards 
  Multimedia 
  Conference FAQ 
  Conference Policies 
  Code of Conduct 
  Publications 
  Membership 
  Students 
  Search 
  Donate Today 

 Sign In 
  Search 

    About | USENIX Board 
  Staff 
  Newsroom 
  Good Works 
  Blog 
  Governance and Financials 
  USENIX Awards 
  USENIX Supporters 
  2024 Board Election 
  Board Meeting Minutes 
  Donate 
  Conferences | Upcoming 
  By Name 
  Calls for Papers 
  Grants 
  Sponsorship 
  Best Papers 
  Test of Time Awards 
  Multimedia 
  Conference FAQ 
  Conference Policies 
  Code of Conduct 
  Publications | Proceedings 
  Author Resources 
  ;login: Online 
  Writing for ;login: Online 
  ;login: Archive 
  Membership 
  Students | Conference Fees 
  Campus Representative Program 
  Student Grant Program 
  Search 
  Donate Today 

 You are here  
 Conferences    

 SOUPS Symposia  

 Donate Today    

 2025 | Twenty-First Symposium on Usable Privacy and Security | August 10, 2025  – August 12, 2025   | Seattle, WA, United States |  
 2024 | Twentieth Symposium on Usable Privacy and Security | August 11, 2024  – August 13, 2024   | Philadelphia, PA, United States |  
 2023 | Nineteenth Symposium on Usable Privacy and Security | August 6, 2023  – August 8, 2023   | Anaheim, CA, United States |  
 2022 | Eighteenth Symposium on Usable Privacy and Security | August 7, 2022  – August 9, 2022   | Boston, MA, United States |  
 2021 | Seventeenth Symposium on Usable Privacy and Security | August 8, 2021  – August 10, 2021   | |  
 2020 | Sixteenth Symposium on Usable Privacy and Security | August 7, 2020  – August 11, 2020   | |  
 2019 | Fifteenth Symposium on Usable Privacy and Security | August 11, 2019  – August 13, 2019   | Santa Clara, CA, United States |  
 2018 | Fourteenth Symposium on Usable Privacy and Security | August 12, 2018  – August 14, 2018   | Baltimore, MD, United States |  
 2017 | Thirteenth Symposium on Usable Privacy and Security | July 12, 2017  – July 14, 2017   | Santa Clara, CA, United States |  
 2016 | Twelfth Symposium on Usable Privacy and Security | June 22, 2016  – June 24, 2016   | Denver, CO, United States |  
 2015 | Eleventh Symposium On Usable Privacy and Security | July 22, 2015  – July 24, 2015   | Ottawa, Canada |  

 © USENIX 2024  
  Website designed and built  
  by Giant Rabbit LLC   

 Privacy Policy 
  Contact Us 

  Sign up for Our Newsletter:   

  Call for papers data:Skip to main content    
   USENIX supports diversity, equity, and inclusion and condemns hate and discrimination  .  

 About 
  Conferences | Upcoming 
  By Name 
  Calls for Papers 
  Grants 
  Sponsorship 
  Best Papers 
  Test of Time Awards 
  Multimedia 
  Conference FAQ 
  Conference Policies 
  Code of Conduct 
  Publications 
  Membership 
  Students 
  Search 
  Donate Today 

 Sign In 
  Search 

    About | USENIX Board 
  Staff 
  Newsroom 
  Good Works 
  Blog 
  Governance and Financials 
  USENIX Awards 
  USENIX Supporters 
  2024 Board Election 
  Board Meeting Minutes 
  Donate 
  Conferences | Upcoming 
  By Name 
  Calls for Papers 
  Grants 
  Sponsorship 
  Best Papers 
  Test of Time Awards 
  Multimedia 
  Conference FAQ 
  Conference Policies 
  Code of Conduct 
  Publications | Proceedings 
  Author Resources 
  ;login: Online 
  Writing for ;login: Online 
  ;login: Archive 
  Membership 
  Students | Conference Fees 
  Campus Representative Program 
  Student Grant Program 
  Search 
  Donate Today 

 You are here  
 Conferences    

 Calls for Papers and Calls for Participation  

 Donate Today    
   
 Publish and Present Your Work at USENIX Conferences  
 The program committees of the following conferences are seeking submissions. CiteSeer ranks the USENIX Conference Proceedings among the the top ten highest-impact publication venues for computer science. By submitting a paper to a USENIX conference, you have the opportunity to present your work directly to your peers and to share it with a wide audience of readers of the Proceedings  . Please see our Conference Submissions Policy  .  
 Please note: All submission deadline times listed below are for the Pacific time zone. See the original CFP for submission deadlines that are in Anywhere on Earth (AoE) or Coordinated Universal Time (UTC).  
   
 USENIX ATC '25:  2025 USENIX Annual Technical Conference | July 7, 2025  – July 9, 2025   , Boston, MA, United States | Abstract registrations due: | January 7, 2025 - 3:59 pm | The 2025 USENIX Annual Technical Conference seeks original, high-quality submissions that improve and further the knowledge of computing systems, with an emphasis on implementations and experimental results. We are interested in systems of all scales, from small embedded mobile devices to data centers and clouds. The scope of USENIX ATC covers all practical aspects related to computer systems, including but not limited to: operating systems; runtime systems; parallel and distributed systems; storage; networking; security and privacy; virtualization; software-hardware interactions; performance evaluation and workload characterization; reliability, availability, and scalability; energy and power management; and bug-finding, tracing, analyzing, and troubleshooting. | We value submissions more highly if they are accompanied by clearly defined artifacts not previously available, including traces, original data, source code, or tools developed as part of the submitted work. We particularly encourage new ideas and approaches. | Submissions must contain original unpublished material that is not under review at any other forum, including journals, conferences, and workshops with proceedings. They will be judged on relevance, novelty, technical merit, correctness, and clarity. An idea or a design that the PC deems flawed can be grounds for rejection. USENIX ATC '25 will employ double-blind reviewing. Papers that are not properly anonymized may be rejected without review. | Read More 

 © USENIX 2024  
  Website designed and built  
  by Giant Rabbit LLC   

 Privacy Policy 
  Contact Us 

  Sign up for Our Newsletter:   

  Important dates data

41. Conference SP_0:
S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Since 1980, the IEEE Symposium on Security and Privacy has been the premier forum for presenting developments in computer security and electronic privacy, and for bringing together researchers and practitioners in the field. The 2025 Symposium will mark the 46 th  annual meeting of this flagship conference.  
 The Symposium will be held on May 12-14, 2025, and the Security and Privacy Workshops will be held on May 15, 2025. Both events will be in San Francisco, CA at the Hyatt Regency San Francisco.  
   
 S&P on X (Twitter)  
 Don't forget to send your workshop proposals!  
  The deadline is approaching: September 26. #ieeesp2025   
   
  More info: https://t.co/dbFqQCpEWN   
 — IEEE S&P (@IEEESSP) September 17, 2024   
 S&P on LinkedIn   
 Organizing Committee  
   
 General Chair | Marina Blanton | University at Buffalo 
 Program Chairs | William Enck | North Carolina State University 
 Cristina Nita-Rotaru | Northeastern University 
 Vice Chair / Registration | Alina Oprea | Northeastern University 
 Treasurer | Adwait Nadkarni | College of William & Mary 
 Workshops Chairs | Ziming Zhao | Northeastern University 
 Gang Wang | University of Illinois at Urbana-Champaign 
 Test of Time Awards Chair | Florian Kerschbaum | University of Waterloo 
 Web Chair | Andreas Brüggemann | TU Darmstadt 
 Publicity Chairs | Prajwal Panzade | Old Dominion University 
 Sandra Rueda | Universidad de Los Andes 
 Donations Chair | Briland Hitaj | SRI International 
 Publications Chairs | Syed Hussain | Pennsylvania State University 
 Shagufta Mehnaz | Pennsylvania State University 
 Diversity, Equity, and Inclusion Chair | Ghada Almashaqbeh | University of Connecticut 
 General Chair Emeritus | Trent Jaeger | University of California, Riverside 

  Call for papers data:    S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Call for Papers   
 Since 1980 in Oakland, the IEEE Symposium on Security and Privacy has been the premier forum for computer security research, presenting the latest developments and bringing together researchers and practitioners. We solicit previously unpublished papers offering novel research contributions in any aspect of security or privacy. Papers may present advances in the theory, design, implementation, analysis, verification, or empirical evaluation and measurement of secure systems. Theoretical papers must make a convincing case for the relevance of their results to practice.  
 Topics of interest include:   
 Applied cryptography 
  Attacks with novel insights, techniques, or results 
  Authentication, access control, and authorization 
  Blockchains and distributed ledger security 
  Cloud computing security 
  Cyber physical systems security 
  Distributed systems security 
  Economics of security and privacy 
  Embedded systems security 
  Formal methods and verification 
  Hardware security 
  Hate, Harassment, and Online Abuse 
  Human-centered security and privacy 
  Intrusion detection and prevention 
  Machine learning and computer security 
  Malware and unwanted software 
  Network security and measurement 
  Operating systems security 
  Privacy-enhancing technologies, anonymity, and censorship 
  Program and binary analysis 
  Protocol security 
  Security and privacy metrics 
  Security and privacy policies 
  Security architectures 
  Security for at-risk populations 
  Software supply chain security 
  Systems security 
  User studies for security and privacy 
  Web security and privacy 
  Wireless and mobile security/privacy 
  This topic list is not meant to be exhaustive; S&P is interested in all aspects of computer security and privacy. Papers without a clear application to security or privacy, however, will be considered out of scope and may be rejected without full review.  
 Systematization of Knowledge Papers   
 As in past years, we solicit systematization of knowledge (SoK) papers that evaluate, systematize, and contextualize existing knowledge, as such papers can provide a high value to our community. Suitable papers are those that provide an important new viewpoint on an established, major research area, support or challenge long-held beliefs in such an area with compelling evidence, or present a convincing, comprehensive new taxonomy of such an area. Survey papers without such insights are not appropriate and may be rejected without full review. Submissions will be distinguished by the prefix “SoK:” in the title and a checkbox on the submission form. They will be reviewed by the full PC and held to the same standards as traditional research papers, but they will be accepted based on their treatment of existing work and value to the community, and not based on any new research results they may contain. Accepted papers will be presented at the symposium and included in the proceedings. You can find an overview of recent SoK papers at https://oaklandsok.github.io  .  
 Submission Deadlines & Decisions   
 Similar to 2024, for each submission, one of the following decisions will be made:  
 Accept:  Papers in this category will be accepted for publication in the proceedings and presentation at the conference. Within one month of acceptance, all accepted papers must submit a camera-ready copy incorporating reviewer feedback. The papers will immediately be published, open access, in the Computer Society’s Digital Library and they may be cited as “To appear in the IEEE Symposium on Security & Privacy, May 2025”. After the symposium, papers will be behind a paywall for one year before they are again made open access. 
  Reject:  Papers in this category are declined for inclusion in the conference. Rejected papers must wait for one year, from the date of original submission, to resubmit to IEEE S&P. A paper will be judged to be a resubmit (as opposed to a new submission) if the paper is from the same or similar authors, and a reviewer could write a substantially similar summary of the paper compared with the original submission. As a rule of thumb, if there is more than 40% overlap between the original submission and the new paper, it will be considered a resubmission. 
  Public Meta-Reviews:  Similar to 2024, all accepted papers will be published with a meta-review (< 500 words) in the final PDF that lists: (a) the reasons the PC decided to accept the paper and (b) concerns the PC has with the paper. Authors will be given the option to write a response to the meta-review (< 500 words) which will be published as part of the meta-review. Authors will be given a draft meta-review at the time of acceptance. Authors will be given the option of addressing some or all of the concerns within one review cycle. A shepherd will remove concerns from the meta-review if they are sufficiently addressed by the revisions.  
   
  The goal of this process is to provide greater transparency and to better scope change requests made by reviewers. More information about the reasons behind this change can be found on the 2024 IEEE S&P website  .  
 Symposium Event (Important Changes)   
 The number of papers accepted to IEEE S&P continues to grow substantially each year. Due to conference venue limitations and costs, each accepted paper will have: (a) a short talk presentation (e.g., 5-7 minutes, length determined based on the number of accepted papers) and (b) a poster presentation immediately following the talk session containing the paper. All accepted papers are required to present both a short talk and a poster.  
 Important Dates   
 All deadlines are 23:59:59 AoE (UTC-12).  
 First deadline   
 Paper submission deadline: June 6, 2024 
  Early-reject notification: July 22, 2024 
  Rebuttal period (interactive): August 19 - August 30, 2024 
  Rebuttal text due: August 26, 2024 
  Acceptance notification: September 9, 2024 
  Camera-ready deadline: October 18, 2024 
  Second deadline   
 Paper submission deadline: November 14, 2024 
  Early-reject notification: January 20, 2025 
  Rebuttal period (interactive): February 17 - February 28, 2025 
  Rebuttal text due: February 24, 2025 
  Acceptance notification: March 10, 2025 
  Camera-ready deadline: April 18, 2025 
  Rebuttal Period   
 Papers reaching the second round of reviewing will be given an opportunity to write a rebuttal to reviewer questions. The rebuttal period will be interactive, and is separate from the meta-review rebuttal given to accepted papers. Authors have the opportunity to exchange messages with the reviewers and respond to questions asked. To this end, we will use HotCRP’s anonymous communication feature to enable a communication channel between authors and reviewers. The authors should mainly focus on factual errors in the reviews and concrete questions posed by the reviewers. New research results can also be discussed if they help to clarify open questions. More instructions will be sent out to the authors at the beginning of the rebuttal period.  
 Resubmission of Rejected Papers   
 As with previous IEEE S&P symposia with multiple submission cycles, rejected papers must wait one year before resubmission to IEEE S&P. Given the move from three submission deadlines in 2024 to two submission deadlines in 2025, rejected papers are eligible to submit according to the table below.  
  
 2024 deadlines | Reject decision  
  Eligible 2025 deadlines 
 First 2024  
  (April 13, 2023) | Either 2025 deadline 
 Second 2024  
  (August 3, 2023) | Either 2025 deadline 
 Third 2024  
  (Dec 6, 2023) | Second deadline  
  (Nov 14, 2024) 
  
 Instructions for Paper Submission   
 These instructions apply to both the research papers and systematization of knowledge (SoK) papers. All submissions must be original work; the submitter must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. Failure to point out and explain overlap will be grounds for rejection. Simultaneous submission of the same paper to another venue with proceedings or a journal is not allowed and will be grounds for automatic rejection. Contact the program committee chairs if there are questions about this policy.  
 Anonymous Submission   
 Papers must be submitted in a form suitable for anonymous review: no author names or affiliations may appear on the title page, and papers should avoid revealing authors’ identity in the text. When referring to their previous work, authors are required to cite their papers in the third person, without identifying themselves. In the unusual case in which a third-person reference is infeasible, authors can blind the reference itself. Papers that are not properly anonymized may be rejected without review. PC members who have a genuine conflict of interest with a paper, including the PC Co-Chairs and the Associate Chairs, will be excluded from evaluation and discussion of that paper.  
   
 While a paper is under submission to the IEEE Security & Privacy Symposium, authors may choose to give talks about their work, post a preprint of the paper to an archival repository such as arXiv, and disclose security vulnerabilities to vendors. Authors should refrain from widely advertising their results, but in special circumstances they should contact the PC chairs to discuss exceptions. Authors are not allowed to directly contact PC members to discuss their submission.  
   
 The submissions will be treated confidentially by the PC chairs and the program committee members. Program committee members are not allowed to share the submitted papers with anyone, with the exception of qualified external reviewers approved by the program committee chairs. Please contact the PC chairs if you have any questions or concerns.  
 Conflicts of Interest   
 During submission of a research paper, the submission site will request information about conflicts of interest of the paper’s authors with program committee (PC) members. It is the full responsibility of all authors of a paper to identify all and only their potential conflict-of-interest PC members, according to the following definition. A paper author has a conflict of interest with a PC member when and only when one or more of the following conditions holds:  
 The PC member is a co-author of the paper. 
  The PC member has been a co-worker in the same company or university within the past two years. | For student interns, the student is conflicted with their supervisors and with members of the same research group. If the student no longer works for the organization, then they are not conflicted with a PC member from the larger organization. 
  The PC member has been a collaborator within the past two years. 
  The PC member is or was the author’s primary thesis advisor, no matter how long ago. 
  The author is or was the PC member’s primary thesis advisor, no matter how long ago. 
  The PC member is a relative or close personal friend of the author. 
  For any other situation where the authors feel they have a conflict with a PC member, they must explain the nature of the conflict to the PC chairs, who will mark the conflict if appropriate. The program chairs will review declared conflicts. Papers with incorrect or incomplete conflict of interest information as of the submission closing time are subject to immediate rejection.  
 Research Ethics Committee   
 Similar to 2024, IEEE S&P 2025 has a research ethics committee (REC) that will check papers flagged by reviewers as potentially including ethically fraught research. The REC will review flagged papers and may suggest to the PC Chairs rejection of a paper on ethical grounds. The REC consists of members of the PC. Authors are encouraged to review the Menlo Report  for general ethical guidelines for computer and information security research.  
 Ethical Considerations for Vulnerability Disclosure   
 Where research identifies a vulnerability (e.g., software vulnerabilities in a given program, design weaknesses in a hardware system, or any other kind of vulnerability in deployed systems), we expect that researchers act in a way that avoids gratuitous harm to affected users and, where possible, affirmatively protects those users. In nearly every case, disclosing the vulnerability to vendors of affected systems, and other stakeholders, will help protect users. It is the committee’s sense that a disclosure window of 45 days https://vuls.cert.org/confluence/display/Wiki/Vulnerability+Disclosure+Policy  to 90 days https://googleprojectzero.blogspot.com/p/vulnerability-disclosure-faq.html  ahead of publication is consistent with authors’ ethical obligations.  
   
 Longer disclosure windows (which may keep vulnerabilities from the public for extended periods of time) should only be considered in exceptional situations, e.g., if the affected parties have provided convincing evidence the vulnerabilities were previously unknown and the full rollout of mitigations requires additional time. The authors are encouraged to consult with the PC chairs in case of questions or concerns.  
   
 The version of the paper submitted for review must discuss in detail the steps the authors have taken or plan to take to address these vulnerabilities; but, consistent with the timelines above, the authors do not have to disclose vulnerabilities ahead of submission. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Note  : Submitted papers should not  include full CVE identifiers in order to preserve the anonymity of the submission.  
 Ethical Considerations for Human Subjects Research   
 Submissions that describe experiments that could be viewed as involving human subjects, that analyze data derived from human subjects (even anonymized data), or that otherwise may put humans at risk should:  
 Disclose whether the research received an approval or waiver from each of the authors’ institutional ethics review boards (IRB) if applicable. 
  Discuss steps taken to ensure that participants and others who might have been affected by an experiment were treated ethically and with respect. 
  If a submission deals with any kind of personal identifiable information (PII) or other kinds of sensitive data, the version of the paper submitted for review must discuss in detail the steps the authors have taken to mitigate harms to the persons identified. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Financial and Non-financial competing interests   
 In the interests of transparency and to help readers form their own judgements of potential bias, the IEEE Symposium on Security & Privacy requires authors and PC members to declare any competing financial and/or non-financial interests in relation to the work described. Authors need to include a disclosure of relevant financial interests in the camera-ready versions of their papers. This includes not just the standard funding lines, but should also include disclosures of any financial interest related to the research described. For example, “Author X is on the Technical Advisory Board of the ByteCoin Foundation,” or “Professor Y is the CTO of DoubleDefense, which specializes in malware analysis.” More information regarding this policy is available here  .  
 Page Limit and Formatting (Important Changes)   
 Submitted papers may include up to 13 pages of text and up to 5 pages for references and appendices, totaling no more than 18 pages. All text and figures past page 13 must be clearly marked as part of the appendix. The final camera-ready paper must be no more than 18 pages, although, at the PC chairs’ discretion, additional pages may be allowed. Reviewers are not required to read appendices.  
   
 Papers must be formatted for US letter (not A4) size paper. All submissions must use the IEEE “compsoc” conference proceedings template. LaTeX submissions using the IEEE templates must use IEEEtran.cls version 1.8b with options “conference,compsoc.” (That is, begin your LaTeX document with the line \documentclass[conference,compsoc]{IEEEtran}.). See the “IEEE Demo Template for Computer Society Conferences” Overleaf template  for an example. We are not aware of an MS Word template that matches this style.  
   
 Papers that fail to use the “compsoc” template (including using the non-compsoc IEEE conference template), modify margins, font, or line spacing, or use egregious space scrunching are subject to rejection without review. Authors are responsible for verifying the paper format (e.g., compare with the above linked Overleaf template)  . While HotCRP provides some automated checking, the checks are limited. Note that some LaTeX packages (e.g., \usepackage{usenix}) override the compsoc formatting and must be removed.  
 Withdrawing Policy   
 A paper can be withdrawn at any point before the reviews have been sent to the authors. Once the reviews have been sent to the authors the paper can not be withdrawn.  
 Authorship Policy   
 Changes to the authorship list (adding or removing authors) are not permitted after paper submission. Changes to the authors affiliation after paper acceptance are not permitted without PC chairs approval. If authors anticipate that they might change affiliation during the time the paper is under submission it is recommended to mark both the current and future institution as COI.  
 Conference Submission Server   
 Submissions must be in Portable Document Format (.pdf). Authors should pay special attention to unusual fonts, images, and figures that might create problems for reviewers.  
   
 Submission servers  :  
   
 First deadline | : | https://cycle1.sp2025.ieee-security.org/ 
  Second deadline | : | https://cycle2.sp2025.ieee-security.org/ 
  Publication and Presentation   
 Authors are responsible for obtaining appropriate publication clearances. One of the authors of the accepted paper is expected to register and present the paper at the conference.  
 Program Committee   
 PC Chairs   
  
 William Enck | North Carolina State University 
 Cristina Nita-Rotaru | Northeastern University 
  
 Associate Chairs   
  
 Adwait Nadkarni | William & Mary 
 Alex Kapravelos | North Carolina State University 
 Amir Houmansadr | University of Massachusetts Amherst 
 Batista Biggio | University of Cagliari 
 Christina Garman | Purdue University 
 Ian Miers | University of Maryland, College Park 
 Ioana Boureanu | Univ. of Surrey, Surrey Centre for Cybersecurity 
 Sara Rampazzi | University of Florida 
 Sascha Fahl | CISPA 
 William Robertson | Northeastern University 
  
 REC Chairs   
  
 René Mayrhofer | Johannes Kepler University Linz 
 Blase Ur | University of Chicago 
  
 PC Members   
  
 Adam Bates | University of Illinois at Urbana-Champaign 
 Adam Doupé | Arizona State University 
 Adam Oest | Amazon 
 Adil Ahmad | Arizona State University 
 Ahmad-Reza Sadeghi | Technical University Darmstadt 
 Alena Naiakshina | Ruhr University Bochum 
 Alesia Chernikova | Northeastern University 
 Alessandro Brighente | University of Padova 
 Alexander Block | Georgetown University & University of Maryland 
 Alexandra Dmitrienko | University of Wuerzburg 
 Alexios Voulimeneas | TU Delft 
 Ali Abbasi | CISPA Helmholtz Center for Information Security 
 Álvaro Feal | Northeastern University 
 Amit Seal Ami | William & Mary 
 Ana-Maria Cretu | EPFL, Lausanne, Switzerland 
 Andrei Sabelfeld | Chalmers University of Technology 
 Andrew Kwong | UNC Chapel Hill 
 Andrew Paverd | Microsoft 
 Ang Chen | University of Michigan 
 Angelos Stavrou | Virginia Tech 
 Aniket Kate | Purdue University / Supra Research 
 Antonio Bianchi | Purdue University 
 Anupam Das | North Carolina State University 
 Anwar Hithnawi | ETH Zurich 
 Aravind Machiry | Purdue University 
 Arslan Khan | Pennsylvania State University/ Purdue University 
 Arthur Gervais | UCL 
 Ashish Kundu | Cisco Research 
 Aysajan Abidin | COSIC KU Leuven 
 Bailey Kacsmar | University of Alberta 
 Ben Fisch | Yale University 
 Ben Stock | CISPA Helmholtz Center for Information Security 
 Ben Weintraub | Northeastern University 
 Ben Zhao | University of Chicago 
 Benjamin Beurdouche | Mozilla 
 Blaine Hoak | University of Wisconsin-Madison 
 Bo Chen | Michigan Technological University 
 Bogdan Carbunar | Florida International University 
 Brad Reaves | North Carolina State University 
 Brendan Saltaformaggio | Georgia Institute of Technology 
 Byoungyoung Lee | Seoul National University 
 Chao Zhang | Tsinghua University 
 Charalampos Papamanthou | Yale University 
 Chen-Da Liu-Zhang | Lucerne University of Applied Sciences and Arts & Web3 Foundation 
 Christof Ferreira Torres | ETH Zürich 
 Christopher A. Choquette-Choo | Google DeepMind 
 Claudio Soriente | NEC Laboratories Europe 
 Constantin Catalin Dragan | University of Surrey 
 Daniel Genkin | Georgia Tech 
 Daniel Votipka | Tufts University 
 Daniele Cono D'Elia | Sapienza University of Rome 
 David Balash | University of Richmond 
 Debajyoti Das | KU Leuven 
 Deian Stefan | UC San Diego 
 Dimitrios Papadopoulos | HKUST 
 Diogo Barradas | University of Waterloo 
 Dominik Wermke | NC State 
 Dongdong She | Hong Kong University of Science and Technology 
 Duc Le | Visa Research 
 Earlence Fernandes | UC San Diego 
 Eleonora Losiouk | University of Padua 
 Elisa Bertino | Purdue University 
 Emiliano De Cristofaro | UC Riverside 
 Emily Wenger | Duke University 
 Endadul Hoque | Syracuse University 
 Eric Pauley | University of Wisconsin–Madison 
 Eyal Ronen | Tel Aviv University 
 Eysa Lee | Brown University 
 Fabio De Gaspari | Sapienza Università di Roma 
 Faysal hossain Shezan | University of Texas at Arlington 
 Fengwei Zhang | Southern University of Science and Technology 
 Fernando Virdia | King's College London 
 Florian Kerschbaum | University of Waterloo 
 Florian Tramer | ETH Zurich 
 Frank Li | Georgia Institute of Technology 
 Frank Piessens | KU Leuven 
 Gang Wang | University of Illinois at Urbana-Champaign 
 Gaoning Pan | Hangzhou Dianzi University 
 Georgios Smaragdakis | Delft University of Technology 
 Giovanni Camurati | ETH Zurich 
 Giovanni Cherubin | Microsoft 
 Giulia Fanti | Carnegie Mellon University 
 Giuseppe Ateniese | George Mason University 
 Guangdong Bai | The University of Queensland 
 Guangliang Yang | Fudan University 
 Guanhong Tao | University of Utah 
 Guevara Noubir | Northeastern University 
 Guillermo Suarez-Tangil | IMDEA Networks Institute 
 Habiba Farrukh | University of California, Irvine 
 Haoyu Wang | Huazhong University of Science and Technology 
 Harshad Sathaye | ETH Zürich 
 Haya Schulmann | Goethe-Universität Frankfurt 
 Heather Zheng | University of Chicago 
 Heng Yin | UC Riverside 
 Homa Alemzadeh | University of Virginia 
 Hongxin Hu | University at Buffalo 
 Hyungsub Kim | Purdue University & Indiana University 
 Imtiaz Karim | Purdue University 
 Jack Doerner | Brown University 
 Jaron Mink | Arizona State University 
 Jason Nieh | Columbia University 
 Jason (Minhui) Xue | CSIRO’s Data61 
 Jeremiah Blocki | Purdue University 
 Jiarong Xing | Rice University 
 Jiska Classen | Hasso Plattner Institute 
 Jon McCune | Google 
 Jonas Hielscher | Ruhr University Bochum 
 Joseph Bonneau | a16z crypto research and New York University 
 Jun Han | KAIST 
 Kaihua Qin | Yale University 
 Kelsey Fulton | Colorado School of Mines 
 Kevin Borgolte | Ruhr University Bochum 
 Kevin Butler | University of Florida 
 Klaus v. Gleissenthall | VU Amsterdam 
 Kun Sun | George Mason University 
 Lorenzo Cavallaro | University College London 
 Lucianna Kiffer | ETH Zurich 
 Lucy Simko | Barnard College 
 Luyi Xing | Indiana University Bloomington 
 Man-Ki Yoon | North Carolina State University 
 Marco Squarcina | TU Wien 
 Maria Apostolaki | Princeton University 
 Marina Blanton | University at Buffalo 
 Markus Miettinen | Frankfurt University of Applied Sciences 
 Martin Henze | RWTH Aachen University & Fraunhofer FKIE 
 Matthew Jones | Block 
 Matthew Lentz | Duke University and Broadcom 
 Mauro Conti | University of Padua 
 Meera Sridhar | University of North Carolina Charlotte 
 Meng Shen | Beijing Institute of Technology 
 Michael Waidner | Technische Universität Darmstadt 
 Mohammad Islam | University of Texas at Arlington 
 Mridula Singh | CISPA Helmholtz Center for Information Security 
 Mu Zhang | University of Utah 
 Mulong Luo | The University of Texas at Austin 
 Muoi Tran | ETH Zurich 
 Murtuza Jadliwala | University of Texas at San Antonio 
 Muslum Ozgur Ozmen | Arizona State University 
 Nils Lukas | University of Waterloo 
 Ning Zhang | Washington University in St. Louis 
 Nuno Santos | INESC-ID and Instituto Superior Técnico, University of Lisbon 
 Omar Chowdhury | Stony Brook University 
 Peng Gao | Virginia Tech 
 Pramod Bhatotia | TU Munich 
 Pratik Sarkar | Supra Research 
 Pratyush Mishra | University of Pennsylvania 
 Qi Li | Tsinghua University 
 Qiang Tang | The University of Sydney 
 Qiben Yan | Michigan State University 
 Qingkai Shi | Nanjing University 
 Quinn Burke | University of Wisconsin-Madison 
 Rahul Chatterjee | University of Wisconsin-Madison 
 Ram Sundara Raman | University of Michigan 
 Ramya Jayaram Masti | Ampere Computing 
 Rei Safavi-Naini | University of Calgary 
 Ryan Sheatsley | University of Wisconsin-Madison 
 Saba Eskandarian | University of North Carolina at Chapel Hill 
 Saman Zonouz | Georgia Tech 
 Samira Mirbagher Ajorpaz | North Carolina State University 
 Sathvik Prasad | North Carolina State University 
 Sazzadur Rahaman | University of Arizona 
 Sen Chen | Tianjin University 
 Seyedhamed Ghavamnia | University of Connecticut 
 Sherman S. M. Chow | The Chinese University of Hong Kong 
 Shih-Wei Li | National Taiwan University 
 Shitong Zhu | Meta Platforms Inc. 
 Shuai Wang | Hong Kong University of Science and Technology 
 Siqi Ma | The University of New South Wales 
 Sisi Duan | Tsinghua University 
 Soheil Khodayari | CISPA Helmholtz Center for Information Security 
 Song Li | Zhejiang University 
 Srdjan Capkun | ETH Zurich 
 Sri AravindaKrishnan Thyagarajan | University of Sydney 
 Stephen Herwig | William & Mary 
 Sunil Manandhar | IBM Research 
 Sven Bugiel | CISPA Helmholtz Center for Information Security 
 Swarn Priya | Virginia Tech 
 Syed Rafiul Hussain | Pennsylvania State University 
 Tapti Palit | University of California, Davis 
 Teodora Baluta | National University of Singapore 
 Tianhao Wang | University of Virginia 
 Tobias Fiebig | MPI-INF 
 Trent Jaeger | UC Riverside 
 Tushar Jois | City College of New York 
 VARUN CHANDRASEKARAN | University of Illinois Urbana-Champaign 
 Varun Madathil | Yale University 
 Wajih Ul Hassan | The University of Virginia 
 Weijia He | Dartmouth College 
 Wenjing Lou | Virginia Tech 
 Xiaojing Liao | Indiana University Bloomington 
 Xinda Wang | University of Texas at Dallas 
 Xingliang Yuan | The University of Melbourne 
 Xinyu Xing | Northwestern University 
 Xusheng Xiao | Arizona State University 
 Yan Chen | Northwestern University 
 Yan Shoshitaishvili | Arizona State University 
 Yanchao Zhang | Arizona State University 
 Yaxing Yao | Virginia Tech 
 Yigitcan Kaya | UC Santa Barbara 
 Yingying Chen | Rutgers University 
 Yinxi Liu | Rochester Institute of Technology 
 Yinzhi Cao | Johns Hopkins University 
 Yizheng Chen | University of Maryland 
 Yonghwi Kwon | University of Maryland 
 Yossi Oren | Ben-Gurion University, Israel 
 Yu Ding | Google DeepMind 
 Yuan Tian | UCLA 
 Yupeng Zhang | University of Illinois Urbana Champaign 
 Yuseok Jeon | Ulsan National Institute of Science and Technology (UNIST) 
 Yuval Yarom | Ruhr University Bochum 
 Yuzhe Tang | Syracuse University 
 Z. Berkay Celik | Purdue University 
 Zane Ma | Oregon State University 
 Zhiqiang Lin | Ohio State University 
 Zhiyun Qian | University of California, Riverside 
 Zhou Li | University of California, Irvine 
 Zhuotao Liu | Tsinghua University 
 Ziming Zhao | University at Buffalo 
 Ziqi Yang | Zhejiang University 

  Important dates data

42. Conference SOUPS_1:
Menu Navigation   About | Test of Time Award 
  Why NDSS Symposium 
  Sponsorship 
  2025 Symposium | Attend 
  Accepted Papers (Summer Cycle) 
  Submissions 
  Co-located Events 
  Leadership 
  2024 Symposium | Accepted Papers 
  Accepted Posters 
  Program 
  Co-located Events 
  Leadership 
  Previous Events | Previous NDSS Symposia 
  Previous USEC Events 
  Previous VehicleSec Events 

    Register    

 Search for:     Search Button         

 Symposium on Usable Security and Privacy (USEC) 2025  
 Co-located with NDSS Symposium 2025, San Diego, CA  

 The Symposium on Usable Security and Privacy (USEC) 2025 serves as an international forum for research and discussion in the area of human factors in security and privacy. USEC is a symposium with proceedings.  
 USEC 2025 will take place on 24 February 2025, in conjunction with the Network and Distributed System Security Symposium (NDSS) 2025 in San Diego, California, from 24 to 28 February 2025.  

        Submissions   
 The call for papers is open until 25 November 2024.  

 Read More Submissions    

    Leadership   
 Organizing Committee, Technical Program Committee, and Steering Committee.  

 Read More Leadership    

 About  
 About 
  Test of Time Award 
  Why NDSS Symposium 
  Sponsorship 
  News 

 NDSS Symposium 2023  
 2025 Symposium 
  Attend 
  Submissions 
  Co-located Events 
  Sponsorship 
  Leadership 

 NDSS Symposium 2022  
 2024 Symposium 
  Accepted Papers 
  Program 
  Co-located Events 
  Leadership 

 Previous Events  
 Previous Events 
  Previous NDSS Symposia 
  Previous USEC Events 
  Previous VehicleSec Events 

 Privacy Policy  | Terms of Use  |  NDSS Code of Conduct  | Contact Us   

   Internet Society © 1992-2024    

      Call for papers data:    
    Menu Navigation   About | Test of Time Award 
  Why NDSS Symposium 
  Sponsorship 
  2025 Symposium | Attend 
  Accepted Papers (Summer Cycle) 
  Submissions 
  Co-located Events 
  Leadership 
  2024 Symposium | Accepted Papers 
  Accepted Posters 
  Program 
  Co-located Events 
  Leadership 
  Previous Events | Previous NDSS Symposia 
  Previous USEC Events 
  Previous VehicleSec Events 

    Register    

 Search for:     Search Button         

 Call for Papers: Symposium on Usable Security and Privacy (USEC) 2025  
 The call for papers is now open.  

 The Symposium on Usable Security and Privacy (USEC) invites submissions on all aspects of human factors and usability in the context of security and privacy. USEC ’25 aims to bring together researchers already engaged in this interdisciplinary effort with other researchers in relevant areas. We encourage economics, HCI, AI, theoretical computer science, cryptography, psychology, and business studies researchers and practitioners to submit original research in this area. We particularly encourage collaborative research from authors in multiple fields.  
 To honor significant contributions that have had a lasting impact on the field, USEC ’25 will also feature a Test of Time Award  . This award will celebrate research demonstrating enduring relevance and influence in usable security and privacy over the past 14 years of USEC. We will invite nominations for this award from the Organizing Committee, Program Committee, and authors submitting their works to USEC ’25. This recognition will honor research that continues to shape and inspire current and future investigations in the discipline.  

 Submission Guidelines for Papers  
 All submissions must be original work; authors must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. All papers should be written in English. We will review longer papers on mature/completed work in a research track, as well as shorter papers on work in progress, or work that has yet to begin, in a vision track. We aim to provide a venue for researchers at all stages of their careers and at all stages of their projects. The text must be in Times font, 10-point or larger, with 11-point or larger line spacing. Use the templates for NDSS Symposium and co-located events  .  
 Research Track:  The research track is intended to report on mature work that has been completed. The goal of the USEC’s research track is to disseminate results of interest to the broader usable security and privacy community. Papers must not be more than 12 pages in length using the two-column submission format, excluding bibliography and well-marked appendices. Try to scale the length of the paper according to the contributions you describe therein. Authors have the option to attach to their paper‘s supplementary appendices with study materials (e.g., survey instruments, interview guides, etc.) that would not otherwise take up valuable space within the body of the paper. Reviewers are not required to read appendices, so your paper should be self-contained without them.  
 Meta-Science Track:  The Meta-Science Track is intended to report on mature work and seeks to disseminate results that contribute to the broader understanding and improvement of research practices, including the replicability of studies and the systematization of existing knowledge. Submissions in this track may include comprehensive evaluations of research methodologies, studies that replicate and verify prior findings, meta-analyses that synthesize existing literature, and SoK papers that systematically organize and analyze research in a specific domain. Papers must not exceed 12 pages in length using the two-column submission format, excluding bibliography and well-marked appendices. Authors are encouraged to scale the length of their paper according to the contributions they describe therein. Additionally, authors have the option to attach supplementary appendices with materials such as study protocols, datasets, or detailed methodological descriptions that would not otherwise take up valuable space within the body of the paper. However, reviewers are not required to read these appendices, so the main paper should be self-contained without them.  
 Vision Track:  The vision track is intended to report on work in progress or concrete ideas for work that has yet to begin. The focus of the vision track is to spark discussion with the goal of providing the authors helpful feedback, pointers to potentially related investigations, and new ideas to explore. Suitable submissions to the vision track include traditional work-in-progress pieces such as preliminary results of pre-studies but also research proposals and position papers outlining future research. Papers must be up to 5 pages in length using the two-column format, excluding bibliography and well-marked appendices.  
 The submission portal for papers: https://usec25.hotcrp.com/    
 Reviewing will be double-blind. Author names and affiliations should not appear in the paper. The authors should make a reasonable effort not to reveal their identities or institutional affiliations in the text, figures, photos, links, or other data that is contained in the paper. Authors’ prior work should be preferably referred to in the third person; if this is not feasible, the references should be blinded. Submissions that violate these requirements will be rejected without review. The list of authors cannot be changed after the acceptance decision is made unless approved by the Program Chairs.  
 Areas of Interest  
 Topics include, but are not limited to:  
 Innovative security or privacy functionality and design 
  New applications of existing models or technology 
  Usability evaluations of new or existing security or privacy features and lessons learned 
  Security testing of new or existing usability features 
  Psychological, sociological, and economic aspects of security and privacy 
  Research and design methodologies for human-centric security and privacy research 
    
 Reports of replicating previously published studies and experiments 
  Reports of failed usable privacy/security studies or experiments, with the focus on the lessons learned from such experience 
  Systematization of Knowledge 
  Inclusive security and privacy 
  Ethics in human-centric security and privacy research 
  Workforce, labels, cyber-physical systems 
  Usability in smart manufacturing 

 All submissions must clearly relate to the human aspects of security or privacy. Papers on security or privacy that do not address usability or human factors will not be considered. Likewise, papers on usability or human factors that do not address security or privacy will not be considered. The determination of whether a paper is within scope will be solely at the discretion of the program committee chairs.  
 For accepted papers, at least one author must attend USEC 2025 and present their paper.  
 Important Dates  
 Submission Deadline: | 25 November 2024, 11:59 pm, | Anywhere-on-earth (AOE) 
  Reviews Due: 16 December 2024 
  Discussion Period: 16-19 December 2024 
  Notification of Acceptance: 20 December 2024 
  Camera Ready Deadline: 28 January 2025 
  Workshop Date: 24 February 2025 
  Conflicts of Interest  
 Authors and Program Committee members are required to indicate any conflict of interest and its nature. Advisors and those that they are advising, as well as authors and PC members with an institutional relationship are considered to share a conflict of interest. Professional collaborations (irrespective of whether they resulted in publication or funding) that occurred in the past 2 years and close personal relationships equally constitute a conflict of interest. PC members, including chairs, that have a conflict of interest with a paper, will be entirely excluded from the evaluation of that paper.  

 About  
 About 
  Test of Time Award 
  Why NDSS Symposium 
  Sponsorship 
  News 

 NDSS Symposium 2023  
 2025 Symposium 
  Attend 
  Submissions 
  Co-located Events 
  Sponsorship 
  Leadership 

 NDSS Symposium 2022  
 2024 Symposium 
  Accepted Papers 
  Program 
  Co-located Events 
  Leadership 

 Previous Events  
 Previous Events 
  Previous NDSS Symposia 
  Previous USEC Events 
  Previous VehicleSec Events 

 Privacy Policy  | Terms of Use  |  NDSS Code of Conduct  | Contact Us   

   Internet Society © 1992-2024    

      Important dates data

43. Conference SP_1:
S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Call for Papers   
 Since 1980 in Oakland, the IEEE Symposium on Security and Privacy has been the premier forum for computer security research, presenting the latest developments and bringing together researchers and practitioners. We solicit previously unpublished papers offering novel research contributions in any aspect of security or privacy. Papers may present advances in the theory, design, implementation, analysis, verification, or empirical evaluation and measurement of secure systems. Theoretical papers must make a convincing case for the relevance of their results to practice.  
 Topics of interest include:   
 Applied cryptography 
  Attacks with novel insights, techniques, or results 
  Authentication, access control, and authorization 
  Blockchains and distributed ledger security 
  Cloud computing security 
  Cyber physical systems security 
  Distributed systems security 
  Economics of security and privacy 
  Embedded systems security 
  Formal methods and verification 
  Hardware security 
  Hate, Harassment, and Online Abuse 
  Human-centered security and privacy 
  Intrusion detection and prevention 
  Machine learning and computer security 
  Malware and unwanted software 
  Network security and measurement 
  Operating systems security 
  Privacy-enhancing technologies, anonymity, and censorship 
  Program and binary analysis 
  Protocol security 
  Security and privacy metrics 
  Security and privacy policies 
  Security architectures 
  Security for at-risk populations 
  Software supply chain security 
  Systems security 
  User studies for security and privacy 
  Web security and privacy 
  Wireless and mobile security/privacy 
  This topic list is not meant to be exhaustive; S&P is interested in all aspects of computer security and privacy. Papers without a clear application to security or privacy, however, will be considered out of scope and may be rejected without full review.  
 Systematization of Knowledge Papers   
 As in past years, we solicit systematization of knowledge (SoK) papers that evaluate, systematize, and contextualize existing knowledge, as such papers can provide a high value to our community. Suitable papers are those that provide an important new viewpoint on an established, major research area, support or challenge long-held beliefs in such an area with compelling evidence, or present a convincing, comprehensive new taxonomy of such an area. Survey papers without such insights are not appropriate and may be rejected without full review. Submissions will be distinguished by the prefix “SoK:” in the title and a checkbox on the submission form. They will be reviewed by the full PC and held to the same standards as traditional research papers, but they will be accepted based on their treatment of existing work and value to the community, and not based on any new research results they may contain. Accepted papers will be presented at the symposium and included in the proceedings. You can find an overview of recent SoK papers at https://oaklandsok.github.io  .  
 Submission Deadlines & Decisions   
 Similar to 2024, for each submission, one of the following decisions will be made:  
 Accept:  Papers in this category will be accepted for publication in the proceedings and presentation at the conference. Within one month of acceptance, all accepted papers must submit a camera-ready copy incorporating reviewer feedback. The papers will immediately be published, open access, in the Computer Society’s Digital Library and they may be cited as “To appear in the IEEE Symposium on Security & Privacy, May 2025”. After the symposium, papers will be behind a paywall for one year before they are again made open access. 
  Reject:  Papers in this category are declined for inclusion in the conference. Rejected papers must wait for one year, from the date of original submission, to resubmit to IEEE S&P. A paper will be judged to be a resubmit (as opposed to a new submission) if the paper is from the same or similar authors, and a reviewer could write a substantially similar summary of the paper compared with the original submission. As a rule of thumb, if there is more than 40% overlap between the original submission and the new paper, it will be considered a resubmission. 
  Public Meta-Reviews:  Similar to 2024, all accepted papers will be published with a meta-review (< 500 words) in the final PDF that lists: (a) the reasons the PC decided to accept the paper and (b) concerns the PC has with the paper. Authors will be given the option to write a response to the meta-review (< 500 words) which will be published as part of the meta-review. Authors will be given a draft meta-review at the time of acceptance. Authors will be given the option of addressing some or all of the concerns within one review cycle. A shepherd will remove concerns from the meta-review if they are sufficiently addressed by the revisions.  
   
  The goal of this process is to provide greater transparency and to better scope change requests made by reviewers. More information about the reasons behind this change can be found on the 2024 IEEE S&P website  .  
 Symposium Event (Important Changes)   
 The number of papers accepted to IEEE S&P continues to grow substantially each year. Due to conference venue limitations and costs, each accepted paper will have: (a) a short talk presentation (e.g., 5-7 minutes, length determined based on the number of accepted papers) and (b) a poster presentation immediately following the talk session containing the paper. All accepted papers are required to present both a short talk and a poster.  
 Important Dates   
 All deadlines are 23:59:59 AoE (UTC-12).  
 First deadline   
 Paper submission deadline: June 6, 2024 
  Early-reject notification: July 22, 2024 
  Rebuttal period (interactive): August 19 - August 30, 2024 
  Rebuttal text due: August 26, 2024 
  Acceptance notification: September 9, 2024 
  Camera-ready deadline: October 18, 2024 
  Second deadline   
 Paper submission deadline: November 14, 2024 
  Early-reject notification: January 20, 2025 
  Rebuttal period (interactive): February 17 - February 28, 2025 
  Rebuttal text due: February 24, 2025 
  Acceptance notification: March 10, 2025 
  Camera-ready deadline: April 18, 2025 
  Rebuttal Period   
 Papers reaching the second round of reviewing will be given an opportunity to write a rebuttal to reviewer questions. The rebuttal period will be interactive, and is separate from the meta-review rebuttal given to accepted papers. Authors have the opportunity to exchange messages with the reviewers and respond to questions asked. To this end, we will use HotCRP’s anonymous communication feature to enable a communication channel between authors and reviewers. The authors should mainly focus on factual errors in the reviews and concrete questions posed by the reviewers. New research results can also be discussed if they help to clarify open questions. More instructions will be sent out to the authors at the beginning of the rebuttal period.  
 Resubmission of Rejected Papers   
 As with previous IEEE S&P symposia with multiple submission cycles, rejected papers must wait one year before resubmission to IEEE S&P. Given the move from three submission deadlines in 2024 to two submission deadlines in 2025, rejected papers are eligible to submit according to the table below.  
  
 2024 deadlines | Reject decision  
  Eligible 2025 deadlines 
 First 2024  
  (April 13, 2023) | Either 2025 deadline 
 Second 2024  
  (August 3, 2023) | Either 2025 deadline 
 Third 2024  
  (Dec 6, 2023) | Second deadline  
  (Nov 14, 2024) 
  
 Instructions for Paper Submission   
 These instructions apply to both the research papers and systematization of knowledge (SoK) papers. All submissions must be original work; the submitter must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. Failure to point out and explain overlap will be grounds for rejection. Simultaneous submission of the same paper to another venue with proceedings or a journal is not allowed and will be grounds for automatic rejection. Contact the program committee chairs if there are questions about this policy.  
 Anonymous Submission   
 Papers must be submitted in a form suitable for anonymous review: no author names or affiliations may appear on the title page, and papers should avoid revealing authors’ identity in the text. When referring to their previous work, authors are required to cite their papers in the third person, without identifying themselves. In the unusual case in which a third-person reference is infeasible, authors can blind the reference itself. Papers that are not properly anonymized may be rejected without review. PC members who have a genuine conflict of interest with a paper, including the PC Co-Chairs and the Associate Chairs, will be excluded from evaluation and discussion of that paper.  
   
 While a paper is under submission to the IEEE Security & Privacy Symposium, authors may choose to give talks about their work, post a preprint of the paper to an archival repository such as arXiv, and disclose security vulnerabilities to vendors. Authors should refrain from widely advertising their results, but in special circumstances they should contact the PC chairs to discuss exceptions. Authors are not allowed to directly contact PC members to discuss their submission.  
   
 The submissions will be treated confidentially by the PC chairs and the program committee members. Program committee members are not allowed to share the submitted papers with anyone, with the exception of qualified external reviewers approved by the program committee chairs. Please contact the PC chairs if you have any questions or concerns.  
 Conflicts of Interest   
 During submission of a research paper, the submission site will request information about conflicts of interest of the paper’s authors with program committee (PC) members. It is the full responsibility of all authors of a paper to identify all and only their potential conflict-of-interest PC members, according to the following definition. A paper author has a conflict of interest with a PC member when and only when one or more of the following conditions holds:  
 The PC member is a co-author of the paper. 
  The PC member has been a co-worker in the same company or university within the past two years. | For student interns, the student is conflicted with their supervisors and with members of the same research group. If the student no longer works for the organization, then they are not conflicted with a PC member from the larger organization. 
  The PC member has been a collaborator within the past two years. 
  The PC member is or was the author’s primary thesis advisor, no matter how long ago. 
  The author is or was the PC member’s primary thesis advisor, no matter how long ago. 
  The PC member is a relative or close personal friend of the author. 
  For any other situation where the authors feel they have a conflict with a PC member, they must explain the nature of the conflict to the PC chairs, who will mark the conflict if appropriate. The program chairs will review declared conflicts. Papers with incorrect or incomplete conflict of interest information as of the submission closing time are subject to immediate rejection.  
 Research Ethics Committee   
 Similar to 2024, IEEE S&P 2025 has a research ethics committee (REC) that will check papers flagged by reviewers as potentially including ethically fraught research. The REC will review flagged papers and may suggest to the PC Chairs rejection of a paper on ethical grounds. The REC consists of members of the PC. Authors are encouraged to review the Menlo Report  for general ethical guidelines for computer and information security research.  
 Ethical Considerations for Vulnerability Disclosure   
 Where research identifies a vulnerability (e.g., software vulnerabilities in a given program, design weaknesses in a hardware system, or any other kind of vulnerability in deployed systems), we expect that researchers act in a way that avoids gratuitous harm to affected users and, where possible, affirmatively protects those users. In nearly every case, disclosing the vulnerability to vendors of affected systems, and other stakeholders, will help protect users. It is the committee’s sense that a disclosure window of 45 days https://vuls.cert.org/confluence/display/Wiki/Vulnerability+Disclosure+Policy  to 90 days https://googleprojectzero.blogspot.com/p/vulnerability-disclosure-faq.html  ahead of publication is consistent with authors’ ethical obligations.  
   
 Longer disclosure windows (which may keep vulnerabilities from the public for extended periods of time) should only be considered in exceptional situations, e.g., if the affected parties have provided convincing evidence the vulnerabilities were previously unknown and the full rollout of mitigations requires additional time. The authors are encouraged to consult with the PC chairs in case of questions or concerns.  
   
 The version of the paper submitted for review must discuss in detail the steps the authors have taken or plan to take to address these vulnerabilities; but, consistent with the timelines above, the authors do not have to disclose vulnerabilities ahead of submission. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Note  : Submitted papers should not  include full CVE identifiers in order to preserve the anonymity of the submission.  
 Ethical Considerations for Human Subjects Research   
 Submissions that describe experiments that could be viewed as involving human subjects, that analyze data derived from human subjects (even anonymized data), or that otherwise may put humans at risk should:  
 Disclose whether the research received an approval or waiver from each of the authors’ institutional ethics review boards (IRB) if applicable. 
  Discuss steps taken to ensure that participants and others who might have been affected by an experiment were treated ethically and with respect. 
  If a submission deals with any kind of personal identifiable information (PII) or other kinds of sensitive data, the version of the paper submitted for review must discuss in detail the steps the authors have taken to mitigate harms to the persons identified. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Financial and Non-financial competing interests   
 In the interests of transparency and to help readers form their own judgements of potential bias, the IEEE Symposium on Security & Privacy requires authors and PC members to declare any competing financial and/or non-financial interests in relation to the work described. Authors need to include a disclosure of relevant financial interests in the camera-ready versions of their papers. This includes not just the standard funding lines, but should also include disclosures of any financial interest related to the research described. For example, “Author X is on the Technical Advisory Board of the ByteCoin Foundation,” or “Professor Y is the CTO of DoubleDefense, which specializes in malware analysis.” More information regarding this policy is available here  .  
 Page Limit and Formatting (Important Changes)   
 Submitted papers may include up to 13 pages of text and up to 5 pages for references and appendices, totaling no more than 18 pages. All text and figures past page 13 must be clearly marked as part of the appendix. The final camera-ready paper must be no more than 18 pages, although, at the PC chairs’ discretion, additional pages may be allowed. Reviewers are not required to read appendices.  
   
 Papers must be formatted for US letter (not A4) size paper. All submissions must use the IEEE “compsoc” conference proceedings template. LaTeX submissions using the IEEE templates must use IEEEtran.cls version 1.8b with options “conference,compsoc.” (That is, begin your LaTeX document with the line \documentclass[conference,compsoc]{IEEEtran}.). See the “IEEE Demo Template for Computer Society Conferences” Overleaf template  for an example. We are not aware of an MS Word template that matches this style.  
   
 Papers that fail to use the “compsoc” template (including using the non-compsoc IEEE conference template), modify margins, font, or line spacing, or use egregious space scrunching are subject to rejection without review. Authors are responsible for verifying the paper format (e.g., compare with the above linked Overleaf template)  . While HotCRP provides some automated checking, the checks are limited. Note that some LaTeX packages (e.g., \usepackage{usenix}) override the compsoc formatting and must be removed.  
 Withdrawing Policy   
 A paper can be withdrawn at any point before the reviews have been sent to the authors. Once the reviews have been sent to the authors the paper can not be withdrawn.  
 Authorship Policy   
 Changes to the authorship list (adding or removing authors) are not permitted after paper submission. Changes to the authors affiliation after paper acceptance are not permitted without PC chairs approval. If authors anticipate that they might change affiliation during the time the paper is under submission it is recommended to mark both the current and future institution as COI.  
 Conference Submission Server   
 Submissions must be in Portable Document Format (.pdf). Authors should pay special attention to unusual fonts, images, and figures that might create problems for reviewers.  
   
 Submission servers  :  
   
 First deadline | : | https://cycle1.sp2025.ieee-security.org/ 
  Second deadline | : | https://cycle2.sp2025.ieee-security.org/ 
  Publication and Presentation   
 Authors are responsible for obtaining appropriate publication clearances. One of the authors of the accepted paper is expected to register and present the paper at the conference.  
 Program Committee   
 PC Chairs   
  
 William Enck | North Carolina State University 
 Cristina Nita-Rotaru | Northeastern University 
  
 Associate Chairs   
  
 Adwait Nadkarni | William & Mary 
 Alex Kapravelos | North Carolina State University 
 Amir Houmansadr | University of Massachusetts Amherst 
 Batista Biggio | University of Cagliari 
 Christina Garman | Purdue University 
 Ian Miers | University of Maryland, College Park 
 Ioana Boureanu | Univ. of Surrey, Surrey Centre for Cybersecurity 
 Sara Rampazzi | University of Florida 
 Sascha Fahl | CISPA 
 William Robertson | Northeastern University 
  
 REC Chairs   
  
 René Mayrhofer | Johannes Kepler University Linz 
 Blase Ur | University of Chicago 
  
 PC Members   
  
 Adam Bates | University of Illinois at Urbana-Champaign 
 Adam Doupé | Arizona State University 
 Adam Oest | Amazon 
 Adil Ahmad | Arizona State University 
 Ahmad-Reza Sadeghi | Technical University Darmstadt 
 Alena Naiakshina | Ruhr University Bochum 
 Alesia Chernikova | Northeastern University 
 Alessandro Brighente | University of Padova 
 Alexander Block | Georgetown University & University of Maryland 
 Alexandra Dmitrienko | University of Wuerzburg 
 Alexios Voulimeneas | TU Delft 
 Ali Abbasi | CISPA Helmholtz Center for Information Security 
 Álvaro Feal | Northeastern University 
 Amit Seal Ami | William & Mary 
 Ana-Maria Cretu | EPFL, Lausanne, Switzerland 
 Andrei Sabelfeld | Chalmers University of Technology 
 Andrew Kwong | UNC Chapel Hill 
 Andrew Paverd | Microsoft 
 Ang Chen | University of Michigan 
 Angelos Stavrou | Virginia Tech 
 Aniket Kate | Purdue University / Supra Research 
 Antonio Bianchi | Purdue University 
 Anupam Das | North Carolina State University 
 Anwar Hithnawi | ETH Zurich 
 Aravind Machiry | Purdue University 
 Arslan Khan | Pennsylvania State University/ Purdue University 
 Arthur Gervais | UCL 
 Ashish Kundu | Cisco Research 
 Aysajan Abidin | COSIC KU Leuven 
 Bailey Kacsmar | University of Alberta 
 Ben Fisch | Yale University 
 Ben Stock | CISPA Helmholtz Center for Information Security 
 Ben Weintraub | Northeastern University 
 Ben Zhao | University of Chicago 
 Benjamin Beurdouche | Mozilla 
 Blaine Hoak | University of Wisconsin-Madison 
 Bo Chen | Michigan Technological University 
 Bogdan Carbunar | Florida International University 
 Brad Reaves | North Carolina State University 
 Brendan Saltaformaggio | Georgia Institute of Technology 
 Byoungyoung Lee | Seoul National University 
 Chao Zhang | Tsinghua University 
 Charalampos Papamanthou | Yale University 
 Chen-Da Liu-Zhang | Lucerne University of Applied Sciences and Arts & Web3 Foundation 
 Christof Ferreira Torres | ETH Zürich 
 Christopher A. Choquette-Choo | Google DeepMind 
 Claudio Soriente | NEC Laboratories Europe 
 Constantin Catalin Dragan | University of Surrey 
 Daniel Genkin | Georgia Tech 
 Daniel Votipka | Tufts University 
 Daniele Cono D'Elia | Sapienza University of Rome 
 David Balash | University of Richmond 
 Debajyoti Das | KU Leuven 
 Deian Stefan | UC San Diego 
 Dimitrios Papadopoulos | HKUST 
 Diogo Barradas | University of Waterloo 
 Dominik Wermke | NC State 
 Dongdong She | Hong Kong University of Science and Technology 
 Duc Le | Visa Research 
 Earlence Fernandes | UC San Diego 
 Eleonora Losiouk | University of Padua 
 Elisa Bertino | Purdue University 
 Emiliano De Cristofaro | UC Riverside 
 Emily Wenger | Duke University 
 Endadul Hoque | Syracuse University 
 Eric Pauley | University of Wisconsin–Madison 
 Eyal Ronen | Tel Aviv University 
 Eysa Lee | Brown University 
 Fabio De Gaspari | Sapienza Università di Roma 
 Faysal hossain Shezan | University of Texas at Arlington 
 Fengwei Zhang | Southern University of Science and Technology 
 Fernando Virdia | King's College London 
 Florian Kerschbaum | University of Waterloo 
 Florian Tramer | ETH Zurich 
 Frank Li | Georgia Institute of Technology 
 Frank Piessens | KU Leuven 
 Gang Wang | University of Illinois at Urbana-Champaign 
 Gaoning Pan | Hangzhou Dianzi University 
 Georgios Smaragdakis | Delft University of Technology 
 Giovanni Camurati | ETH Zurich 
 Giovanni Cherubin | Microsoft 
 Giulia Fanti | Carnegie Mellon University 
 Giuseppe Ateniese | George Mason University 
 Guangdong Bai | The University of Queensland 
 Guangliang Yang | Fudan University 
 Guanhong Tao | University of Utah 
 Guevara Noubir | Northeastern University 
 Guillermo Suarez-Tangil | IMDEA Networks Institute 
 Habiba Farrukh | University of California, Irvine 
 Haoyu Wang | Huazhong University of Science and Technology 
 Harshad Sathaye | ETH Zürich 
 Haya Schulmann | Goethe-Universität Frankfurt 
 Heather Zheng | University of Chicago 
 Heng Yin | UC Riverside 
 Homa Alemzadeh | University of Virginia 
 Hongxin Hu | University at Buffalo 
 Hyungsub Kim | Purdue University & Indiana University 
 Imtiaz Karim | Purdue University 
 Jack Doerner | Brown University 
 Jaron Mink | Arizona State University 
 Jason Nieh | Columbia University 
 Jason (Minhui) Xue | CSIRO’s Data61 
 Jeremiah Blocki | Purdue University 
 Jiarong Xing | Rice University 
 Jiska Classen | Hasso Plattner Institute 
 Jon McCune | Google 
 Jonas Hielscher | Ruhr University Bochum 
 Joseph Bonneau | a16z crypto research and New York University 
 Jun Han | KAIST 
 Kaihua Qin | Yale University 
 Kelsey Fulton | Colorado School of Mines 
 Kevin Borgolte | Ruhr University Bochum 
 Kevin Butler | University of Florida 
 Klaus v. Gleissenthall | VU Amsterdam 
 Kun Sun | George Mason University 
 Lorenzo Cavallaro | University College London 
 Lucianna Kiffer | ETH Zurich 
 Lucy Simko | Barnard College 
 Luyi Xing | Indiana University Bloomington 
 Man-Ki Yoon | North Carolina State University 
 Marco Squarcina | TU Wien 
 Maria Apostolaki | Princeton University 
 Marina Blanton | University at Buffalo 
 Markus Miettinen | Frankfurt University of Applied Sciences 
 Martin Henze | RWTH Aachen University & Fraunhofer FKIE 
 Matthew Jones | Block 
 Matthew Lentz | Duke University and Broadcom 
 Mauro Conti | University of Padua 
 Meera Sridhar | University of North Carolina Charlotte 
 Meng Shen | Beijing Institute of Technology 
 Michael Waidner | Technische Universität Darmstadt 
 Mohammad Islam | University of Texas at Arlington 
 Mridula Singh | CISPA Helmholtz Center for Information Security 
 Mu Zhang | University of Utah 
 Mulong Luo | The University of Texas at Austin 
 Muoi Tran | ETH Zurich 
 Murtuza Jadliwala | University of Texas at San Antonio 
 Muslum Ozgur Ozmen | Arizona State University 
 Nils Lukas | University of Waterloo 
 Ning Zhang | Washington University in St. Louis 
 Nuno Santos | INESC-ID and Instituto Superior Técnico, University of Lisbon 
 Omar Chowdhury | Stony Brook University 
 Peng Gao | Virginia Tech 
 Pramod Bhatotia | TU Munich 
 Pratik Sarkar | Supra Research 
 Pratyush Mishra | University of Pennsylvania 
 Qi Li | Tsinghua University 
 Qiang Tang | The University of Sydney 
 Qiben Yan | Michigan State University 
 Qingkai Shi | Nanjing University 
 Quinn Burke | University of Wisconsin-Madison 
 Rahul Chatterjee | University of Wisconsin-Madison 
 Ram Sundara Raman | University of Michigan 
 Ramya Jayaram Masti | Ampere Computing 
 Rei Safavi-Naini | University of Calgary 
 Ryan Sheatsley | University of Wisconsin-Madison 
 Saba Eskandarian | University of North Carolina at Chapel Hill 
 Saman Zonouz | Georgia Tech 
 Samira Mirbagher Ajorpaz | North Carolina State University 
 Sathvik Prasad | North Carolina State University 
 Sazzadur Rahaman | University of Arizona 
 Sen Chen | Tianjin University 
 Seyedhamed Ghavamnia | University of Connecticut 
 Sherman S. M. Chow | The Chinese University of Hong Kong 
 Shih-Wei Li | National Taiwan University 
 Shitong Zhu | Meta Platforms Inc. 
 Shuai Wang | Hong Kong University of Science and Technology 
 Siqi Ma | The University of New South Wales 
 Sisi Duan | Tsinghua University 
 Soheil Khodayari | CISPA Helmholtz Center for Information Security 
 Song Li | Zhejiang University 
 Srdjan Capkun | ETH Zurich 
 Sri AravindaKrishnan Thyagarajan | University of Sydney 
 Stephen Herwig | William & Mary 
 Sunil Manandhar | IBM Research 
 Sven Bugiel | CISPA Helmholtz Center for Information Security 
 Swarn Priya | Virginia Tech 
 Syed Rafiul Hussain | Pennsylvania State University 
 Tapti Palit | University of California, Davis 
 Teodora Baluta | National University of Singapore 
 Tianhao Wang | University of Virginia 
 Tobias Fiebig | MPI-INF 
 Trent Jaeger | UC Riverside 
 Tushar Jois | City College of New York 
 VARUN CHANDRASEKARAN | University of Illinois Urbana-Champaign 
 Varun Madathil | Yale University 
 Wajih Ul Hassan | The University of Virginia 
 Weijia He | Dartmouth College 
 Wenjing Lou | Virginia Tech 
 Xiaojing Liao | Indiana University Bloomington 
 Xinda Wang | University of Texas at Dallas 
 Xingliang Yuan | The University of Melbourne 
 Xinyu Xing | Northwestern University 
 Xusheng Xiao | Arizona State University 
 Yan Chen | Northwestern University 
 Yan Shoshitaishvili | Arizona State University 
 Yanchao Zhang | Arizona State University 
 Yaxing Yao | Virginia Tech 
 Yigitcan Kaya | UC Santa Barbara 
 Yingying Chen | Rutgers University 
 Yinxi Liu | Rochester Institute of Technology 
 Yinzhi Cao | Johns Hopkins University 
 Yizheng Chen | University of Maryland 
 Yonghwi Kwon | University of Maryland 
 Yossi Oren | Ben-Gurion University, Israel 
 Yu Ding | Google DeepMind 
 Yuan Tian | UCLA 
 Yupeng Zhang | University of Illinois Urbana Champaign 
 Yuseok Jeon | Ulsan National Institute of Science and Technology (UNIST) 
 Yuval Yarom | Ruhr University Bochum 
 Yuzhe Tang | Syracuse University 
 Z. Berkay Celik | Purdue University 
 Zane Ma | Oregon State University 
 Zhiqiang Lin | Ohio State University 
 Zhiyun Qian | University of California, Riverside 
 Zhou Li | University of California, Irvine 
 Zhuotao Liu | Tsinghua University 
 Ziming Zhao | University at Buffalo 
 Ziqi Yang | Zhejiang University 

  Call for papers data:    S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Call for Papers   
 Since 1980 in Oakland, the IEEE Symposium on Security and Privacy has been the premier forum for computer security research, presenting the latest developments and bringing together researchers and practitioners. We solicit previously unpublished papers offering novel research contributions in any aspect of security or privacy. Papers may present advances in the theory, design, implementation, analysis, verification, or empirical evaluation and measurement of secure systems. Theoretical papers must make a convincing case for the relevance of their results to practice.  
 Topics of interest include:   
 Applied cryptography 
  Attacks with novel insights, techniques, or results 
  Authentication, access control, and authorization 
  Blockchains and distributed ledger security 
  Cloud computing security 
  Cyber physical systems security 
  Distributed systems security 
  Economics of security and privacy 
  Embedded systems security 
  Formal methods and verification 
  Hardware security 
  Hate, Harassment, and Online Abuse 
  Human-centered security and privacy 
  Intrusion detection and prevention 
  Machine learning and computer security 
  Malware and unwanted software 
  Network security and measurement 
  Operating systems security 
  Privacy-enhancing technologies, anonymity, and censorship 
  Program and binary analysis 
  Protocol security 
  Security and privacy metrics 
  Security and privacy policies 
  Security architectures 
  Security for at-risk populations 
  Software supply chain security 
  Systems security 
  User studies for security and privacy 
  Web security and privacy 
  Wireless and mobile security/privacy 
  This topic list is not meant to be exhaustive; S&P is interested in all aspects of computer security and privacy. Papers without a clear application to security or privacy, however, will be considered out of scope and may be rejected without full review.  
 Systematization of Knowledge Papers   
 As in past years, we solicit systematization of knowledge (SoK) papers that evaluate, systematize, and contextualize existing knowledge, as such papers can provide a high value to our community. Suitable papers are those that provide an important new viewpoint on an established, major research area, support or challenge long-held beliefs in such an area with compelling evidence, or present a convincing, comprehensive new taxonomy of such an area. Survey papers without such insights are not appropriate and may be rejected without full review. Submissions will be distinguished by the prefix “SoK:” in the title and a checkbox on the submission form. They will be reviewed by the full PC and held to the same standards as traditional research papers, but they will be accepted based on their treatment of existing work and value to the community, and not based on any new research results they may contain. Accepted papers will be presented at the symposium and included in the proceedings. You can find an overview of recent SoK papers at https://oaklandsok.github.io  .  
 Submission Deadlines & Decisions   
 Similar to 2024, for each submission, one of the following decisions will be made:  
 Accept:  Papers in this category will be accepted for publication in the proceedings and presentation at the conference. Within one month of acceptance, all accepted papers must submit a camera-ready copy incorporating reviewer feedback. The papers will immediately be published, open access, in the Computer Society’s Digital Library and they may be cited as “To appear in the IEEE Symposium on Security & Privacy, May 2025”. After the symposium, papers will be behind a paywall for one year before they are again made open access. 
  Reject:  Papers in this category are declined for inclusion in the conference. Rejected papers must wait for one year, from the date of original submission, to resubmit to IEEE S&P. A paper will be judged to be a resubmit (as opposed to a new submission) if the paper is from the same or similar authors, and a reviewer could write a substantially similar summary of the paper compared with the original submission. As a rule of thumb, if there is more than 40% overlap between the original submission and the new paper, it will be considered a resubmission. 
  Public Meta-Reviews:  Similar to 2024, all accepted papers will be published with a meta-review (< 500 words) in the final PDF that lists: (a) the reasons the PC decided to accept the paper and (b) concerns the PC has with the paper. Authors will be given the option to write a response to the meta-review (< 500 words) which will be published as part of the meta-review. Authors will be given a draft meta-review at the time of acceptance. Authors will be given the option of addressing some or all of the concerns within one review cycle. A shepherd will remove concerns from the meta-review if they are sufficiently addressed by the revisions.  
   
  The goal of this process is to provide greater transparency and to better scope change requests made by reviewers. More information about the reasons behind this change can be found on the 2024 IEEE S&P website  .  
 Symposium Event (Important Changes)   
 The number of papers accepted to IEEE S&P continues to grow substantially each year. Due to conference venue limitations and costs, each accepted paper will have: (a) a short talk presentation (e.g., 5-7 minutes, length determined based on the number of accepted papers) and (b) a poster presentation immediately following the talk session containing the paper. All accepted papers are required to present both a short talk and a poster.  
 Important Dates   
 All deadlines are 23:59:59 AoE (UTC-12).  
 First deadline   
 Paper submission deadline: June 6, 2024 
  Early-reject notification: July 22, 2024 
  Rebuttal period (interactive): August 19 - August 30, 2024 
  Rebuttal text due: August 26, 2024 
  Acceptance notification: September 9, 2024 
  Camera-ready deadline: October 18, 2024 
  Second deadline   
 Paper submission deadline: November 14, 2024 
  Early-reject notification: January 20, 2025 
  Rebuttal period (interactive): February 17 - February 28, 2025 
  Rebuttal text due: February 24, 2025 
  Acceptance notification: March 10, 2025 
  Camera-ready deadline: April 18, 2025 
  Rebuttal Period   
 Papers reaching the second round of reviewing will be given an opportunity to write a rebuttal to reviewer questions. The rebuttal period will be interactive, and is separate from the meta-review rebuttal given to accepted papers. Authors have the opportunity to exchange messages with the reviewers and respond to questions asked. To this end, we will use HotCRP’s anonymous communication feature to enable a communication channel between authors and reviewers. The authors should mainly focus on factual errors in the reviews and concrete questions posed by the reviewers. New research results can also be discussed if they help to clarify open questions. More instructions will be sent out to the authors at the beginning of the rebuttal period.  
 Resubmission of Rejected Papers   
 As with previous IEEE S&P symposia with multiple submission cycles, rejected papers must wait one year before resubmission to IEEE S&P. Given the move from three submission deadlines in 2024 to two submission deadlines in 2025, rejected papers are eligible to submit according to the table below.  
  
 2024 deadlines | Reject decision  
  Eligible 2025 deadlines 
 First 2024  
  (April 13, 2023) | Either 2025 deadline 
 Second 2024  
  (August 3, 2023) | Either 2025 deadline 
 Third 2024  
  (Dec 6, 2023) | Second deadline  
  (Nov 14, 2024) 
  
 Instructions for Paper Submission   
 These instructions apply to both the research papers and systematization of knowledge (SoK) papers. All submissions must be original work; the submitter must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. Failure to point out and explain overlap will be grounds for rejection. Simultaneous submission of the same paper to another venue with proceedings or a journal is not allowed and will be grounds for automatic rejection. Contact the program committee chairs if there are questions about this policy.  
 Anonymous Submission   
 Papers must be submitted in a form suitable for anonymous review: no author names or affiliations may appear on the title page, and papers should avoid revealing authors’ identity in the text. When referring to their previous work, authors are required to cite their papers in the third person, without identifying themselves. In the unusual case in which a third-person reference is infeasible, authors can blind the reference itself. Papers that are not properly anonymized may be rejected without review. PC members who have a genuine conflict of interest with a paper, including the PC Co-Chairs and the Associate Chairs, will be excluded from evaluation and discussion of that paper.  
   
 While a paper is under submission to the IEEE Security & Privacy Symposium, authors may choose to give talks about their work, post a preprint of the paper to an archival repository such as arXiv, and disclose security vulnerabilities to vendors. Authors should refrain from widely advertising their results, but in special circumstances they should contact the PC chairs to discuss exceptions. Authors are not allowed to directly contact PC members to discuss their submission.  
   
 The submissions will be treated confidentially by the PC chairs and the program committee members. Program committee members are not allowed to share the submitted papers with anyone, with the exception of qualified external reviewers approved by the program committee chairs. Please contact the PC chairs if you have any questions or concerns.  
 Conflicts of Interest   
 During submission of a research paper, the submission site will request information about conflicts of interest of the paper’s authors with program committee (PC) members. It is the full responsibility of all authors of a paper to identify all and only their potential conflict-of-interest PC members, according to the following definition. A paper author has a conflict of interest with a PC member when and only when one or more of the following conditions holds:  
 The PC member is a co-author of the paper. 
  The PC member has been a co-worker in the same company or university within the past two years. | For student interns, the student is conflicted with their supervisors and with members of the same research group. If the student no longer works for the organization, then they are not conflicted with a PC member from the larger organization. 
  The PC member has been a collaborator within the past two years. 
  The PC member is or was the author’s primary thesis advisor, no matter how long ago. 
  The author is or was the PC member’s primary thesis advisor, no matter how long ago. 
  The PC member is a relative or close personal friend of the author. 
  For any other situation where the authors feel they have a conflict with a PC member, they must explain the nature of the conflict to the PC chairs, who will mark the conflict if appropriate. The program chairs will review declared conflicts. Papers with incorrect or incomplete conflict of interest information as of the submission closing time are subject to immediate rejection.  
 Research Ethics Committee   
 Similar to 2024, IEEE S&P 2025 has a research ethics committee (REC) that will check papers flagged by reviewers as potentially including ethically fraught research. The REC will review flagged papers and may suggest to the PC Chairs rejection of a paper on ethical grounds. The REC consists of members of the PC. Authors are encouraged to review the Menlo Report  for general ethical guidelines for computer and information security research.  
 Ethical Considerations for Vulnerability Disclosure   
 Where research identifies a vulnerability (e.g., software vulnerabilities in a given program, design weaknesses in a hardware system, or any other kind of vulnerability in deployed systems), we expect that researchers act in a way that avoids gratuitous harm to affected users and, where possible, affirmatively protects those users. In nearly every case, disclosing the vulnerability to vendors of affected systems, and other stakeholders, will help protect users. It is the committee’s sense that a disclosure window of 45 days https://vuls.cert.org/confluence/display/Wiki/Vulnerability+Disclosure+Policy  to 90 days https://googleprojectzero.blogspot.com/p/vulnerability-disclosure-faq.html  ahead of publication is consistent with authors’ ethical obligations.  
   
 Longer disclosure windows (which may keep vulnerabilities from the public for extended periods of time) should only be considered in exceptional situations, e.g., if the affected parties have provided convincing evidence the vulnerabilities were previously unknown and the full rollout of mitigations requires additional time. The authors are encouraged to consult with the PC chairs in case of questions or concerns.  
   
 The version of the paper submitted for review must discuss in detail the steps the authors have taken or plan to take to address these vulnerabilities; but, consistent with the timelines above, the authors do not have to disclose vulnerabilities ahead of submission. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Note  : Submitted papers should not  include full CVE identifiers in order to preserve the anonymity of the submission.  
 Ethical Considerations for Human Subjects Research   
 Submissions that describe experiments that could be viewed as involving human subjects, that analyze data derived from human subjects (even anonymized data), or that otherwise may put humans at risk should:  
 Disclose whether the research received an approval or waiver from each of the authors’ institutional ethics review boards (IRB) if applicable. 
  Discuss steps taken to ensure that participants and others who might have been affected by an experiment were treated ethically and with respect. 
  If a submission deals with any kind of personal identifiable information (PII) or other kinds of sensitive data, the version of the paper submitted for review must discuss in detail the steps the authors have taken to mitigate harms to the persons identified. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Financial and Non-financial competing interests   
 In the interests of transparency and to help readers form their own judgements of potential bias, the IEEE Symposium on Security & Privacy requires authors and PC members to declare any competing financial and/or non-financial interests in relation to the work described. Authors need to include a disclosure of relevant financial interests in the camera-ready versions of their papers. This includes not just the standard funding lines, but should also include disclosures of any financial interest related to the research described. For example, “Author X is on the Technical Advisory Board of the ByteCoin Foundation,” or “Professor Y is the CTO of DoubleDefense, which specializes in malware analysis.” More information regarding this policy is available here  .  
 Page Limit and Formatting (Important Changes)   
 Submitted papers may include up to 13 pages of text and up to 5 pages for references and appendices, totaling no more than 18 pages. All text and figures past page 13 must be clearly marked as part of the appendix. The final camera-ready paper must be no more than 18 pages, although, at the PC chairs’ discretion, additional pages may be allowed. Reviewers are not required to read appendices.  
   
 Papers must be formatted for US letter (not A4) size paper. All submissions must use the IEEE “compsoc” conference proceedings template. LaTeX submissions using the IEEE templates must use IEEEtran.cls version 1.8b with options “conference,compsoc.” (That is, begin your LaTeX document with the line \documentclass[conference,compsoc]{IEEEtran}.). See the “IEEE Demo Template for Computer Society Conferences” Overleaf template  for an example. We are not aware of an MS Word template that matches this style.  
   
 Papers that fail to use the “compsoc” template (including using the non-compsoc IEEE conference template), modify margins, font, or line spacing, or use egregious space scrunching are subject to rejection without review. Authors are responsible for verifying the paper format (e.g., compare with the above linked Overleaf template)  . While HotCRP provides some automated checking, the checks are limited. Note that some LaTeX packages (e.g., \usepackage{usenix}) override the compsoc formatting and must be removed.  
 Withdrawing Policy   
 A paper can be withdrawn at any point before the reviews have been sent to the authors. Once the reviews have been sent to the authors the paper can not be withdrawn.  
 Authorship Policy   
 Changes to the authorship list (adding or removing authors) are not permitted after paper submission. Changes to the authors affiliation after paper acceptance are not permitted without PC chairs approval. If authors anticipate that they might change affiliation during the time the paper is under submission it is recommended to mark both the current and future institution as COI.  
 Conference Submission Server   
 Submissions must be in Portable Document Format (.pdf). Authors should pay special attention to unusual fonts, images, and figures that might create problems for reviewers.  
   
 Submission servers  :  
   
 First deadline | : | https://cycle1.sp2025.ieee-security.org/ 
  Second deadline | : | https://cycle2.sp2025.ieee-security.org/ 
  Publication and Presentation   
 Authors are responsible for obtaining appropriate publication clearances. One of the authors of the accepted paper is expected to register and present the paper at the conference.  
 Program Committee   
 PC Chairs   
  
 William Enck | North Carolina State University 
 Cristina Nita-Rotaru | Northeastern University 
  
 Associate Chairs   
  
 Adwait Nadkarni | William & Mary 
 Alex Kapravelos | North Carolina State University 
 Amir Houmansadr | University of Massachusetts Amherst 
 Batista Biggio | University of Cagliari 
 Christina Garman | Purdue University 
 Ian Miers | University of Maryland, College Park 
 Ioana Boureanu | Univ. of Surrey, Surrey Centre for Cybersecurity 
 Sara Rampazzi | University of Florida 
 Sascha Fahl | CISPA 
 William Robertson | Northeastern University 
  
 REC Chairs   
  
 René Mayrhofer | Johannes Kepler University Linz 
 Blase Ur | University of Chicago 
  
 PC Members   
  
 Adam Bates | University of Illinois at Urbana-Champaign 
 Adam Doupé | Arizona State University 
 Adam Oest | Amazon 
 Adil Ahmad | Arizona State University 
 Ahmad-Reza Sadeghi | Technical University Darmstadt 
 Alena Naiakshina | Ruhr University Bochum 
 Alesia Chernikova | Northeastern University 
 Alessandro Brighente | University of Padova 
 Alexander Block | Georgetown University & University of Maryland 
 Alexandra Dmitrienko | University of Wuerzburg 
 Alexios Voulimeneas | TU Delft 
 Ali Abbasi | CISPA Helmholtz Center for Information Security 
 Álvaro Feal | Northeastern University 
 Amit Seal Ami | William & Mary 
 Ana-Maria Cretu | EPFL, Lausanne, Switzerland 
 Andrei Sabelfeld | Chalmers University of Technology 
 Andrew Kwong | UNC Chapel Hill 
 Andrew Paverd | Microsoft 
 Ang Chen | University of Michigan 
 Angelos Stavrou | Virginia Tech 
 Aniket Kate | Purdue University / Supra Research 
 Antonio Bianchi | Purdue University 
 Anupam Das | North Carolina State University 
 Anwar Hithnawi | ETH Zurich 
 Aravind Machiry | Purdue University 
 Arslan Khan | Pennsylvania State University/ Purdue University 
 Arthur Gervais | UCL 
 Ashish Kundu | Cisco Research 
 Aysajan Abidin | COSIC KU Leuven 
 Bailey Kacsmar | University of Alberta 
 Ben Fisch | Yale University 
 Ben Stock | CISPA Helmholtz Center for Information Security 
 Ben Weintraub | Northeastern University 
 Ben Zhao | University of Chicago 
 Benjamin Beurdouche | Mozilla 
 Blaine Hoak | University of Wisconsin-Madison 
 Bo Chen | Michigan Technological University 
 Bogdan Carbunar | Florida International University 
 Brad Reaves | North Carolina State University 
 Brendan Saltaformaggio | Georgia Institute of Technology 
 Byoungyoung Lee | Seoul National University 
 Chao Zhang | Tsinghua University 
 Charalampos Papamanthou | Yale University 
 Chen-Da Liu-Zhang | Lucerne University of Applied Sciences and Arts & Web3 Foundation 
 Christof Ferreira Torres | ETH Zürich 
 Christopher A. Choquette-Choo | Google DeepMind 
 Claudio Soriente | NEC Laboratories Europe 
 Constantin Catalin Dragan | University of Surrey 
 Daniel Genkin | Georgia Tech 
 Daniel Votipka | Tufts University 
 Daniele Cono D'Elia | Sapienza University of Rome 
 David Balash | University of Richmond 
 Debajyoti Das | KU Leuven 
 Deian Stefan | UC San Diego 
 Dimitrios Papadopoulos | HKUST 
 Diogo Barradas | University of Waterloo 
 Dominik Wermke | NC State 
 Dongdong She | Hong Kong University of Science and Technology 
 Duc Le | Visa Research 
 Earlence Fernandes | UC San Diego 
 Eleonora Losiouk | University of Padua 
 Elisa Bertino | Purdue University 
 Emiliano De Cristofaro | UC Riverside 
 Emily Wenger | Duke University 
 Endadul Hoque | Syracuse University 
 Eric Pauley | University of Wisconsin–Madison 
 Eyal Ronen | Tel Aviv University 
 Eysa Lee | Brown University 
 Fabio De Gaspari | Sapienza Università di Roma 
 Faysal hossain Shezan | University of Texas at Arlington 
 Fengwei Zhang | Southern University of Science and Technology 
 Fernando Virdia | King's College London 
 Florian Kerschbaum | University of Waterloo 
 Florian Tramer | ETH Zurich 
 Frank Li | Georgia Institute of Technology 
 Frank Piessens | KU Leuven 
 Gang Wang | University of Illinois at Urbana-Champaign 
 Gaoning Pan | Hangzhou Dianzi University 
 Georgios Smaragdakis | Delft University of Technology 
 Giovanni Camurati | ETH Zurich 
 Giovanni Cherubin | Microsoft 
 Giulia Fanti | Carnegie Mellon University 
 Giuseppe Ateniese | George Mason University 
 Guangdong Bai | The University of Queensland 
 Guangliang Yang | Fudan University 
 Guanhong Tao | University of Utah 
 Guevara Noubir | Northeastern University 
 Guillermo Suarez-Tangil | IMDEA Networks Institute 
 Habiba Farrukh | University of California, Irvine 
 Haoyu Wang | Huazhong University of Science and Technology 
 Harshad Sathaye | ETH Zürich 
 Haya Schulmann | Goethe-Universität Frankfurt 
 Heather Zheng | University of Chicago 
 Heng Yin | UC Riverside 
 Homa Alemzadeh | University of Virginia 
 Hongxin Hu | University at Buffalo 
 Hyungsub Kim | Purdue University & Indiana University 
 Imtiaz Karim | Purdue University 
 Jack Doerner | Brown University 
 Jaron Mink | Arizona State University 
 Jason Nieh | Columbia University 
 Jason (Minhui) Xue | CSIRO’s Data61 
 Jeremiah Blocki | Purdue University 
 Jiarong Xing | Rice University 
 Jiska Classen | Hasso Plattner Institute 
 Jon McCune | Google 
 Jonas Hielscher | Ruhr University Bochum 
 Joseph Bonneau | a16z crypto research and New York University 
 Jun Han | KAIST 
 Kaihua Qin | Yale University 
 Kelsey Fulton | Colorado School of Mines 
 Kevin Borgolte | Ruhr University Bochum 
 Kevin Butler | University of Florida 
 Klaus v. Gleissenthall | VU Amsterdam 
 Kun Sun | George Mason University 
 Lorenzo Cavallaro | University College London 
 Lucianna Kiffer | ETH Zurich 
 Lucy Simko | Barnard College 
 Luyi Xing | Indiana University Bloomington 
 Man-Ki Yoon | North Carolina State University 
 Marco Squarcina | TU Wien 
 Maria Apostolaki | Princeton University 
 Marina Blanton | University at Buffalo 
 Markus Miettinen | Frankfurt University of Applied Sciences 
 Martin Henze | RWTH Aachen University & Fraunhofer FKIE 
 Matthew Jones | Block 
 Matthew Lentz | Duke University and Broadcom 
 Mauro Conti | University of Padua 
 Meera Sridhar | University of North Carolina Charlotte 
 Meng Shen | Beijing Institute of Technology 
 Michael Waidner | Technische Universität Darmstadt 
 Mohammad Islam | University of Texas at Arlington 
 Mridula Singh | CISPA Helmholtz Center for Information Security 
 Mu Zhang | University of Utah 
 Mulong Luo | The University of Texas at Austin 
 Muoi Tran | ETH Zurich 
 Murtuza Jadliwala | University of Texas at San Antonio 
 Muslum Ozgur Ozmen | Arizona State University 
 Nils Lukas | University of Waterloo 
 Ning Zhang | Washington University in St. Louis 
 Nuno Santos | INESC-ID and Instituto Superior Técnico, University of Lisbon 
 Omar Chowdhury | Stony Brook University 
 Peng Gao | Virginia Tech 
 Pramod Bhatotia | TU Munich 
 Pratik Sarkar | Supra Research 
 Pratyush Mishra | University of Pennsylvania 
 Qi Li | Tsinghua University 
 Qiang Tang | The University of Sydney 
 Qiben Yan | Michigan State University 
 Qingkai Shi | Nanjing University 
 Quinn Burke | University of Wisconsin-Madison 
 Rahul Chatterjee | University of Wisconsin-Madison 
 Ram Sundara Raman | University of Michigan 
 Ramya Jayaram Masti | Ampere Computing 
 Rei Safavi-Naini | University of Calgary 
 Ryan Sheatsley | University of Wisconsin-Madison 
 Saba Eskandarian | University of North Carolina at Chapel Hill 
 Saman Zonouz | Georgia Tech 
 Samira Mirbagher Ajorpaz | North Carolina State University 
 Sathvik Prasad | North Carolina State University 
 Sazzadur Rahaman | University of Arizona 
 Sen Chen | Tianjin University 
 Seyedhamed Ghavamnia | University of Connecticut 
 Sherman S. M. Chow | The Chinese University of Hong Kong 
 Shih-Wei Li | National Taiwan University 
 Shitong Zhu | Meta Platforms Inc. 
 Shuai Wang | Hong Kong University of Science and Technology 
 Siqi Ma | The University of New South Wales 
 Sisi Duan | Tsinghua University 
 Soheil Khodayari | CISPA Helmholtz Center for Information Security 
 Song Li | Zhejiang University 
 Srdjan Capkun | ETH Zurich 
 Sri AravindaKrishnan Thyagarajan | University of Sydney 
 Stephen Herwig | William & Mary 
 Sunil Manandhar | IBM Research 
 Sven Bugiel | CISPA Helmholtz Center for Information Security 
 Swarn Priya | Virginia Tech 
 Syed Rafiul Hussain | Pennsylvania State University 
 Tapti Palit | University of California, Davis 
 Teodora Baluta | National University of Singapore 
 Tianhao Wang | University of Virginia 
 Tobias Fiebig | MPI-INF 
 Trent Jaeger | UC Riverside 
 Tushar Jois | City College of New York 
 VARUN CHANDRASEKARAN | University of Illinois Urbana-Champaign 
 Varun Madathil | Yale University 
 Wajih Ul Hassan | The University of Virginia 
 Weijia He | Dartmouth College 
 Wenjing Lou | Virginia Tech 
 Xiaojing Liao | Indiana University Bloomington 
 Xinda Wang | University of Texas at Dallas 
 Xingliang Yuan | The University of Melbourne 
 Xinyu Xing | Northwestern University 
 Xusheng Xiao | Arizona State University 
 Yan Chen | Northwestern University 
 Yan Shoshitaishvili | Arizona State University 
 Yanchao Zhang | Arizona State University 
 Yaxing Yao | Virginia Tech 
 Yigitcan Kaya | UC Santa Barbara 
 Yingying Chen | Rutgers University 
 Yinxi Liu | Rochester Institute of Technology 
 Yinzhi Cao | Johns Hopkins University 
 Yizheng Chen | University of Maryland 
 Yonghwi Kwon | University of Maryland 
 Yossi Oren | Ben-Gurion University, Israel 
 Yu Ding | Google DeepMind 
 Yuan Tian | UCLA 
 Yupeng Zhang | University of Illinois Urbana Champaign 
 Yuseok Jeon | Ulsan National Institute of Science and Technology (UNIST) 
 Yuval Yarom | Ruhr University Bochum 
 Yuzhe Tang | Syracuse University 
 Z. Berkay Celik | Purdue University 
 Zane Ma | Oregon State University 
 Zhiqiang Lin | Ohio State University 
 Zhiyun Qian | University of California, Riverside 
 Zhou Li | University of California, Irvine 
 Zhuotao Liu | Tsinghua University 
 Ziming Zhao | University at Buffalo 
 Ziqi Yang | Zhejiang University 

  Important dates data

44. Conference SP_2:
S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Call for Workshops  
  Since 1980, the IEEE Symposium on Security and Privacy (SP) has been the premier forum for the presentation of developments in computer security and electronic privacy, and for bringing together researchers and practitioners in the field. To expand opportunities for scientific exchanges, the IEEE CS Technical Committee on Security and Privacy created the Security and Privacy Workshops (SPW). The typical purpose of such a workshop is to cover a specific aspect of security and privacy in more detail, making it easy for the participants to attend IEEE SP and a specialized workshop at SPW with just one trip. Furthermore, the co-location offers synergies for the organizers. The number of workshops and attendees has grown steadily in recent years. Workshops can be annual events, one-time events, or periodic.  
 The 2025 Security and Privacy Workshops will be held on Thursday, May 15, 2025. All workshops will occur on that day. Up to seven workshops will be hosted by SPW.  
 Important Dates  
 All deadlines are 23:59:59 AoE (UTC-12)  .  
  
 Workshop proposals due | September 26, 2024 
 Acceptance notification | October 26, 2024 
 Workshop date | May 15, 2025 
  
 Submission Details  
 Submit your proposal (a single PDF file) at  
  Submit your proposal   
 Please direct questions to sp25-workshopchair@ieee-security.org  .  
 Proposal Requirements  
 There will be some interaction in deciding upon and setting up a workshop, but the initial proposal should already contain a considerable amount of information. A workshop proposal template  is available online at the IEEE S&P “Call for Workshops” website providing instructions and a more detailed description of information to include in proposals:  
 Workshop organizers 
  Workshop length 
  Technical proposal 
  Topics to be addressed 
  Importance of these topics 
  Preliminary call for papers/posters/contributions 
  Preliminary program committee 
  Proposed review process 
  Expected number of participants 
  Publication policy 
  Workshop planning schedule 
  Publicity plan 
  Special meeting logistics requirements 
  Workshop track record 
  Support to Workshop Organizers  
 All workshops associated with the IEEE Symposium on Security and Privacy will be under the financial and legal responsibility of the IEEE Computer Society. This has great advantages for organizers, e.g., with respect to risk coverage and insurance, but also entails some responsibilities and constraints. The SPW organizers can help you with the following: meeting rooms at the conference hotel, meeting logistics (A/V, meals, etc.), registration, awards production, publishing proceedings with IEEE conference publication services (via IEEEXplore), and workshop publicity complimentary with IEEE S&P publicity efforts. Workshops will be advertised through, and workshop websites can be hosted at, ieee-security.org. The SPW committee will also help with publicity via mechanisms available to the IEEE Technical Committee on Security and Privacy, like the Cipher newsletter, and email lists of past attendees (those with opt-in).  
 Responsibilities of Workshop Organizers  
 Workshop organizers have responsibility for maintaining their workshop website; publicity for their workshop; soliciting, reviewing, and accepting papers; constructing the final program; and all interactions with authors, speakers, etc. Reviewing should be done in accordance with IEEE guidelines (3 reviews per paper, avoid conflict of interest (COI), program chair must review all comments before they are sent back to authors, etc.). If you are interested, we will send you a more detailed list of the responsibilities, meeting room configuration options, template schedule for sessions, etc., and would hope to jointly set up a successful workshop. We encourage workshop organizers to seek their own sponsor funding for their needs (e.g., support invited keynote speakers or panelists) but this is not required. However, workshop organizers must check with the main conference’s Donation Chairs before approaching the sponsors.  
 Workshop Evaluation Criteria  
 The purpose of SPW is to complement IEEE S&P and provide an environment conducive to new ideas and discussion. The criteria for evaluation are intended to assess workshop proposals in this context by considering the following:  
 Organizational details: Is the workshop CFP clear, sensible, and thorough? 
  Suitability for SPW by topic 
  Suitability for IEEE S&P attendees: Would a conference attendee want to attend the workshop? 
  Technical merit 
  Conflict or overlap with existing workshops, both those hosted with SPW and others in the community 
  Likelihood of workshop success 
  Preliminary call for participation: Is it clear about the workshop’s purpose? 
  Proposal quality 
  Anticipated attendance: Workshops should have between 30 and 50 attendees 
  Organizing committee: One or more of the organizers should have experience in organizing successful technical events 
  Organizers  
  Chairs  
  
 Workshop Chairs | Gang Wang | University of Illinois Urbana-Champaign 
 Ziming Zhao | Northeastern University 
 Web Chair | Andreas Brüggemann | TU Darmstadt 
  
 Proposal Review Committee  
  
 David Balenson | University of Southern California 
 Adam Doupe | Arizona State University 
 Earlence Fernandes | University of California San Diego 
 Benjamin Fuller | University of Connecticut 
 Xiali Hei | University of Louisiana at Lafayette 
 Limin Jia | Carnegie Mellon University 
 Shirin Nilizadeh | The University of Texas at Arlington 
 Ben Stock | CISPA Helmholtz Center for Information Security 
 Yuan Tian | University of California, Los Angeles 
 Luyi Xing | Indiana University Bloomington 

  Call for papers data:    S & P    
 Home 
  Program | Accepted Papers 
  Call For... | Papers 
  Workshops 
  Donors 
  Attend | Attendee Code of Conduct 
  Twitter 
  Facebook 
  LinkedIn 
  Contact 
  About | Past Conferences 
  Conference Organizers 
  Technical Committee 

 MAY 12-15, 2025 AT THE HYATT REGENCY SAN FRANCISCO SAN FRANCISCO, CA  
 46th IEEE Symposium on  
  Security and Privacy  
 Sponsored by the IEEE Computer Society Technical Committee on Security and Privacy  in cooperation with the International Association for Cryptologic Research   

 Call for Papers   
 Since 1980 in Oakland, the IEEE Symposium on Security and Privacy has been the premier forum for computer security research, presenting the latest developments and bringing together researchers and practitioners. We solicit previously unpublished papers offering novel research contributions in any aspect of security or privacy. Papers may present advances in the theory, design, implementation, analysis, verification, or empirical evaluation and measurement of secure systems. Theoretical papers must make a convincing case for the relevance of their results to practice.  
 Topics of interest include:   
 Applied cryptography 
  Attacks with novel insights, techniques, or results 
  Authentication, access control, and authorization 
  Blockchains and distributed ledger security 
  Cloud computing security 
  Cyber physical systems security 
  Distributed systems security 
  Economics of security and privacy 
  Embedded systems security 
  Formal methods and verification 
  Hardware security 
  Hate, Harassment, and Online Abuse 
  Human-centered security and privacy 
  Intrusion detection and prevention 
  Machine learning and computer security 
  Malware and unwanted software 
  Network security and measurement 
  Operating systems security 
  Privacy-enhancing technologies, anonymity, and censorship 
  Program and binary analysis 
  Protocol security 
  Security and privacy metrics 
  Security and privacy policies 
  Security architectures 
  Security for at-risk populations 
  Software supply chain security 
  Systems security 
  User studies for security and privacy 
  Web security and privacy 
  Wireless and mobile security/privacy 
  This topic list is not meant to be exhaustive; S&P is interested in all aspects of computer security and privacy. Papers without a clear application to security or privacy, however, will be considered out of scope and may be rejected without full review.  
 Systematization of Knowledge Papers   
 As in past years, we solicit systematization of knowledge (SoK) papers that evaluate, systematize, and contextualize existing knowledge, as such papers can provide a high value to our community. Suitable papers are those that provide an important new viewpoint on an established, major research area, support or challenge long-held beliefs in such an area with compelling evidence, or present a convincing, comprehensive new taxonomy of such an area. Survey papers without such insights are not appropriate and may be rejected without full review. Submissions will be distinguished by the prefix “SoK:” in the title and a checkbox on the submission form. They will be reviewed by the full PC and held to the same standards as traditional research papers, but they will be accepted based on their treatment of existing work and value to the community, and not based on any new research results they may contain. Accepted papers will be presented at the symposium and included in the proceedings. You can find an overview of recent SoK papers at https://oaklandsok.github.io  .  
 Submission Deadlines & Decisions   
 Similar to 2024, for each submission, one of the following decisions will be made:  
 Accept:  Papers in this category will be accepted for publication in the proceedings and presentation at the conference. Within one month of acceptance, all accepted papers must submit a camera-ready copy incorporating reviewer feedback. The papers will immediately be published, open access, in the Computer Society’s Digital Library and they may be cited as “To appear in the IEEE Symposium on Security & Privacy, May 2025”. After the symposium, papers will be behind a paywall for one year before they are again made open access. 
  Reject:  Papers in this category are declined for inclusion in the conference. Rejected papers must wait for one year, from the date of original submission, to resubmit to IEEE S&P. A paper will be judged to be a resubmit (as opposed to a new submission) if the paper is from the same or similar authors, and a reviewer could write a substantially similar summary of the paper compared with the original submission. As a rule of thumb, if there is more than 40% overlap between the original submission and the new paper, it will be considered a resubmission. 
  Public Meta-Reviews:  Similar to 2024, all accepted papers will be published with a meta-review (< 500 words) in the final PDF that lists: (a) the reasons the PC decided to accept the paper and (b) concerns the PC has with the paper. Authors will be given the option to write a response to the meta-review (< 500 words) which will be published as part of the meta-review. Authors will be given a draft meta-review at the time of acceptance. Authors will be given the option of addressing some or all of the concerns within one review cycle. A shepherd will remove concerns from the meta-review if they are sufficiently addressed by the revisions.  
   
  The goal of this process is to provide greater transparency and to better scope change requests made by reviewers. More information about the reasons behind this change can be found on the 2024 IEEE S&P website  .  
 Symposium Event (Important Changes)   
 The number of papers accepted to IEEE S&P continues to grow substantially each year. Due to conference venue limitations and costs, each accepted paper will have: (a) a short talk presentation (e.g., 5-7 minutes, length determined based on the number of accepted papers) and (b) a poster presentation immediately following the talk session containing the paper. All accepted papers are required to present both a short talk and a poster.  
 Important Dates   
 All deadlines are 23:59:59 AoE (UTC-12).  
 First deadline   
 Paper submission deadline: June 6, 2024 
  Early-reject notification: July 22, 2024 
  Rebuttal period (interactive): August 19 - August 30, 2024 
  Rebuttal text due: August 26, 2024 
  Acceptance notification: September 9, 2024 
  Camera-ready deadline: October 18, 2024 
  Second deadline   
 Paper submission deadline: November 14, 2024 
  Early-reject notification: January 20, 2025 
  Rebuttal period (interactive): February 17 - February 28, 2025 
  Rebuttal text due: February 24, 2025 
  Acceptance notification: March 10, 2025 
  Camera-ready deadline: April 18, 2025 
  Rebuttal Period   
 Papers reaching the second round of reviewing will be given an opportunity to write a rebuttal to reviewer questions. The rebuttal period will be interactive, and is separate from the meta-review rebuttal given to accepted papers. Authors have the opportunity to exchange messages with the reviewers and respond to questions asked. To this end, we will use HotCRP’s anonymous communication feature to enable a communication channel between authors and reviewers. The authors should mainly focus on factual errors in the reviews and concrete questions posed by the reviewers. New research results can also be discussed if they help to clarify open questions. More instructions will be sent out to the authors at the beginning of the rebuttal period.  
 Resubmission of Rejected Papers   
 As with previous IEEE S&P symposia with multiple submission cycles, rejected papers must wait one year before resubmission to IEEE S&P. Given the move from three submission deadlines in 2024 to two submission deadlines in 2025, rejected papers are eligible to submit according to the table below.  
  
 2024 deadlines | Reject decision  
  Eligible 2025 deadlines 
 First 2024  
  (April 13, 2023) | Either 2025 deadline 
 Second 2024  
  (August 3, 2023) | Either 2025 deadline 
 Third 2024  
  (Dec 6, 2023) | Second deadline  
  (Nov 14, 2024) 
  
 Instructions for Paper Submission   
 These instructions apply to both the research papers and systematization of knowledge (SoK) papers. All submissions must be original work; the submitter must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. Failure to point out and explain overlap will be grounds for rejection. Simultaneous submission of the same paper to another venue with proceedings or a journal is not allowed and will be grounds for automatic rejection. Contact the program committee chairs if there are questions about this policy.  
 Anonymous Submission   
 Papers must be submitted in a form suitable for anonymous review: no author names or affiliations may appear on the title page, and papers should avoid revealing authors’ identity in the text. When referring to their previous work, authors are required to cite their papers in the third person, without identifying themselves. In the unusual case in which a third-person reference is infeasible, authors can blind the reference itself. Papers that are not properly anonymized may be rejected without review. PC members who have a genuine conflict of interest with a paper, including the PC Co-Chairs and the Associate Chairs, will be excluded from evaluation and discussion of that paper.  
   
 While a paper is under submission to the IEEE Security & Privacy Symposium, authors may choose to give talks about their work, post a preprint of the paper to an archival repository such as arXiv, and disclose security vulnerabilities to vendors. Authors should refrain from widely advertising their results, but in special circumstances they should contact the PC chairs to discuss exceptions. Authors are not allowed to directly contact PC members to discuss their submission.  
   
 The submissions will be treated confidentially by the PC chairs and the program committee members. Program committee members are not allowed to share the submitted papers with anyone, with the exception of qualified external reviewers approved by the program committee chairs. Please contact the PC chairs if you have any questions or concerns.  
 Conflicts of Interest   
 During submission of a research paper, the submission site will request information about conflicts of interest of the paper’s authors with program committee (PC) members. It is the full responsibility of all authors of a paper to identify all and only their potential conflict-of-interest PC members, according to the following definition. A paper author has a conflict of interest with a PC member when and only when one or more of the following conditions holds:  
 The PC member is a co-author of the paper. 
  The PC member has been a co-worker in the same company or university within the past two years. | For student interns, the student is conflicted with their supervisors and with members of the same research group. If the student no longer works for the organization, then they are not conflicted with a PC member from the larger organization. 
  The PC member has been a collaborator within the past two years. 
  The PC member is or was the author’s primary thesis advisor, no matter how long ago. 
  The author is or was the PC member’s primary thesis advisor, no matter how long ago. 
  The PC member is a relative or close personal friend of the author. 
  For any other situation where the authors feel they have a conflict with a PC member, they must explain the nature of the conflict to the PC chairs, who will mark the conflict if appropriate. The program chairs will review declared conflicts. Papers with incorrect or incomplete conflict of interest information as of the submission closing time are subject to immediate rejection.  
 Research Ethics Committee   
 Similar to 2024, IEEE S&P 2025 has a research ethics committee (REC) that will check papers flagged by reviewers as potentially including ethically fraught research. The REC will review flagged papers and may suggest to the PC Chairs rejection of a paper on ethical grounds. The REC consists of members of the PC. Authors are encouraged to review the Menlo Report  for general ethical guidelines for computer and information security research.  
 Ethical Considerations for Vulnerability Disclosure   
 Where research identifies a vulnerability (e.g., software vulnerabilities in a given program, design weaknesses in a hardware system, or any other kind of vulnerability in deployed systems), we expect that researchers act in a way that avoids gratuitous harm to affected users and, where possible, affirmatively protects those users. In nearly every case, disclosing the vulnerability to vendors of affected systems, and other stakeholders, will help protect users. It is the committee’s sense that a disclosure window of 45 days https://vuls.cert.org/confluence/display/Wiki/Vulnerability+Disclosure+Policy  to 90 days https://googleprojectzero.blogspot.com/p/vulnerability-disclosure-faq.html  ahead of publication is consistent with authors’ ethical obligations.  
   
 Longer disclosure windows (which may keep vulnerabilities from the public for extended periods of time) should only be considered in exceptional situations, e.g., if the affected parties have provided convincing evidence the vulnerabilities were previously unknown and the full rollout of mitigations requires additional time. The authors are encouraged to consult with the PC chairs in case of questions or concerns.  
   
 The version of the paper submitted for review must discuss in detail the steps the authors have taken or plan to take to address these vulnerabilities; but, consistent with the timelines above, the authors do not have to disclose vulnerabilities ahead of submission. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Note  : Submitted papers should not  include full CVE identifiers in order to preserve the anonymity of the submission.  
 Ethical Considerations for Human Subjects Research   
 Submissions that describe experiments that could be viewed as involving human subjects, that analyze data derived from human subjects (even anonymized data), or that otherwise may put humans at risk should:  
 Disclose whether the research received an approval or waiver from each of the authors’ institutional ethics review boards (IRB) if applicable. 
  Discuss steps taken to ensure that participants and others who might have been affected by an experiment were treated ethically and with respect. 
  If a submission deals with any kind of personal identifiable information (PII) or other kinds of sensitive data, the version of the paper submitted for review must discuss in detail the steps the authors have taken to mitigate harms to the persons identified. If a paper raises significant ethical and/or legal concerns, it will be checked by the REC and it might be rejected based on these concerns. The PC chairs will be happy to consult with authors about how this policy applies to their submissions.  
 Financial and Non-financial competing interests   
 In the interests of transparency and to help readers form their own judgements of potential bias, the IEEE Symposium on Security & Privacy requires authors and PC members to declare any competing financial and/or non-financial interests in relation to the work described. Authors need to include a disclosure of relevant financial interests in the camera-ready versions of their papers. This includes not just the standard funding lines, but should also include disclosures of any financial interest related to the research described. For example, “Author X is on the Technical Advisory Board of the ByteCoin Foundation,” or “Professor Y is the CTO of DoubleDefense, which specializes in malware analysis.” More information regarding this policy is available here  .  
 Page Limit and Formatting (Important Changes)   
 Submitted papers may include up to 13 pages of text and up to 5 pages for references and appendices, totaling no more than 18 pages. All text and figures past page 13 must be clearly marked as part of the appendix. The final camera-ready paper must be no more than 18 pages, although, at the PC chairs’ discretion, additional pages may be allowed. Reviewers are not required to read appendices.  
   
 Papers must be formatted for US letter (not A4) size paper. All submissions must use the IEEE “compsoc” conference proceedings template. LaTeX submissions using the IEEE templates must use IEEEtran.cls version 1.8b with options “conference,compsoc.” (That is, begin your LaTeX document with the line \documentclass[conference,compsoc]{IEEEtran}.). See the “IEEE Demo Template for Computer Society Conferences” Overleaf template  for an example. We are not aware of an MS Word template that matches this style.  
   
 Papers that fail to use the “compsoc” template (including using the non-compsoc IEEE conference template), modify margins, font, or line spacing, or use egregious space scrunching are subject to rejection without review. Authors are responsible for verifying the paper format (e.g., compare with the above linked Overleaf template)  . While HotCRP provides some automated checking, the checks are limited. Note that some LaTeX packages (e.g., \usepackage{usenix}) override the compsoc formatting and must be removed.  
 Withdrawing Policy   
 A paper can be withdrawn at any point before the reviews have been sent to the authors. Once the reviews have been sent to the authors the paper can not be withdrawn.  
 Authorship Policy   
 Changes to the authorship list (adding or removing authors) are not permitted after paper submission. Changes to the authors affiliation after paper acceptance are not permitted without PC chairs approval. If authors anticipate that they might change affiliation during the time the paper is under submission it is recommended to mark both the current and future institution as COI.  
 Conference Submission Server   
 Submissions must be in Portable Document Format (.pdf). Authors should pay special attention to unusual fonts, images, and figures that might create problems for reviewers.  
   
 Submission servers  :  
   
 First deadline | : | https://cycle1.sp2025.ieee-security.org/ 
  Second deadline | : | https://cycle2.sp2025.ieee-security.org/ 
  Publication and Presentation   
 Authors are responsible for obtaining appropriate publication clearances. One of the authors of the accepted paper is expected to register and present the paper at the conference.  
 Program Committee   
 PC Chairs   
  
 William Enck | North Carolina State University 
 Cristina Nita-Rotaru | Northeastern University 
  
 Associate Chairs   
  
 Adwait Nadkarni | William & Mary 
 Alex Kapravelos | North Carolina State University 
 Amir Houmansadr | University of Massachusetts Amherst 
 Batista Biggio | University of Cagliari 
 Christina Garman | Purdue University 
 Ian Miers | University of Maryland, College Park 
 Ioana Boureanu | Univ. of Surrey, Surrey Centre for Cybersecurity 
 Sara Rampazzi | University of Florida 
 Sascha Fahl | CISPA 
 William Robertson | Northeastern University 
  
 REC Chairs   
  
 René Mayrhofer | Johannes Kepler University Linz 
 Blase Ur | University of Chicago 
  
 PC Members   
  
 Adam Bates | University of Illinois at Urbana-Champaign 
 Adam Doupé | Arizona State University 
 Adam Oest | Amazon 
 Adil Ahmad | Arizona State University 
 Ahmad-Reza Sadeghi | Technical University Darmstadt 
 Alena Naiakshina | Ruhr University Bochum 
 Alesia Chernikova | Northeastern University 
 Alessandro Brighente | University of Padova 
 Alexander Block | Georgetown University & University of Maryland 
 Alexandra Dmitrienko | University of Wuerzburg 
 Alexios Voulimeneas | TU Delft 
 Ali Abbasi | CISPA Helmholtz Center for Information Security 
 Álvaro Feal | Northeastern University 
 Amit Seal Ami | William & Mary 
 Ana-Maria Cretu | EPFL, Lausanne, Switzerland 
 Andrei Sabelfeld | Chalmers University of Technology 
 Andrew Kwong | UNC Chapel Hill 
 Andrew Paverd | Microsoft 
 Ang Chen | University of Michigan 
 Angelos Stavrou | Virginia Tech 
 Aniket Kate | Purdue University / Supra Research 
 Antonio Bianchi | Purdue University 
 Anupam Das | North Carolina State University 
 Anwar Hithnawi | ETH Zurich 
 Aravind Machiry | Purdue University 
 Arslan Khan | Pennsylvania State University/ Purdue University 
 Arthur Gervais | UCL 
 Ashish Kundu | Cisco Research 
 Aysajan Abidin | COSIC KU Leuven 
 Bailey Kacsmar | University of Alberta 
 Ben Fisch | Yale University 
 Ben Stock | CISPA Helmholtz Center for Information Security 
 Ben Weintraub | Northeastern University 
 Ben Zhao | University of Chicago 
 Benjamin Beurdouche | Mozilla 
 Blaine Hoak | University of Wisconsin-Madison 
 Bo Chen | Michigan Technological University 
 Bogdan Carbunar | Florida International University 
 Brad Reaves | North Carolina State University 
 Brendan Saltaformaggio | Georgia Institute of Technology 
 Byoungyoung Lee | Seoul National University 
 Chao Zhang | Tsinghua University 
 Charalampos Papamanthou | Yale University 
 Chen-Da Liu-Zhang | Lucerne University of Applied Sciences and Arts & Web3 Foundation 
 Christof Ferreira Torres | ETH Zürich 
 Christopher A. Choquette-Choo | Google DeepMind 
 Claudio Soriente | NEC Laboratories Europe 
 Constantin Catalin Dragan | University of Surrey 
 Daniel Genkin | Georgia Tech 
 Daniel Votipka | Tufts University 
 Daniele Cono D'Elia | Sapienza University of Rome 
 David Balash | University of Richmond 
 Debajyoti Das | KU Leuven 
 Deian Stefan | UC San Diego 
 Dimitrios Papadopoulos | HKUST 
 Diogo Barradas | University of Waterloo 
 Dominik Wermke | NC State 
 Dongdong She | Hong Kong University of Science and Technology 
 Duc Le | Visa Research 
 Earlence Fernandes | UC San Diego 
 Eleonora Losiouk | University of Padua 
 Elisa Bertino | Purdue University 
 Emiliano De Cristofaro | UC Riverside 
 Emily Wenger | Duke University 
 Endadul Hoque | Syracuse University 
 Eric Pauley | University of Wisconsin–Madison 
 Eyal Ronen | Tel Aviv University 
 Eysa Lee | Brown University 
 Fabio De Gaspari | Sapienza Università di Roma 
 Faysal hossain Shezan | University of Texas at Arlington 
 Fengwei Zhang | Southern University of Science and Technology 
 Fernando Virdia | King's College London 
 Florian Kerschbaum | University of Waterloo 
 Florian Tramer | ETH Zurich 
 Frank Li | Georgia Institute of Technology 
 Frank Piessens | KU Leuven 
 Gang Wang | University of Illinois at Urbana-Champaign 
 Gaoning Pan | Hangzhou Dianzi University 
 Georgios Smaragdakis | Delft University of Technology 
 Giovanni Camurati | ETH Zurich 
 Giovanni Cherubin | Microsoft 
 Giulia Fanti | Carnegie Mellon University 
 Giuseppe Ateniese | George Mason University 
 Guangdong Bai | The University of Queensland 
 Guangliang Yang | Fudan University 
 Guanhong Tao | University of Utah 
 Guevara Noubir | Northeastern University 
 Guillermo Suarez-Tangil | IMDEA Networks Institute 
 Habiba Farrukh | University of California, Irvine 
 Haoyu Wang | Huazhong University of Science and Technology 
 Harshad Sathaye | ETH Zürich 
 Haya Schulmann | Goethe-Universität Frankfurt 
 Heather Zheng | University of Chicago 
 Heng Yin | UC Riverside 
 Homa Alemzadeh | University of Virginia 
 Hongxin Hu | University at Buffalo 
 Hyungsub Kim | Purdue University & Indiana University 
 Imtiaz Karim | Purdue University 
 Jack Doerner | Brown University 
 Jaron Mink | Arizona State University 
 Jason Nieh | Columbia University 
 Jason (Minhui) Xue | CSIRO’s Data61 
 Jeremiah Blocki | Purdue University 
 Jiarong Xing | Rice University 
 Jiska Classen | Hasso Plattner Institute 
 Jon McCune | Google 
 Jonas Hielscher | Ruhr University Bochum 
 Joseph Bonneau | a16z crypto research and New York University 
 Jun Han | KAIST 
 Kaihua Qin | Yale University 
 Kelsey Fulton | Colorado School of Mines 
 Kevin Borgolte | Ruhr University Bochum 
 Kevin Butler | University of Florida 
 Klaus v. Gleissenthall | VU Amsterdam 
 Kun Sun | George Mason University 
 Lorenzo Cavallaro | University College London 
 Lucianna Kiffer | ETH Zurich 
 Lucy Simko | Barnard College 
 Luyi Xing | Indiana University Bloomington 
 Man-Ki Yoon | North Carolina State University 
 Marco Squarcina | TU Wien 
 Maria Apostolaki | Princeton University 
 Marina Blanton | University at Buffalo 
 Markus Miettinen | Frankfurt University of Applied Sciences 
 Martin Henze | RWTH Aachen University & Fraunhofer FKIE 
 Matthew Jones | Block 
 Matthew Lentz | Duke University and Broadcom 
 Mauro Conti | University of Padua 
 Meera Sridhar | University of North Carolina Charlotte 
 Meng Shen | Beijing Institute of Technology 
 Michael Waidner | Technische Universität Darmstadt 
 Mohammad Islam | University of Texas at Arlington 
 Mridula Singh | CISPA Helmholtz Center for Information Security 
 Mu Zhang | University of Utah 
 Mulong Luo | The University of Texas at Austin 
 Muoi Tran | ETH Zurich 
 Murtuza Jadliwala | University of Texas at San Antonio 
 Muslum Ozgur Ozmen | Arizona State University 
 Nils Lukas | University of Waterloo 
 Ning Zhang | Washington University in St. Louis 
 Nuno Santos | INESC-ID and Instituto Superior Técnico, University of Lisbon 
 Omar Chowdhury | Stony Brook University 
 Peng Gao | Virginia Tech 
 Pramod Bhatotia | TU Munich 
 Pratik Sarkar | Supra Research 
 Pratyush Mishra | University of Pennsylvania 
 Qi Li | Tsinghua University 
 Qiang Tang | The University of Sydney 
 Qiben Yan | Michigan State University 
 Qingkai Shi | Nanjing University 
 Quinn Burke | University of Wisconsin-Madison 
 Rahul Chatterjee | University of Wisconsin-Madison 
 Ram Sundara Raman | University of Michigan 
 Ramya Jayaram Masti | Ampere Computing 
 Rei Safavi-Naini | University of Calgary 
 Ryan Sheatsley | University of Wisconsin-Madison 
 Saba Eskandarian | University of North Carolina at Chapel Hill 
 Saman Zonouz | Georgia Tech 
 Samira Mirbagher Ajorpaz | North Carolina State University 
 Sathvik Prasad | North Carolina State University 
 Sazzadur Rahaman | University of Arizona 
 Sen Chen | Tianjin University 
 Seyedhamed Ghavamnia | University of Connecticut 
 Sherman S. M. Chow | The Chinese University of Hong Kong 
 Shih-Wei Li | National Taiwan University 
 Shitong Zhu | Meta Platforms Inc. 
 Shuai Wang | Hong Kong University of Science and Technology 
 Siqi Ma | The University of New South Wales 
 Sisi Duan | Tsinghua University 
 Soheil Khodayari | CISPA Helmholtz Center for Information Security 
 Song Li | Zhejiang University 
 Srdjan Capkun | ETH Zurich 
 Sri AravindaKrishnan Thyagarajan | University of Sydney 
 Stephen Herwig | William & Mary 
 Sunil Manandhar | IBM Research 
 Sven Bugiel | CISPA Helmholtz Center for Information Security 
 Swarn Priya | Virginia Tech 
 Syed Rafiul Hussain | Pennsylvania State University 
 Tapti Palit | University of California, Davis 
 Teodora Baluta | National University of Singapore 
 Tianhao Wang | University of Virginia 
 Tobias Fiebig | MPI-INF 
 Trent Jaeger | UC Riverside 
 Tushar Jois | City College of New York 
 VARUN CHANDRASEKARAN | University of Illinois Urbana-Champaign 
 Varun Madathil | Yale University 
 Wajih Ul Hassan | The University of Virginia 
 Weijia He | Dartmouth College 
 Wenjing Lou | Virginia Tech 
 Xiaojing Liao | Indiana University Bloomington 
 Xinda Wang | University of Texas at Dallas 
 Xingliang Yuan | The University of Melbourne 
 Xinyu Xing | Northwestern University 
 Xusheng Xiao | Arizona State University 
 Yan Chen | Northwestern University 
 Yan Shoshitaishvili | Arizona State University 
 Yanchao Zhang | Arizona State University 
 Yaxing Yao | Virginia Tech 
 Yigitcan Kaya | UC Santa Barbara 
 Yingying Chen | Rutgers University 
 Yinxi Liu | Rochester Institute of Technology 
 Yinzhi Cao | Johns Hopkins University 
 Yizheng Chen | University of Maryland 
 Yonghwi Kwon | University of Maryland 
 Yossi Oren | Ben-Gurion University, Israel 
 Yu Ding | Google DeepMind 
 Yuan Tian | UCLA 
 Yupeng Zhang | University of Illinois Urbana Champaign 
 Yuseok Jeon | Ulsan National Institute of Science and Technology (UNIST) 
 Yuval Yarom | Ruhr University Bochum 
 Yuzhe Tang | Syracuse University 
 Z. Berkay Celik | Purdue University 
 Zane Ma | Oregon State University 
 Zhiqiang Lin | Ohio State University 
 Zhiyun Qian | University of California, Riverside 
 Zhou Li | University of California, Irvine 
 Zhuotao Liu | Tsinghua University 
 Ziming Zhao | University at Buffalo 
 Ziqi Yang | Zhejiang University 

  Important dates data

45. Conference SPAA_0:
Skip to content    ACM Symposium on Parallelism in Algorithms and Architectures   
 Portland, Oregon, July 28-August 1, 2025  
   
     Menu  Organizations 
  Awards | SPAA Best Paper Award 
  SPAA Test-of-Time Award 
  SPAA Parallel Computing Award 
  Previous SPAAs 
  SPAA Mailing List 
  Call For Papers 

 SPAA 2025  
  
 The 37th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA ’25) is sponsored by the ACM Special Interest Groups on Algorithms and Computation Theory ( SIGACT  ) and Computer Architecture ( SIGARCH  ) and organized in cooperation with the European Association for Theoretical Computer Science  .  
   
  The conference will run July 28-August 1, 2025, in Portland, Oregon.  
 SafeTOC:  
 SPAA follows the  ACM anti-harassment policy  .  
 Sponsors:  
 Coming soon.  

 Proudly powered by WordPress  ~  Theme: Penscratch 2 by WordPress.com  .   

  Call for papers data:Skip to content    ACM Symposium on Parallelism in Algorithms and Architectures   
 Portland, Oregon, July 28-August 1, 2025  
   
     Menu  Organizations 
  Awards | SPAA Best Paper Award 
  SPAA Test-of-Time Award 
  SPAA Parallel Computing Award 
  Previous SPAAs 
  SPAA Mailing List 
  Call For Papers 

 SPAA Best Paper Award  
  
 Starting from 2007, the SPAA conference has been awarding annual Best Paper Award. In addition, starting in 2016, the SPAA conference has started awarding Outstanding Paper Award or Best Paper Finalists. The paper selection is done by the program committee. Past awards are:  
  
 2024 | Best Papers: | Jeonghyeon Kim, Jaehwang Jung, and Jeehoon Kang. | Expediting Hazard Pointers with Bounded RCU Critical Sections 
  Kunal Agrawal, William Kuszmaul, Zhe Wang, and Jinhao Zhao. | Distributed Load Balancing in the Face of Reappearance Dependencies 
  Outstanding Papers: | Xiangyun Ding, Yan Gu, and Yihan Sun. | Parallel and (Nearly) Work-Efficient Dynamic Programming 
  Klaus Jansen, Malin Rau, and Malte Tutas. | Hardness and Tight Approximations of Demand Strip Packing 
  Sungjin Im, Ravi Kumar, Shi Li, Aditya Petety, and Manish Purohit. | Online Load and Graph Balancing for Random Order Inputs 
  2023 | Best Paper: | Mohsen Ghaffari, Christoph Grunau, and Jiahao Qu. | Nearly Work-Efficient Parallel DFS in Undirected Graphs 
  Outstanding Papers: | Alireza Haqi and Hamid Zarrabi-Zadeh. | Almost Optimal Massively Parallel Algorithms for k-Center Clustering and Diversity Maximization 
  Nairen Cao, Shang-En Huang, and Hsin-Hao Su. | Nearly Optimal Parallel Algorithms for Longest Increasing Subsequence 
  Alexander Fedorov, Diba Hashemi, Giorgi Nadiradze, and Dan Alistarh. | Provably-Efficient and Internally-Deterministic Parallel Union-Find 
  2022 | Best Paper: | Quanquan C. Liu, Jessica Shi, Shangdi Yu, Laxman Dhulipala, and Julian Shun. | Parallel Batch-Dynamic Algorithms for k-Core Decomposition and Related Graph Problems 
  Outstanding Papers  : | Nairen Cao, Jeremy T. Fineman, and Katina Russell. | Parallel Shortest Paths with Negative Edge Weights 
  Gaetano C. Coccimiglio, Trevor A. Brown, and Srivatsan Ravi. | PREP-UC: A Practical Replicated Persistent Universal Construction 
  Kunal Agrawal, Michael A. Bender, Rathish Das, William Kuszmaul, Enoch Peserico, and Michele Scquizzato. | Online Parallel Paging with Optimal Makespan 
  2021 | Best Paper: | Daniel Anderson and Guy Blelloch. | Parallel Minimum Cuts in O(m log^2(n)) Work and Low Depth 
  Outstanding Papers  : | Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Pramod Ganapathi, Aaron Gregory and Yimin Zhu. | Fast Stencil | Computations using Fast Fourier Transforms 
  Susanne Albers and Jens Quedenfeld. | Algorithms for Right-Sizing Heterogeneous Data Centers 
  Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem and Manish Purohit. | Non-Clairvoyant Scheduling with Predictions 
  Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Pramod Ganapathi, Aaron Gregory and Mohammad Javanmard. | Low-Span Parallel Algorithms for the Binary-Forking Model 
  2020 | Best Paper: | Irvan Jahja and Haifeng Yu. | Sublinear Algorithms in T-interval Dynamic Networks 
  Outstanding Papers  : | Guy Blelloch, Jeremy Fineman, Yan Gu and Yihan Sun. | Optimal Parallel Algorithms in the Binary-Forking Model 
  Lazar Milenkovic and Shay Solomon. | A Unified Sparsification Approach for Matching Problems in Graphs of Bounded Neighborhood Independence 
  Lukas Gianinazzi and Torsten Hoefler. | Parallel Planar Subgraph Isomorphism and Vertex Connectivity 
  Udit Agarwal and Vijaya Ramachandran. | Faster Deterministic All Pairs Shortest Paths in Congest Model 
  2019 | Best Paper: | Faith Ellen, Barun Gorain, Avery Miller and Andrej Pelc. | Constant-Length Labeling Schemes for Deterministic Radio Broadcast 
  2018 | Best Papers: | Barbara Geissmann and Lukas Gianinazzi. | Parallel Minimum Cuts in Near-linear Work and Low Depth 
  Laxman Dhulipala, Guy E. Blelloch, and Julian Shun. | Theoretically Efficient Parallel Graph Algorithms Can be Fast and Scalable 
  2017 | Best Papers: | Sepehr Assadi and Sanjeev Khanna. | Randomized Composable Coresets for Matching and Vertex Cover 
  Sudipto Guha, Yi Li and Qin Zhang. | Distributed Partial Clustering 
  2016 | Best Paper: | Tim Roughgarden, Sergei Vassilvitskii and Joshua Wang. | On Lower Bounds for Modern Parallel Computation 
  Outstanding Papers: | Mingmou Liu, Xiaoyin Pan and Yitong Yin. | Randomized Approximate Nearest Neighbor Search with Limited Adaptivity 
  Madhukar Korupolu and Rajmohan Rajaraman. | Robust and Probabilistic Failure-Aware Placement 
  Deli Zhang and Damian Dechev. | Lock-free Transactions without Aborts for Linked Data Structures 
  2015 | Best Paper: | Yossi Azar, Nikhil Devanur, Zhiyi Huang and Debmalya Panigrahi. | Speed Scaling in the Non-clairvoyant Model 
  2014 | Best Paper: | Justin Thaler, Michael Mitzenmacher, and Jiayang Jiang. | Parallel Peeling Algorithms 
  2013 | Best Papers: | Ravi Kumar, Benjamin Moseley, Sergei Vassilvitskii and Andrea Vattani. | Fast Greedy Algorithms in MapReduce and Streaming 
  Martina Eikel and Christian Scheideler. | IRIS: A Robust Information System Against Insider DoS-Attacks 
  2012 | Best Paper: | I-Ting Lee, Aamir Shafi, and Charles Leiserson. | Memory-Mapping Support for Reducer Hyperobjects 
  2011: | Best Paper: | Grey Ballard, James Demmel, Olga Holtz, and Oded Schwartz. | Graph Expansion and Communication Costs of Fast Matrix Multiplication 
  2010: | Best Paper: | Noga Alon, Erik D. Demaine, MohammadTaghi Hajiaghayi and Tom Leighton. | Basic Network Creation Games 
  2009: | Best Paper: | Matteo Frigo, Pablo Halpern, Charles E. Leiserson, and Stephen Lewin-Berlin. | Reducers and Other Cilk++ Hyperobjects 
  2008: | Best Paper: | Zvika Guz, Idit Keidar, Avinoam Kolodny and Uri C. Weiser. | Utilizing Shared Data in Chip Multiprocessors with the Nahalal Architecture 
  2007: | Best Papers: | Pierre Fraigniaud, Cyril Gavoille, Emmanuelle Lebhar, Zvi Lotker and Adrian Kosowski. | Universal Augmentation Schemes for Network Navigability: Overcoming the √n-Barrier 
  Fabian Kuhn, Thomas Locher and Roger Wattenhofer. | Tight Bounds for Distributed Selection 

 Proudly powered by WordPress  ~  Theme: Penscratch 2 by WordPress.com  .   

  Important dates data

46. Conference SOUPS_2:
JavaScript is not available.  
 We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.  
 Help Center   
 Terms of Service  Privacy Policy  Cookie Policy  Imprint  Ads info  © 2024 X Corp.  

 Something went wrong, but don’t fret — let’s give it another shot.    
  
   Try again    
   Some privacy related extensions may cause issues on x.com. Please disable them and try again.    

                  Call for papers data:Important dates data

47. Conference SP_3:
EuroS&P 2025    
 Home 
  Call For... | Papers 
  Sponsorship 
  Workshop Proposals 
  Organization | Steering Committee 
  Program Committee 
  Organizing Committee 
  Past Editions | EuroS&P 2024 
  EuroS&P 2023 
  EuroS&P 2022 
  EuroS&P 2021 
  EuroS&P 2020 
  EuroS&P 2019 
  EuroS&P 2018 
  EuroS&P 2017 
  EuroS&P 2016 
  Twitter 
  Facebook 
  Youtube 

 Venice, June 30 - July 4, 2025  
 10th IEEE European Symposium on Security and Privacy  
   
 Since 1980, the IEEE Symposium on Security and Privacy has been the premier forum for presenting developments in computer security and electronic privacy, and for bringing together researchers and practitioners in the field. Following this story of success, IEEE initiated the European  Symposium on Security and Privacy (EuroS&P), which is organized every year in a European city.  

 Last Updates  

 EuroS&P 2025 will have a mandatory paper registration again ( October 21, 2024, AoE  ), followed by the submission deadline for the papers on October 24, 2024, AoE  . For details, see the Call for Papers    

 October 2024: The submission server is open: https://hotcrp.eurosp2025.ieee-security.org  .  
 31/08/2024: The call for papers is out on our website  .  
 05 2024: EuroS&P 2025 is again looking for self-nomination to the PC. If you are interested, please fill in the Google form    .  
  Important Dates  
 All deadlines are Anywhere on Earth (AoE = UTC-12h)   .  
  
 Research Papers | Registration deadline (incl. topics and abstracts) | 21 October 2024 (Monday) 
 Submission deadline | 24 October 2024 (Thursday) 
 Early rejection notification | 11 December 2024 (Wednesday) 
 R1 Rebuttal period | 12 December - 16 December 2024 (Monday) 
 R2 Rebuttal period | 20 - 23 January 2025 (Monday to Thursday) 
 Author Notification | 13 February 2025 (Thursday) 
 Submission of revised papers | 20 March 2025 (Thursday) 
 Revision Decisions | 3 April 2025 (Thursday) 
 Camera-ready deadline | tentatively:  17 April 2025 (Thursday) 
 Conference | Venice, Italy | 30 June - 4 July 2025 
  
  Organization  

  Call for papers data:   
     EuroS&P 2025    
 Home 
  Call For... | Papers 
  Sponsorship 
  Workshop Proposals 
  Organization | Steering Committee 
  Program Committee 
  Organizing Committee 
  Past Editions | EuroS&P 2024 
  EuroS&P 2023 
  EuroS&P 2022 
  EuroS&P 2021 
  EuroS&P 2020 
  EuroS&P 2019 
  EuroS&P 2018 
  EuroS&P 2017 
  EuroS&P 2016 
  Twitter 
  Facebook 
  Youtube 

 Venice, June 30 - July 4, 2025  
 10th IEEE European Symposium on Security and Privacy  
   
 Call For Papers  
  The IEEE European Symposium on Security and Privacy (Euro S&P) is the younger, more adventurous, and tastier sibling conference of the IEEE Symposium on Security and Privacy ("Oakland" or "NorCal S&P") conference. It is a premier forum for computer security and privacy research, presenting the latest developments and bringing together researchers and practitioners.  
 We solicit previously unpublished papers offering novel research contributions in security or privacy as well as Systematization of Knowledge papers that systematize previous results. EuroS&P is interested in all aspects of applied computer security and privacy. We especially encourage papers that are far-reaching and risky, provided those papers show sufficient promise for creating interesting discussions and usefully questioning widely-held beliefs. Papers without a clear connection to security or privacy will be considered out of scope and may be rejected without full review.  
 Conference Expectations  
 Since its inception, EuroS&P has been running as a single-track conference. We believe that maintaining the engagement and sense-of-community benefits that come from a single-track conference is very beneficial. At the same time, we expect that with the rising number of submissions, the time allocated to each will decrease more and more. Therefore, at the time of publishing the CfP, we can neither commit to a single-track conference nor to the length of presentations at the conference.  
 We aim for a review process that will be rigorous and thorough, resulting in the acceptance of every paper with scientific merit and sufficient value to the community, and incorporate a four-week revision opportunity in which the PC assists authors to try to get as many papers as possible to the level needed.  
 Revision Option  
 EuroS&P features the option to revise papers for which the program committee sees a path for revision that is likely to lead to acceptance, even though the initial submission was not considered acceptable. If authors who are invited to do so wish to submit a revised paper, they must do so within four weeks of the notification. Revised papers will be re-reviewed by the same reviewers who reviewed the original submission. Neither acceptance with shepherding nor an invitation to submit a revised paper implies that eventual acceptance is certain.  
 New in 2025: Per-Reviewer Responses  
 Almost all major security and privacy conferences feature an author-response phase, sometimes including interactive exchanges between authors and reviewers. As chairs, we have experienced this process to be challenging for both authors and reviewers; authors need to fit their response into a short word limit and reviewers must untangle the answers to their questions from the dense responses. To improve on this, EuroS&P 2025 will feature per-reviewer responses. Reviewers will be asked to provide a limited set of explicit questions that the response should focus on. Authors are then expected to solely  focus on the questions as well as factual errors. To ensure timely responses, we will provide the reviews for all papers which advance to Round 2 and will subsequently give authors approx. three working days to respond to the initial Round 1 reviews. Then, after Round 2, authors will be provided with all additional reviews and can respond to the new ones. Note that papers rejected after Round 1 will not be able to provide responses.  
 With this change, we hope to improve on the communication between individual reviewers and authors, but also to provide reviewers to read the responses with the papers still fresh in their minds rather than weeks after submitting their Round 1 reviews.  
 Returning from 2024: Meta Reviews  
 The discussions about individual papers are conducted “behind closed doors” within the set of reviewers. In the best case, reviewers will leave a summary of the discussion visible exclusively to the authors. To facilitate more transparency in the process of accepting papers, EuroS&P 2025 will feature a publicly available meta review (accessible through the EuroS&P website) for each accepted paper. This meta review will outline the PC’s main reasons for accepting the paper and may also contain limitations the PC identified.  
 Systematization of Knowledge Papers  
 We solicit systematization of knowledge (SoK) papers that evaluate, systematize, and contextualize existing knowledge, as such papers can provide a high value to our community. Suitable papers are those that provide an important new viewpoint on an established, major research area; support or challenge long-held beliefs in such an area with compelling evidence; or present a convincing, comprehensive new taxonomy of such an area. Survey papers without such insights are not appropriate.  
 Submissions will be distinguished by the prefix "SoK:" in the title on the submission form. They will be reviewed by the full PC and held to the same standards as traditional research papers, except instead of emphasizing novel research contributions, the emphasis will be on their value to the community. Accepted papers will be presented at the symposium and included in the proceedings.  
 Paper Awards  
 Outstanding papers will be selected by the program committee for paper awards. The award finalists and winners will be announced at the symposium.  
 Important Dates  
 All deadlines are Anywhere on Earth (AoE = UTC-12h)   .  
  
 Research Papers | Registration deadline (incl. topics and abstracts) | 21 October 2024 (Monday) 
 Submission deadline | 24 October 2024 (Thursday) 
 Early rejection notification | 11 December 2024 (Wednesday) 
 R1 Rebuttal period | 12 December - 16 December 2024 (Monday) 
 R2 Rebuttal period | 20 - 23 January 2025 (Monday to Thursday) 
 Author Notification | 13 February 2025 (Thursday) 
 Submission of revised papers | 20 March 2025 (Thursday) 
 Revision Decisions | 3 April 2025 (Thursday) 
 Camera-ready deadline | tentatively:  17 April 2025 (Thursday) 
 Conference | Venice, Italy | 30 June - 4 July 2025 

 Proactive Prevention of Harm  
 We expect authors to carefully consider and address the potential harms associated with carrying out their research, as well as the potential negative consequences that could stem from publishing their work. Failure to adequately discuss such potential harms within the body of the submission may result in rejection of a submission, regardless of its quality and scientific value.  
 Although risking to cause harm is sometimes a necessary and legitimate aspect of scientific research in computer security and privacy, authors are expected to document how they addressed and mitigated such risks. This includes, but is not limited to, considering the impact of the research on deployed systems, understanding the costs the research imposes on others, safely and appropriately collecting data, and following responsible disclosure practices. Papers should include a clear statement as to how the benefit of the research outweighs the potential harms, and how the authors have taken measures and followed best practices to ensure safety and minimize the potential harms caused by their research.  
 If the submitted research has potential to cause harm, and authors have access to an Institutional Review Board (IRB), we expect that this IRB was consulted appropriately and that its approval and recommendations are documented in the paper. We note that IRBs are not necessarily well-versed in computer security research and may not know the best practices and community norms in our field, so IRB approval does not absolve researchers from considering ethical aspects of their work. In particular, IRB approval is not sufficient to guarantee that the PC will not have additional concerns with respect to harms associated with the research.  
 We encourage authors to consult existing documentation, e.g., Common Pitfalls in Writing about Security and Privacy Human Subjects Experiments, and How to Avoid Them  or the Menlo Report  and existing Safety consultation entities, e.g., the Tor Safety Research Board  . These can help in thinking about potential harms, and in designing the safest experiments and disclosure processes.  
 Open Science Expectations  
 Our expectation for Euro S&P is that researchers will maximize the scientific and community value of their work by making it as open as possible. This means that, by default, all of the code, data, and other materials (such as survey instruments) needed to reproduce your work described in an accepted paper will be released publicly under an open source license. Sometimes it is not possible to share work this openly, such as when it involves malware samples, data from human subjects that must be protected, or proprietary data obtained under agreement that preclude publishing the data itself. All submissions must  therefore include a clear statement on Data Availability ( as a separate appendix which does not count towards the page limit  ) that explains how the artifacts needed to reproduce their work will be shared, or an explanation of why they will not be shared. The Program Chairs will hold authors to the commitments made in their submissions, and papers that fail to satisfy these commitments may be removed from the conference.  
 Plagiarism and Duplicate Submission  
 All submissions must be original work. Plagiarism (whether of others or self) will be grounds for rejection. The submission must clearly document any overlap with previously published or simultaneously submitted papers from any of the authors. Failure to point out and explain overlap will be grounds for rejection.  
 Simultaneous submission of the same or substantially similar paper to another venue with proceedings or a journal is not allowed and will be grounds for automatic rejection.  
 Anonymous Submission  
 Papers must be submitted in a form suitable for anonymous review: no author names or affiliations may appear on the title page, and papers should avoid revealing their identity in the text. When referring to your previous work, do so in the third person, as though it were written by someone else. References should only be blinded in the (unusual) case that a third-person reference is infeasible. Any source code or other material (e.g., data sets) which requires hosting must use anonymous services. This explicitly excludes hosting on Github (which may leak author identities) or Google Drive (which could leak reviewer identities). Instead, authors are encouraged to use services such Anonymous Github  . Contact the program chairs if you have any questions. Papers that are not properly anonymized may be rejected without review.  
 The purpose of anonymous submissions is to give reviewers the chance to read the paper without being biased by knowing the authors. Hence authors are required to ensure that the paper they submit does not, within reason, leak their identity.  
 However, the process of anonymous submission is considered to be cooperative, not adversarial. Authors should not put explicit clues to their identity in the paper or otherwise purposefully deanonymize themselves to reviewers. Authors who think disclosing revealing aspects of their identities or setting would be important for positioning the paper, should consult with the PC chairs on how to do this in their submission. Reviewers are trusted to not actively look for the identity of authors, for instance by searching the internet for the paper title. By policy, authors may post their paper to public "preprint" archives (including arxiv) before, during, or after the review period.  
 The Program Chairs will reject papers that, in their sole judgment, blatantly violate the requirement for author anonymity.  
 Reviews from Prior Submissions  
 For papers that were previously submitted to, and rejected from, another conference, authors may optionally submit a separate document containing the (anonymized, but otherwise unedited) prior reviews along with a description of how those reviews were addressed in the current version of the paper.  
 To avoid biasing reviewers, reviewers will only see the provided supplementary material after submitting their own review. Then, reviewers will be able to see the submitted previous reviews, and may revise their review as a result.  
 Page Limit and Formatting  
 Papers shall not exceed 13 pages of body text, with unlimited additional pages for references and appendices. The statement on Data Availability should be part of the appendix, and does not count towards the page limit. Reviewers are explicitly not expected to read the appendices while deciding whether to accept or reject the paper.  
 Papers must be typeset in LaTeX in A4 format (not "US Letter") using the IEEE conference proceeding template we supply eurosp-template.zip  Please do not use other IEEE templates.  
 Submissions must be in Portable Document Format (.pdf). Authors should pay special attention to unusual fonts, images, and figures that might create problems for reviewers. Your document should render correctly in Adobe Reader XI and when printed in black and white.  
 Failure to adhere to the page limit and formatting requirements can be grounds for rejection without review.  
 Conference Submission Server  
 Papers must be submitted at https://hotcrp.eurosp2025.ieee-security.org  and may be updated at any time until the submission deadline expires.  
 Publication and Presentation  
 Authors are responsible for obtaining appropriate publication clearances. One of the authors of the accepted paper is expected to present the paper at the conference. We are expecting to hold an in-person conference and that authors will be able to travel to the conference to present their paper. In case this is not possible, at least one author still must register for the conference, but unless a replacement for the presenter can be found, the presentation will be skipped. Instead, EuroS&P will offer to link to a video presentation from its website.  

  Important dates data

48. Conference SPAA_1:
Conference Partner   Home 
  Conferences 
  Journals 
  Proofreading 
  Login 

  中文  |  English  |  Español  |  日本語     

 Conference Partner  » Conferences  » SPAA    
  Conference Information   
   
 SPAA 2025: ACM Symposium on Parallelism in Algorithms and Architectures  
 https://spaa.acm.org/   
   
 Submission Date: | 2025-02-11 
 Notification Date: | 2025-05-20 
 Conference Date: | 2025-07-28 
 Location: | Portland, Oregon, USA 
 Years: | 37 
  
 CCF: b  CORE: a  QUALIS: a2  Viewed: 54506  Tracked: 89  Attend: 3    

  Call For Papers   
   
 The 37th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA ’25) will run on July 28—August 1, 2025 in Portland, Oregon. Submissions are sought in all areas of parallel and distributed computing, including algorithms, data structures, computational models, complexity theory, architectures, performance engineering, languages, runtime systems, compilers, programming systems, and networking systems. Papers that are purely theoretical, purely experimental, or contain both theory and experiments are welcome. Topics of interest include, but are not limited to: Parallel and Distributed Algorithms Parallel, Concurrent, and Distributed Data Structures Models for Parallel and Distributed Computing Parallel and Distributed Architectures Parallel Programming Languages System Software for Parallel and Concurrent Programming (including but not limited to Runtime, Compilers, and Tools) Parallel Programming Frameworks and Domain-Specific Languages Management of Massive Data Sets Transactional Memory Hardware and Software Supercomputer Architecture and Computing Routing and Information Dissemination Peer-to-Peer Systems Mobile, Ad-Hoc, and Sensor Networks Synergy of Parallelism in Algorithms, Programming and Architecture Memory or I/O-efficient algorithms Parallel Complexity Theory Green Computing & Power-Efficient Architectures Instruction Level Parallelism and VLSI Scheduling Algorithms for Parallel Machines Parallelism in Quantum Computing  Last updated by Dou Sun  in 2024-11-23   

  Best Papers   

 Year | Best Papers 
 2020 | Sublinear Algorithms in T-interval Dynamic Networks 
 2020 | A Unified Sparsification Approach for Matching Problems in Graphs of Bounded Neighborhood Independence 
 2020 | Parallel Planar Subgraph Isomorphism and Vertex Connectivity 
 2020 | Faster Deterministic All Pairs Shortest Paths in Congest Model 
 2020 | Optimal Parallel Algorithms in the Binary-Forking Model 
 2019 | Constant-Length Labeling Schemes for Deterministic Radio Broadcast 
 2018 | Parallel Minimum Cuts in Near-linear Work and Low Depth 
 2018 | Theoretically Efficient Parallel Graph Algorithms Can be Fast and Scalable 
 2017 | Randomized Composable Coresets for Matching and Vertex Cover 
 2017 | Distributed Partial Clustering 
  
 Go to page: << First 
  < Previous 
  1 
  2 
  3 
  Next > 
  Last >> 
    
 4043  4042  4041  4040  4039  2125  2126  2127  2128  2129    

  Related Conferences   

 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 ISAIMT | International Symposium on Advanced and Intelligent Manufacturing Technology | 2017-12-20 | 2017-12-30 
 ISCTEE | International Seminar on Information Science, Computer Technology and Electrical Engineering | 2017-08-11 | 2017-08-18 
 AIIoT | IEEE World AI IoT Congress | 2024-04-03 | 2024-04-19 | 2024-05-29 
 AINTEC | Asian Internet Engineering Conference | 2024-05-08 | 2024-06-18 | 2024-08-09 
 b | b1 | PPDP | ACM SIGPLAN Symposium on Principles and Practice of Declarative Programming | 2024-05-06 | 2024-07-03 | 2024-09-09 
 ICDV | International Conference on Integrated Circuits, Design, and Verification | 2024-01-30 | 2024-03-15 | 2024-06-06 
 SoutheastCon | IEEE Region 3 South East Conference | 2019-02-17 | 2019-03-03 | 2019-04-11 
 b3 | RAW | Reconfigurable Architectures Workshop | 2013-02-01 | 2013-05-20 
 c | a | b1 | ICSA | IEEE International Conference on Software Architecture | 2024-11-08 | 2024-12-15 | 2025-03-31 
 NSS/MIC | Nuclear Science Symposium and Medical Imaging Conference | 2015-05-05 | 2015-10-31 
  
 2472  2310  4367  684  454  4738  1833  198  176  870    

 Short | Full Name | Submission | Conference 
 ISAIMT | International Symposium on Advanced and Intelligent Manufacturing Technology | 2017-12-20 | 2017-12-30 
 ISCTEE | International Seminar on Information Science, Computer Technology and Electrical Engineering | 2017-08-11 | 2017-08-18 
 AIIoT | IEEE World AI IoT Congress | 2024-04-03 | 2024-05-29 
 AINTEC | Asian Internet Engineering Conference | 2024-05-08 | 2024-08-09 
 PPDP | ACM SIGPLAN Symposium on Principles and Practice of Declarative Programming | 2024-05-06 | 2024-09-09 
 ICDV | International Conference on Integrated Circuits, Design, and Verification | 2024-01-30 | 2024-06-06 
 SoutheastCon | IEEE Region 3 South East Conference | 2019-02-17 | 2019-04-11 
 RAW | Reconfigurable Architectures Workshop | 2013-05-20 
 ICSA | IEEE International Conference on Software Architecture | 2024-11-08 | 2025-03-31 
 NSS/MIC | Nuclear Science Symposium and Medical Imaging Conference | 2015-05-05 | 2015-10-31 
  
 2472  2310  4367  684  454  4738  1833  198  176  870    

  Related Journals   

 CCF | Full Name | Impact Factor | Publisher | ISSN 
 IEEE Computer Architecture Letters | 1.400 | IEEE | 1556-6056 
 a | IEEE Transactions on Image Processing | 10.80 | IEEE | 1057-7149 
 International Journal of Control, Automation, and Systems | 2.500 | Springer | 1598-6446 
 Computers, Materials & Continua | 2.000 | Tech Science Press | 1546-2218 
 Processes | 2.800 | MDPI | 2227-9717 
 ACM SIGSOFT Software Engineering Notes | ACM | 0163-5948 
 The International Journal of Advanced Manufacturing Technology | 2.900 | Springer | 0268-3768 
 Electronic Commerce Research and Applications | 5.900 | Elsevier | 1567-4223 
 Telecommunications Policy | 5.900 | Elsevier | 0308-5961 
 a | The VLDB Journal | 2.800 | Springer | 1066-8888 
  
 831  140  813  868  1065  91  487  371  822  102    

 Full Name | Impact Factor | Publisher 
 IEEE Computer Architecture Letters | 1.400 | IEEE 
 IEEE Transactions on Image Processing | 10.80 | IEEE 
 International Journal of Control, Automation, and Systems | 2.500 | Springer 
 Computers, Materials & Continua | 2.000 | Tech Science Press 
 Processes | 2.800 | MDPI 
 ACM SIGSOFT Software Engineering Notes | ACM 
 The International Journal of Advanced Manufacturing Technology | 2.900 | Springer 
 Electronic Commerce Research and Applications | 5.900 | Elsevier 
 Telecommunications Policy | 5.900 | Elsevier 
 The VLDB Journal | 2.800 | Springer 
  
 831  140  813  868  1065  91  487  371  822  102    

  Recommendation   

 Track It 89 
  Attend It 3 
  Edit CFP 

 Tracker 
 HongLi Zhong (772) 
 Xin Xiao (330) 
 Gongming Zhao (1812) 
 M D (299) 
 Qin Siyuan (127) 
 Xuyang Zhao (208) 
 Peng Liu (421) 
 Wenda Tang (1156) 
 Zewei Mo (210) 
 Lei Xiao (281) 
 Xinyu Hao (773) 
 Tang Bisheng (1388) 
 Zaixing Sun (688) 
 Zenghui Ren (872) 
 Yang Jianchao (897) 
 Wei Li (4637) 
 Zhou Shuxin (791) 
 Bob Alice (183) 
 Wenjie Qi (536) 
 Yc Z (292) 
 Qi Guo (1314) 
 Qinglin Wang (423) 
 Renzhi Xiao (453) 
 Baosen Zhao (1694) 
 Luis Gong (193) 
 Mufei Qiu (460) 
 Yansong Zhang (220) 
 Zhihua Fan (859) 
 Wang Hao (693) 
 Zhenlong Ma (415) 
 Xiaoyang Zhang (377) 
 Hongliang Li (986) 
 Liang Zhang (1042) 
 Shizhi Jiang (346) 
 Tongxue Chen (167) 
 Roolmich Pierre (407) 
 Xiaoni Meng (843) 
 Yj C (1672) 
 Zhongkai Tong (4010) 
 Li Zhigang (340) 
 Sunyear Jack (2096) 
 HU QINGHAO (557) 
 Wu Zheng (1071) 
 Miao Hu (5116) 
 Ye Wang (103) 
 Borena Liu (358) 
 Yaoyao Ying (363) 
 Lu My (345) 
 Shuiliusheng Shuiliusheng (511) 
 WANG Farui (150) 
 Wentao Li (1231) 
 Chao Zhang (645) 
 Xu Bin (1398) 
 A B (125) 
 Xiaoqing Cai (601) 
 L CL (1224) 
 Hu Deqi (330) 
 Chunhui HE (1874) 
 Chen Wenyan (78) 
 Yuan Meng (312) 
 Daning Cheng (1127) 
 Gu Jiangtao (351) 
 Yangyang Zhang (1219) 
 Hong Zhou (589) 
 Xun Jia (425) 
 Miao Yu (1213) 
 Yajuan Du (1221) 
 Feng Sheng (3443) 
 He Huaiwen (543) 
 G J (612) 
 Haoran Cai (5042) 
 Changbalao Lee (508) 
 Lu Gangzhao (1166) 
 Wellington Martins (48) 
 Huifeng Wang (374) 
 Hanshen Xiao (701) 
 Xiaowei Shen (992) 
 Hongfei Tan (149) 
 C Yang (604) 
 Jiacheng Zhang (828) 
 Yatao Zhu (161) 
 Yang Zhang (479) 
 Yanhua Li (581) 
 Giorgis Georgakoudis (138) 
 Xiaox Lee (542) 
 Suzuki Mineko (149) 
 Wu Na (1303) 
 Starking Chen (1166) 
 Jiao Dai (741) 
  
 44062  53725  4084  67350  65483  60652  59471  8612  47772  53373  46958  43862  33399  51873  30489  5218  15709  48127  43257  28324  37212  19675  38890  43001  39372  43027  42833  31958  21233  30621  23943  38052  20283  35938  34528  35745  31407  25405  26722  31666  28671  23316  18373  18092  28852  25038  24116  17931  23730  23251  2463  18599  15893  19716  19669  18218  19148  15857  18858  13022  8716  12785  882  6631  7095  9380  6325  6956  5438  3971  4864  3310  5532  754  2185  2671  548  3246  3045  2923  2563  2297  128  982  864  251  221  102  118    

 Attender | Year 
 Hua Yang (4898) | 2024 
 Haifei Zhang (75) | 2023 
 Renzhi Xiao (453) | 2023 
  
 11900  54910  38890    
   
  Advertisment   

  4,945  Conferences | 1,179  Journals | 69,627  Researchers | 385,881,284 PV  
  Copyright © 2011-2024 myhuiban.com. All Rights Reserved. About Us  | Facebook  | X  | Post CFP or Contact Us  | Promotion    

  Call for papers data:Đang tải...   
 Hệ thống không thể thực hiện thao tác ngay bây giờ. Hãy thử lại sau.   
   
     Trích dẫn  

     Tìm kiếm nâng cao  

 Tìm bài viết    
   
 có tất cả  các từ    

 có cụm từ chính xác     

 có ít nhất một  trong các từ    

 không có  các từ    

 nơi xuất hiện các từ của tôi    
  bất cứ nơi nào trong bài viết       
  trong tiêu đề bài viết       

 Trả về các bài viết được viết  bởi    

 ví dụ: "PJ Hayes"  hoặc McCarthy    

 Trả về các bài viết được xuất bản  trong    

 ví dụ: J Biol Chem  hoặc Nature    

 Trả về các bài viết đề ngày  trong khoảng    

 —    

 ví dụ: 1996    

     Đã lưu vào Thư viện của tôi  

 Xong     Xóa bài viết       

   Bài viết     Hồ sơ     
   Hồ sơ của tôi     Thư viện của tôi     Thông báo     Số liệu     
   Tìm kiếm nâng cao     
   Cài đặt     
   
   Đăng nhập     

 Đăng nhập    

 Bài viết  Scholar   

   Hồ sơ của tôi     Thư viện của tôi   Năm     Mọi lúc  Từ 2024  Từ 2023  Từ 2020    
 Sắp xếp theo mức độ liên quan  Sắp xếp theo ngày    

     Mọi loại  Bài viết đánh giá    
 bao gồm bằng sáng chế     bao gồm trích dẫn       

 Mọi lúc 
  Từ 2024 
  Từ 2023 
  Từ 2020 
  Phạm vi tùy chọn... 

 —    

 Tìm kiếm      
    
 Sắp xếp theo mức độ liên quan 
  Sắp xếp theo ngày 
  Mọi loại 
  Bài viết đánh giá 
  bao gồm bằng sáng chế 
  bao gồm trích dẫn 

 [PDF]  acm.org    

 Theoretically efficient parallel graph algorithms can be fast and scalable   
 L Dhulipala  , GE Blelloch  , J Shun  - ACM Transactions on Parallel …, 2021 - dl.acm.org   
 L Dhulipala  , GE Blelloch  , J Shun    
 ACM Transactions on Parallel Computing (TOPC), 2021 •  dl.acm.org   
 There has been significant recent interest in parallel graph processing due to the need to  
  quickly analyze the large graphs available today. Many graph codes have been designed  
  for distributed memory or external memory. However, today even the largest publicly-  
  available real-world graph (the Hyperlink Web graph with over 3.5 billion vertices and 128  
  billion edges) can fit in the memory of a single commodity multicore server. Nevertheless,  
  most experimental work in the literature report results on much smaller graphs, and the ones …   

 There has been significant recent interest in parallel graph processing due to the need to quickly analyze the large graphs available today. Many graph codes have been designed for distributed memory or external memory. However, today even the largest publicly-available real-world graph (the Hyperlink Web graph with over 3.5 billion vertices and 128 billion edges) can fit in the memory of a single commodity multicore server. Nevertheless, most experimental work in the literature report results on much smaller graphs, and the ones for the Hyperlink graph use distributed or external memory. Therefore, it is natural to ask whether we can efficiently solve a broad class of graph problems on this graph in memory.   
 This paper shows that theoretically-efficient parallel graph algorithms can scale to the largest publicly-available graphs using a single machine with a terabyte of RAM, processing them in minutes. We give implementations of theoretically-efficient parallel algorithms for 20 important graph problems. We also present the interfaces, optimizations, and graph processing techniques that we used in our implementations, which were crucial in enabling us to process these large graphs quickly. We show that the running times of our implementations outperform existing state-of-the-art implementations on the largest real-world graphs. For many of the problems that we consider, this is the first time they have been solved on graphs at this scale. We have made the implementations developed in this work publicly-available as the Graph Based Benchmark Suite (GBBS).   
   
  ACM Digital Library   

 Hiện thêm  Ẩn bớt      

   Lưu     Trích dẫn   Trích dẫn 186 bài viết  Bài viết có liên quan  Tất cả 16 phiên bản          

 Đang hiển thị kết quả tốt nhất cho tìm kiếm này. Xem tất cả kết quả    

 Quyền riêng tư  Điều khoản  Trợ giúp    
 Giới thiệu về Scholar  Trợ giúp về Tìm kiếm    

   Important dates data

49. Conference SOUPS_3:
usenix_logo_notag_white                         Sign In 
  Conferences 

 USENIX supports diversity, equity, and inclusion and condemns hate and discrimination  .  

   Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Program At a Glance 
  Technical Sessions 
    Activities 
  Poster Session 
  Participate | Call for Papers 
  Call for Workshops and Beyond 
  Call for Workshops Submissions 
    Call for Posters 
  Call for Lightning Talks 
    Karat Award Call for Nominations 
  Mentoring Program 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Symposium Organizers 
  Past Symposia 
    Conference Policies 
  Code of Conduct 
  Questions 

  Twentieth Symposium on Usable Privacy and Security  
   
 August 11–13, 2024   

 Philadelphia, PA, USA   

 Co-located with   
 USENIX Security '24    

  Thanks to those who joined us in Philadelphia, PA, USA for the Twentieth Symposium on Usable Privacy and Security (SOUPS 2024). We hope you enjoyed the event.  
 SOUPS brings together an interdisciplinary group of researchers and practitioners in human-computer interaction, security, and privacy.  
 As part of our commitment to open access to research, the full proceedings and presentation slides are free and open to the public on the technical sessions  page. Videos are posted within a few weeks of the end of the event.  

 SOUPS 2024 Workshops  
 See the Call for Workshops Submissions page  for an overview of all of these events.  
 The following events were held on Sunday, August 11:  
 SUPA 2024: Societal and User-Centered Privacy in AI    
  9:00 am–1:00 pm  
 Designing Effective and Accessible Approaches for Digital Product Cybersecurity Education and Awareness    
  9:00 am–1:00 pm  
 GOSS: Gender, Online Safety, and Sexuality Workshop (GOSS)    
  2:00 pm–6:00 pm (Hybrid Event)   
 WSIW 2024: 10th Workshop on Security (and Privacy) Information Workers    
  2:30 pm–6:00 pm  
 S&PEI: Workshop on Creating Engaging Security and Privacy Educational Interfaces for Educators and Families   :  
  9:00 am–5:00 pm (offsite at Drexel University)   
  
  The following workshops were held as a virtual events prior to SOUPS 2024:  
 Workshop on Usable Cybersecurity and Privacy for Immersive Technologies    
  Wednesday, August 7, 1:00 pm–4:30 pm  
 WPTM 2024: 3rd Annual Workshop on Privacy Threat Modeling    
  Thursday, August 8, 11:00 am–2:00 pm  
 WIPS 2024: 9th Workshop on Inclusive Privacy and Security    
  Friday, August 9, 9:00 am–5:00 pm  

 Registration Information  
 Early Bird Registration Deadline: Monday, July 22, 2024   
 See the Registration Information page  for details, including fees, discount information, and other deadlines.  
 Discounts  
 In addition to our member discounts  , USENIX offers several discounts  to help you to attend SOUPS 2024, including a hardship discount for USENIX members who are unemployed or retired, in between jobs, or lack employer support.  

 USENIX Conference Policies  
 We encourage you to learn more about USENIX's values  and how we put them into practice at our conferences.  
 Accessibility Information  
 USENIX is committed to ensuring that our meetings are fully accessible to all attendees. Visit our accessibility information page  for details on mothers' rooms, ADA accessibility accommodation options, and how to make a request.  

 Venue  
 Philadelphia Marriott Downtown   
  1201 Market Street  
  Philadelphia, PA 19107  
  USA  
  +1 215.625.2900  
 Hotel Reservation Deadline: Monday, July 22, 2024   
 USENIX has negotiated a special conference attendee room rate of US$219 plus tax for single/double occupancy for conference attendees, including in-room wireless internet. To receive this rate, book your room online  or call the hotel and mention USENIX or SOUPS 2024 when making your reservation.  
 The group rate is available through July 22, 2024,  or until the block sells out, whichever occurs first. After this date, contact the hotel directly to inquire about room availability.  
 Room and Ride Sharing  
 USENIX maintains a Google Group  to facilitate communication among attendees seeking roommates and ride sharing. You can sign up for free to find attendees with whom you can share a hotel room, taxi, shuttle, or other ride-share service. Please include "SOUPS 2024"  in the subject line when posting a new request.  
 Parking  
 See the hotel's website for up-to-date parking information and rates  .  

 About SOUPS 2024  
 Conference Policies   
  Code of Conduct   
  View Past Symposia   

 Questions?  
 Review our Conference FAQs  , and send direct queries via email:  
 Registration: conference@usenix.org   
  Membership: membership@usenix.org   
  Sponsorship: sponsorship@usenix.org   
  Student Grants: students@usenix.org   
  Proceedings Papers: production@usenix.org   

 Symposium Organizers  

 Patrick Gage Kelley   
 Google   
 General Chair   

 Apu Kapadia   
 Indiana University Bloomington   
 General Chair   

 Technical Papers Co-Chairs   
 Katharina Krombholz, CISPA Helmholtz Center for Information Security    

 Mainack Mondal, IIT Kharagpur    

 Technical Papers Committee   
 Svetlana Abramova, University of Innsbruck    

 Taslima Akter, University of California, Irvine    

 Nalin Asanka Gamagedara Arachchilage, The University of Auckland    

 Hala Assal, Carleton University    

 Adam J. Aviv, The George Washington University    

 Alexandru Bardas, University of Kansas    

 Lujo Bauer, Carnegie Mellon University    

 Eleanor Birrell, Pomona College    

 Kevin Butler, University of Florida    

 Joe Calandrino, Federal Trade Commission    

 Sonia Chiasson, Carleton University    

 Camille Cobb, University of Illinois Urbana–Champaign    

 Lynne Coventry, Northumbria University    

 Sauvik Das, Carnegie Mellon University    

 Sascha Fahl, CISPA Helmholtz Center for Information Security    

 Cori Faklaris, University of North Carolina at Charlotte    

 Yuanyuan Feng, University of Vermont    

 Carrie Gates, Bank of America    

 Maximilian Golla, CISPA Helmholtz Center for Information Security    

 Julie Haney, National Institute of Standards and Technology    

 Jun Ho, Huh, Samsung Research    

 Bailey Kacsmar, University of Alberta    

 Hassan Khan, University of Guelph    

 Doowon Kim, University of Tennessee    

 Hyoungshick Kim, Sungkyunkwan University    

 Bart Knijnenburg, Clemson University    

 Maina Korir, University of Suffolk    

 Heather Lipford, University of North Carolina at Charlotte    

 Sana Maqsood, York University    

 Karola Marky, Ruhr University Bochum    

 Abigail Marsh, Macalester College    

 Peter Mayer, University of Southern Denmark    

 Michelle Mazurek, University of Maryland    

 Susan E. McGregor, Data Science Institute and Columbia University    

 Imani Munyaka, University of California, San Diego    

 Alena Naiakshina, Ruhr University Bochum    

 Simon Parkin, Delft University of Technology    

 Irwin Reyes, Two Six Technologies    

 Joshua Reynolds, Walmart    

 Scott Ruoti, University of Tennessee    

 Florian Schaub, University of Michigan    

 Kent Seamons, Brigham Young University    

 Elizabeth Stobert, Carleton University    

 Jose Such, King's College London and Universitat Politecnica de Valencia    

 Zhibo (Eric) Sun, Drexel University    

 Nida ul Habib Bajwa, Saarland University    

 Kami Vaniea, University of Waterloo    

 Emanuel von Zezschwitz, Google    

 Josephine Wolff, Tufts University Fletcher School    

 Yaxing Yao, Virginia Tech    

 Daniel Zappala, Brigham Young University    

 Yixin Zou, Max Planck Institute for Security and Privacy    

 Mary Ellen Zurko, MIT Lincoln Laboratory    

 Invited Talks Chair   
 Heather Lipford, University of North Carolina at Charlotte    

 Lightning Talks and Demos Co-Chairs   
 Taslima Akter, University of California Irvine    

 Alexandru Bardas, University of Kansas    

 Lightning Talks and Demos Junior Co-Chair   
 Eva Gerlitz, Fraunhofer FKIE    

 Karat Award Chair   
 Emilee Rader, University of Wisconsin—Madison    

 Posters Co-Chairs   
 Kovila P.L. Coopamootoo, King's College London    

 Joshua Reynolds, Walmart    

 Posters Junior Co-Chair   
 Sophie Stephenson, University of Wisconsin—Madison    

 Tutorials and Workshops Co-Chairs   
 Kelsey Fulton, Colorado School of Mines    

 Daniel Votipka, Tufts University    

 Tutorials and Workshops Junior Co-Chair   
 Sabrina Klivan, CISPA Helmholtz Center for Information Security    

 Mentoring Co-Chairs   
 Sauvik Das, Carnegie Mellon University    

 Sana Maqsood, York University    

 Mentoring Junior Co-Chairs   
 Nicholas Huaman, Leibniz University Hannover    

 Tanusree Sharma, University of Illinois at Urbana–Champaign    

 Publicity Co-Chairs   
 Yaxing Yao, Virginia Tech    

 Yixin Zou, Max Planck Institute for Security and Privacy    

 Email List Chair   
 Lorrie Faith Cranor, Carnegie Mellon University    

 Accessibility Chair   
 Casey Henderson-Ross, USENIX Association    

 USENIX Liaison   
 Casey Henderson-Ross, USENIX Association    

 Gold Sponsors  

 Silver Sponsor  

 Bronze Sponsor  

 General Sponsor  

 Conference Sponsorship  
 Become a Sponsor:  Sponsorship exposes your brand to highly qualified attendees, funds our grants program, supports open access to our conference content, and keeps USENIX conferences affordable. USENIX is a 501(c)(3) non-profit organization that relies on sponsor support to fulfill its mission. To learn more, please contact the Sponsorship Department  with the conference name in your subject line.  
 The acceptance of any organization as a sponsor does not imply explicit or implicit approval by USENIX of the donor organization’s values or actions. In addition, sponsorship does not provide any control over conference program content. Questions? Contact the Sponsorship Department  .  

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Program At a Glance 
  Technical Sessions 
  Activities 
  Poster Session 
  Participate | Call for Papers 
  Call for Workshops and Beyond 
  Call for Workshops Submissions 
  Call for Posters 
  Call for Lightning Talks 
  Karat Award Call for Nominations 
  Mentoring Program 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Symposium Organizers 
  Past Symposia 
  Conference Policies 
  Code of Conduct 
  Questions 

  LinkedIn    Facebook    Youtube    Twitter    Mastodon     

 Privacy Policy 
  Contact Us 

 © USENIX 2024  

  Call for papers data:  usenix_logo_notag_white                         Sign In 
  Conferences 

   Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Program At a Glance 
  Technical Sessions 
    Activities 
  Poster Session 
  Participate | Call for Papers 
  Call for Workshops and Beyond 
  Call for Workshops Submissions 
    Call for Posters 
  Call for Lightning Talks 
    Karat Award Call for Nominations 
  Mentoring Program 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Symposium Organizers 
  Past Symposia 
    Conference Policies 
  Code of Conduct 
  Questions 

 SOUPS 2024 Call for Papers  

 The Twentieth Symposium on Usable Privacy and Security (SOUPS 2024)  will take place August 11–13, 2024, and will be co-located with the 33rd USENIX Security Symposium  in Philadelphia, PA, USA.  
 In cooperation with USENIX  , the Advanced Computing Systems Association   
 Important Dates  
 All dates are at 23:59 AoE ( Anywhere on Earth  ) time. These are firm deadlines; no extensions will be granted.   
 Mandatory Paper Registration Deadline: | Thursday, February 8, 2024 
  Paper Submission Deadline: | Thursday, February 15, 2024 
  Early Rejection Notification: | Thursday, March 21, 2024 
  Author Response Period: | Thursday, April 18–Thursday, April 25, 2024 
  Paper Notifications: | Monday, May 13, 2024 
  Camera Ready Deadline: | Monday, June 10, 2024 
  Download Call for Papers PDF    
 Symposium Organizers  

 General Chair   
 Patrick Gage Kelley, Google    

 Apu Kapadia, Indiana University Bloomington    

 Technical Papers Co-Chairs   
 Katharina Krombholz, CISPA Helmholtz Center for Information Security    

 Mainack Mondal, IIT Kharagpur    

 Technical Papers Committee   
 Svetlana Abramova, University of Innsbruck    

 Taslima Akter, University of California, Irvine    

 Nalin Asanka Gamagedara Arachchilage, The University of Auckland    

 Hala Assal, Carleton University    

 Adam J. Aviv, The George Washington University    

 Alexandru Bardas, University of Kansas    

 Lujo Bauer, Carnegie Mellon University    

 Eleanor Birrell, Pomona College    

 Kevin Butler, University of Florida    

 Joe Calandrino, Federal Trade Commission    

 Sonia Chiasson, Carleton University    

 Camille Cobb, University of Illinois Urbana–Champaign    

 Lynne Coventry, Northumbria University    

 Sauvik Das, Carnegie Mellon University    

 Sascha Fahl, CISPA Helmholtz Center for Information Security    

 Cori Faklaris, University of North Carolina at Charlotte    

 Yuanyuan Feng, University of Vermont    

 Carrie Gates, Bank of America    

 Maximilian Golla, CISPA Helmholtz Center for Information Security    

 Julie Haney, National Institute of Standards and Technology    

 Jun Ho, Huh, Samsung Research    

 Bailey Kacsmar, University of Alberta    

 Hassan Khan, University of Guelph    

 Doowon Kim, University of Tennessee    

 Hyoungshick Kim, Sungkyunkwan University    

 Bart Knijnenburg, Clemson University    

 Maina Korir, University of Suffolk    

 Heather Lipford, University of North Carolina at Charlotte    

 Sana Maqsood, York University    

 Karola Marky, Ruhr University Bochum    

 Abigail Marsh, Macalester College    

 Peter Mayer, University of Southern Denmark    

 Michelle Mazurek, University of Maryland    

 Susan E. McGregor, Data Science Institute and Columbia University    

 Imani Munyaka, University of California, San Diego    

 Alena Naiakshina, Ruhr University Bochum    

 Simon Parkin, Delft University of Technology    

 Irwin Reyes, Two Six Technologies    

 Joshua Reynolds, Walmart    

 Scott Ruoti, University of Tennessee    

 Florian Schaub, University of Michigan    

 Kent Seamons, Brigham Young University    

 Elizabeth Stobert, Carleton University    

 Jose Such, King's College London and Universitat Politecnica de Valencia    

 Zhibo (Eric) Sun, Drexel University    

 Nida ul Habib Bajwa, Saarland University    

 Kami Vaniea, University of Waterloo    

 Emanuel von Zezschwitz, Google    

 Josephine Wolff, Tufts University Fletcher School    

 Yaxing Yao, Virginia Tech    

 Daniel Zappala, Brigham Young University    

 Yixin Zou, Max Planck Institute for Security and Privacy    

 Mary Ellen Zurko, MIT Lincoln Laboratory    

 Invited Talks Chair   
 Heather Lipford, University of North Carolina at Charlotte    

 Lightning Talks and Demos Co-Chairs   
 Taslima Akter, University of California Irvine    

 Alexandru Bardas, University of Kansas    

 Lightning Talks and Demos Junior Co-Chair   
 Eva Gerlitz, Fraunhofer FKIE    

 Karat Award Chair   
 Emilee Rader, University of Wisconsin—Madison    

 Posters Co-Chairs   
 Kovila P.L. Coopamootoo, King's College London    

 Joshua Reynolds, Walmart    

 Posters Junior Co-Chair   
 Sophie Stephenson, University of Wisconsin—Madison    

 Tutorials and Workshops Co-Chairs   
 Kelsey Fulton, Colorado School of Mines    

 Daniel Votipka, Tufts University    

 Tutorials and Workshops Junior Co-Chair   
 Sabrina Klivan, CISPA Helmholtz Center for Information Security    

 Mentoring Co-Chairs   
 Sauvik Das, Carnegie Mellon University    

 Sana Maqsood, York University    

 Mentoring Junior Co-Chairs   
 Nicholas Huaman, Leibniz University Hannover    

 Tanusree Sharma, University of Illinois at Urbana–Champaign    

 Publicity Co-Chairs   
 Yaxing Yao, Virginia Tech    

 Yixin Zou, Max Planck Institute for Security and Privacy    

 Email List Chair   
 Lorrie Faith Cranor, Carnegie Mellon University    

 Accessibility Chair   
 Casey Henderson-Ross, USENIX Association    

 USENIX Liaison   
 Casey Henderson-Ross, USENIX Association    

 Overview  
 The 2024 Symposium on Usable Privacy and Security (SOUPS) will bring together an interdisciplinary group of researchers and practitioners in human computer interaction, security, and privacy. The program will feature:  
 Technical papers, including replication papers and systematization of knowledge papers 
  Workshops and tutorials 
  A poster session 
  Lightning talks 
  Technical Papers  
 We invite authors to submit previously unpublished papers describing research or experience in all areas of usable privacy and security. We welcome a variety of research methods, including both qualitative and quantitative approaches. Papers will be judged on their scientific quality, overall quality, and contribution to the field. Topics include, but are not limited to:  
 Innovative security or privacy functionality and design 
  Field studies of security or privacy technology 
  Usability evaluations of new or existing security or privacy features 
  Security testing of new or existing usability features 
  Longitudinal studies of deployed security or privacy features 
  Studies of administrators or developers and support for security and privacy 
  Organizational policy or procurement decisions and their impact on security and privacy 
  Lessons learned from the deployment and use of usable privacy and security features 
  Foundational principles of usable security or privacy 
  Ethical, psychological, sociological, or anthropological aspects of usable security and privacy 
  Usable security and privacy implications/solutions for specific domains (e.g., IoT, medical, vulnerable populations) 
  Replicating or extending important previously published studies and experiments 
  Systematization of knowledge papers that integrate and systematize existing knowledge to provide new insight into a previously studied area 
  Paper Registration:  Technical papers must be registered by February 8, 2024  . Registration is mandatory for all papers. Registering a paper in the submission system requires filling out all the fields of the online form that describe the submission, but does not require uploading a PDF of the paper. This information must describe the paper accurately, in sufficient detail to assign appropriate reviewers. Placeholder, incomplete, or inaccurate titles and abstracts may result in rejection without review.   
 Paper Submission:  Technical papers must be uploaded as PDFs by February 15, 2024  (but note the mandatory February 8 registration deadline above). All submissions must follow the guidelines described below. Submissions that violate any of the requirements below may be rejected without review.   
 Contact the program chairs prior to submission at soups24chairs@usenix.org  if you have any questions about these requirements.  
 Format and Page Limits:  Papers must use the SOUPS formatting template (available for MS Word  or LaTeX  ) and be submitted as a PDF via the web submission system  . Submissions must be no more than 12 pages (excluding acknowledgments, bibliography, and appendices). For the body of your paper, brevity is appreciated, as evidenced by the fact that many published papers in prior years have been well under this limit.   
 Submissions may include as many additional pages as needed for references and for supplementary material in appendices. The paper should stand alone without the supplementary material. We encourage authors to use the appendices for content that is peripheral to the main contributions of the paper but that may interest some readers or that may facilitate replication. Note that members of the program committee are free to not read this material when reviewing the paper. Camera-ready versions of accepted papers have an official limit of 12 pages (excluding acknowledgments, bibliography, and appendices) and 20 pages total including references and appendices. The program committee chairs will grant any extension they determine reasonable to accommodate references and supplemental material.  
 Paper Content:  Papers need to describe the purpose and goals of the work, cite related work, show how the work effectively integrates usability or human factors with security or privacy, and clearly indicate the innovative aspects of the work or lessons learned as well as the contribution of the work to the field. The paper abstracts should contain a sentence summarizing the contribution to the field and literature.  
 All submissions must clearly relate to the human aspects of security or privacy. Papers on security or privacy that do not address usability or human factors will not be considered. Likewise, papers on usability or human factors that do not address security or privacy will not be considered. The determination of whether a paper is within scope will be solely at the discretion of the program committee chairs.  
 Your paper and research approach—including research instruments—should be inclusive and respectful. A variety  of guidance  exists  on this topic. Please be sure to follow guidance on language use from the USENIX statement on racism and Black, African-American, and African Diaspora inclusion  .  
 Systematization of Knowledge Papers:  We are soliciting Systematization of Knowledge (SoK) papers that integrate and systematize existing knowledge to provide new insight into a previously studied area of usable security or privacy. SoK papers should draw on prior work to put forth a new taxonomy, argument, or observation in an area in which substantial work has already been done. SoK papers should be more than a survey or summary of prior work in an area. SoK papers will be held to the same scientific and presentation standards as other technical papers. Please prefix the title of these papers with “SoK:” and check the SoK checkbox on the submission form to flag them for the review process.  
 Replication Papers:  In addition to original work, we are soliciting well-executed replication studies that meaningfully confirm, question, or clarify the result under consideration. Please prefix the title of these papers with the word “Replication:” for the review process.  
 Replication papers should aim to replicate important/influential findings from the literature. They may not necessarily offer new or unexpected findings; papers confirming previous findings are also considered contributions. Replication of a result that has already been replicated many times is less valuable. Replication of an obscure study that originally had only minimal influence on the community is less valuable. Authors should clearly state why they conducted a replication study, describe the methodological differences precisely, and compare their findings with the results from the original study.  
 Replication papers will be held to the same scientific standards as other technical papers. They should use currently accepted methodologies and technologies. Authors should not reuse outdated methods/technologies simply because they were used in the original paper. Replications may follow the same protocol as the original study, or may vary one or more key variables to see whether the result is extensible (e.g., re-running a study with a sample from a different population).  
 Anonymous Submission:  Reviewing is anonymous. No names or affiliations should appear on the title page or in the body of the paper, acknowledgments should be removed, and papers should avoid revealing the authors' identities in the text (e.g., don't name a specific organization's ethics review board or similar) or in the PDF metadata. Any references to the authors' own work should be made in the third person, as if it was work by someone else.  Appendices and figures should also be de-identified (e.g., do not leave logos or contact info on study materials, and remove identifying URLs from screenshots). Please ensure all author names, affiliations, URLs, etc. have been removed; even minor mistakes may result in rejection without review. Contact the program chairs at soups24chairs@usenix.org  if you have any questions.  
 Overlap with Previous Papers:  USENIX policy  prohibits simultaneous submission of the same work to multiple venues, submission of previously published work, and plagiarism. SOUPS further prohibits the submission of substantially similar work to multiple venues. On the recommendation of a program chair, USENIX may take action against authors who have committed these practices. Any overlap between your submitted paper and other work either under submission, previously published, or submitted elsewhere before the SOUPS notification deadline must be documented in an explanatory note sent to the chairs. If a subsequent overlapping submission is made during the review process, the chairs should be notified. State precisely how the two works differ in their goals, share experiments or data sources, and offer unique contributions. If the other work is under submission elsewhere, the program committee may ask to review that work to evaluate the overlap. Please note that program committees frequently share information about papers under review and reviewers usually work on multiple conferences simultaneously. Technical reports, e.g., arXiv reports, are exempt from this rule. If in doubt, please contact the program chairs at soups24chairs@usenix.org  for advice.  
 Self-plagiarism includes verbatim or near-verbatim use of one's own published work without citing the original source, and is generally not acceptable. In some cases, it may be acceptable to include a brief  portion of selected content from the introduction, background, related work, or methods of a closely related paper. In these cases, the original paper must be explicitly referenced and the overlap should be clear to the reader. The reused content must not be part of the main contributions of the paper and, where possible, rewriting the text is preferred. Papers with significant text reuse may be rejected because of too much overlap. If in doubt, please contact the program chairs at soups24chairs@usenix.org  for advice.  
 Appendices:  Authors may attach to their paper supplementary appendices containing study materials (e.g., survey instruments, interview guides, etc.) that would not otherwise fit within the body of the paper. These appendices may also include any material that could assist reviewers with questions that fall outside the stated contribution of your paper on which your work is to be evaluated. Appendices can include links (e.g. to a working prototype or source code repository or data repository); please include full links (not shortened ones), and try to use long-term archives like osf.io or Dataverse for online appendices. Reviewers are not required to read any appendices, so your paper should be self contained without them. We note that in recent years, inclusion of study materials as appendices has become very common, and reviewers may choose to refer to appendices for clarification or confirmation. Accepted papers will be published online with their supplementary appendices included.  
 Conflicts of Interest:  The submission system will request information about conflicts of interest between the paper's authors and program committee (PC) members, including a brief explanation. It is the full responsibility of all authors of a paper to identify their potential conflict-of-interest PC members, according to the following definition. A paper author has a conflict of interest with a PC member when one or more of the following conditions holds:  
 The PC member shared an institutional affiliation with the author in the prior two years. 
  The PC member was the advisor or advisee of the author at any time. 
  The PC member has collaborated or published with the author in the prior two years. 
  The PC member is serving as the sponsor or administrator of a grant that funds the author's research. 
  The PC member is a close personal friend or relative of the author. 
  We recognize that special circumstances may exist, such as deep personal animosity. If you have any questions or concerns, please contact the program chairs at soups24chairs@usenix.org  .  
 Ethical Research:  User studies should follow the basic principles of ethical research, including beneficence (maximizing the benefits to an individual or to society while minimizing harm to the individual), minimal risk (appropriateness of the risk versus benefit ratio), voluntary consent, respect for privacy, and limited deception. Studies that rely on crowdworkers can incur additional ethical obligations, including but not limited to paying a fair wage. If images of participants are included in the paper, make sure that these images will not create potential risk for participants and that the informed consent covers potential publication of participant images.  
 All papers, especially those with human subjects studies, are expected to discuss ethical considerations. Risks and benefits of the presented research should be weighed. Methodological decisions should be justified. Authors may be asked to provide additional explanations should questions arise during the review process.  
 If your organization or institution requires formal clearance for research with human subjects, your paper may be rejected if clearance is not obtained. However, such clearance alone does not guarantee acceptance, and the program committee may reject a paper on ethical grounds.  
 Early Rejections:  Papers that receive substantially negative initial reviews will be rejected early. The authors of early-rejected papers, and only such papers, will receive a copy of their initial reviews. At this point, papers are no longer considered under submission (except if authors appeal).  
 Authors who substantively disagree with the reviews can appeal to the program committee chairs. Authors' appeals must clearly and explicitly identify concrete disagreements with factual statements in the initial reviews. Appealing a submission that was rejected early will keep it under consideration, and it cannot be withdrawn or resubmitted elsewhere until the final notification of acceptance or rejection.  
 Response:  A response period will occur after the second round of reviews. Authors will be given a chance to see reviews, and they may provide a short response that will be considered in subsequent discussions. Due to time constraints, the response period is fairly short. Please ensure that you reserve enough time between April 18 and 25 for the response process. Late responses will not be accepted.   
 Presentation:  For accepted papers, we require at least one of the paper authors to attend the conference and present the work. However, in exceptional cases, authors of accepted papers may present remotely with permission from the PC Co-Chairs. If you have any questions, please contact the program chairs at soups24chairs@usenix.org  .  
 Credits   
  * Overlap with Previous Papers policy adapted from USENIX Security 2021  
  * Conflict of Interest policy adapted from USENIX Security 2020  
  * Early Rejection policy adapted from IEEE Symposium on Security and Privacy 2017  
  * Replication papers description adapted from Elsevier Journal of Molecular and Cellular Cardiology   
  * SoK papers description adapted from IEEE Symposium on Security and Privacy 2018  
 SUBMIT YOUR WORK   

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Program At a Glance 
  Technical Sessions 
  Activities 
  Poster Session 
  Participate | Call for Papers 
  Call for Workshops and Beyond 
  Call for Workshops Submissions 
  Call for Posters 
  Call for Lightning Talks 
  Karat Award Call for Nominations 
  Mentoring Program 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Symposium Organizers 
  Past Symposia 
  Conference Policies 
  Code of Conduct 
  Questions 

  LinkedIn    Facebook    Youtube    Twitter    Mastodon     

 Privacy Policy 
  Contact Us 

 © USENIX 2024  

  Important dates data

50. Conference SPAA_2:
Account | Sign In  Register 
  Join | Join plus  today to earn stamps and receive other rewards as you spend in our shops, cafes, and online* 
  Wish list 
    
  Shop Finder 
  Help 
  Events 
  Blog 
  Gift Cards 
  Win 

 Waterstones    
   
  Menu   
  New 
  Christmas 
  Special Editions 
  Books 
  Our Favourites 
  Games 
  Stationery & Gifts 
  Festive Favourites   Christmas Shop 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  Great Book Deals 
  2024's Most Wanted 
  Signed & Special Editions 
  Bestsellers 
  Paperbacks of the Year 
  Gift Cards 
  The Best Books of 2024 Blogs 
  Writers Recommend: Winter Reads 
  Christmas Entertainment 
    Christmas Essentials   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Festive Reads 
  Christmas Eve Boxes 
  Calendars 
  Full Year Diaries 
     Top Categories   Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Crime 
  Science Fiction & Fantasy 
  Romantasy 
  Manga 
  Clothbound Classics 
  Biography 
  Food & Drink 
  Humour 
  Puzzles & Quizes 
  Sport 
     Children's Christmas    Children's Stationery and Gifts 
  Stocking Fillers 
  Christmas Eve Boxes 
  First Christmas 
  Children's Gifts For ... 
  Annuals 
  Games & Puzzles 
  Toys 
  Jellycat 
  Soft Toys 
  Harry Potter 
  Favourite Characters 
  Favourite Authors 
  Reference 
  LEGO® 
  Children's Paperbacks of the Year 
  Gift Books 
  Legami 
     Stationery & Gifts    Gifts 
  Games 
  Jigsaw Puzzles 
  Calendars & Diaries 
  Arts & Crafts 
  Top Categories   Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Great Book Deals 
  Paperback Offers 
  Book Awards 
  Books of the Month 
  Dyslexia-friendly Books 
    Fiction    Waterstones Debut Fiction Prize 
  Anthologies & Short Stories 
  Classics 
  Clothbound Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  LGBTQ+ Fiction 
     Crime    Classic Crime 
  Cosy Crime 
  Historical Crime 
  Thrillers 
  True Crime 
    Graphic Novels & Manga    Graphic Novels 
  Manga 
    Science Fiction, Fantasy & Horror    Fantasy 
  Fantasy Romance 
  Horror 
  Science Fiction 
     Non-Fiction Books    Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Entertainment 
  Environment 
  Film & TV 
  Food & Drink 
  Health & Lifestyle 
  History 
  Hobbies, Quizzes & Games 
  Home & Garden 
  Humour 
  Language & Reference 
  Mindfulness 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, Technology & Medicine 
  Self-Help 
  Spirituality & Beliefs 
  Sport 
  Transport 
  Travel 
     Children's    Baby, Toddler & Pre-School 
  Picture Books 
  Favourite Characters & Authors 
  Ages 5-8 
  Ages 9-12 
  Teenage and Young Adult 
  Children's Paperback Offers 
    Popular Children's Categories   Children's Favourite Authors 
  Annuals 2025 
  Gift Books 
  LGBTQ+ Young Adult 
  Activity Books 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Laureate 
  Dyslexia-friendly Books for Children 
  Books for Reluctant Readers 
  School Holidays 
  Our Favourite Pages   Bestsellers 
  Christmas 
  Waterstones Book of the Year 
  The Books You've Always Meant to Read 
  Coming Soon 
  Gift Books 
  Gifts For... 
  Between the Covers 
  The Booker Library 
  BookTok 
  Books of the Month 
  Game of the Month 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Great Book Deals 
  Careers 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Events 
  Waterstones Podcast 
     Favourite Authors   Agatha Christie 
  Cassandra Clare 
  Colleen Hoover 
  David Nicholls 
  Elly Griffiths 
  Frank Herbert 
  George R.R. Martin 
  Haruki Murakami 
  J.R.R. Tolkien 
  Julia Quinn 
  Kazuo Ishiguro 
  Lee Child 
  Leigh Bardugo 
  Rebecca Yarros 
  Richard Osman 
  Sarah J Maas 
  Stephen King 
  Taylor Jenkins Reid 
  Terry Pratchett 
    Favourite Series   Bridgerton 
  Discworld 
  Doctor Who 
  Dune 
  A Game of Thrones 
  Hunger Games 
  Star Wars 
     Favourite Children's & YA Authors   Alice Oseman 
  A.F. Steadman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  Jennifer Lynn Barnes 
  J.K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  Suzanne Collins 
  Tom Fletcher 
     Favourite Children's Characters, Friends & Series    Asterix & Obelix 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tintin 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  All Games    Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
     Top Categories   Family Games 
  Logic & Deduction Games 
  Party Games 
  Strategy Games 
  Traditional Games 
  Travel Games 
  Word Games 
  Accessories & Dice 
  Dungeons & Dragons 
     More Games Categories   Abstract Games 
  Bluffing Games 
  Cooperative Games 
  Film & TV Games 
  Single Player Games 
  Thematic Games 
  Two Player Games 
  Christmas   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Calendars 
  Full Year Diaries 
    Gifts    Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Jigsaw Puzzles 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  Toys & Games 
     Children's    Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaw Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  Toys 
     Stationery    Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Calendars & Diaries 
    Book Accessories    Book Lights and Lamps 
  Bookmarks 
  Reading Glasses & Magnifiers 
     Arts & Crafts    Brushes 
  Canvas 
  Crafting 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
    
 Books 
  Christmas 
  Children's 
  Games 
  Our Favourites 
  New Books 
  Great Book Deals 
  Coming Soon 
  Stationery & Gifts 
  Gift Cards 
  Gift Books 
  Signed & Special Editions 
  Blog 
  Events 
  Podcast 
  Prize Draws 
  BACK 
  Fiction Bestsellers 
  Anthologies and Short Stories 
  Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  BACK 
  Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Paperback Offers 
  Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Manga 
  Waterstones Debut Fiction Prize 
  Book Awards 
  Books of the Month 
  Cultural Highlights 
  BACK 
  Advent Calendars 
  Christmas Gift Wrap 
  Christmas Cards 
  Calendars 
  Full Year Diaries 
  BACK 
  Crime Bestsellers 
  Agatha Christie 
  Classic Crime 
  Cosy Crime 
  historical Crime 
  Thrillers 
  True Crime 
  BACK 
  Dungeons & Dragons 
  Abstract 
  Accessories & Dice 
  Bluffing Games 
  Board Games 
  Card Games 
  Cooperative Games 
  Family Games 
  Film & TV Games 
  Logic & Deduction 
  Party Games 
  Quiz & Trivia Games 
  Single Player Games 
  Strategy Games 
  Thematic Games 
  Traditional Games 
  Travel Games 
  Two Player Games 
  Word Games 
  BACK 
  Christmas Entertainment 
  Christmas Shop 
  Festive Favourites 
  Christmas Essentials 
  Children's Christmas 
  BACK 
  Writers Recommend: Winter Reads 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  2024's Most Wanted 
  Signed & Special Editions 
  Paperbacks of the Year 
  Gift Cards 
  Best Books of 2024 Blogs 
  BACK 
  Sci-fi & fantasy bestsellers 
  Science Fiction 
  fantasy 
  Fantasy Romance 
  Graphic Novels 
  Horror 
  Manga 
  game of thrones 
  Doctor Who 
  Good Omens 
  Star Wars 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks Offers 
  Children's Favourite Authors 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Calendars 
  Full Year Diaries 
  Advent Calendars 
  Christmas Cards 
  Christmas Eve Boxes 
  Festive Reads 
  Christmas Gift Wrap 
  BACK 
  Children's Stationery & Gifts 
  Stocking Fillers 
  First Christmas 
  Christmas Eve Boxes 
  Children's Gifts For ... 
  Annuals 
  Harry Potter 
  Jellycat 
  Favourite Characters 
  Favourite Authors 
  Children's Paperbacks of the Year 
  Gift Books 
  BACK 
  All Games 
  Browse Categories 
  Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
  BACK 
  Toys & Games 
  Gifts 
  Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  BACK 
  Book Lights 
  Bookmarks 
  Reading Glasses & Magnifiers 
  BACK 
  Bestsellers 
  Christmas 
  The Books You've Always Meant to Read 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Gift Cards 
  Gifts For... 
  Great Book Deals 
  Between the Covers 
  The Booker Library 
  BookTok 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Books of the Month 
  Game of the Month 
  Manga 
  Dyslexia-friendly Books 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Bookshops 
  Waterstones Events 
  Waterstones Podcast 
  BACK 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  BACK 
  Stationery Bestsellers 
  Calendars & Diaries 
  Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Pens & Pencils 
  BACK 
  Fiction 
  Crime 
  Sci-fi & fantasy 
  Graphic Novels 
  Manga 
  Clothbound Classics 
  Modern & Contemporary Fiction 
  BACK 
  Bluey 
  Elmer 
  Dog Man 
  the gruffalo 
  Guess How Much I Love You 
  harry potter 
  Heartstopper 
  Horrible histories 
  Little People, Big Dreams 
  Mog the Cat 
  Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Tom Gates 
  That's Not My... 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  Elmer 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People, Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Christmas 
  Stationery & Gifts 
  Children's Stationery & Gifts 
  Gifts 
  Book Accessories 
  Children's 
  Stationery 
  Calendars & Diaries 
  Arts & Crafts 
  BACK 
  Browse All Arts & Crafts 
  Brushes 
  Canvas 
  Craft 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
  BACK 
  Non-Fiction Bestsellers 
  Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Education & Study Guides 
  entertainment 
  environment 
  Film & TV 
  food & drink 
  health & lifestyle 
  History 
  Hobbies, quizzes & games 
  home & garden 
  Humour 
  Language & reference 
  Mind, body & spirit 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, technology & medicine 
  Self-Help 
  spirituality & beliefs 
  Sports 
  Transport 
  Travel & Maps 
  True Crime 
  BACK 
  Alice Oseman 
  Beatrix Potter 
  Cassandra Clare 
  David Walliams 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J.K. Rowling 
  Julia Donaldson 
  Liz Pichon 
  Karen McManus 
  Malorie Blackman 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Suzanne Collins 
  Tom Fletcher 
  A.F. Steadman 
  Alice Oseman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J. K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Liz Pichon 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks of the Year 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Children's Fiction 
  Annuals 2025 
  Dyslexic & Reluctant Readers 
  early learning 
  Education & Study Guides 
  Hobbies & Interests 
  Gift Books 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Activity Books 
  Waterstones Children's Laureate 
  BACK 
  Annuals 2025 
  Gift Books 
  Books for Reluctant Readers 
  Dyslexia-friendly Books for Children 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Activity Books 
  LGBTQ+ Young Adult 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Waterstones Children's Laureate 
  School Holidays 
  BACK 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 
  Colouring & Painting 
  Crafts & Hobbies 
  Educational Toys & Games 
  Jellycat 
  LEGO ® 
  Soft Toys 
  Toys 
  BACK 
  Children's Stationery & Gifts 
  Educational Toys & Games 
  Jellycat Toys 
  LEGO® 
  Soft Toys 
  Toys 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 

 0  Basket   
  Spend £25.00   to qualify for free UK delivery.   
 Your order qualifies for free UK delivery.   

  Join  plus   before checkout to earn stamps on your order and be eligible for plus  rewards.   
 Unavailable | Update 

 0 items | £0.00 
  
 Checkout    
   
 Your basket is empty.  

 Books 

 Shops 
  Help 
  Careers 
  Account Sales 
    
 Free UK delivery on orders over £25    
   
  Close   

   Free  UK Standard Delivery   On all orders over £25   Order in time for Christmas   18 th  December by 2pm 2nd  Class  |  
  20 th  December by 2pm 1st  Class    Free  Click & Collect   From 2 hours after you order*     

 This item can be found in:   
  Computing & Internet  > Information technology: general issues   
    
    zoom   

 SPAA 15 27th ACM Symposium on Parallelism in Algorithms and Architectures (Paperback)   
 Spaa 15 Conference Committee    (author)   Sign in to write a review      
   
 £62.99     
   
 Paperback  364  Pages  
  Published:  18/08/2015    

 Free UK delivery on orders over £25   
 We can order this from the publisher 
    
 Usually dispatched within 3 weeks  
   
 Free UK delivery on orders over £25   
 Quantity     
 Add to basket    

 This item has been added to your basket 
  View basket  Checkout    

 View other formats and editions     

 Synopsis    
   
 Publisher: ACM    
  ISBN: 9781450338752    
  Number of pages: 364    
  Weight: 844 g    
  Dimensions: 279  x 216  x 19  mm    

 You may also be interested in...  
    Added to basket    

 The Most Human Human    
 Brian Christian      
 Paperback  £10.99    

    Added to basket    

 Finance for IT Decision Makers    
 Michael Blackstaff      
 Paperback  £44.99    

    Added to basket    

 The Second Machine Age    
 Erik Brynjolfsson      
 Paperback  £14.99    

    Added to basket    

 Early Home Computers    
 Kevin Murrell      
 Paperback  £6.99    

    Added to basket    

 Things a Computer Scientist Rarely Talks About    
 Donald E. Knuth      
 Paperback  £20.00    

    Added to basket    

 The Big Switch    
 Nicholas Carr      
 Paperback  £20.99    

    Added to basket    

 Alan M. Turing    
 Sara Turing      
 Paperback  £12.99    

    Added to basket    

 Founders at Work    
 Jessica Livingston      
 Paperback  £24.99    

    Added to basket    

 Pearson REVISE BTEC First in I&CT Revision Workbook - for 2025 and 2026 exams    
 Pearson Education Limited      
 Paperback  £5.99    

    Added to basket    

 TechGnosis    
 Erik Davis      
 Paperback  £19.99    

    Added to basket    

 Untangling the Web    
 Aleks Krotoski      
 Paperback  £12.99    

    Added to basket    

 Cybersecurity and Cyberwar    
 Peter W. Singer      
 Paperback  £10.99    

    Added to basket    

 You Are Not A Gadget    
 Jaron Lanier      
 Paperback  £10.99    

    Added to basket    

 To Save Everything, Click Here    
 Evgeny Morozov      
 Paperback  £10.99    

    Added to basket    

 The Computer    
 Darrel Ince      
 Paperback  £8.99    

    Added to basket    

 Who Owns The Future?    
 Jaron Lanier      
 Paperback  £10.99    

  Reviews  
 Sign In To Write A Review    
 Please sign in  to write a review  
   
 Your review has been submitted successfully.  

 Shopping with us  
 Contact Us 
  Bookshops 
  Click & Collect 
  Delivery Options 
  Online Pricing 
  Returning Items 
  Student Discount 
  Waterstones Gift Cards 
    
 Legal  
 Accessibility 
  Cookie Policy 
  Manage Cookies 
  Modern Slavery Statement 
  Privacy Notice - How We Use Your Information 
  Terms & Conditions 
  Gender Pay Gap Report 
  Complaints Process 
    
 About Waterstones  
 About us 
  Affiliates 
  Careers at Waterstones 
  Hatchards 
  Independent Publishers 
  Waterstones Account Sales 
  Waterstones App 
  Waterstones Children's Laureate 
  Waterstones Plus 
    
 Follow us  
 X 
  Facebook 
  Instagram 
  TikTok 
  YouTube 
    
 Contact us    
 Help    
 Waterstones App    
 Privacy Policy - How We Use Your Information    
 Complaints Process    
 Cookie Policy    
 Gender Pay Gap Report    
 Manage Cookies    
 Modern Slavery Statement    
 Student Discount    
 Waterstones Account Sales    
 © Waterstones, 2024. Waterstones Booksellers Limited. Registered in England and Wales. Company number 00610095. Registered office address: 203-206 Piccadilly, London, W1J 9HD.    
  
  ×  Sign In / Register  
  
 Not registered? CREATE AN ACCOUNT  CREATE A plus  ACCOUNT         

   Remember me   ?   
   
 Reset password    
   
 Sign in    
    
 Forgotten password  Create a new password   
 Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
  Back to login    

 ×  Sign In  
  
   Not you?    

  Reset password    
 Sign in    

 Forgotten password  Create a new password   
  Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
 If you have changed your email address then contact us  and we will update your details.  
   
  Back to login    

 ×  Download the Waterstones App  
  
 Would you like to proceed to the App store  to download the Waterstones App?  
 Download Now  Dismiss   

  ×  Click & Collect  
  
 Reserve online, pay on collection. Reservations are held for 5 days.   

 Thank you for your reservation   
 Your order is now being processed and we have sent a confirmation email to you at    

 This item can be requested from the shops shown below.   
   
     Go    

      First name *      
   
 Last name *      
   
 Email address *      

 Please provide me with your latest book news, views and details of Waterstones’ special offers.      
 Place Order     
   
 When will my order be ready to collect?   
 Following the initial email, you will be contacted by the shop to confirm that your item is available for collection.   
 Call us on  or send us an email at    
 OK    
   
 Unfortunately there has been a problem with your order   
   
 Please try again or alternatively you can contact your chosen shop on  or send us an email at    

 ×  Report Review   
  
   Please select a reason for reporting this review  :  
  Hateful, abusive or threatening    Legal issue    Inappropriate language/content    Personally identifying information   Submit     

  Call for papers data:     
   
 Account | Sign In  Register 
  Join | Join plus  today to earn stamps and receive other rewards as you spend in our shops, cafes, and online* 
  Wish list 
    
  Shop Finder 
  Help 
  Events 
  Blog 
  Gift Cards 
  Win 

 Waterstones    
   
  Menu   
  New 
  Christmas 
  Special Editions 
  Books 
  Our Favourites 
  Games 
  Stationery & Gifts 
  Festive Favourites   Christmas Shop 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  Great Book Deals 
  2024's Most Wanted 
  Signed & Special Editions 
  Bestsellers 
  Paperbacks of the Year 
  Gift Cards 
  The Best Books of 2024 Blogs 
  Writers Recommend: Winter Reads 
  Christmas Entertainment 
    Christmas Essentials   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Festive Reads 
  Christmas Eve Boxes 
  Calendars 
  Full Year Diaries 
     Top Categories   Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Crime 
  Science Fiction & Fantasy 
  Romantasy 
  Manga 
  Clothbound Classics 
  Biography 
  Food & Drink 
  Humour 
  Puzzles & Quizes 
  Sport 
     Children's Christmas    Children's Stationery and Gifts 
  Stocking Fillers 
  Christmas Eve Boxes 
  First Christmas 
  Children's Gifts For ... 
  Annuals 
  Games & Puzzles 
  Toys 
  Jellycat 
  Soft Toys 
  Harry Potter 
  Favourite Characters 
  Favourite Authors 
  Reference 
  LEGO® 
  Children's Paperbacks of the Year 
  Gift Books 
  Legami 
     Stationery & Gifts    Gifts 
  Games 
  Jigsaw Puzzles 
  Calendars & Diaries 
  Arts & Crafts 
  Top Categories   Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Great Book Deals 
  Paperback Offers 
  Book Awards 
  Books of the Month 
  Dyslexia-friendly Books 
    Fiction    Waterstones Debut Fiction Prize 
  Anthologies & Short Stories 
  Classics 
  Clothbound Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  LGBTQ+ Fiction 
     Crime    Classic Crime 
  Cosy Crime 
  Historical Crime 
  Thrillers 
  True Crime 
    Graphic Novels & Manga    Graphic Novels 
  Manga 
    Science Fiction, Fantasy & Horror    Fantasy 
  Fantasy Romance 
  Horror 
  Science Fiction 
     Non-Fiction Books    Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Entertainment 
  Environment 
  Film & TV 
  Food & Drink 
  Health & Lifestyle 
  History 
  Hobbies, Quizzes & Games 
  Home & Garden 
  Humour 
  Language & Reference 
  Mindfulness 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, Technology & Medicine 
  Self-Help 
  Spirituality & Beliefs 
  Sport 
  Transport 
  Travel 
     Children's    Baby, Toddler & Pre-School 
  Picture Books 
  Favourite Characters & Authors 
  Ages 5-8 
  Ages 9-12 
  Teenage and Young Adult 
  Children's Paperback Offers 
    Popular Children's Categories   Children's Favourite Authors 
  Annuals 2025 
  Gift Books 
  LGBTQ+ Young Adult 
  Activity Books 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Laureate 
  Dyslexia-friendly Books for Children 
  Books for Reluctant Readers 
  School Holidays 
  Our Favourite Pages   Bestsellers 
  Christmas 
  Waterstones Book of the Year 
  The Books You've Always Meant to Read 
  Coming Soon 
  Gift Books 
  Gifts For... 
  Between the Covers 
  The Booker Library 
  BookTok 
  Books of the Month 
  Game of the Month 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Great Book Deals 
  Careers 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Events 
  Waterstones Podcast 
     Favourite Authors   Agatha Christie 
  Cassandra Clare 
  Colleen Hoover 
  David Nicholls 
  Elly Griffiths 
  Frank Herbert 
  George R.R. Martin 
  Haruki Murakami 
  J.R.R. Tolkien 
  Julia Quinn 
  Kazuo Ishiguro 
  Lee Child 
  Leigh Bardugo 
  Rebecca Yarros 
  Richard Osman 
  Sarah J Maas 
  Stephen King 
  Taylor Jenkins Reid 
  Terry Pratchett 
    Favourite Series   Bridgerton 
  Discworld 
  Doctor Who 
  Dune 
  A Game of Thrones 
  Hunger Games 
  Star Wars 
     Favourite Children's & YA Authors   Alice Oseman 
  A.F. Steadman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  Jennifer Lynn Barnes 
  J.K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  Suzanne Collins 
  Tom Fletcher 
     Favourite Children's Characters, Friends & Series    Asterix & Obelix 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tintin 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  All Games    Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
     Top Categories   Family Games 
  Logic & Deduction Games 
  Party Games 
  Strategy Games 
  Traditional Games 
  Travel Games 
  Word Games 
  Accessories & Dice 
  Dungeons & Dragons 
     More Games Categories   Abstract Games 
  Bluffing Games 
  Cooperative Games 
  Film & TV Games 
  Single Player Games 
  Thematic Games 
  Two Player Games 
  Christmas   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Calendars 
  Full Year Diaries 
    Gifts    Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Jigsaw Puzzles 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  Toys & Games 
     Children's    Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaw Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  Toys 
     Stationery    Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Calendars & Diaries 
    Book Accessories    Book Lights and Lamps 
  Bookmarks 
  Reading Glasses & Magnifiers 
     Arts & Crafts    Brushes 
  Canvas 
  Crafting 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
    
 Books 
  Christmas 
  Children's 
  Games 
  Our Favourites 
  New Books 
  Great Book Deals 
  Coming Soon 
  Stationery & Gifts 
  Gift Cards 
  Gift Books 
  Signed & Special Editions 
  Blog 
  Events 
  Podcast 
  Prize Draws 
  BACK 
  Fiction Bestsellers 
  Anthologies and Short Stories 
  Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  BACK 
  Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Paperback Offers 
  Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Manga 
  Waterstones Debut Fiction Prize 
  Book Awards 
  Books of the Month 
  Cultural Highlights 
  BACK 
  Advent Calendars 
  Christmas Gift Wrap 
  Christmas Cards 
  Calendars 
  Full Year Diaries 
  BACK 
  Crime Bestsellers 
  Agatha Christie 
  Classic Crime 
  Cosy Crime 
  historical Crime 
  Thrillers 
  True Crime 
  BACK 
  Dungeons & Dragons 
  Abstract 
  Accessories & Dice 
  Bluffing Games 
  Board Games 
  Card Games 
  Cooperative Games 
  Family Games 
  Film & TV Games 
  Logic & Deduction 
  Party Games 
  Quiz & Trivia Games 
  Single Player Games 
  Strategy Games 
  Thematic Games 
  Traditional Games 
  Travel Games 
  Two Player Games 
  Word Games 
  BACK 
  Christmas Entertainment 
  Christmas Shop 
  Festive Favourites 
  Christmas Essentials 
  Children's Christmas 
  BACK 
  Writers Recommend: Winter Reads 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  2024's Most Wanted 
  Signed & Special Editions 
  Paperbacks of the Year 
  Gift Cards 
  Best Books of 2024 Blogs 
  BACK 
  Sci-fi & fantasy bestsellers 
  Science Fiction 
  fantasy 
  Fantasy Romance 
  Graphic Novels 
  Horror 
  Manga 
  game of thrones 
  Doctor Who 
  Good Omens 
  Star Wars 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks Offers 
  Children's Favourite Authors 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Calendars 
  Full Year Diaries 
  Advent Calendars 
  Christmas Cards 
  Christmas Eve Boxes 
  Festive Reads 
  Christmas Gift Wrap 
  BACK 
  Children's Stationery & Gifts 
  Stocking Fillers 
  First Christmas 
  Christmas Eve Boxes 
  Children's Gifts For ... 
  Annuals 
  Harry Potter 
  Jellycat 
  Favourite Characters 
  Favourite Authors 
  Children's Paperbacks of the Year 
  Gift Books 
  BACK 
  All Games 
  Browse Categories 
  Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
  BACK 
  Toys & Games 
  Gifts 
  Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  BACK 
  Book Lights 
  Bookmarks 
  Reading Glasses & Magnifiers 
  BACK 
  Bestsellers 
  Christmas 
  The Books You've Always Meant to Read 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Gift Cards 
  Gifts For... 
  Great Book Deals 
  Between the Covers 
  The Booker Library 
  BookTok 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Books of the Month 
  Game of the Month 
  Manga 
  Dyslexia-friendly Books 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Bookshops 
  Waterstones Events 
  Waterstones Podcast 
  BACK 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  BACK 
  Stationery Bestsellers 
  Calendars & Diaries 
  Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Pens & Pencils 
  BACK 
  Fiction 
  Crime 
  Sci-fi & fantasy 
  Graphic Novels 
  Manga 
  Clothbound Classics 
  Modern & Contemporary Fiction 
  BACK 
  Bluey 
  Elmer 
  Dog Man 
  the gruffalo 
  Guess How Much I Love You 
  harry potter 
  Heartstopper 
  Horrible histories 
  Little People, Big Dreams 
  Mog the Cat 
  Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Tom Gates 
  That's Not My... 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  Elmer 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People, Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Christmas 
  Stationery & Gifts 
  Children's Stationery & Gifts 
  Gifts 
  Book Accessories 
  Children's 
  Stationery 
  Calendars & Diaries 
  Arts & Crafts 
  BACK 
  Browse All Arts & Crafts 
  Brushes 
  Canvas 
  Craft 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
  BACK 
  Non-Fiction Bestsellers 
  Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Education & Study Guides 
  entertainment 
  environment 
  Film & TV 
  food & drink 
  health & lifestyle 
  History 
  Hobbies, quizzes & games 
  home & garden 
  Humour 
  Language & reference 
  Mind, body & spirit 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, technology & medicine 
  Self-Help 
  spirituality & beliefs 
  Sports 
  Transport 
  Travel & Maps 
  True Crime 
  BACK 
  Alice Oseman 
  Beatrix Potter 
  Cassandra Clare 
  David Walliams 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J.K. Rowling 
  Julia Donaldson 
  Liz Pichon 
  Karen McManus 
  Malorie Blackman 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Suzanne Collins 
  Tom Fletcher 
  A.F. Steadman 
  Alice Oseman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J. K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Liz Pichon 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks of the Year 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Children's Fiction 
  Annuals 2025 
  Dyslexic & Reluctant Readers 
  early learning 
  Education & Study Guides 
  Hobbies & Interests 
  Gift Books 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Activity Books 
  Waterstones Children's Laureate 
  BACK 
  Annuals 2025 
  Gift Books 
  Books for Reluctant Readers 
  Dyslexia-friendly Books for Children 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Activity Books 
  LGBTQ+ Young Adult 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Waterstones Children's Laureate 
  School Holidays 
  BACK 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 
  Colouring & Painting 
  Crafts & Hobbies 
  Educational Toys & Games 
  Jellycat 
  LEGO ® 
  Soft Toys 
  Toys 
  BACK 
  Children's Stationery & Gifts 
  Educational Toys & Games 
  Jellycat Toys 
  LEGO® 
  Soft Toys 
  Toys 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 

 0  Basket   
  Spend £25.00   to qualify for free UK delivery.   
 Your order qualifies for free UK delivery.   

  Join  plus   before checkout to earn stamps on your order and be eligible for plus  rewards.   
 Unavailable | Update 

 0 items | £0.00 
  
 Checkout    
   
 Your basket is empty.  

 Books 

 Shops 
  Help 
  Careers 
  Account Sales 
    
 Free UK delivery on orders over £25    
   
  Close   

   Free  UK Standard Delivery   On all orders over £25   Order in time for Christmas   18 th  December by 2pm 2nd  Class  |  
  20 th  December by 2pm 1st  Class    Free  Click & Collect   From 2 hours after you order*     

 Our Paperbacks of the Year  
 As the nights draw in and the cosy glow of autumn comforts, it’s definitely time to curl up with our favourite paperbacks of the year. Discover the most talked- about bestsellers, award-winning masterpieces, unputdownable thrillers and compelling non-fiction selected from across 2024.  
   
 Best Fiction Paperbacks  
   
    Added to basket    

 Yellowface    
 R.F. Kuang      
 Paperback  £9.99  £8.49    

    Added to basket    

 What You Are Looking for is in the Library    
 Michiko Aoyama      
 Paperback  £9.99  £7.99    

    Added to basket    

 The Bee Sting    
 Paul Murray      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Figurine    
 Victoria Hislop      
 Paperback  £9.99  £7.99    

    Added to basket    

 Kala    
 Colin Walsh      
 Paperback  £9.99  £8.49    

    Added to basket    

 Moscow X    
 David McCloskey      
 Paperback  £9.99  £8.49    

    Added to basket    

 Welcome to the Hyunam-dong Bookshop    
 Hwang Bo-reum      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Seventh Son    
 Sebastian Faulks      
 Paperback  £9.99  £8.49    

    Added to basket    

 Tom Lake    
 Ann Patchett      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Heaven & Earth Grocery Store    
 James McBride      
 Paperback  £9.99  £7.99    

    Added to basket    

 Prophet Song    
 Paul Lynch      
 Paperback  £9.99  £8.49    

    Added to basket    

 Someone Else’s Shoes    
 Jojo Moyes      
 Paperback  £9.99  £7.99    

    Added to basket    

 Good Material    
 Dolly Alderton      
 Paperback  £9.99  £7.99    

    Added to basket    

 North Woods    
 Daniel Mason      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Burnout    
 Sophie Kinsella      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Ghost Ship    
 Kate Mosse      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Fraud    
 Zadie Smith      
 Paperback  £9.99  £8.49    

    Added to basket    

 Hello Beautiful    
 Ann Napolitano      
 Paperback  £9.99  £8.49    

 Iron Flame - The Empyrean (Paperback)    
 Rebecca Yarros    
 £10.99  £8.99     
   
 Paperback   
 10+ in stock    
 Usually dispatched within 1-2 days   
 The fallout from Violet's jaw-dropping discoveries in Fourth Wing  takes spectacular flight in this completely unputdownable second instalment of Yarros' TikTok-dominating fantasy series.  

     Add to basket  Click &  Collect    

 This item has been added to your basket 
  View basket  Checkout    

 Best Crime & Thriller Paperbacks  
   
    Added to basket    

 The Wrong Sister    
 Claire Douglas      
 Paperback  £9.99  £7.99    

    Added to basket    

 Murder on Lake Garda    
 Tom Hindle      
 Paperback  £9.99  £7.99    

    Added to basket    

 How To Solve Your Own Murder    
 Kristen Perrin      
 Paperback  £9.99  £7.99    

    Added to basket    

 The Last Devil To Die    
 Richard Osman      
 Paperback  £9.99  £7.99    

    Added to basket    

 Close to Death    
 Anthony Horowitz      
 Paperback  £9.99  £7.99    

    Added to basket    

 The Housemaid Is Watching    
 Freida McFadden      
 Paperback  £8.99  £7.49    

    Added to basket    

 The Secret    
 Lee Child      
 Paperback  £9.99  £7.99    

    Added to basket    

 Homecoming    
 Kate Morton      
 Paperback  £9.99  £8.49    

    Added to basket    

 None of This is True    
 Lisa Jewell      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Fury    
 Alex Michaelides      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Secret Hours    
 Mick Herron      
 Paperback  £9.99  £7.99    

    Added to basket    

 The Running Grave    
 Robert Galbraith      
 Paperback  £10.99  £8.99    

    Added to basket    

 The Trial    
 Rob Rinder      
 Paperback  £9.99  £7.49    

    Added to basket    

 The Housekeepers    
 Alex Hay      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Year of the Locust    
 Terry Hayes      
 Paperback  £9.99  £7.99    

    Added to basket    

 The Raging Storm    
 Ann Cleeves      
 Paperback  £9.99  £8.49    

    Added to basket    

 Strange Sally Diamond    
 Liz Nugent      
 Paperback  £8.99  £7.49    

    Added to basket    

 The Cloisters    
 Katy Hays      
 Paperback  £9.99  £8.49    

 Murder at Holly House (Paperback)    
 Denzil Meyrick    
 £9.99  £7.99     
   
 Paperback   
 10+ in stock    
 Usually dispatched within 1-2 days   
 Cosy and noirish in equal measure, Murder at Holly House  is an ingeniously plotted festive murder mystery set on the 1950s Yorkshire Moors from the bestselling author of the D.C.I. Daley series.  

     Add to basket  Click &  Collect    

 This item has been added to your basket 
  View basket  Checkout    

 Best Science-Fiction, Fantasy & Horror Paperbacks  
   
    Added to basket    

 A Court of Thorns and Roses    
 Sarah J. Maas      
 Paperback  £8.99  £6.99    

    Added to basket    

 DallerGut Dream Department Store    
 Miye Lee      
 Paperback  £9.99  £8.49    

    Added to basket    

 Fourth Wing    
 Rebecca Yarros      
 Paperback  £10.99  £8.99    

    Added to basket    

 The Serpent and the Wings of Night    
 Carissa Broadbent      
 Paperback  £9.99  £8.49    

    Added to basket    

 Starling House    
 Alix E. Harrow      
 Paperback  £9.99  £7.99    

    Added to basket    

 A Curse For True Love    
 Stephanie Garber      
 Paperback  £9.99  £8.49    

    Added to basket    

 Ink Blood Sister Scribe    
 Emma Torzs      
 Paperback  £9.99  £8.49    

    Added to basket    

 Faebound    
 Saara El-Arifi      
 Paperback  £9.99  £8.49    

    Added to basket    

 Godkiller    
 Hannah Kaner      
 Paperback  £9.99  £8.49    

    Added to basket    

 Emily Wilde's Map of the Otherlands    
 Heather Fawcett      
 Paperback  £9.99  £7.99    

    Added to basket    

 In Ascension    
 Martin MacInnes      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Ferryman    
 Justin Cronin      
 Paperback  £9.99  £8.49    

    Added to basket    

 A Day of Fallen Night    
 Samantha Shannon      
 Paperback  £9.99  £8.49    

    Added to basket    

 The Adventures of Amina al-Sirafi    
 S. A. Chakraborty      
 Paperback  £9.99  £8.49    

    Added to basket    

 Chain-Gang All-Stars    
 Nana Kwame Adjei-Brenyah      
 Paperback  £9.99  £8.49    

 Return to the DallerGut Dream Department Store (Paperback)    
 Miye Lee  , Sandy Joosun Lee    
 £14.99  £12.99     
   
 Paperback   
 In stock   
 Expected to be dispatched in 7-10 days   
 The beguiling sequel to DallerGut Dream Department Store  finds Penny embracing the wider remit of the dream industry, such as the Civil Complaint Center and how to lure back unsatisfied regulars.  

     Add to basket  Click &  Collect    

 This item has been added to your basket 
  View basket  Checkout    

 Best Non-Fiction Paperbacks  
   
    Added to basket    

 Unruly    
 David Mitchell      
 Paperback  £10.99  £9.49    

    Added to basket    

 Politics On the Edge    
 Rory Stewart      
 Paperback  £10.99  £8.99    

    Added to basket    

 Shakespeare    
 Judi Dench      
 Paperback  £10.99  £8.99    

    Added to basket    

 Abroad in Japan    
 Chris Broad      
 Paperback  £10.99  £8.99    

    Added to basket    

 Just One Thing    
 Michael Mosley      
 Paperback  £9.99  £8.49    

    Added to basket    

 Ultra-Processed People    
 Chris van Tulleken      
 Paperback  £10.99  £9.49    

    Added to basket    

 The Wager    
 David Grann      
 Paperback  £10.99  £8.99    

    Added to basket    

 How to Read a Tree    
 Tristan Gooley      
 Paperback  £10.99  £9.49    

    Added to basket    

 How They Broke Britain    
 James O'Brien      
 Paperback  £10.99  £9.49    

    Added to basket    

 Emperor of Rome    
 Mary Beard      
 Paperback  £11.99  £9.99    

    Added to basket    

 Great-Uncle Harry    
 Michael Palin      
 Paperback  £10.99  £8.99    

    Added to basket    

 Material World    
 Ed Conway      
 Paperback  £10.99  £9.49    

    Added to basket    

 Killing Thatcher    
 Rory Carroll      
 Paperback  £10.99  £9.49    

    Added to basket    

 Normal Women    
 Philippa Gregory      
 Paperback  £10.99  £8.99    

    Added to basket    

 How Westminster Works . . . and Why It Doesn't    
 Ian Dunt      
 Paperback  £10.99  £9.49    

    Added to basket    

 Doppelganger    
 Naomi Klein      
 Paperback  £10.99  £9.49    

    Added to basket    

 Friends, Lovers and the Big Terrible Thing    
 Matthew Perry      
 Paperback  £10.99  £8.99    

    Added to basket    

 Hitler, Stalin, Mum and Dad    
 Daniel Finkelstein      
 Paperback  £10.99  £9.49    

 The Seven Wonders of the Ancient World (Paperback)    
 Bettany Hughes    
 £12.99  £10.99     
   
 Paperback   
 10+ in stock    
 Usually dispatched within 1-2 days   
 From the Great Pyramid at Giza to the Hanging Gardens of Babylon, acclaimed historian and author of Istanbul Bettany Hughes charts the construction, fame and legacy of these marvels of the Ancient World in page-turning prose.  

     Add to basket  Click &  Collect    

 This item has been added to your basket 
  View basket  Checkout    

 Sort by:  
 Bestselling  Price (low to high)  Price (high to low)  Average review rating  Publication Date (old to new)  Publication Date (new to old)     

 Page  Prev    of 16  Next    

 Paperback Offers  

 Sort by:  
 Bestselling  Price (low to high)  Price (high to low)  Average review rating  Publication Date (old to new)  Publication Date (new to old)     
 Choose filters:  
 Category   
 Art, Fashion & Photography 
  Biography & True Stories 
  Business, Finance & Law 
  Children's & Teenage 
  Computing & Internet 
  Crime, Thrillers & Mystery 
  Entertainment 
  Fiction 
  Food & Drink 
  Health & Lifestyle 
  History 
  Hobbies, Quiz Books & Games 
  Home & Garden 
  Humour 
  Language & Reference 
  Poetry, Drama & Criticism 
  Politics, Society & Education 
  Popular Science & Nature 
  Romantic Fiction 
  Science Fiction, Fantasy & Horror 
  Science, Technology & Medicine 
  Spirituality & Beliefs 
  Sports Books 
  Stationery & Gifts 
  Transport: General Interest 
  Travel & Maps 

 Price   
 Under £5 
  £5 - £10 
  £10 - £20 
  £20 - £50 
  Over £50 
  Go     

 Interest age   
 Teen / young adult 

 Review ratings   

 Publisher   
 Penguin Books Ltd 
  Daphne Press 
  HarperCollins Publishers 
  Pan Macmillan 
  Little, Brown Book Group 
   Transworld Publishers Ltd 
  Vintage Publishing 
  Bloomsbury Publishing PLC 
  Cornerstone 
  Simon & Schuster Ltd 
  More    

 Author   
 Hilary Mantel 
  Bernard Cornwell 
  David Nicholls 
  Lisa Jewell 
  Colm Toibin 
   Brandon Sanderson 
  Jo Nesbo 
  David Baldacci 
  Charles Cumming 
  Michael Mosley 
  More    

 Language   
 English 

 Geographic region   
 Africa 
  Americas 
  Asia 
  Australasia & Oceania 
  British Isles 
   Europe 
  Other geographic areas 
  More    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Murder at Holly House    
 Denzil Meyrick    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Christmas Tree Farm    
 Laurie Gilmore    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Yellowface    
 R.F. Kuang    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 A Court of Thorns and Roses    
 Sarah J. Maas    In stock online  £8.99  £6.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Pumpkin Spice Cafe    
 Laurie Gilmore    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Cinnamon Bun Book Store    
 Laurie Gilmore    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Wrong Sister    
 Claire Douglas    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Unruly    
 David Mitchell    In stock online  £10.99  £9.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 What You Are Looking for is in the Library    
 Michiko Aoyama    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Murder on Lake Garda    
 Tom Hindle    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Iron Flame    
 Rebecca Yarros    In stock online  £10.99  £8.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Politics On the Edge    
 Rory Stewart    In stock online  £10.99  £8.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 How To Solve Your Own Murder    
 Kristen Perrin    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Seven Wonders of the Ancient World    
 Bettany Hughes    In stock online  £12.99  £10.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Last Devil To Die    
 Richard Osman    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 DallerGut Dream Department Store    
 Miye Lee    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Small Things Like These    
 Claire Keegan    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Fourth Wing    
 Rebecca Yarros    In stock online  £10.99  £8.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Housemaid    
 Freida McFadden    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Bee Sting    
 Paul Murray    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 The Figurine    
 Victoria Hislop    In stock online  £9.99  £7.99  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Kala    
 Colin Walsh    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Moscow X    
 David McCloskey    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

    Added to basket    

     Add to Basket  Click &  Collect    
 View basket  Checkout    
    
   Go    

 Welcome to the Hyunam-dong Bookshop    
 Hwang Bo-reum    In stock online  £9.99  £8.49  Paperback    
 ★  ★  ★  ★  ★    

 show more    

 Shopping with us  
 Contact Us 
  Bookshops 
  Click & Collect 
  Delivery Options 
  Online Pricing 
  Returning Items 
  Student Discount 
  Waterstones Gift Cards 
    
 Legal  
 Accessibility 
  Cookie Policy 
  Manage Cookies 
  Modern Slavery Statement 
  Privacy Notice - How We Use Your Information 
  Terms & Conditions 
  Gender Pay Gap Report 
  Complaints Process 
    
 About Waterstones  
 About us 
  Affiliates 
  Careers at Waterstones 
  Hatchards 
  Independent Publishers 
  Waterstones Account Sales 
  Waterstones App 
  Waterstones Children's Laureate 
  Waterstones Plus 
    
 Follow us  
 X 
  Facebook 
  Instagram 
  TikTok 
  YouTube 
    
 Contact us    
 Help    
 Waterstones App    
 Privacy Policy - How We Use Your Information    
 Complaints Process    
 Cookie Policy    
 Gender Pay Gap Report    
 Manage Cookies    
 Modern Slavery Statement    
 Student Discount    
 Waterstones Account Sales    
 © Waterstones, 2024. Waterstones Booksellers Limited. Registered in England and Wales. Company number 00610095. Registered office address: 203-206 Piccadilly, London, W1J 9HD.    
  
  ×  Sign In / Register  
  
 Not registered? CREATE AN ACCOUNT  CREATE A plus  ACCOUNT         

   Remember me   ?   
   
 Reset password    
   
 Sign in    
    
 Forgotten password  Create a new password   
 Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
  Back to login    

 ×  Sign In  
  
   Not you?    

  Reset password    
 Sign in    

 Forgotten password  Create a new password   
  Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
 If you have changed your email address then contact us  and we will update your details.  
   
  Back to login    

 ×  Download the Waterstones App  
  
 Would you like to proceed to the App store  to download the Waterstones App?  
 Download Now  Dismiss   

  ×  Click & Collect  
  
 Reserve online, pay on collection. Reservations are held for 5 days.   

 Thank you for your reservation   
 Your order is now being processed and we have sent a confirmation email to you at    

 This item can be requested from the shops shown below.   
   
     Go    

      First name *      
   
 Last name *      
   
 Email address *      

 Please provide me with your latest book news, views and details of Waterstones’ special offers.      
 Place Order     
   
 When will my order be ready to collect?   
 Following the initial email, you will be contacted by the shop to confirm that your item is available for collection.   
 Call us on  or send us an email at    
 OK    
   
 Unfortunately there has been a problem with your order   
   
 Please try again or alternatively you can contact your chosen shop on  or send us an email at    

  Important dates data     
   
 Account | Sign In  Register 
  Join | Join plus  today to earn stamps and receive other rewards as you spend in our shops, cafes, and online* 
  Wish list 
    
  Shop Finder 
  Help 
  Events 
  Blog 
  Gift Cards 
  Win 

 Waterstones    
   
  Menu   
  New 
  Christmas 
  Special Editions 
  Books 
  Our Favourites 
  Games 
  Stationery & Gifts 
  Festive Favourites   Christmas Shop 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  Great Book Deals 
  2024's Most Wanted 
  Signed & Special Editions 
  Bestsellers 
  Paperbacks of the Year 
  Gift Cards 
  The Best Books of 2024 Blogs 
  Writers Recommend: Winter Reads 
  Christmas Entertainment 
    Christmas Essentials   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Festive Reads 
  Christmas Eve Boxes 
  Calendars 
  Full Year Diaries 
     Top Categories   Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Crime 
  Science Fiction & Fantasy 
  Romantasy 
  Manga 
  Clothbound Classics 
  Biography 
  Food & Drink 
  Humour 
  Puzzles & Quizes 
  Sport 
     Children's Christmas    Children's Stationery and Gifts 
  Stocking Fillers 
  Christmas Eve Boxes 
  First Christmas 
  Children's Gifts For ... 
  Annuals 
  Games & Puzzles 
  Toys 
  Jellycat 
  Soft Toys 
  Harry Potter 
  Favourite Characters 
  Favourite Authors 
  Reference 
  LEGO® 
  Children's Paperbacks of the Year 
  Gift Books 
  Legami 
     Stationery & Gifts    Gifts 
  Games 
  Jigsaw Puzzles 
  Calendars & Diaries 
  Arts & Crafts 
  Top Categories   Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Great Book Deals 
  Paperback Offers 
  Book Awards 
  Books of the Month 
  Dyslexia-friendly Books 
    Fiction    Waterstones Debut Fiction Prize 
  Anthologies & Short Stories 
  Classics 
  Clothbound Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  LGBTQ+ Fiction 
     Crime    Classic Crime 
  Cosy Crime 
  Historical Crime 
  Thrillers 
  True Crime 
    Graphic Novels & Manga    Graphic Novels 
  Manga 
    Science Fiction, Fantasy & Horror    Fantasy 
  Fantasy Romance 
  Horror 
  Science Fiction 
     Non-Fiction Books    Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Entertainment 
  Environment 
  Film & TV 
  Food & Drink 
  Health & Lifestyle 
  History 
  Hobbies, Quizzes & Games 
  Home & Garden 
  Humour 
  Language & Reference 
  Mindfulness 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, Technology & Medicine 
  Self-Help 
  Spirituality & Beliefs 
  Sport 
  Transport 
  Travel 
     Children's    Baby, Toddler & Pre-School 
  Picture Books 
  Favourite Characters & Authors 
  Ages 5-8 
  Ages 9-12 
  Teenage and Young Adult 
  Children's Paperback Offers 
    Popular Children's Categories   Children's Favourite Authors 
  Annuals 2025 
  Gift Books 
  LGBTQ+ Young Adult 
  Activity Books 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Laureate 
  Dyslexia-friendly Books for Children 
  Books for Reluctant Readers 
  School Holidays 
  Our Favourite Pages   Bestsellers 
  Christmas 
  Waterstones Book of the Year 
  The Books You've Always Meant to Read 
  Coming Soon 
  Gift Books 
  Gifts For... 
  Between the Covers 
  The Booker Library 
  BookTok 
  Books of the Month 
  Game of the Month 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Great Book Deals 
  Careers 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Events 
  Waterstones Podcast 
     Favourite Authors   Agatha Christie 
  Cassandra Clare 
  Colleen Hoover 
  David Nicholls 
  Elly Griffiths 
  Frank Herbert 
  George R.R. Martin 
  Haruki Murakami 
  J.R.R. Tolkien 
  Julia Quinn 
  Kazuo Ishiguro 
  Lee Child 
  Leigh Bardugo 
  Rebecca Yarros 
  Richard Osman 
  Sarah J Maas 
  Stephen King 
  Taylor Jenkins Reid 
  Terry Pratchett 
    Favourite Series   Bridgerton 
  Discworld 
  Doctor Who 
  Dune 
  A Game of Thrones 
  Hunger Games 
  Star Wars 
     Favourite Children's & YA Authors   Alice Oseman 
  A.F. Steadman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  Jennifer Lynn Barnes 
  J.K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  Suzanne Collins 
  Tom Fletcher 
     Favourite Children's Characters, Friends & Series    Asterix & Obelix 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tintin 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  All Games    Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
     Top Categories   Family Games 
  Logic & Deduction Games 
  Party Games 
  Strategy Games 
  Traditional Games 
  Travel Games 
  Word Games 
  Accessories & Dice 
  Dungeons & Dragons 
     More Games Categories   Abstract Games 
  Bluffing Games 
  Cooperative Games 
  Film & TV Games 
  Single Player Games 
  Thematic Games 
  Two Player Games 
  Christmas   Advent Calendars 
  Christmas Cards 
  Christmas Gift Wrap 
  Calendars 
  Full Year Diaries 
    Gifts    Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Jigsaw Puzzles 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  Toys & Games 
     Children's    Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaw Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  Toys 
     Stationery    Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Calendars & Diaries 
    Book Accessories    Book Lights and Lamps 
  Bookmarks 
  Reading Glasses & Magnifiers 
     Arts & Crafts    Brushes 
  Canvas 
  Crafting 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
    
 Books 
  Christmas 
  Children's 
  Games 
  Our Favourites 
  New Books 
  Great Book Deals 
  Coming Soon 
  Stationery & Gifts 
  Gift Cards 
  Gift Books 
  Signed & Special Editions 
  Blog 
  Events 
  Podcast 
  Prize Draws 
  BACK 
  Fiction Bestsellers 
  Anthologies and Short Stories 
  Classics 
  Fiction in Translation 
  Historical Fiction 
  Modern & Contemporary 
  Myths & Legends 
  Novellas 
  Poetry, Drama & Literary Criticism 
  Romance 
  BACK 
  Bestsellers 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Paperback Offers 
  Fiction 
  Non-Fiction 
  Children's 
  Teenage & Young Adult 
  Manga 
  Waterstones Debut Fiction Prize 
  Book Awards 
  Books of the Month 
  Cultural Highlights 
  BACK 
  Advent Calendars 
  Christmas Gift Wrap 
  Christmas Cards 
  Calendars 
  Full Year Diaries 
  BACK 
  Crime Bestsellers 
  Agatha Christie 
  Classic Crime 
  Cosy Crime 
  historical Crime 
  Thrillers 
  True Crime 
  BACK 
  Dungeons & Dragons 
  Abstract 
  Accessories & Dice 
  Bluffing Games 
  Board Games 
  Card Games 
  Cooperative Games 
  Family Games 
  Film & TV Games 
  Logic & Deduction 
  Party Games 
  Quiz & Trivia Games 
  Single Player Games 
  Strategy Games 
  Thematic Games 
  Traditional Games 
  Travel Games 
  Two Player Games 
  Word Games 
  BACK 
  Christmas Entertainment 
  Christmas Shop 
  Festive Favourites 
  Christmas Essentials 
  Children's Christmas 
  BACK 
  Writers Recommend: Winter Reads 
  Stocking Fillers 
  Gifts For ... 
  Gift Books 
  Little But Lovely 
  2024's Most Wanted 
  Signed & Special Editions 
  Paperbacks of the Year 
  Gift Cards 
  Best Books of 2024 Blogs 
  BACK 
  Sci-fi & fantasy bestsellers 
  Science Fiction 
  fantasy 
  Fantasy Romance 
  Graphic Novels 
  Horror 
  Manga 
  game of thrones 
  Doctor Who 
  Good Omens 
  Star Wars 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks Offers 
  Children's Favourite Authors 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Calendars 
  Full Year Diaries 
  Advent Calendars 
  Christmas Cards 
  Christmas Eve Boxes 
  Festive Reads 
  Christmas Gift Wrap 
  BACK 
  Children's Stationery & Gifts 
  Stocking Fillers 
  First Christmas 
  Christmas Eve Boxes 
  Children's Gifts For ... 
  Annuals 
  Harry Potter 
  Jellycat 
  Favourite Characters 
  Favourite Authors 
  Children's Paperbacks of the Year 
  Gift Books 
  BACK 
  All Games 
  Browse Categories 
  Board Games 
  Card Games 
  Children's Games & Puzzles 
  Games Flagships 
  Game of the Month 
  Jigsaw Puzzles 
  BACK 
  Toys & Games 
  Gifts 
  Accessories 
  Cloth Bags 
  Gadgets & Technology 
  Home & Lifestyle 
  Literary Gifts 
  Manga Gifts 
  Novelty Gifts 
  BACK 
  Book Lights 
  Bookmarks 
  Reading Glasses & Magnifiers 
  BACK 
  Bestsellers 
  Christmas 
  The Books You've Always Meant to Read 
  Coming Soon 
  New Books 
  Signed & Special Editions 
  Waterstones Book of the Year 
  Gift Books 
  Gift Cards 
  Gifts For... 
  Great Book Deals 
  Between the Covers 
  The Booker Library 
  BookTok 
  Paperbacks of the Year 
  Children's Paperbacks of the Year 
  Books of the Month 
  Game of the Month 
  Manga 
  Dyslexia-friendly Books 
  Book Awards 
  Cultural Highlights 
  Prize Draws 
  Waterstones App 
  Waterstones Blog 
  Waterstones Bookshops 
  Waterstones Events 
  Waterstones Podcast 
  BACK 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Stationery 
  Educational Toys & Games 
  Jellycat 
  Legami 
  LEGO® 
  Soft Toys 
  BACK 
  Stationery Bestsellers 
  Calendars & Diaries 
  Cards, Postcards & Notecards 
  Gift Wrap 
  Notebooks & Journals 
  Stationery Essentials 
  Pens & Pencils 
  BACK 
  Fiction 
  Crime 
  Sci-fi & fantasy 
  Graphic Novels 
  Manga 
  Clothbound Classics 
  Modern & Contemporary Fiction 
  BACK 
  Bluey 
  Elmer 
  Dog Man 
  the gruffalo 
  Guess How Much I Love You 
  harry potter 
  Heartstopper 
  Horrible histories 
  Little People, Big Dreams 
  Mog the Cat 
  Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Tom Gates 
  That's Not My... 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Bluey 
  Bunny vs Monkey 
  Dog Man 
  Elmer 
  The Gruffalo 
  Guess How Much I Love You 
  Harry Potter 
  Heartstopper 
  Horrible Histories 
  Jellycat 
  Little People, Big Dreams 
  Mog the Cat 
  The Moomins 
  Paddington 
  Peppa Pig 
  Peter Rabbit 
  Pip & Posy 
  Skandar 
  Supertato 
  That's Not My... 
  Thomas the Tank Engine 
  Tom Gates 
  The Very Hungry Caterpillar 
  We're Going on a Bear Hunt 
  Wimpy Kid 
  Winnie the Pooh 
  BACK 
  Christmas 
  Stationery & Gifts 
  Children's Stationery & Gifts 
  Gifts 
  Book Accessories 
  Children's 
  Stationery 
  Calendars & Diaries 
  Arts & Crafts 
  BACK 
  Browse All Arts & Crafts 
  Brushes 
  Canvas 
  Craft 
  Paint 
  Paper 
  Pens, Pencils & Pastels 
  BACK 
  Non-Fiction Bestsellers 
  Art, Fashion & Photography 
  Astronomy & Space 
  Biography & True Stories 
  Business, Finance & Law 
  Computing & Internet 
  Education & Study Guides 
  entertainment 
  environment 
  Film & TV 
  food & drink 
  health & lifestyle 
  History 
  Hobbies, quizzes & games 
  home & garden 
  Humour 
  Language & reference 
  Mind, body & spirit 
  Music 
  Nature Writing 
  Outdoor Pursuits 
  Parenting 
  Pets 
  Philosophy 
  Politics 
  Popular Science 
  Science, technology & medicine 
  Self-Help 
  spirituality & beliefs 
  Sports 
  Transport 
  Travel & Maps 
  True Crime 
  BACK 
  Alice Oseman 
  Beatrix Potter 
  Cassandra Clare 
  David Walliams 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J.K. Rowling 
  Julia Donaldson 
  Liz Pichon 
  Karen McManus 
  Malorie Blackman 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Suzanne Collins 
  Tom Fletcher 
  A.F. Steadman 
  Alice Oseman 
  Beatrix Potter 
  David Walliams 
  Dr Seuss 
  Frank Cottrell Boyce 
  Holly Jackson 
  Jacqueline Wilson 
  Jeff Kinney 
  J. K. Rowling 
  Joseph Coelho 
  Julia Donaldson 
  Karen McManus 
  Katherine Rundell 
  Lauren Roberts 
  Liz Pichon 
  Malorie Blackman 
  Marcus Rashford 
  M.G. Leonard 
  Philip Pullman 
  Roald Dahl 
  BACK 
  Dyslexia-friendly Books for Children 
  Children's Bestsellers 
  Baby & Toddler 
  Picture Books 
  Ages 5-8 
  Ages 9-12 
  Teenage & Young Adult 
  Children's Paperbacks of the Year 
  Characters, Friends & Series 
  Popular Authors 
  Popular Categories 
  Toys, Games & Stationery 
  Education & Study Guides 
  BACK 
  Children's Fiction 
  Annuals 2025 
  Dyslexic & Reluctant Readers 
  early learning 
  Education & Study Guides 
  Hobbies & Interests 
  Gift Books 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Activity Books 
  Waterstones Children's Laureate 
  BACK 
  Annuals 2025 
  Gift Books 
  Books for Reluctant Readers 
  Dyslexia-friendly Books for Children 
  Children's Fiction 
  Early Learning 
  Education & Study Guides 
  Hobbies & Interests 
  Activity Books 
  LGBTQ+ Young Adult 
  Poetry & Anthologies 
  Reference 
  Waterstones Children's Book Prize 
  Waterstones Children's Laureate 
  School Holidays 
  BACK 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 
  Colouring & Painting 
  Crafts & Hobbies 
  Educational Toys & Games 
  Jellycat 
  LEGO ® 
  Soft Toys 
  Toys 
  BACK 
  Children's Stationery & Gifts 
  Educational Toys & Games 
  Jellycat Toys 
  LEGO® 
  Soft Toys 
  Toys 
  Children's Arts & Crafts 
  Children's Games & Puzzles 
  Children's Jigsaws 
  Children's Stationery 

 0  Basket   
  Spend £25.00   to qualify for free UK delivery.   
 Your order qualifies for free UK delivery.   

  Join  plus   before checkout to earn stamps on your order and be eligible for plus  rewards.   
 Unavailable | Update 

 0 items | £0.00 
  
 Checkout    
   
 Your basket is empty.  

 Books 

 Shops 
  Help 
  Careers 
  Account Sales 
    
 Free UK delivery on orders over £25    
   
  Close   

   Free  UK Standard Delivery   On all orders over £25   Order in time for Christmas   18 th  December by 2pm 2nd  Class  |  
  20 th  December by 2pm 1st  Class    Free  Click & Collect   From 2 hours after you order*     

 ​ Help menu  
 About Waterstones   
 About Us 
  Affiliate Programme 
  BookTrust 
  Recycling Electrical Equipment 
  Waterstones Children's Laureate 

 Careers   
 Careers at Waterstones 
  Job Applicant Privacy Notice 

 Contact Us   
 Contact Us 
  Event Tickets 

 Publishers & Authors   
 How To Get Published 
  Independent Publishers 

 Shopping With Us   
 Accessibility 
  Account Sales 
  Christmas Last Posting Dates 
  Click & Collect 
  Delivery Options 
  Free UK Delivery 
  Frequently Asked Questions 
  Gift Cards and Vouchers 
  Online Pricing and Payments 
  Ordering With Us 
  Returning Items 
  Secure Shopping 
  Tax on International Deliveries 
  Tips for creating a strong password 
  Update Your Browser 
  Waterstones App 
  Wish Lists 

 Terms & Conditions & Legal   
 Company Information 
  Complaints Process 
  Cookie Policy 
  Gender Pay Gap Report 2023 
  Modern Slavery Statement 
  Online Contributions, Postings and Submissions 
  Privacy Notice - How We Use Your Information 
  Purchase of Goods and Services by Waterstones from Suppliers 
  Supply of Waterstones Products to Customers 
  Waterstones Tax Strategy 

 Waterstones Plus   
 Waterstones Plus Card Terms & Conditions 
  Waterstones Plus FAQ 
  Waterstones Plus Offer 

 ​ Christmas Last Posting Dates  
 Below are our last posting dates for ordering on Waterstones.com for the festive season, but don't forget you can always Click & Collect  or simply walk into a Waterstones bookshop right up until Christmas Eve.  
  
 Please note:   
 *Orders should be placed on the day and before the time stated below.  
 *Applies to items showing as ' in stock  ' at the time of the order.  
 *Our free, two-hour Click & Collect service will be available right up to Christmas Eve.  
 *We are pleased to be able to offer an extended returns period  after Christmas.  

 UK Delivery  
  
 Wednesday 18 December  
 2pm | Second Class (includes free delivery) 
 Friday 20 December  
 2pm | First Class 

 International Delivery  
  
 Friday 6 December | Australia, Bulgaria, Cyprus, Czech Republic, Falklands Islands, Finland, Greece, Israel, Italy, Kuwait, Malta, New Zealand, Norway, Poland, Portugal, Romania, Saudi Arabia, Serbia, Spain, Sri Lanka, Sweden, Turkey and United Arab Emirates (UAE). 
 Tuesday 10 December | Austria, Denmark, Gibraltar, India, Lithuania, Philippines, Qatar, Slovakia and Slovenia 
 Thursday 12 December | Belgium, Canada, China, Croatia, Estonia, Hungary, Iceland, Latvia, Luxembourg, Monaco, South Korea, Thailand and USA 
 Friday 13 December | France, Germany, Hong Kong, Ireland, Japan, Netherlands, Switzerland and Taiwan 

 Shopping with us  
 Contact Us 
  Bookshops 
  Click & Collect 
  Delivery Options 
  Online Pricing 
  Returning Items 
  Student Discount 
  Waterstones Gift Cards 
    
 Legal  
 Accessibility 
  Cookie Policy 
  Manage Cookies 
  Modern Slavery Statement 
  Privacy Notice - How We Use Your Information 
  Terms & Conditions 
  Gender Pay Gap Report 
  Complaints Process 
    
 About Waterstones  
 About us 
  Affiliates 
  Careers at Waterstones 
  Hatchards 
  Independent Publishers 
  Waterstones Account Sales 
  Waterstones App 
  Waterstones Children's Laureate 
  Waterstones Plus 
    
 Follow us  
 X 
  Facebook 
  Instagram 
  TikTok 
  YouTube 
    
 Contact us    
 Help    
 Waterstones App    
 Privacy Policy - How We Use Your Information    
 Complaints Process    
 Cookie Policy    
 Gender Pay Gap Report    
 Manage Cookies    
 Modern Slavery Statement    
 Student Discount    
 Waterstones Account Sales    
 © Waterstones, 2024. Waterstones Booksellers Limited. Registered in England and Wales. Company number 00610095. Registered office address: 203-206 Piccadilly, London, W1J 9HD.    
  
  ×  Sign In / Register  
  
 Not registered? CREATE AN ACCOUNT  CREATE A plus  ACCOUNT         

   Remember me   ?   
   
 Reset password    
   
 Sign in    
    
 Forgotten password  Create a new password   
 Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
  Back to login    

 ×  Sign In  
  
   Not you?    

  Reset password    
 Sign in    

 Forgotten password  Create a new password   
  Please enter your email address below and we'll send you a link to reset your password.  
   
 To keep your account safe, please enter your email address below so that we can send you a secure link to update your password  
   
 Submit    
    
 Submit    
   
 If you have changed your email address then contact us  and we will update your details.  
   
  Back to login    

 ×  Download the Waterstones App  
  
 Would you like to proceed to the App store  to download the Waterstones App?  
 Download Now  Dismiss   

  ×  Click & Collect  
  
 Reserve online, pay on collection. Reservations are held for 5 days.   

 Thank you for your reservation   
 Your order is now being processed and we have sent a confirmation email to you at    

 This item can be requested from the shops shown below.   
   
     Go    

      First name *      
   
 Last name *      
   
 Email address *      

 Please provide me with your latest book news, views and details of Waterstones’ special offers.      
 Place Order     
   
 When will my order be ready to collect?   
 Following the initial email, you will be contacted by the shop to confirm that your item is available for collection.   
 Call us on  or send us an email at    
 OK    
   
 Unfortunately there has been a problem with your order   
   
 Please try again or alternatively you can contact your chosen shop on  or send us an email at

