input:
1. ICIAP_2 conference:
MSAS 
   Cite Key  
 iciap-2023-1 
    Statistics  
 References: 0 
 Sign up  for an account to create a profile with publication list, tag and review your related work, and share bibliographies with your co-authors.  
    Image Analysis and Processing - ICIAP 2023 - 22nd International Conference, ICIAP 2023, Udine, Italy, September 11-15, 2023, Proceedings, Part I  
 Conference: iciap2023
2. ICIAP_3 conference:
Image Analysis and Processing - ICIAP 2023 Workshops | springerprofessional.de  Skip to main content    Menu   Disciplines Chevron down icon     Chevron up icon        Automotive    Business IT + Informatics    Construction + Real Estate    Electrical Engineering + Electronics    Energy + Sustainability    Insurance + Risk    Finance + Banking    Management + Leadership    Marketing + Sales    Mechanical Engineering + Materials      
 Events       
 Read chapter  Read first chapter     
 Image Analysis and Processing - ICIAP 2023 Workshops  
 Udine, Italy, September 11â€“15, 2023, Proceedings, Part I  
 Editors: Gian Luca Foresti, Andrea Fusiello, Edwin Hancock   
 On-Device Learning with Binary Neural Networks  
  Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs. In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models. We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead. The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authorsâ€™ knowledge, this is the first attempt to prove on-device learning with BNN. The experimental validation carried out confirms the validity and the suitability of the proposed method.  
 Lorenzo Vorabbi, Davide Maltoni, Stefano Santi   
 Towards One-Shot PCB Component Detection with YOLO  
  Consumer electronic devices such as smartphones, TV sets, etc. are designed around printed circuit boards (PCBs) with a large number of surface mounted components. The pick and place machine soldering these components on the PCB may pick the wrong component, may solder the component in the wrong position or fail to solder it at all. Therefore, Automated Optical Inspection (AOI) is essential to detect the above defects even prior to electric tests by comparing populated PCBs with the schematics. In this context, we leverage YOLO, a deep convolutional architecture designed for one-shot object detection, for AOI of PCBs. This architecture enables real-time processing of large images and can be trained end-to-end. In this work we also exploit a modified architecture of YOLOv5 designed to detect small components of which boards are often highly populated. Moreover, we proposed a strategy to transfer weights from the original pre-trained model to this improved one. We report here our experimental setup and some performance measures.  
 Gabriele Spadaro, Gaspare Vetrano, Barbara Penna, Antonio Serena, Attilio Fiandrotti   
 Automated Identification of Failure Cases in Organ at Risk Segmentation Using Distance Metrics: A Study on CT Data  
  Automated organ at risk (OAR) segmentation is crucial for radiation therapy planning in CT scans, but the generated contours by automated models can be inaccurate, potentially leading to treatment planning issues. The reasons for these inaccuracies could be varied, such as unclear organ boundaries or inaccurate ground truth due to annotation errors. To improve the modelâ€™s performance, it is necessary to identify these failure cases during the training process and to correct them with some potential post-processing techniques. However, this process can be time-consuming, as traditionally it requires manual inspection of the predicted output. This paper proposes a method to automatically identify failure cases by setting a threshold for the combination of Dice and Hausdorff distances. This approach reduces the time-consuming task of visually inspecting predicted outputs, allowing for faster identification of failure case candidates. The method was evaluated on 20 cases of six different organs in CT images from clinical expert curated datasets. By setting the thresholds for the Dice and Hausdorff distances, the study was able to differentiate between various states of failure cases and evaluate over 12 cases visually. This thresholding approach could be extended to other organs, leading to faster identification of failure cases and thereby improving the quality of radiation therapy planning.  
 Amin Honarmandi Shandiz, Attila RÃ¡dics, Rajesh Tamada, Makk ÃrpÃ¡d, Karolina Glowacka, Lehel Ferenczi, Sandeep Dutta, Michael Fanariotis   
 Digitizer: A Synthetic Dataset for Well-Log Analysis  
  Raster well-log images are digital representations of paper copies that retain the original analog data gathered during subsurface drilling. Geologists heavily rely on these images to interpret well-log curves and gain insights into the geological formations beneath the surface. However, manually extracting and analyzing data from these images is time-consuming and demanding. To tackle these challenges, researchers increasingly turn to computer vision and machine learning techniques to assist in the analysis process. Nonetheless, developing such approaches, mainly those dependent on machine learning requires a sufficient number of accurately labelled samples for model training and fine-tuning. Unfortunately, this is not a straightforward task, as existing datasets are derived from scanned hand-compiled paper copies, resulting in digital images that suffer from noise and errors. Furthermore, these samples only represent images and not the digital signals of the measured natural phenomena. To overcome these obstacles, we present a new synthetic dataset that includes both images and digital signals of well-logs. This dataset aims to facilitate more effective and accurate analysis techniques, addressing the limitations of current methods. By utilizing this dataset, researchers and practitioners can develop solutions that mitigate the shortcomings of existing methods, ultimately leading to more reliable and precise results in interpreting well-log curves and understanding subsurface geological formations.  
 M. Quamer Nasim, Narendra Patwardhan, Javed Ali, Tannistha Maiti, Stefano Marrone, Tarry Singh, Carlo Sansone   
 Abstracts Embeddings Evaluation: A Case Study of Artificial Intelligence and Medical Imaging for the COVID-19 Infection  
  During the COVID-19 pandemic, a huge amount of literature was produced covering different aspects of infection. The use of artificial intelligence (AI) in medical imaging has been shown to improve screening, diagnosis, treatment, and medication for the COVID-19 virus. Applying natural language processing (NLP) solutions to COVID-19 literature has contributed to infer significant COVID-19-related topics and correlated diseases. In this paper, we aim at evaluating biomedical transformer-based NLP techniques in COVID-19 research to understand if they are able to classify problems related to COVID-19. Particularly, once collected COVID-19 publications encompassing the terms AI and medical imaging, fifteen BERT-based models have been compared with respect to modality prediction and task prediction.  
 Giovanni Zurlo, Elisabetta Ronchieri   
 Towards a Better Understanding of Human Emotions: Challenges of Dataset Labeling  
  A major challenge in automatic human emotion recognition is that of categorizing the very broad and complex spectrum of human emotions. In this regard, a critical bottleneck is represented by the difficulty in obtaining annotated data to build such models. Indeed, all the publicly available datasets collected to this aim are either annotated with (i) the six prototypical emotions, or (ii) continuous valence/arousal (VA) values. On the one hand, the six basic emotions represent a coarse approximation of the vast spectrum of human emotions, and are of limited utility to understand a personâ€™s emotional state. Oppositely, performing dimensional emotion recognition using VA can cover the full range of human emotions, yet it lacks a clear interpretation. Moreover, data annotation with VA is challenging as it requires expert annotators, and there is no guarantee that annotations are consistent with the six prototypical emotions. In this paper, we present an investigation aiming to bridge the gap between the two modalities. We propose to leverage VA values to obtain a fine-grained taxonomy of emotions, interpreting emotional states as probability distributions over the VA space. This has the potential for enabling automatic annotation of existing datasets with this new taxonomy, avoiding the need for expensive data collection and labeling. However, our preliminary results disclose two major problems: first, continuous VA values and the six standard emotion labels are often inconsistent, raising concerns about the validity of existing datasets; second, datasets claimed to be balanced in terms of emotion labels become instead severely unbalanced if provided with a fine-grained emotion annotation. We conclude that efforts are needed in terms of data collection to further push forward the research in this field.  
 Hajer Guerdelli, Claudio Ferrari, Joao Baptista Cardia Neto, Stefano Berretti, Walid Barhoumi, Alberto Del Bimbo   
 Frontmatter  
 ONFIRE Contest 2023: Real-Time Fire Detection on the Edge  
  ONFIRE Contest 2023 is a competition, organized within ICIAP 2023 conference, among methods based on deep learning, aimed at the recognition of fire from videos in real-time on edge devices. This topic is inspiring various research groups for the underlying security reasons and for the growing necessity to realize a system that allows to safeguard the territory from the enormous damage that fires can cause. The participants are required to design fire detection methods, starting from a training set that consists of videos in which fire (flames and/or smoke) is present (positive samples), and others (negative samples) that do not contain a fire. The videos have been collected from existing datasets by selecting as positive videos only those that really frame a fire and not flames and smoke in controlled conditions, and as negative videos the ones that contain moving objects that can be confused with flames or smoke. Since the videos are collected in different conditions, the dataset is very heterogeneous in terms of image resolution, illumination, pixel size of flame or smoke, background activity, scenario (urban or wildfire). The submitted methods are evaluated over a private test set, whose videos are different from the ones available in the training set; this choice allows to test the approaches in realistic conditions, namely in unknown operative scenarios. The proposed experimental protocol allows to measure not only the accuracy but also the computational resources required by the methods, so that the top-rank approaches will be both effective and suited for real-time processing on the edge.  
 Diego Gragnaniello, Antonio Greco, Carlo Sansone, Bruno Vento   
 Generalized Deepfake Detection Algorithm Based on Inconsistency Between Inner and Outer Faces  
  Deepfake refers to using artificial intelligence (AI) and machine learning techniques to create compelling and realistic media content, such as videos, images, or recordings, that appear real but are fake. The most common form of deepfake involves using deep neural networks to replace or superimpose faces in existing videos or images on top of other peopleâ€™s faces. While this technology can be used for various benign purposes, such as filmmaking or online education, it can also be used maliciously to spread misinformation by creating fake videos or images. Based on the classic deepfake generation process, this paper explores the Inconsistency between inner and outer faces in fake content to find synthetic defects and proposes a general deepfake detection algorithm. Experimental results show that our proposed method has certain advantages, especially regarding cross-method detection performance.  
 Jie Gao, Sara Concas, Giulia OrrÃ¹, Xiaoyi Feng, Gian Luca Marcialis, Fabio Roli   
 Real-Time Multiclass Face Spoofing Recognition Through Spatiotemporal Convolutional 3D Features  
  Face recognition is used in numerous authentication applications, unfortunately they are susceptible to spoofing attacks such as paper and screen attacks. In this paper, we propose a method that is able to recognise if a face detected in a video is not real and the type of attack performed on the fake video. We propose to learn the temporal features exploiting a 3D Convolution Network that is more suitable for temporal information. The 3D ConvNet, other than summarizing temporal information, allows us to build a real-time method since it is so much more efficient to analyse clips instead of analyzing single frames. The learned features are classified using a binary classifier to distinguish if the person in the clip video is real (i.e. live) or not, multi class classifier recognises if the person is real or the type of attack (screen, paper, ect.). We performed our test on 5 public datasets: Replay Attack, Replay Mobile, MSU-MSFD, Rose-Youtu, RECOD-MPAD.  
 Salvatore Giurato, Alessandro Ortis, Sebastiano Battiato   
 Enhancing Air Quality Forecasting Through Deep Learning and Continuous Wavelet Transform  
  Air quality forecasting plays a crucial role in environmental management and public health. In this paper, we propose a novel approach that combines deep learning techniques with the Continuous Wavelet Transform (CWT) for air quality forecasting based on sensor data. The proposed methodology is agnostic to the target pollutant and can be applied to estimate any available pollutant without loss of generality. The pipeline consists of two main steps: the generation of stacked samples from raw sensor signals using CWT, and the prediction through a custom deep neural network based on the ResNet18 architecture.We compare our approach with traditional one-dimensional signal processing models. The results show that our 2D pipeline, employing the Morlet mother wavelet, outperforms the baselines significantly. The localized time-frequency representations obtained through CWT highlight hidden dynamics and relationships within the parameter behavior and external factors, leading to more accurate predictions. Overall, our approach demonstrates the potential to advance air quality forecasting and environmental management for healthier living environments worldwide.  
 Pietro Manganelli Conforti, Andrea Fanti, Pietro Nardelli, Paolo Russo   
 Automatic Alignment of Multi-scale Aerial and Underwater Photogrammetric Point Clouds: A Case Study in the Maldivian Coral Reef  
  The research question that the paper investigates is whether the usage of state of the art algorithms for point clouds registration solves the problem of multi-scale vision-based point clouds registration in mixed aerial and underwater environments. This paper reports very preliminary results on the data we have been able to procure, in the context of a coral reef restoration project nearby Magoodhoo Island (Maldives). The results obtained by exploiting state of the art algorithms are promising, considering that those data presents hard samples, in particular for their multi-scale nature (noise in captured 3D points increases with depth). However, further investigation on larger data-sets is needed to confirm the overall applicability of the current algorithms to this problem.  
 Federica Di Lauro, Luca Fallati, Simone Fontana, Alessandra Savini, Domenico G. Sorrenti   
 Generative Data Augmentation of Human Biomechanics  
  Wearable sensors are miniature and affordable devices used for monitoring human motion in daily life. Data-driven models applied to wearable sensor data can enhance the accuracy of movement analysis outside of controlled settings. However, obtaining a large and representative database for training these models is challenging due to the specialised motion laboratories and expensive equipment required. To address this limitation, this study proposes a data augmentation approach using generative deep learning to enhance biomechanical datasets. A novel conditional generative adversarial network (GAN) was developed to synthesise biomechanical data during gait. The GAN takes into account the subjectâ€™s anthropometric measures to generate data that represents specific body types as well as information about the gait cycle for reconstruction back into the time domain. The proposed model was evaluated for generating biomechanical data of unseen subjects and fine-tuning the model with small percentages (1%, 2% and 5%) of the test dataset. Researchers and practitioners can overcome the limitations of obtaining large training datasets from human participants by synthesising realistic and diverse synthetic data. This paper outlines the methodology and experimental setup for developing and evaluating the GAN and discusses its potential impact on the field of biomechanics and human motion analysis.  
 HalldÃ³r KÃ¡rason, Pierluigi Ritrovato, Nicola Maffulli, Francesco Tortorella   
 Avatar Reaction to Multimodal Human Behavior  
  In this paper, we propose a virtual agent application. We develop a virtual agent that reacts to gestures and a virtual environment in which it can interact with the user. We capture motion with a Kinect V2 camera, predict the end of the motion and then classify it. The application also features a facial expression recognition module. In addition, to all these modules, we include also OpenAI conversation module. The application can also be used with a virtual reality headset.  
 Baptiste Chopin, Mohamed Daoudi, Angela Bartolo   
 Metadata   
 Title  Image Analysis and Processing - ICIAP 2023 Workshops    
 Editors  Gian Luca Foresti  
  Andrea Fusiello
3. ICICSE_1 conference:
ICCSEEA2023: The 6th International Conference on Computer Science, Engineering and Education Applications  
 March 17 - March 19 , 2023 , Warsaw, Poland  
 About 
  Important dates 
  Committees 
  Paper submission 
  Conference program 
  Keynote speakers 
 The 6th International Conference on Computer Science, Engineering and Education Applications (ICCSEEA2023) - Virtual Conference     
 March 17â€“19, 2023     
 Warsaw, Poland     
 The 6th International Conference on Computer Science, Engineering and Education Applications (ICCSEEA2023) will be held on March 17â€“19, 2023, in Warsaw, Poland. The ICCSEEA2023 will bring together the top researchers from the Asian Pacific Nations, North America, Europe, and around the world to exchange their research results and address open issues in computer science, engineering, and education applications. The organization of such a conference is one of the examples of growing Ukraine-Poland cooperation in different fields of science and education. The official conference language is English. All the papers need to be written and presented in English.    
 ~^o^~ Please click here to submit your paper. ~^o^~     
 ğŸ’– The conference book has been published online by Springer Publisher.  ( 2023-08-18)  
 ğŸ’– Conferece Program.  ( 2023-03-15)  
 ğŸ’– Call for paper.  (2022-7-27)    
 ğŸ’– The Book of ICCSEEA2022 has been published online by Springer.  (2022-5-4)    
 Formal and Informal Learning Research     
 Paper Submission Deadline: December 30, 2022 Extended to February 16, 2023      
 Notification Date: February 24, 2023     
 Authors' Registration: February 27, 2023     
 Camera Ready: February 26, 2023     
 Conference Dates: March 17â€“19, 2023     
 Chairs     
 Prof. Ivan Dychka, National Technical University of Ukraine "Igor Sikorsky Kyiv Polytechnic Institute", Kyiv, Ukraine  
 Prospective authors are encouraged to submit a full paper for review by Dec   ember 30, 2022, in Word or PDF format. Papers will be accepted based on peer review and should contain original, high-quality work. Claims and results should be substantive enough to be further developed as quality work. All papers must be written in English.  The length of the standard paper submitted is 9â€“10 pages, including figures and references. An extra page fee will be paid for the number of pages exceeding 10 pages (Paper Word Templates, Conference Paper Example)   , including figures and references. All accepted papers will be presented in oral sessions or poster sessions.    
 >>Online Paper Submission<<    
 Notice: If the authors have some problems during the paper submission, please contact us by e-mail: iccseea@icics.net.  
 Please click here to download the conference program.
4. ICICSE_2 conference:
ICIT 2023     
 The 2nd International Conference on Intelligence of Things   
 Toggle navigation    ICIT 2023     
 HOME 
  COMMITTEE 
  AUTHORS | Call for Papers 
  Submission Guidelines 
  Presentation Guidelines 
  SPECIAL SESSION 
  HISTORY 
 25 th - 27 th October, 2023   
 HCMUT, Ho Chi Minh City, Vietnam   
 Submission - June 10, 2023  July 1, 2023 (Hard deadline) 
  Notification - July 20, 2023 
  Camera Ready - July 25, 2023 
  Registration - July 25, 2023 
 The 2nd International Conference on Intelligence of Things 2023   
 Introduction   
 The International Conference on Intelligence of things (ICIT) is an International Conference on the current state of technology and the outcome of ongoing research in the area of the Internet of things, the intelligence of things (IoT2/AIoT), and related fields of Information Technology, technically sponsored by Springer.  
  After the first successful organization, the 2nd ICIT 2023 continues to be organized by Ho Chi Minh City University of Technology (HCMUT), Hanoi University of Mining and Geology (HUMG), Vietnam National University of Agriculture (VNUA), Ho Chi Minh City Open University, and Quy Nhon University.  
  ICIT 2023 will be hosted by Ho Chi Minh City University of Technology (HCMUT) in Ho Chi Minh City, Vietnam from October 25 to October 27, 2023.  
 Accepted and presented papers will be published by Springer in series Lecture Notes on Data Engineering and Communications Technologies, indexed by SCOPUS.  
  Paper Submission    
   Artificial Intelligence(AI) and Internet of Things(IoT) Technologies in Healthcare Applications: Heart and Brain Case Studies   
 Abstract  
 Disadvantaged communities across the world are disproportionately affected by a lack of access to healthcare with high societal and individual costs. Conditions such as congenital heart disease and brain seizures can have devastating effects if not detected in time. The main issue is that there is often a lack of trained personnel and/or expensive equipment to detect these conditions. Advances in the Internet of Things and AI technologies can provide reliable, low-cost solutions to detect these conditions without disrupting existing hospital protocols and operating within a secure framework. In our approach, solutions that involve the communion between the medical professional and AI are of special interest. These solutions must be explainable to gain wider acceptance in a medical setting. The presentation will discuss some implementations using EDGE and IoT platforms for an AI-driven auscultation for congenital heart disease and AI-driven sonification of brainwaves. Some aspects of IoT/EDGE security will also be briefly discussed.  
  Special thanks to my colleagues: Prof. Andriy Temko; Dr. Andreea Factor; Prof Viktoria Shelevytska, Prof. Volodymyr Sarana, , Dr. Sergi Gomez Quintana, Feargal Oâ€™Sullivan, Lavanya Pampana, Dominic Lightbody, Duc-Minh Ngo, Tien Van Nguyen, Giuseppe Carracciolo, Leah Twomey, Adam Creed, as well as our funders and supporters.  
 Biography of Dr. Emanuel M. Popovici  
 GALLERY   
 ICIT 2023   
 Contact  
 Home 
  Commitee 
  Submission 
 Â© 2023 The CSE Faculty, HCMUT  , inc. All rights reserved.
5. ICICSE_3 conference:
Institution Edition 
  Discover | Subject category 
  Conference in Socialist Republic of Vietnam 
  Contribution library 
  Browse by venue 
  Share    
  Call for paper ã€”OPENã€•  
 My Submissions   
  This conference is organized and sponsored by Science, Technology, Engineering Mathematics Education Society (STEMES), and MediX Computing LLC., USA, cooperated and supported by Shanghai Shanda University, China. It will be operated by the conference program committee. We hope to attract people from diverse science and engineering disciplines, nationally and internationally, to attend the workshop, present their research results, share their experiences and ideas, and plan future collaborations.  
 Call for paper  
 Important date  
 Draft paper submission deadline   
 Draft paper acceptance notification   
 Submission Topics  
 Big Data, Cloud computing systems and applications in sciences, engineering, education, environment, and medical and healthcare systems, military and defenses, etc. 
  Cloud-based e-Commerce, e-Business, e-Government 
 All Comments  
 Submission Template  
 Ã—    
  Paper Template  
  Paper Template  
 Home 
 Important Date  
 Aug 13  
 Previous Conferences  
 2024-05-10 China Beijing | 2024 4th International Conference on Information Communication and Software Engineering (ICICSE) 
  2023-04-07 China Chongqing | 2023 3rd International Conference on Information Communication and Software Engineering 
  2022-03-18 China Chongqing | 2022 IEEE 2nd International Conference on Information Communication and Software Engineering
6. ICICS_0 conference:
(Subscribe) | (I forgot my password) 
 ICICS 2023: The 25th International Conference on Information and Communications Security   
  Conference   
  in-person   
  18th to 20th November 2023   
  Tianjin, China   
  Deadline for abstracts/proposals:  30th March 2023   
  Check the event website  for more details.
7. ICICS_3 conference:
Your Memberships and Subscriptions     
  There was an error.  We were unable to process your subscription due to an error. Please refresh and try again.   
 Buy for others  
 Read instantly on your browser with Kindle for Web.  
  Using your mobile phone camera, scan the code below and download the Kindle app.  
 Image Unavailable  
  Publisher     Springer 
  Publication date     19 October 2023 
  Language     English 
 Next slide of product details       
  Due to its large file size, this book may take longer to download    
  Report an issue with this product    
  Product details  
 ASIN â€ : â€  B0CJNB4XRV 
  Publisher â€ : â€  Springer (19 October 2023) 
  Language â€ : â€  English
8. ICIDS_0 conference:
Contact 
 ICIDS - International Conference on Interactive Digital Storytelling  
 Periodicity:      
 Description
9. ICIDS_1 conference:
Search for: 
 Home  /  Conferences  /  ICIDS Interactive Storytelling   
 ICIDS Interactive Storytelling  
 International Conference on Interactive Digital Storytelling  
 This page provides information related to these conference series.  
 Published rules for the ICIDS review process are available here  (PDF).  
 Call for organisers  
 Peers interested in organising an edition of the ICIDS conference are invited to  
 read the | call for organisers | (PDF) and 
  return the completed | application form | (RTF). 
  Next conference:  
 ICIDS 2024 â€“ Interactive Storytelling 24  
  December 2-6, 2024, Barranquilla, Columbia  
 ICIDS steering committee  
 Luis Emilio Bruni, Andrew Gordon, Mads Haahr, Lissa Holloway-Attaway, Hartmut Koenitz, Alex Mitchell, Frank Nack, Valentina Nisi, Rebecca Rouse, David Thue  
 Past members  
 Past conferences  
 ICIDS 2023 â€“ Interactive Storytelling 23   
  November 11-15, 2023, Kobe, Japan  
    ICIDS 2022 â€“ Interactive Storytelling 22   
  December 4-7, 2022, Santa Cruz, California  
 Useful links  
 ICIDS Facebook page 
  Publication database on Interactive Storytelling 
  Wiki on Interactive Storytelling and Narrative Theories 
 Search for:       
 Recent Posts  
 ARDIN Online Social Video June 5, 2024 
  Announcing the first issue of the ARDIN Journal of Interactive Narrative 
  ICIDS 2024 Call for Workshops is out 
  ICIDS 2024 Call for Artworks is out 
  ICIDS 2024 Call for Papers is out 
 Recent Comments  
 Archives  
 June 2024 
  May 2024 
  April 2024 
  May 2023 
  May 2022
10. ICIDS_2 conference:
Open Data Sources 
  NordMedia Conference 2023 
  Divisions and Temporary Working Groups 
  Open Resources | keyboard_arrow_down 
  NordMedia Conference 2023 | keyboard_arrow_down 
  Divisions and Temporary Working Groups | keyboard_arrow_down 
  Submission Guidelines 2023 | keyboard_arrow_down 
  Registration | keyboard_arrow_down 
 menu    
 International Conference on Interactive Digital Storytelling 2023  
 Published  
 7 August 2023  
 Date  
 Nov 11 - Nov 15 2023  
 Country  
          email     
 The annual conference is an interdisciplinary gathering that combines technology-focused approaches with humanities-inspired theoretical inquiry, empirical research and artistic expression. ICIDS 2023 is the 16th edition of the conference and will be presented as a fully hybrid event.  
 The theme for the conference this year is Traversing Boundaries, Barriers and Borders.   
 More info  
 open_in_new  Visit conference website     
 Dec 10 - Dec 12 2024  Finland   
 The Digital Research Data and Human Sciences (DRDHum) conference  
  The theme of the conference is Digital Humanities in the Age of AI.  
 open_in_new  visit conference website

output:1. ICIAP_2 information:
2. ICIAP_3 information:
3. ICICSE_1 information:
4. ICICSE_2 information:
5. ICICSE_3 information:
6. ICICS_0 information:
7. ICICS_3 information:
8. ICIDS_0 information:
9. ICIDS_1 information:
10. ICIDS_2 information:
