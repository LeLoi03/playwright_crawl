input:
1. ICOTA_2 conference:
Members Area     
     About | ICoTA Organization 
  ICoTA Honorary Members 
  ICoTA Governance 
  ICoTA Membership & Renewals 
  Technical | History 
  Coiled Tubing 
  Well Integrity - An Overview 
  Stimulation 
  ICoTA Chapters 
  Events 
  News 
  Members Section 
 About | ICoTA Organization 
  ICoTA Honorary Members 
  ICoTA Governance 
  ICoTA Membership & Renewals 
  Technical | History 
  Coiled Tubing 
  Well Integrity - An Overview 
  Stimulation 
  ICoTA Chapters 
  Events 
  News 
  Training 
  2023 SPE/ICoTA Well Intervention Conference & Exhibition  
 Preparations are well underway for the 2023 conference and exhibition, to be held 21–22 March  at The Woodlands Waterway Marriott Convention Cen  ter  in The Woodlands, Texas, USA. This, the 22 nd  edition of the global event, is expected to be the best one yet, as the world emerges from the pandemic and the intervention space becomes increasingly relevant and thrives. An exciting keynote speaker has already been secured, and abstract submissions are rolling in for the technical sessions  
  Event key details  
 Waterway Marriott & Convention Center, The Woodlands, Texas   
  21st March 2023 - 22nd March 2023   
 Register to Attend    
  Horizontal and ERD Solutions 
  Intervention Solutions in Challenging Environments 
  In addition to the keynote presentation, the recipients of the Curtis Blount Outstanding Paper Award and the ICoTA Global Annual Intervention Technology Award   winner will be announced.  
 See who is exhibiting!    
  Keynote Speaker  
    Operator Events  
 Plenary Breakfast: Operator Roundtable  This plenary discussion will focus on the value interventions bring to the industry in a time of intense capital discipline, but expect us to cover a wide range of other relevant topics. Hear from operators on what they see as needs in the industry and where we should be heading forward. This event will be a highlight of our 2023 program and will provide some key insights.  
 Abshar Nor | , General Manager Well Intervention & Workover at PETRONAS 
  Tony Ryan | , Manager Well Intervention & Integrity at ConocoPhillips 
  Roger Savoldi Roman | , Advisor Well Completions at PETROBRAS 
  Rebecca Ugalde | , Senior Wells Engineer Continuous Improvement at BP 
  The roundtable will be moderated by Matt Billingham, Technical Director for Interventions at SLB and Executive Director at ICoTA.  
 We are also very glad to have Kamel Ben-Naceur, 2022 SPE President, co-moderate the session. Kamel brings a wealth of information with a background including being Chief Economist for Adnoc, Director for Sustainable Energy Policies and Technologies at the IEA and Minister of Industry, Energy and Mines for the Tunisian Government.  
 Operator Showcase  The Operator Showcase will provide a designated space for collaboration and networking between Operators and Service Providers. This event will take place on the exhibit floor and is promised to be unique and very important to discuss industry challenges. Operating company representatives will discuss current and future technical issues that their companies are facing and solicit solutions from the service industry.  
   Connect & Engage with the Well Intervention Industry  
 Exhibiting   
 Whether your goal is to display your latest products and services or align your brand with the niche technical content in the industry, the 2023 SPE/ICoTA Well Intervention Conference and Exhibition represents an unmatched opportunity.  
 Share your brand with a targeted group of key decision-makers 
  Showcase your technologies, valuable services, and unique expertise 
  Cookie Policy 
 Copyright 2024 Icota, all rights reserved
2. ICOTA_3 conference:
Download Free PDF   
 Preface: Special issue dedicated to the tenth international conference on optimization techniques and applications (ICOTA 10)  
  Rentsen Enkhbat    
 Optimization Letters  
 Introduction to Global Optimization  Leo Liberti    
 Accurate modelling of real-world problems often requires nonconvex terms to be introduced in the model, either in the objective function or in the constraints. Nonconvex programming is one of the hardest fields of optimization, presenting many challenges in both practical and theoretical aspects. The presence of multiple local minima calls for the application of global optimization techniques. This paper is a mini-course about global optimization techniques in nonconvex programming; it deals with some theoretical aspects of nonlinear programming as well as with some of the current stateof-the-art algorithms in global optimization. The syllabus is as follows. Some examples of Nonlinear Programming Problems (NLPs). General description of two-phase algorithms. Local optimization of NLPs: derivation of KKT conditions. Short notes about stochastic global multistart algorithms with a concrete example (SobolOpt). In-depth study of a deterministic spatial Branch-and-Bound algorithm, and con...  
 download  Download free PDF   View PDF  chevron_right     
 Proceedings of the XIII Global Optimization Workshop: GOW'16  Ana Maria A.c. Rocha    
 Large scale problems in the design of networks and energy systems, the biomedical field, finance, and engineering are modeled as optimization problems. Humans and nature are constantly optimizing to minimize costs or maximize profits, to maximize the flow in a network, or to minimize the probability of a blackout in the smart grid. Due to new algorithmic developments and the computational power of computers, optimization algorithms have been used to solve problems in a wide spectrum of applications in science and engineering. In this talk I am going to address new challenges in the theory and practice of optimization. First, we have to reflect back a few decades to see what has been achieved and then address the new research challenges and directions.  
 download  Download free PDF   View PDF  chevron_right     
 A survey on the global optimization problem: General theory and computational approaches  Francesco Archetti    
 Several different approaches have been suggested for the numerical solution of the global optimization problem: space covering methods, trajectory methods, random sampling, random search and methods based on a stochastic model of the objective function are considered in this paper and their relative computational effectiveness is discussed. A closer analysis is performed of random sampling methods along with cluster analysis of sampled data and of Bayesian nonparametric stopping rules.  
 download  Download free PDF   View PDF  chevron_right     
  Loading Preview  
 Sorry, preview is currently unavailable. You can download the paper by clicking the button above.  
 Related papers
3. ICPC_0 conference:
ICPC 2023   Mon 15 - Tue 16 May 2023 Melbourne, Australia    
 co-located with ICSE 2023    
 Toggle navigation        
 Attending | Venue: Melbourne Convention Exhibition Centre | MCEC 
  Keynotes 
  ICPC Social Event 
  ICSE 2023 
  Keynotes 
  Melbourne 
  Code of Conduct 
  Diversity and Inclusion Plan 
  Main Conference In-Person Presenter Instructions 
  Main Conference Virtual Presenter Instructions 
  Workshop and Co-Located Event Instructions 
  Visa Letter of Invitation 
  Social Events 
  Recruitment Opportunities at ICSE 2023 
  IEEE Computer Society Open Conference Statement 
  Travel Support 
  Childcare Support 
  Program | ICPC Program 
  Your Program 
   Mon 15 May 
  Tue 16 May 
  Tracks | ICPC 2023 
  Closing 
  Discussion 
  Early Research Achievements (ERA) 
  ICPC Keynotes 
  Journal First 
  MIP Talk 
  Research 
  Tool Demonstration 
  Organization | ICPC 2023 Committees 
  Organizing Committee 
  Steering Committee 
  Series | Series 
  ICPC 2024 
  ICPC 2023 
  ICPC 2022 
  Sign up 
 Thank you all for attending ICPC 2023!  
 International Conference on Program Comprehension 2023  
 The 31st IEEE/ACM International Conference on Program Comprehension (ICPC 2023) is the premier venue for work in the area of program comprehension. It encompasses both human activities for comprehending the software and technologies for supporting such comprehension. ICPC 2023 promises to provide a quality forum for researchers and practitioners from academia and industry to present and to discuss state-of-the-art results and best practices in the field of program comprehension. ICPC 2023 is co-located with ICSE 2023.  
 ICPC 2023 solicits four main categories of research contributions: research papers, early research achievement (ERA) papers, replications and negative results papers, and tool demos. On top of this, journal first papers from selected journals will be accepted for presentation. Research papers describe original work in the area of program comprehension; ERA papers report early research results with the main goal of fostering discussion at the conference. Replications and negative results papers concern with the re-execution of existing research aimed at strengthening previous findings as well as the presentation of sound empirical methods leading to negative results. Finally, tool demonstrations report about new instruments making available and usable to practitioners program comprehension methods.  
  ICPC 2023 Tracks   
 Closing  | Discussion  | Early Research Achievements (ERA)  | ICPC Keynotes  | Journal First  | MIP Talk  | Opening  | Replications and Negative Results (RENE)  | Research  | Tool Demonstration    
  ICPC 2023   
  contact form    
  Discussion   
  Early Research Achievements (ERA)   
  ICPC Keynotes   
  Journal First   
  MIP Talk   
 Venue: Melbourne Convention Exhibition Centre | MCEC   
  Keynotes   
  ICPC Social Event   
  Keynotes   
  Melbourne   
  Code of Conduct   
  Diversity and Inclusion Plan   
  Main Conference In-Person Presenter Instructions   
  Main Conference Virtual Presenter Instructions   
  Workshop and Co-Located Event Instructions   
  Visa Letter of Invitation   
  Social Events   
  Recruitment Opportunities at ICSE 2023   
  IEEE Computer Society Open Conference Statement   
  Travel Support
4. ICPC_1 conference:
An IEEE Computer Society  
   sponsored venue |  
 Program comprehension is a vital software engineering and maintenance activity. It is necessary to facilitate reuse, inspection, maintenance, reverse engineering, reengineering, migration, and extension of existing software systems. ICPC (formerly IWPC) provides an opportunity for researchers and industry practitioners to present and discuss both the state of the art and the state of the practice in the general area of program comprehension.  
 Upcoming Events  
  ICPC Steering Committee < moc.spuorgelgoog@cs-cpci  >
5. ICPC_2 conference:
Installing LaTex in Ubuntu     
 What is Impact Factor? How it is calculated?     
 Tips for writing a good research paper     
 What is H-index?     
 How to install LaTex in Windows     
 "Research is creating new knowledge." -Neil Armstrong  
  ICPC Ranking and Rating Metrics   
 Conference Rank/Ranking: | C 
  Star rating based on conference ranking: 
  Conference short name: | ICPC 
 According to this ranking, the following are the categories to which the conference are assigned:  
 A* - Assigned to the flagship conference, the one that is the leading in that area of discipline. 
  A - Assigned to the flagship conference, the one that is the leading in that area of discipline. 
  B - Assigned to the good conference, the one that is well regarded in that area of discipline. 
  C - Assigned to the other conference that satisfies minimum standards. 
  Australasian - This ranking is assigned to the conferences for which the audience is mainly New Zealanders and Australians. 
  Unranked - Assigned to the conference for which no ranking decision has been taken. 
  National - Assigned to the conference that runs mainly in a single country, having chairs from the same country, and that is generally not well known. 
  Regional - It is similar to the National one, but might cover regions crossing national boundaries.
6. ICPE_0 conference:
Double Blind FAQ 
  Code of Conduct 
  About ICPE (external) 
  ICPE 2022 (external) 
 We are happy to have you in ICPE 2023! The conference will be held at the Hotel Quinta das Lágrimas  , Coimbra, Portugal. Check how to get there at the venue page  .  
 Latest Updates:  
 (04/26/2023) Thank you for attending ICPE! The presentations are available | here | . 
  (03/31/2023) Updated directions on how to get to Coimbra from Lisbon or Porto in the | venue page | . 
  (03/14/2023) We proudly present three exciting keynotes: Mathieu Nayrolles (Ubisoft), Federica Sarro (University College London), and Georg Hager (FAU Erlangen-Nürnberg). See the details | here | . 
  (02/25/2023) SIGSOFT CAPS Travel Support is available! More information on the | registration page | . 
  Awards  
 Best Paper Award | : Predicting the Performance of ATL Model Transformations (by Raffaela Groner, Peter Bellmann, Stefan Höppner, Patrick Thiam, Friedhelm Schwenker, Matthias Tichy) 
  Best Industry Paper Award | : Analyzing the Performance of SD-WAN Enabled Service Function Chains Across the Globe with AWS (by Aris Leivadeas, Nikolai Pitaev, Matthias Falkner) 
  Best Data Challenge Paper Award | : Analysing Static Source Code Features to Determine a Correlation to Steady State Performance in Java Microbenchmarks (by Jared Chad Swanzen, Kyle Thomas Botes, Husnaa Molvi, Omphile Monchwe, Dan Phala, Dustin van der Haar) 
  Most Influential Paper Award | : Self-Adaptive Workload Classification and Forecasting for Proactive Resource Provisioning (by Nikolas Roman Herbst, Nikolaus Huber, Samuel Kounev, Erich Amrehn) 
  Best Reviewer and Associated Reviewer | : Hanspeter Mössenböck (PC member), Raphael Mosaner (associated reviewer) 
  Best Reviewer and Associated Reviewers | : Anne Koziolek (PC member), Larissa Schmid and Martin Armbruster (associated reviewers) 
  Candidates to the Best Paper Award  
 Is Sharing Caring? Analyzing the Incentives for Shared Cloud Clusters (by Talha Mehboob, Noman Bashir, Michael Zink, David Irwin) 
  Systematically Exploring High-Performance Representations of Vector Fields Through Compile-Time Composition (by Stephen Nicholas Swatman, Ana Lucia Varbanescu, Andy Pimentel, Andreas Salzburger, Attila Krasznahorkay) 
  DrGPU: A Top-Down Profiler for GPU Applications (by Yueming Hao, Nikhil Jain, Rob Van der Wijngaart, Nirmal Saxena, Yuanbo Fan, Xu Liu) 
  Candidate to the Best Data Challenge Paper Award  
 Efficient Data Processing: Assessing the Performance of Different Programming Languages (by Lukas Beierlieb, Andre Bauer, Robert Leppich, Lukas Ifflaender, Samuel Kounev) 
  About ICPE  
 The International Conference on Performance Engineering (ICPE) originated 14 years ago from the fusion of an ACM workshop on software and performance prediction and a SPEC workshop focused on benchmarking and performance evaluation.  
 ICPE continues true to its origins with focus both on software performance modeling, prediction, and measurement as well as on benchmark-based performance evaluation. The areas to which such principles are applied have evolved over the years with the technological evolution in academia and industry.  
 ICPE contributions appear at all levels of system and software design, performance modeling, and measurements of performance, from the cloud’s core to edge, from mobile devices to major data centers, from web applications to scientific applications.  
 The ICPE focus on engineering performance means that industrial practitioners and academics that participate in ICPE are interested in quantifying the performance impact of all aspects of complex systems design and implementation. Length of design cycles, life-time maintenance issues, quality of experience, costs to delivering a system or service are also the focus of the intellectual curiosity of ICPE participants.  
 Notice  : ICPE 2023 will be held in person. Remote presentations and pre-recorded videos are not allowed unless all authors of an accepted paper are under special circumstances that prevent them from attending the conference in person. Requests for such exceptions will be considered carefully by the organizing committee.  
 If you have any question about ICPE, please contact us through the following e-mail: icpe2023@dei.uc.pt   
 Tweets by ICPEconf   
 14th ACM/SPEC International Conference on Performance Engineering (ICPE)
7. ICPE_1 conference:
Proceedings 
  Companion 
  Author Index 
  Conference website 
 Proceedings of the 2023 ACM/SPEC International Conference  
 It is our great pleasure to welcome you to the 14th annual ACM/SPEC International Conference on Performance Engineering (ICPE 2023) and to the cultural city of Coimbra - located in the center of Portugal, known as A cidade dos estudantes (the city of the students), and hosting the oldest University in Portugal and of Portuguese language, the University of Coimbra.  
 Performance, energy efficiency and reliability are becoming central to the acceptance and sustainability of modern computing systems. However, they are also becoming more and more challenging to achieve. The computing systems are constantly growing in complexity and becoming more tightly integrated in human interaction, which makes their behavior more complex and therefore more difficult to engineer and understand. We need to be able to manage this complexity so that our systems remain reliable, trustable and performant.  
 ICPE 2023 Welcome   
 General Chairs  
 Marco Vieira (University of Coimbra, Portugal)  
  Petr Tůma (Charles University, Czechia)  
 ICPE 2023 Conference Organization   
 ICPE 2023 Sponsors & Supporters   
 Table of contents  
 Keynote Talks
8. ICPE_2 conference:
ICPE '23: Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering  
  Full Citation in the ACM Digital Library    
 SESSION: Keynote Talks  
  Michael Zink 
  David Irwin 
  Many organizations maintain and operate large shared computing clusters, since they can substantially reduce computing costs by leveraging statistical multiplexing to amortize it across all users. Importantly, such shared clusters are generally not free to use, but have an internal pricing model that funds their operation. Since employees at many large organizations, especially Universities, have some budgetary autonomy over purchase decisions, internal shared clusters are increasingly competing for users with cloud platforms, which may offer lower costs and better performance. As a result, many organizations are shifting their shared clusters to operate on cloud resources. This paper empirically analyzes the user incentives for shared cloud clusters under two different pricing models using an 8-year job trace from a large shared cluster for a large University system.  
 Heiko Koziolek 
  Nafise Eskandani 
  With containers becoming a prevalent method of software deployment, there is an increasing interest to use container orchestration frameworks not only in data centers, but also on resource-constrained hardware, such as Internet-of-Things devices, Edge gateways, or developer workstations. Consequently, software vendors have released several lightweight Kubernetes (K8s) distributions for container orchestration in the last few years, but it remains difficult for software developers to select an appropriate solution. Existing studies on lightweight K8s distribution performance tested only small workloads, showed inconclusive results, and did not cover recently released distributions. The contribution of this paper is a comparison of MicroK8s, k3s, k0s, and MicroShift, investigating their minimal resource usage as well as control plane and data plane performance in stress scenarios. While k3s and k0s showed by a small amount the highest control plane throughput and MicroShift showed the highest data plane throughput, usability, security, and maintainability are additional factors that drive the decision for an appropriate distribution.  
 Autoscaler Evaluation and Configuration: A Practitioner's Guideline   
  André Bauer 
  Samuel Kounev 
  Autoscalers are indispensable parts of modern cloud deployments and determine the service quality and cost of a cloud application in dynamic workloads. The configuration of an autoscaler strongly influences its performance and is also one of the biggest challenges and showstoppers for the practical applicability of many research autoscalers. Many proposed cloud experiment methodologies can only be partially applied in practice, and many autoscaling papers use custom evaluation methods and metrics. This paper presents a practical guideline for obtaining meaningful and interpretable results on autoscaler performance with reasonable overhead. We provide step-by-step instructions for defining realistic usage behaviors and traffic patterns. We divide the analysis of autoscaler performance into a qualitative antipattern-based analysis and a quantitative analysis. To demonstrate the applicability of our guideline, we conduct several experiments with a microservice of our industry partner in a realistic test environment.  
 SESSION: Measurement  
  Marco Paolieri 
  Leana Golubchik 
  Due to the proliferation of inference tasks on mobile devices, state-of-the-art neural architectures are typically designed using Neural Architecture Search (NAS) to achieve good tradeoffs between machine learning accuracy and inference latency. While measuring inference latency of a huge set of candidate architectures during NAS is not feasible, latency prediction for mobile devices is challenging, because of hardware heterogeneity, optimizations applied by machine learning frameworks, and diversity of neural architectures. Motivated by these challenges, we first quantitatively assess the characteristics of neural architectures and mobile devices that have significant effects on inference latency. Based on this assessment, we propose an operation-wise framework which addresses these challenges by developing operation-wise latency predictors and achieves high accuracy in end-to-end latency predictions, as shown by our comprehensive evaluations on multiple mobile devices using multicore CPUs and GPUs. To illustrate that our approach does not require expensive data collection, we also show that accurate predictions can be achieved on real-world neural architectures using only small amounts of profiling data.  
 A Method to Evaluate the Performance of Predictors in Cyber-Physical Systems   
  Nikolai Pitaev 
  Matthias Falkner 
  Cloud Computing has revolutionized the information technology world and the application offering over the last two decades. At the same time recent trends in Network Function Virtualization (NFV) and Software-Defined Wide Area Networks (SD-WAN) and the combination of those with the Cloud paradigm has allowed an unprecedented shift of enterprise networking services towards the Public Cloud. Even though this network evolutionary approach brings many benefits, it still presents many drawbacks as well. The performance stability and service continuity over a black box Public Cloud infrastructure can hinder the formal service guarantees that many new emerging applications may have. To this end, in this paper, we aim to shed light on the overall performance achieved when deploying coast-to-coast and intercontinental Service Function Chains (SFCs) that interconnect geographically distributed enterprise branches over the Amazon Web Services (AWS) infrastructure. In particular, we investigate the impact of region, Virtual Machine (VM) instance, time of the day and day of the week in the overall throughput and delay attained. The obtained results show the strengths and weaknesses of entirely relying on the AWS infrastructure to offer networking services by investigating possible hidden performance bottlenecks.  
 HHVM Performance Optimization for Large Scale Web Services   
  Arun Kejariwal 
  Benjamin Lee 
  HHVM is commonly developed for large online web services, yet there remains much room for optimizing HHVM performance. This paper discusses challenges and techniques in optimizing HHVM performance for Meta's web service. We begin by evaluating the effectiveness of semantic request routing, a request routing method aimed at enhancing code cache performance in HHVM, and examine its implications for optimizing HHVM performance. Second, we characterize HHVM performance for a large-scale datacenter and identify the challenges brought by uncontrollable confounding factors. Finally, we present the performance management framework for autotuning HHVM performance at scale.  
 A Methodology and Framework to Determine the Isolation Capabilities of Virtualisation Technologies   
  André Bauer 
  Samuel Kounev 
  Container orchestration frameworks play a critical role in modern cloud computing paradigms such as cloud-native or serverless computing. They significantly impact the quality and cost of service deployment as they manage many performance-critical tasks such as container provisioning, scheduling, scaling, and networking. Consequently, a comprehensive performance assessment of container orchestration frameworks is essential. However, until now, there is no benchmarking approach that covers the many different tasks implemented in such platforms and supports evaluating different technology stacks. In this paper, we present a systematic approach that enables benchmarking of container orchestrators. Based on a definition of container orchestration, we define the core requirements and benchmarking scope for such platforms. Each requirement is then linked to metrics and measurement methods, and a benchmark architecture is proposed. With COFFEE, we introduce a benchmarking tool supporting the definition of complex test campaigns for container orchestration frameworks. We demonstrate the potential of our approach with case studies of the frameworks Kubernetes and Nomad in a self-hosted environment and on the Google Cloud Platform. The presented case studies focus on container startup times, crash recovery, rolling updates, and more.  
 Hunter: Using Change Point Detection to Hunt for Performance Regressions   
  Pushkala Pattabhiraman 
  Henrik Ingo 
  Change point detection has recently gained popularity as a method of detecting performance changes in software due to its ability to cope with noisy data. In this paper we present Hunter, an open source tool that automatically detects performance regressions and improvements in time-series data. Hunter uses a modified E-divisive means algorithm to identify statistically significant changes in normally-distributed performance metrics. We describe the changes we made to the E-divisive means algorithm along with their motivation. The main change we adopted was to replace the significance test using randomized permutations with a Student's t-test, as we discovered that the randomized approach did not produce deterministic results, at least not with a reasonable number of iterations. In addition we've made tweaks that allow us to find change points the original algorithm would not, such as two nearby changes. For evaluation, we developed a method to generate real timeseries, but with artificially injected changes in latency. We used these data sets to compare Hunter against two other well known algorithms, PELT and DYNP. Finally, we conclude with lessons we've learned supporting Hunter across teams with individual responsibility for the performance of their project.  
 SESSION: Performance Analysis  
  Jan S. Rellermeyer 
  Alexandru Uta 
  Widely used in datacenters and clouds, network traffic shaping is a performance influencing factor that is often overlooked when benchmarking or simply deploying distributed applications. While in theory traffic shaping should allow for a fairer sharing of network resources, in practice it also introduces new problems: performance (measurement) inconsistency and long tails. In this paper we investigate the effects of traffic shaping mechanisms on common distributed applications. We characterize the performance of a distributed key-value store, big data workloads, and high-performance computing under state-of-the-art benchmarks, while the underlying network's traffic is shaped using state-of-the-art mechanisms such as token-buckets or priority queues. Our results show that the impact of traffic shaping needs to be taken into account when benchmarking or deploying distributed applications. To help researchers, practitioners, and application developers we uncover several practical implications and make recommendations on how certain applications are to be deployed so that performance is least impacted by the shaping protocols.  
 Packet-Level Analysis of Zoom Performance Anomalies
9. ICPE_3 conference:
ICPE '23 Companion: Companion of the 2023 ACM/SPEC International Conference on Performance Engineering  
  Full Citation in the ACM Digital Library    
 SESSION: Emerging Research Track  
 Incremental Change Detection Method For Data Center Power Efficiency Metrics (Work In Progress Paper)   
 Jana Backhus 
  Yasutaka Kono 
 Design-time Performability Evaluation of Runtime Adaptation Strategies (Work In Progress Paper)   
 Martina Rapp 
  Max Scheerer 
  Ralf Reussner 
  Performability is the classic metric for performance evaluation of static systems in case of failures. Compared to static systems, Self-Adaptive Systems (SASs) are inherently more complex due to their constantly changing nature. Thus software architects are facing more complex design decisions which are preferably evaluated at design-time. Model-Based Quality Analysis (MBQA) provides valuable support by putting software architects in a position to take well-founded design decisions about software system quality attributes over the whole development phase of a system. We claim that combining methods from MBQA and established performability concepts support software architects in this decision making process to design effective fault-tolerant adaptation strategies. Our contribution is a model-based approach to evaluate performability-oriented adaptation strategies of SAS at design-time. We demonstrate the applicability of our approach by a proof-of-concept.  
 Event-based Simulation for Transient Systems with Capture Replay to Predict Self-Adaptive Systems (Work in Progress Paper)   
 Sarah Stieß 
  Stefan Höppner 
  Steffen Becker 
  Matthias Tichy 
  Cloud-native systems are dynamic in nature as they always have to react to changes in the environment, e.g., how users utilize the system. Self-adaptive cloud-native systems manage those changes by predicting how future environmental changes will impact the system's service level objectives and how the system can subsequently reconfigure to ensure that the service level objectives stay fulfilled. The farther the predictions look into the future, the higher the chance that good reconfigurations can be identified and applied. However, this requires efficient exploration of potential future system states, particularly exploring alternative futures resulting from alternative system reconfiguration. We present in this paper an extension to the Slingshot simulator for Palladio component models to efficiently explore the future state space induced by environmental changes and reconfigurations. The extension creates snapshots of simulation states and reloads them to explore alternatives. We show that Slingshot's event-based publish-subscribe architecture enables us to extend the simulator easily and without changes to the simulator itself.  
 Transparent Trace Annotation for Performance Debugging in Microservice-oriented Systems (Work In Progress Paper)   
 Adel Belkhiri 
  Ahmad Shahnejat Bushehri 
  Gabriela Nicolescu 
  Microservices is a cloud-native architecture in which a single application is implemented as a collection of small, independent, and loosely-coupled services. This architecture is gaining popularity in the industry as it promises to make applications more scalable and easier to develop and deploy. Nonetheless, adopting this architecture in practice has raised many concerns, particularly regarding the difficulty of diagnosing performance bugs and explaining abnormal software behaviour. Fortunately, many tools based on distributed tracing were proposed to achieve observability in microservice-oriented systems and address these concerns (e.g., Jaeger). Distributed tracing is a method for tracking user requests as they flow between services. While these tools can identify slow services and detect latency-related problems, they mostly fail to pinpoint the root causes of these issues.  
 This paper presents a new approach for enacting cross-layer tracing of microservice-based applications. It also proposes a framework for annotating traces generated by most distributed tracing tools with relevant tracing data and metrics collected from the kernel. The information added to the traces aims at helping the practitioner get a clear insight into the operations of the application executing user requests. The framework we present is notably efficient in diagnosing the causes of long tail latencies. Unlike other solutions, our approach for annotating traces is completely transparent as it does not require the modification of the application, the tracer, or the operating system. Furthermore, our evaluation shows that this approach incurs low overhead costs.  
 Visualizing Runtime Evolution Paths in a Multidimensional Space (Work In Progress Paper)   
 Hagen Tarner 
  Fabian Beck 
  Runtime data of software systems is often of multivariate nature, describing different aspects of performance among other characteristics, and evolves along different versions or changes depending on the execution context. This poses a challenge for visualizations, which are typically only two- or three-dimensional. Using dimensionality reduction, we project the multivariate runtime data to 2D and visualize the result in a scatter plot. To show changes over time, we apply the projection to multiple timestamps and connect temporally adjacent points to form trajectories. This allows for cluster and outlier detection, analysis of co-evolution, and finding temporal patterns. While projected temporal trajectories have been applied to other domains before, we use it to visualize software evolution and execution context changes as evolution paths. We experiment with and report results of two application examples: (I) the runtime evolution along different versions of components from the Apache Commons project, and (II) a benchmark suite from scientific visualization comparing different rendering techniques along camera paths.  
 Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)   
 Gagan Somashekar 
  Rajat Kumar 
  The performance of distributed applications implemented using microservice architecture depends heavily on the configuration of various parameters, which are hard to tune due to large configuration search space and inter-dependence of parameters. While the information in product manuals and technical documents guides the tuning process, manual collection of meta-data for all application parameters is laborious and not scalable. Prior works have largely overlooked the automated use of product manuals, technical documents and source code for extracting such meta-data. In the current work, we propose using large language models for automated meta-data extraction and enhancing the configuration tuning pipeline. We further ideate on building an in-house knowledge system using experimental data to learn important parameters in configuration tuning using historical data on parameter dependence, workload statistics, performance metrics and resource utilization. We expect productionizing the proposed system will reduce the total time and experimental iterations required for configuration tuning in new applications, saving an organization both developer time and money.  
 A Case of Multi-Resource Fairness for Serverless Workflows (Work In Progress Paper)   
 Amit Samanta 
  Ryan Stutsman 
 Our assertion is that beyond the glaring issues like cold start costs, a more fundamental shift is needed in how serverless function invocations are provisioned and scheduled in order to support these more demanding applications. Specifically, we propose a platform that leverages the observability and predictability of serverless functions to enforce multi-resource fairness. We explain why we believe interference across a spectrum of resources (CPU, network, and storage) contributes to lower resource utilization and poor response times for latency-sensitive and high-fanout serverless application patterns. Finally, we propose a new distributed and hierarchical function scheduling architecture that combines lessons from multi-resource fair scheduling, hierarchical scheduling, batch-analytics resource scheduling, and statistics to create an approach that we believe will enable tighter SLAs on serverless platforms than has been possible in the past.  
 Challenges and Future Directions in Efficiency Benchmarking (Vision Paper)   
 Maximilian Meissner 
  Klaus-Dieter Lange 
  Samuel Kounev 
 As the IT landscape experiences radical transformations, efficiency benchmarks need to be updated accordingly to generate results relevant to government regulators, manufacturers, and customers. In this paper, we outline current challenges efficiency benchmark developers are tackling and highlight recent technological developments the next generation of efficiency benchmarks should take into account.  
 A Reference Architecture for Datacenter Scheduler Programming Abstractions: Design and Experiments (Work In Progress Paper)   
 Aratz Manterola Lasa 
  Sacheendra Talluri 
  Sneh Patel 
  Naser Ezzati-Jivan 
  Developers often use microbenchmarking tools to evaluate the performance of a Java program. These tools run a small section of code multiple times and measure its performance. However, this process can be problematic as Java execution is traditionally divided into two stages: a warmup stage where the JVM's JIT compiler optimizes frequently used code and a steady stage where performance is stable. Measuring performance before reaching the steady stage can provide an inaccurate representation of the program's efficiency. The challenge comes from determining when a program should be considered as in a steady state. In this paper, we propose that call stack sampling data should be considered when conducting steady state performance evaluations. By analyzing this data, we can generate call graphs for individual microbenchmark executions. Our proposed method of using call stack sampling data and visualizing call graphs intuitively empowers developers to effectively distinguish between warmup and steady state executions. Additionally, by utilizing machine learning classification techniques this method can automate the steady state detection, working towards a more accurate and efficient performance evaluation process.  
 A Study of Java Microbenchmark Tail Latencies   
  Lukas Iffländer 
  Samuel Kounev 
  This paper compares the performance of R, Python, and Rust in the context of data processing tasks. A real-world data processing task in the form of an aggregation of benchmark measurement results was implemented in each language, and their execution times were measured. The results indicate that while all languages can perform the tasks effectively, there are significant differences in performance. Even the same code showed significant runtime differences depending on the interpreter used for execution. Rust and Python were the most efficient, with R requiring much longer execution times. Additionally, the paper discusses the potential implications of these findings for data scientists and developers when choosing a language for data processing projects.  
 Analysing Static Source Code Features to Determine a Correlation to Steady State Performance in Java Microbenchmarks   
  Beatrice Ombuki-Berman 
  Naser Ezzati-Jivan 
  The practice of microbenchmarking is very important for observing the performance of code. As such, observing the states and anomalies experienced by the program during a benchmark is equally important. This paper attempts to evaluate the effectiveness of the matrix profile method when applied to analyse JMH benchmarks in time series format, to determine if it is a viable alternative to proven methods. We observe that, when using the matrix profile method, there is a statistically significant difference between the results of the analysis on steady state and non-steady state benchmarks. By comparing results of the matrix profile method and the proven changepoint analysis method, we are able to prove a stronger correlation between the two when the benchmark tested is non-steady state versus that of steady state.  
 Software Mining -- Investigating Correlation between Source Code Features and Michrobenchmark's Steady State   
 Towards Evaluation/Mitigation Risk of Systemic Failures in a Recoverable Network with Redistributed Elastic Load   
 Vladimir Marbukh 
  While systemic failure/overload in recoverable networks with load redistribution is a common phenomenon, current ability to evaluate and moreover mitigate the corresponding systemic risk is vastly insufficient due to complexity of the problem and relying on oversimplified models. The proposed in this paper framework for systemic risk evaluation relies on approximate dimension reduction at the onset of systemic failure. Assuming a general failure/recovery microscopic model, the macro-level system dynamics is approximated by a 2-state Markov process alternating between systemically operational and failed states.  
 Challenges and Possible Approaches for Sustainable Digital Twinning   
 Paulo Roberto Farah 
  Silvia Regina Vergilio 
  In this paper, we present PerfoRT, a tool to ease software performance regression measurement of Java systems. Its main characteristics include: minimal configuration to ease automation and hide complexity to the end user; a broad scope of performance metrics including system, process, JVM, and tracing; and presentation of the results from a developer's perspective. We show some of its features in a usage example using Apache Commons BCEL project.  
 SESSION: Tutorials  
 SESSION: First Workshop on Artificial Intelligence for Performance Modeling, Prediction, and Control (AIPerf 2023)  
 ICPE'23 AIPerf Workshop Chairs' Welcome   
 Emilio Incerto 
  Marin Litoiu 
  Riccardo Pinciroli 
  We are pleased to welcome you to the 2023 ACM Workshop on Artificial Intelligence for Performance Modeling, Prediction, and Control - AIPerf'23.  
 In its first edition, AIPerf intends to foster the usage of AI (such as probabilistic methods, machine learning, and deep learning) to control, model, and predict the performance of computer systems. The relevance of these topics reflects current and future trends toward exploiting AI-based approaches to deal with complex, large, and interconnected systems. Despite AI and ML being widely adopted techniques to investigate several mainstream domains, their usage for performance modeling and evaluation is still limited, and their benefit to the performance engineering field remains unclear. AIPerf proposes a meeting venue to promote the dissemination of research works that use or study AI techniques for quantitative analysis of modern ICT systems and to engage academics and practitioners of this field. The workshop focuses on presenting experiences and results of applying AI/ML-based techniques to performance-related problems, as well as sharing performance datasets and benchmarks with the community to facilitate the development of new and more accurate learning procedures.  
 Putting together AIPerf'23 was a team effort. We first thank the authors for providing the content of the program. We are grateful to the program committee and the senior program committee, who worked very hard to review papers and provide authors' feedback. Finally, We thank the ICPE23 organizers for sponsoring AIPerf in its community.  
  Germán Moltó 
  Miguel Caballer 
  This paper proposes an auto-profiling tool for OSCAR, an open-source platform able to support serverless computing in cloud and edge environments. The tool, named OSCAR-P, is designed to automatically test a specified application workflow on different hardware and node combinations, obtaining relevant information on the execution time of the individual components. It then uses the collected data to build performance models using machine learning, making it possible to predict the performance of the application on unseen configurations. The preliminary evaluation of the performance models accuracy is promising, showing a mean absolute percentage error for extrapolation lower than 10%.  
 Towards Novel Statistical Methods for Anomaly Detection in Industrial Processes   
  Daniele Licari 
  Andrea Vandin 
  This paper presents a novel methodology based on first principles of statistics and statistical learning for anomaly detection in industrial processes and IoT environments. We present a 5-level analytical pipeline that cleans, smooths, and eliminates redundancies from the data, and identifies outliers as well as the features that contribute most to these anomalies. We show how smoothing can make our methodology less sensitive to short-lived anomalies that might be, e.g., due to sensor noise. We validate the methodology on a dataset freely available in the literature. Our results show that we can identify all anomalies in the considered dataset, with the ability of controlling the amount of false positives. This work is the result of a research project co-funded by the Tuscany Region and a company leader in the paper and nonwovens sector. Although the methodology was developed for this domain, we consider here a dataset from a different industrial sector. This shows that our methodology can be generalized to other contexts with similar constraints on limited resources, interpretability, time, and budget.  
 SESSION: First FastContinuum Workshop (Fast Continuum 2023)  
 ICPE'23 Fast Continuum Workshop Chairs' Welcome   
 Danilo Ardagna 
  Elisabetta Di Nitto 
  Lorenzo Blasi 
  Francesc Lordan 
  It is our great pleasure to welcome you to the first FastContinuum Workshop held on April 16th 2023. The goal of the workshop is to foster discussion and collaboration among researchers from cloud/edge/fog computing and performance analysis communities, to share the relevant topics and results of the current approaches proposed by industry and academia. FastContinuum solicited full papers as well as demo and short papers including reports about research activities not mature enough for a full paper as well as new ideas and vision papers.  
 The final program includes four full papers and three short ones. They cover some of the most interesting areas of computing continua, from FaaS development and acceleration to the management of heterogeneous datasets to the development of Infrastructure as Code and the automation of deployment through the computing continuum. DevSecOps is also brought to the attendees' attention as one of the crucial ingredients for proper management of the continuum.  
 The workshop keynote, given by Samuel Kunev, investigates further the area of serverless computing properly positioning the multiple aspects and approaches developed in this area and highlighting the main challenges related to the performance of these approaches. The keynote is held in collaboration with the eleventh International Workshop on Load Testing and Benchmarking of Software Systems (LTB 2023).  
 On the Acceleration of FaaS Using Remote GPU Virtualization   
  Javier Prades 
  Federico Silla 
  Serverless computing and, in particular, Function as a Service (FaaS) has introduced novel computational approaches with its highly-elastic capabilities, per-millisecond billing and scale-to-zero capacities, thus being of interest for the computing continuum. Services such as AWS Lambda allow efficient execution of event-driven short-lived bursty applications, even if there are limitations in terms of the amount of memory and the lack of GPU support for accelerated execution. To this aim, this paper analyses the suitability of including GPU support in AWS Lambda through the rCUDA middleware, which provides CUDA applications with remote GPU execution capabilities. A reference architecture for data-driven accelerated processing is introduced, based on elastic queues and event-driven object storage systems to manage resource contention and GPU scheduling. The benefits and limitations are assessed through a use case of sequence alignment. The results indicate that, for certain scenarios, the usage of remote GPUs in AWS Lambda represents a viable approach to reduce the execution time.  
 A Pattern-based Function and Workflow Visual Environment for FaaS Development across the Continuum   
  Alessandro Mamelli 
  Teta Stamati 
  The ability to split applications across different locations in the continuum (edge/cloud) creates needs for application break down into smaller and more distributed chunks. In this realm the Function as a Service approach appears as a significant enabler in this process. The paper presents a visual function and workflow development environment for complex FaaS (Apache OpenwhisK) applications. The environment offers a library of pattern based and reusable nodes and flows while mitigating function orchestration limitations in the domain. Generation of the deployable artefacts, i.e. the functions, is performed through embedded DevOps pipelines. A range of annotations are available for dictating diverse options including QoS needs, function or data locality requirements, function affinity considerations etc. These are propagated to the deployment and operation stacks for supporting the cloud/edge interplay. The mechanism is evaluated functionally through creating, registering and executing functions and orchestrating workflows, adapting typical parallelization patterns and an edge data collection process.  
 Heterogeneous Datasets for Federated Survival Analysis Simulation   
  André Martin 
  Matteo Matteucci 
  Survival analysis studies time-modeling techniques for an event of interest occurring for a population. Survival analysis found widespread applications in healthcare, engineering, and social sciences. However, the data needed to train survival models are often distributed, incomplete, censored, and confidential. In this context, federated learning can be exploited to tremendously improve the quality of the models trained on distributed data while preserving user privacy. However, federated survival analysis is still in its early development, and there is no common benchmarking dataset to test federated survival models. This work provides a novel technique for constructing realistic heterogeneous datasets by starting from existing non-federated datasets in a reproducible way. Specifically, we propose two dataset-splitting algorithms based on the Dirichlet distribution to assign each data sample to a carefully chosen client: quantity-skewed splitting and label-skewed splitting. Furthermore, these algorithms allow for obtaining different levels of heterogeneity by changing a single hyperparameter. Finally, numerical experiments provide a quantitative evaluation of the heterogeneity level using log-rank tests and a qualitative analysis of the generated splits. The implementation of the proposed methods is publicly available in favor of reproducibility and to encourage common practices to simulate federated environments for survival analysis.  
 Continuum: Automate Infrastructure Deployment and Benchmarking in the Compute Continuum   
  Laurentiu Niculut 
  Debora Benedetto 
  The infrastructure-as-code (IaC) is an approach for automating the deployment, maintenance, and monitoring of environments for online services and applications that developers usually do manually. The benefit is not only reducing the time and effort but also the operational costs. This paper aims at describing our experience in applying IaC in cloud-native applications, mainly discussing the key challenges towards modeling and generating IaC faced in the ongoing project Programming Trustworthy Infrastructure-As-Code in a Secure Framework (PIACERE). The concluding insights could spur the wider adoption of IaC by software developers.  
 IEM: A Unified Lifecycle Orchestrator for Multilingual IaC Deployments   
  Tomaz Martincic 
  Dejan Stepec 
  Security represents one of the crucial concerns when it comes to DevOps methodology-empowered software development and service delivery process. Considering the adoption of Infrastructure as Code (IaC), even minor flaws could potentially cause fatal consequences, especially in sensitive domains such as healthcare and maritime applications. However, most of the existing solutions tackle either Static Application Security Testing (SAST) or run-time behavior analysis distinctly. In this paper, we propose a) IaC Scan Runner, an open-source solution developed in Python for inspecting a variety of state-of-the-art IaC languages in application design time and b) the run time anomaly detection tool called LOMOS. Both tools work in synergy and provide a valuable contribution to a DevSecOps tool set. The proposed approach is demonstrated and their results will be demonstrated on various case studies showcasing the capabilities of static analysis tool IaC Scan Runner combined with LOMOS - log analysis artificial intelligence-enabled framework.  
 SESSION: First Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems (GraphSys 2023)  
 ICPE'23 GraphSys Workshop Chairs Introduction (Welcome)   
 Alexandru Iosup 
  Radu Prodan 
  It is our great pleasure to welcome you to the 2023 ACM/SPEC Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems. This is the first such workshop, aiming to facilitate the exchange of ideas and expertise in the broad field of high-performance large-scale graph processing.  
 Graphs or linked data are crucial to innovation, competition, and prosperity and establish a strategic investment in technical processing and ecosystem enablers. Graphs are universal abstractions that capture, combine, model, analyze, and process knowledge about real and digital worlds into actionable insights through item representation and interconnectedness. For societally relevant problems, graphs are extreme data that require further technological innovations to meet the needs of the European data economy. Digital graphs help pursue the United Nations Sustainable Development Goals (UN SDG) by enabling better value chains, products, and services for more profitable or green investments in the financial sector and deriving trustworthy insight for creating sustainable communities. All science, engineering, industry, economy, and society-at-large domains can leverage graph data for unique analysis and insight, but only if graph processing becomes easy to use, fast, scalable, and sustainable.  
  Peter Haase 
  Wolfgang Schell 
  Knowledge Graphs and semantic technologies allow scientists and domain experts to model complex relations between data in a logically structured and machine readable format. metaphactory is a platform that enables users to build these kinds of semantic graphs easily and efficiently. metaphactory uses standards such as RDF in combination with OWL, SKOS, SHACL, and others to provide a flexible endpoint to interact with graphs of varying complexity and expressivity. As part of the Graph-Massivizer project, metaphactory is supporting integration and infrastructure consolidation for components developed in the project. Part of this work is to develop a toolkit which metaphactory uses to process very large graphs without sacrificing sustainability. In this paper we describe in detail the metaphactory platform and how it supports large-scale graph processing in the Graph-Massivizer project, as well as outlining the current efforts within the project and how they aim to increase capabilities in the present to support future work.  
 Towards Sustainable Serverless Processing of Massive Graphs on the Computing Continuum   
  Reza Farahani 
  Radu Prodan 
  Serverless computing offers an affordable and easy way to code lightweight functions that can be invoked based on some events to perform simple tasks. For more complicated processing, multiple serverless functions can be orchestrated as a directed acyclic graph to form a serverless workflow, so-called function choreography (FC). Although most famous cloud providers offer FC management systems such as AWS Step Functions, and there are also several open-source FC management systems (e.g., Apache OpenWhisk), their primary focus is on describing the control flow and data flow between serverless functions in the FC. Moreover, the existing FC management systems rarely consider the processed data, which is commonly represented in a graph format. In this paper, we review the capabilities of the existing FC management systems in supporting graph processing applications. We also raise two key research questions related to large-scale graph processing using serverless computing in federated Function-as-a-Service (FaaS). As part of the Graph-Massivizer project, funded by the Horizon Europe research and innovation program, we will research and develop (prototype) solutions that will address these challenges.  
 Boosting the Impact of Extreme and Sustainable Graph Processing for Urgent Societal Challenges in Europe Graph-Massivizer: A Horizon Europe Project   
  Andrea Borghesi 
  Andrea Bartolini 
  In this paper, we explore the use of Graph Neural Networks (GNNs) for anomaly anticipation in high performance computing (HPC) systems. We propose a GNN-based approach that leverages the structure of the HPC system (particularly, the physical proximity of the compute nodes) to facilitate anomaly anticipation. We frame the task of forecasting the availability of the compute nodes as a supervised prediction problem; the GNN predicts the probability that a compute node will fail within a fixed-length future window.  
 We empirically demonstrate the viability of the GNN-based approach by conducting experiments on the production Tier-0 super-computer hosted at CINECA datacenter facilities, the largest Italian provider of HPC. The results are extremely promising, showing both anomaly detection capabilities on par with other techniques from the literature (with a special focus on those tested on real, production data) and, more significantly, strong results in terms of anomaly prediction.  
  Joze Rozanec 
  Marko Grobelnik 
  This paper describes how we envision classifying events into the United Nations Sustainable Development Goals (SDGs) by utilizing machine learning techniques on global news data. We propose extracting data from a media intelligence platform using an ontology and a classifier to assign each event to its corresponding SDG. To minimize the labeling effort, a few-shot classification approach is employed. Additionally, a labeling tool is developed to facilitate event analysis and assign labels accurately. We envision this approach could be used for analyzing media events at a large scale and track progress towards the SDGs.  
 AI, What Does the Future Hold for Us? Automating Strategic Foresight   
  Gregor Leban 
  Marko Grobelnik 
  There is an increasing awareness that strategic foresight is much needed to guide efficient policy-making. The growing digitalization implies a rising amount of digital evidence of many aspects of society (e.g., science, economy, and politics). Artificial intelligence can process massive amounts of data and extract meaningful information. Furthermore, a knowledge graph can be developed to capture significant aspects of reality, and machine learning models can be used to identify patterns and derive insights. This paper describes how we envision artificial intelligence could be used to create and deliver strategic foresight automatically.  
 Extreme and Sustainable Graph Processing for Green Finance Investment and Trading   
 In this work, we present the Graph-Optimizer tool. Graph-Optimizer uses optimised BGOs and composition rules to capture and model the workload. It combines the workload model with hardware and infrastructure models, predicting performance and energy consumption. Combined with design space exploration, such predictions select codesigned workload implementations to fit a requested performance objective and guarantee their performance bounds during execution.  
 SESSION: Sixth Workshop on Hot Topics in Cloud Computing Performance (HotCloudPerf 2023)  
 HotCloudPerf'23 Workshop Chairs' Welcome   
 Klervie Toczé 
  Nikolas Herbst 
  Alexandru Iosup 
  It is our great pleasure to welcome you to the 2023 edition of the Workshop on Hot Topics in Cloud Computing Performance - HotCloudPerf 2023.  
 Cloud computing is emerging as one of the most profound changes in the way we build and use IT. The use of global services in public clouds is increasing, and the lucrative and rapidly growing global cloud market already supports over 1 million IT-related jobs. However, it is currently challenging to make the IT services offered by public and private clouds performant (in an extended sense) and efficient. Emerging architectures, techniques, and real-world systems include interactions with the computing continuum, serverless operation, everything as a service, complex workflows, auto-scaling and -tiering, etc. It is unclear to which extent traditional performance engineering, software engineering, and system design and analysis tools can help with understanding and engineering these emerging technologies. The community needs practical tools and powerful methods to address hot topics in cloud computing performance.  
 Responding to this need, the HotCloudPerf workshop proposes a meeting venue for academics and practitioners, from experts to trainees, in the field of cloud computing performance. The workshop aims to engage this community and to lead to the development of new methodological aspects for gaining a deeper understanding not only of cloud performance, but also of cloud operation and behavior, through diverse quantitative evaluation tools, including benchmarks, metrics, and workload generators. The workshop focuses on novel cloud properties such as elasticity, performance isolation, dependability, and other non-functional system properties, in addition to classical performance-related metrics such as response time, throughput, scalability, and efficiency.  
  Markus Zilch 
  Steffen Becker 
  Cloud-native applications force increasingly powerful and complex autoscalers to guarantee the applications' quality of service. For software engineers with operational tasks understanding the autoscalers' behavior and applying appropriate reconfigurations is challenging due to their internal mechanisms, inherent distribution, and decentralized decision-making. Hence, engineers seek appropriate explanations. However, engineers' expectations on feedback and explanations of autoscalers are unclear. In this paper, through a workshop with a representative sample of engineers responsible for operating an autoscaler, we elicit requirements for explainability in autoscaling. Based on the requirements, we propose an evaluation scheme for evaluating explainability as a non-functional property of the autoscaling process and guide software engineers in choosing the best-fitting autoscaler for their scenario. The evaluation scheme is based on a Goal Question Metric approach and contains three goals, nine questions to assess explainability, and metrics to answer these questions. The evaluation scheme should help engineers choose a suitable and explainable autoscaler or guide them in building their own.  
 Enhancing Trace Visualizations for Microservices Performance Analysis   
 Jessica Leone 
  Luca Traini 
  Performance analysis of microservices can be a challenging task, as a typical request to these systems involves multiple Remote Procedure Calls (RPC) spanning across independent services and machines. Practitioners primarily rely on distributed tracing tools to closely monitor microservices performance. These tools enable practitioners to trace, collect, and visualize RPC workflows and associated events in the context of individual end-to-end requests. While effective for analyzing individual end-to-end requests, current distributed tracing visualizations often fall short in providing a comprehensive understanding of the system's overall performance. To address this limitation, we propose a novel visualization approach that enables aggregate performance analysis of multiple end-to-end requests. Our approach builds on a previously developed technique for comparing structural differences of request pairs and extends it for aggregate performance analysis of sets of requests. This paper presents our proposal and discusses our preliminary ongoing progress in developing this innovative approach.  
 Performance Experiences From Running An E-health Inference Process As FaaS Across Diverse Clusters   
 George Kousiouris 
  Aristodemos Pnevmatikakis 
  In this paper we report our experiences from the migration of an AI model inference process, used in the context of an E-health platform to the Function as a Service model. To that direction, a performance analysis is applied, across three available Cloud or Edge FaaS clusters based on the open source Apache Openwhisk FaaS platform. The aim is to highlight differences in performance based on the characteristics of each cluster, the request rates and the parameters of Openwhisk. The conclusions can be applied for understanding the expected behavior of the inference function in each of these clusters as well as the effect of the Openwhisk execution model. Key observations and findings are reported on aspects such as function execution duration, function sizing, wait time in the system, network latency and concurrent container overheads for different load rates. These can be used to detect in a black box manner capabilities of unknown clusters, guide or fine-tune performance models as well as private cloud FaaS deployment setup.  
 Can My WiFi Handle the Metaverse? A Performance Evaluation Of Meta's Flagship Virtual Reality Hardware   
 SESSION: Eleventh International Workshop on Load Testing and Benchmarking of Software Systems (LTB 2023)  
 LTB'23 Workshop Chairs' Welcome   
 Alexander Podelko 
  Daniel Seybold 
  Database management systems~(DBMS) are crucial architectural components of any modern distributed software system. Yet, ensuring a smooth, high-performant operation of a DBMS is a black art that requires tweaking many knobs and is heavily dependent on the experienced workload. Misconfigurations at production systems have an heavy impact on the overall delivered service quality and hence, should be avoided at all costs. Replaying production workload on test and staging systems to estimate the ideal configuration are a valid approach. Yet, this requires traces from the production systems.  
 While many DBMS's have built-in support to capture such traces these have a non-negligible impact on performance. eBPF is a Linux kernel feature claiming to enable low-overhead observability and application tracing. In this paper, we evaluate different eBPF-based approaches to DBMS workload tracing for PostgreSQL and MySQL. The results show that using eBPF causes lower overhead than the built-in mechanisms. Hence, eBPF can be a viable baseline for building a generic tracing framework. Yet, our current results also show that additional optimisation and fine-tuning is needed to further lower the performance overhead.  
 Verifying Transient Behavior Specifications in Chaos Engineering Using Metric Temporal Logic and Property Specification Patterns   
 SESSION: First Practically FAIR Workshop (PFAIR 2023)  
 ICPE'23 PFAIR Workshop Chairs Introduction   
 Jay Lofstead 
  Paula Olaya 
  It is our great pleasure to welcome you to the 2023 ACM Practically FAIR - PFAIR 2023. This workshop builds upon the popular FAIR data principles to investigate and share best practices for adopting FAIR principles in practice. The FAIR proposal only covers some computing and science domains while leaving many unconsidered and also does not prescribe how to achieve the standards in the ideal. As researchers and practitioners begin to meet these standards, we, as a community, need to agree upon what constitutes meeting the principles and how it can be validated. We had a call for research and experience papers and received one submission that met our peer review standards and will fill out our program with a keynote as well as a panel and open discussion.  
 FAIR Enabling Re-Use of Data-Intensive Workflows and Scientific Reproducibility   
 Line C. Pouchard 
  Scientific computing communities often run their experiments using complex data- and compute-intensive workflows that utilize high performance computing (HPC), distributed clusters and specialized architectures targeting machine learning and artificial intelligence. FAIR principles for data and software can be useful enablers for the reproducibility of performance (a key HPC metric) and that of scientific results (a crucial tenet of the scientific method) that are based in part on re-use, the R of FAIR principles. FAIR principles are under-used by HPC and data-intensive communities who have been slow to adopt them. This is due in part to the complexity of workflow life cycles, the numerous workflow management systems, the lack of integration of FAIR within existing technologies, and the specificity of managed systems that include rapidly evolving architectures and software stacks, and execution models that require resource managers and batch schedulers. Numerous challenges emerge for scientists attempting to publish FAIR datasets and software for the purpose of re-use and reproducibility, e.g. what data to publish and where due to sizes, how to "FAIRify" data subsetting, at what level of granularity to attribute persistent identifiers to software, what is the minimal amount of metadata needed to guarantee a certain level of reproducibility, what does reproducible AI actually mean? This talk will focus on such challenges and illustrate the negative impact of not applying FAIR on the reproducibility of experiments. We will introduce the notion of FAIR Digital Objects and present RECUP, a framework for data and metadata services for high performance workflows that proposes micro-solutions for adapting FAIR principles to HPC.  
 Automatic FAIR Provenance Collection and Visualization for Time Series   
  Horacio Gonzalez-Velez 
  Adriana E. Chis 
  Provenance provides data lineage and history of different transformations applied to a dataset. A complete trace of data provenance can enable the reanalysis, reproducibility, and reusability of features, which are essential for validating results and extending them in many projects. Open time series datasets are readily accessible and discoverable, but their full reproducibility and reusability require clear metadata provenance. This paper introduces an assessment of provenance variables using an algorithm for collecting FAIR (Findable, Accessible, Interoperable, Reusable) characteristics in open time series and generating an associated provenance graph. We have evaluated the FAIRness of provenance traces by automatically mapping their properties to a provenance data model graph for a case study employing open time series from weather stations. Our approach arguably enables researchers to analyse time series datasets with similar characteristics, prompting new research questions, insights, and investigations. As a result, this approach has the potential to promote reusability and reproducibility, which are critical factors in scientific research.  
 SESSION: Fourth Workshop on Education and Practice of Performance Engineering (WEPPE 2023)  
 WEPPE'23 Workshop Chairs' Welcome   
 Alberto Avritzer 
  Matteo Camilli 
  It is our great pleasure to welcome you to the 4th International Workshop on Education and Practice of Performance Engineering - WEPPE 2023. The goal of the Workshop on Education and Practice of Performance Engineering is to bring together University researchers and Industry Performance Engineers to share education and practice experiences. This year's symposium continues its tradition of being a forum for performance engineering educators. We are interested in creating opportunities to share valuable experience between researchers that are actively teaching performance engineering and Performance Engineers that are applying Performance Engineering techniques in industry.  
 Performance Engineering Practices for Modern Industrial Applications at ABB Research   
 Heiko Koziolek 
  ABB is developing a vast range of software services for process automation applications used in chemical production facilities, power plants, and container ships. High responsiveness and resource efficiency is important in this domain both for real-time embedded systems and distributed containerized systems, but performance engineering can be challenging due to system complexity and application domain heterogeneity. This talk provides experiences and lessons learned from several selected case studies on performance engineering. It illustrates testing performance of OPC UA pub/sub communication, clustered MQTT brokers for edge computing, software container online updates, and lightweight Kubernetes frameworks while highlighting the applied practices and tools. The talk reports on challenges in workload modeling, performance testing, and performance modeling.  
 Quantitative Analysis of Software Designs: Teaching Design and Experiences   
 Alireza Hakamian 
  Steffen Becker 
  Context. The Software Quality and Architecture group (SQA) at the University of Stuttgart offers the Quantitative Analysis of Software Designs (QASD) course for master students. The goal is to give students the necessary skill to evaluate architecture alternatives of software systems quantitatively. The course offers a combination of required theoretical skills, such as applying stochastic processes and practical exercises using suitable tools. The challenge is providing teaching materials that balance necessary theoretical knowledge and appropriate tooling that can be used in practice. As a solution, the course is designed so that one-third is about the formalisms behind quantitative analysis, including stochastic processes and queuing theory. One-third is modeling languages, such as queuing networks, UML, and UML profiles, including MARTE. The other one-third uses tooling to model and analyze example systems. During Corona, we provided students with an e-learning module with pre-recorded videos, online quizzes at the end of every chapter, and a virtual machine that pre-installed all the required tooling for the exercise sheets. Final-remarks. In the past two years, students' feedback was often positive regarding the balance between theory and tooling. However, it has to be emphasized that the number of students participating in the course has always been no more than ten. Hence, the student feedback has not been collected by the universities' survey.  
 Early Progress on Enhancing Existing Software Engineering Courses to Cultivate Performance Awareness   
 Theory and Practice in Performance Evaluation Courses: The Challenge of Online Teaching   
 Andrea Marin 
  This paper reports the experience gained over several years of teaching the course entitled Software performance and scalability at the University Ca' Foscari of Venice. The course is taken by perspective computer scientists and is taught at the master's level. It covers the topics of modeling and assessment of the performance properties of software systems.  
 In this paper, we will also devote attention to the challenge of online teaching due to the pandemic conditions.  
 Finally, we propose some auspices for the community to collect material for structured courses on performance and reliability evaluation topics.  
 Anna-Lena Roth 
  Tim Süß 
  Performance analysis tools are frequently used to support the development of parallel MPI applications. They facilitate the detection of errors, bottlenecks, or inefficiencies but differ substantially in their instrumentation, measurement, and type of feedback. Especially, tools that provide visual feedback are helpful for educational purposes. They provide a visual abstraction of program behavior, supporting learners to identify and understand performance issues and write more efficient code. However, existing professional tools for performance analysis are very complex, and their use in beginner courses can be very demanding. Foremost, their instrumentation and measurement require deep knowledge and take a long time. Immediate, as well as straightforward feedback, is essential to motivate learners. This paper provides an extensive overview of performance analysis tools for parallel MPI applications, which experienced developers broadly use today. It also gives an overview of existing educational tools for parallel programming with MPI and shows their shortcomings compared to professional tools. Using tools for performance analysis of MPI programs in educational scenarios can promote the understanding of program behavior in large HPC systems and support learning parallel programming. At the same time, the complexity of the programs and the lack of infrastructure in educational institutions are barriers. These aspects will be considered and discussed in detail.  
 SESSION: Eighth Workshop on Challenges in Performance Methods for Software Development (WOSP-C 2023)  
 8th Workshop on Challenges in Performance Methods for Software Development: WOSP-C'23 Chairs' Welcome   
 Daniele Di Pompeo 
  Michele Tucci 
  It is our great pleasure to welcome you to the 8th Workshop on Challenges in Performance Methods for Software Development - WOSP-C 2023. This year's workshop continues its tradition of being the forum for the discussion of emerging or unaddressed challenges in software and performance, including challenges in developing software to be performant, concurrent programming issues, performance and architecture, performance measurement, cloud performance, and testing. Its purpose is to open new avenues for research on methods to address continuously emerging performance challenges. The software world is changing, and new challenges are to be expected.  
 We also encourage attendees to attend the keynote and talk presentations. These valuable and insightful talks can and will guide us to a better understanding of the future: Non-Volatile Hardware Transactional Memory: Advancements, Challenges, and Future Directions, Paolo Romano (who is currently at IST, Lisbon University & INESC-ID)  
 Putting together WOSP-C'23 was a team effort. We first thank the authors for providing the content of the program. We are grateful to the program committee, who worked very hard in reviewing papers and providing feedback for authors. Finally, we thank the hosting organization or university, our sponsor, ACM SIGs.  
 Non-Volatile Hardware Transactional Memory: Challenges, Advancements, and Future Directions   
 Paolo Romano 
  Transactional memory (TM) has emerged as a powerful paradigm to simplify concurrent programming. Nowadays, hardware-based TM (HTM) implementations are available in several mainstream CPUs (e.g., by ARM, Intel and IBM). Due to their hardware nature, HTM implementations spare the cost of software instrumentation and can efficiently detect conflicts by extending existing cache- coherency protocols. However, their cache-centric approach also imposes a number of limitations that impact how effectively such systems can be used in practice.  
 This talk investigates the challenges that arise when leveraging existing HTM systems in conjunction with another recent disrup- tive hardware technology, namely Non-Volatile Memory (NVM). NVM, such as Intel Optane DC, provide much higher density than existing DRAM, while attaining competitive performance and pre- serving DRAM's byte addressability. However, the cache-centric approach adopted by existing HTM implementations raises a crucial problem when these are used in conjunction with NVM: since CPU caches are volatile, existing HTM fail to guarantee that data updated by committed transactions are atomically persisted to NVM.  
 I will overview how this problem has been so far tackled in the literature, with a focus on solutions that do not assume ad-hoc hard- ware mechanisms not provided by current HTM implementations, but that rather rely on hardware-software co-design techniques to ensure consistency on unmodified existing HTM systems. I will conclude by presenting ongoing research directions that depart from state of the art approaches in a twofold way: i) they assume the availability of durable caches, i.e., systems equipped with addi- tional power sources that ensure that cache contents can be safely persisted to NVM upon crashes; ii) they assume a weaker isolation levels at the TM level, namely Snapshot Isolation, which despite being more relaxed than the reference consistency model for TM systems (e.g., opacity), can still ensure correct execution of a wide range of applications while enabling new optimizations to boost the efficiency HTM applications operating on NVM.  
 Heuristic Derivation of a Fluid Model from a Layered Queueing Network   
 Murray Woodside 
  Fluid approximations are useful for representing transient behaviour of queueing systems. For layered queues a fluid model has previously been derived indirectly via transformation first to a PEPA model, or via recursive neural networks. This paper presents a derivation directly from the layered queueing mechanisms, starting from a transformation to a context-sensitive layered form. The accuracy of predictions, compared to transient simulations and steady-state solutions, is evaluated and appears to be useful.  
 dqualizer: Domain-Centric Runtime Quality Analysis of Business-Critical Application Systems
10. ICPM_0 conference:
Menu     
 Process Mining Conference 2023   
 5th International Conference on Process Mining, 23-27 October, 2023  
 Search for:        
 Primary Menu  
 ICPM 
  Organization 
  Venue 
  Programme 
 Welcome to ICPM 2023!  
   Welcome to ICPM 2023!  
 We are happy and honored to welcome you to the Eternal City  , Rome, at the heart of culture and history, for the 5th International Conference on Process Mining  (ICPM 2023)! To know more about the event, please use the links in the bookmarks above. In particular, you might be interested in the proceedings   , the programme   , and the list of presentations and awards   .  
 The event took place from October 23 to October 27, 2023  , organized by the Department of Computer Science  and the Department of Computer, Control and Management Engineering  of Sapienza University of Rome   .  
  ICPM has established itself as the premiere event where process mining vendors, consultants, customers, end-users, and scientists can meet, exchange ideas, and push the boundaries of the field. Keeping up with the tradition of past editions of the conference, ICPM 2023 will offer a reach industrial and scientific program, with a wide range of sponsorship and exhibition options  .  
  More information will be published on this website soon, so stay tuned! We are looking forward to meeting you all in Rome.  
  Claudio Di Ciccio and Andrea Marrella  
  ICPM 2023 General Chairs  
 Platinum sponsors  
 Cookie Policy (EU)    
 Copyright © 2024 Process Mining Conference 2023  . All Rights Reserved. | Clean Journal by Catch Themes    
 Scroll Up   ICPM 
  Organization 
  Venue

output:1. ICOTA_2 information:
2. ICOTA_3 information:
3. ICPC_0 information:
4. ICPC_1 information:
5. ICPC_2 information:
6. ICPE_0 information:
7. ICPE_1 information:
8. ICPE_2 information:
9. ICPE_3 information:
10. ICPM_0 information:
