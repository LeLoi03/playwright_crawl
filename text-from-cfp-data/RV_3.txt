Skip to content      

 Menu   Calls | Call for Papers 
  Call for Posters and Demos 
  Committees 
  Keynotes 
  Tutorials 
  Panel 
  Proceedings 
  Program 
  Awards | Awards 
  Test of Time 
  Registration 

 Call for Papers  

 Scope  
 Runtime verification is concerned with the monitoring and analysis of the runtime behaviour of software and hardware systems. Runtime verification techniques are crucial for system correctness, reliability, and robustness; they provide an additional level of rigor and effectiveness compared to conventional testing and are generally more practical than exhaustive formal verification. Runtime verification can be used prior to deployment, for testing, verification, and debugging purposes, and after deployment for ensuring reliability, safety, and security and for providing fault containment and recovery as well as online system repair.  
 Topics of interest to the conference include, but are not limited to:  
 specification languages for monitoring 
  monitor construction techniques 
  program instrumentation 
  logging, recording, and replay 
  combination of static and dynamic analysis 
  specification mining and machine learning over runtime traces 
  monitoring techniques for concurrent and distributed systems 
  runtime checking of privacy and security policies 
  metrics and statistical information gathering 
  program/system execution visualization 
  fault localization, containment, recovery and repair 
  dynamic type checking and assurance cases 
  runtime verification for autonomy and runtime assurance 
  Application areas of runtime verification include cyber-physical systems, safety/mission critical systems enterprise and systems software, cloud systems, autonomous and reactive control systems, health management and diagnosis systems, and system security and privacy.  
 Submissions  
 All papers and tutorials will appear in the conference proceedings in an LNCS volume. Submitted papers and tutorials must use the LNCS/Springer style detailed here:  
   
  http://www.springer.de/comp/lncs/authors.html   
   
  Papers must be original work and not be submitted for publication elsewhere. Papers must be written in English and submitted electronically (in PDF format) using the EasyChair submission page here:  
   
  https://easychair.org/conferences/?conf=rv20   
   
  The page limitations mentioned below include all text and figures, but exclude references. Additional details omitted due to space limitations may be included in a clearly marked appendix, that will be reviewed at the discretion of reviewers, but not included in the proceedings.  
  At least one author of each accepted paper and tutorial must attend RV 2020 to present.  
 Papers  
 There are four categories of papers which can be submitted: regular, short, tool demo, and benchmark papers. Papers in each category will be reviewed by at least 3 members of the Program Committee.  
 Regular Papers | (up to 16 pages, not including references) should present original unpublished results. We welcome theoretical papers, system papers, papers describing domain-specific variants of RV, and case studies on runtime verification. 
  Short Papers | (up to 8 pages, not including references) may present novel but not necessarily thoroughly worked out ideas, for example emerging runtime verification techniques and applications, or techniques and applications that establish relationships between runtime verification and other domains. 
  Tool Demonstration Papers | (up to 8 pages, not including references) should present a new tool, a new tool component, or novel extensions to existing tools supporting runtime verification. The paper must include information on tool availability, maturity, selected experimental results and it should provide a link to a website containing the theoretical background and user guide. Furthermore, we strongly encourage authors to make their tools and benchmarks available with their submission. 
  Benchmark papers | (up to 8 pages, not including references) should describe a benchmark, suite of benchmarks, or benchmark generator useful for evaluating RV tools. Papers should include information as to what the benchmark consists of and its purpose (what is the domain), how to obtain and use the benchmark, an argument for the usefulness of the benchmark to the broader RV community and may include any existing results produced using the benchmark. We are interested in both benchmarks pertaining to real-world scenarios and those containing synthetic data designed to achieve interesting properties. Broader definitions of benchmark e.g. for generating specifications from data or diagnosing faults are within scope. We encourage benchmarks that are tool agnostic, especially if they have been used to evaluate multiple tools. We also welcome benchmarks that contain verdict labels and with rigorous arguments for correctness of these verdicts, and benchmarks that are demonstrably challenging with respect to the state-of-the-art tools. Benchmark papers must be accompanied by an easily accessible and usable benchmark submission. Papers will be evaluated by a separate benchmark evaluation panel who will assess the benchmarks relevance, clarity, and utility as communicated by the submitted paper. 
  New this year:  Runtime Verification is of special importance in systems that have a high degree of autonomy. This includes applications such as self-driving cars, vehicles equipped with automated driver assistance systems, unmanned aerial vehicles robotic vehicles used in hostile and uncertain environments (e.g. underwater space, etc.), general-purpose service robots, human-in-the-loop medical devices, etc. This year, we specifically solicit papers that focus on RV for autonomy with the goal of having a special session on autonomy. Papers in this category will be subject to the same review process as other submissions, and can be regular papers, short papers, tool demonstrations papers, or benchmark papers.  
 The Program Committee of RV 2020 will give a Springer-sponsored best paper award  to the eligible regular papers.  
 Special journal issue!  The Program Committee of RV 2020 will invite a selection of accepted papers to submit extended versions to a special issue of the International Journal on Software Tools for Technology Transfer (STTT).  
 Tutorial track  
 Tutorials are two-to-three-hour presentations on a selected topic. Additionally, tutorial presenters will be offered to publish a paper of up to 20 pages in the LNCS conference proceedings. A proposal for a tutorial must contain the subject of the tutorial, a proposed timeline, a note on previous similar tutorials (if applicable) and the differences to this incarnation, and biographies of the presenters. The proposal must not exceed 2 pages. Tutorial proposals will be reviewed by the Program Committee and the tutorial chair for the conference.  

 Copyright © 2024 20th International Conference on Runtime Verification –  OnePress  theme by FameThemes   

  We use cookies to personalize and improve your experience. By continuing to use our website you consent to this.  Allow Cookies  Decline  Privacy policy      
 You can revoke your consent any time using the Revoke consent button.  Settings     
   
  