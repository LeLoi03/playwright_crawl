Requirements Engineering 2025   Mon 1 - Fri 5 September 2025 Valencia, Spain    

 Toggle navigation        
 Attending | Venue: ADEIT, Fundación Universidad-Empresa, Valencia 
  Tracks | Requirements Engineering 2025 
  Research Papers 
  RE@Next! Papers 
  Industrial Innovation Papers 
  Workshops 
  Journal-First 
  Artifacts 
  Posters and Tool Demos 
  Doctoral Symposium 
  RE Open Data Initiative 
  Tutorials 
  Organization | Requirements Engineering 2025 Committees 
  Organizing Committee 
  Track Committees 
  Research Papers 
  RE@Next! Papers 
  Industrial Innovation Papers 
  Workshops 
  Journal-First 
  Artifacts 
  Posters and Tool Demos 
  Doctoral Symposium 
  RE Open Data Initiative 
  Tutorials 
  Contributors 
  People Index 
  Search 
  Series | Series 
   Requirements Engineering 2025 
  Requirements Engineering 2024 
  Requirements Engineering 2023 
  Requirements Engineering 2022 
  Requirements Engineering 2021 
  Sign in 
  Sign up 

  Requirements Engineering 2025  ( series  ) /  Research Papers Requirements Engineering 2025   
   
 About 
  Call for Papers 
  Formatting Instructions 
  Submission Instructions 
  Submission Q&A 
  The RE’25 Research Track  is the main track of the conference. It welcomes original research papers focusing on traditional areas of requirements engineering, as well as new ideas which challenge the boundaries of the field.  
 This is the right track if you have developed a novel solution and evaluated it on public or industrial data. This is also the right track if you have evaluated an existing problem through sound empirical methods, e.g., controlled experiments, experimental simulations, case studies, surveys, systematic literature reviews, etc. The main goal of this track is to extend the scientific literature with ground-breaking solutions  and solid evaluations  .  
 Our Program Committee includes prominent researchers in requirements engineering and beyond and will ensure fair treatment of your submissions using high-review standards and well-defined criteria. Their role is not just to select papers for the conference, but also to provide useful feedback on your research  .  
 This year’s theme is “Future-proofing Requirements Engineering”  . This theme focuses on innovating requirements engineering by embracing AI, DevOps, sustainability, security, personalization, and agile practices. It aims to equip professionals with the tools and methodologies needed to address the evolving challenges and opportunities in software development, ensuring robust, user-centric, and adaptable systems. While your contribution does not necessarily need to address this specific theme, we highly encourage you to reflect on how you can provide the technical means and knowledge to confront these challenges.  
   
 Call for Papers  
  
 The RE 2025 Research Track  welcomes original papers focusing on traditional RE topics, such as requirements elicitation, analysis, prioritisation, documentation, validation, evolution, and maintenance. It also highly encourages papers covering novel areas at the boundary of RE and other disciplines, including but not limited to software engineering/computer science at large, mechanical/electronic/civil and other engineering, business, social science, psychology, anthropology, and the humanities.  
 In addition, this year, we particularly encourage submissions addressing the theme “Future-proofing Requirements Engineering”  . This theme focuses on innovating requirements engineering by embracing AI, DevOps, sustainability, security, personalization, and agile practices. It aims to equip professionals with the tools and methodologies needed to address the evolving challenges and opportunities in software development, ensuring robust, user-centric, and adaptable systems.  
 Download the flyer of the Call for Papers here   
 Categories of Research Papers   
 The RE 2025 Research Track invites original submissions of research papers in two categories: Solution-focused papers and Evaluation-focused papers.  
 Solution-focused Papers  present novel or significantly improved solutions for requirements-related problems. This includes new approaches or theories, novel tools, modelling languages, infrastructures, or other technologies. All requirements-related activities, such as elicitation, prioritisation, or analysis are in scope. These papers are mainly evaluated based on the significance of the problem addressed, the novelty of the solution in comparison with existing work, clarity of presentation, technical soundness, and evidence of its benefits. A solution-focused paper does not require a thorough validation, but a preliminary evaluation is expected that shows the effectiveness, ease of use, or other relevant quality attributes of the proposed solution.  
 Evaluation-focused Papers  empirically assess phenomena, theories or real-world artefacts (e.g., methods, techniques, or tools) relevant to requirements engineering. These papers apply empirical software engineering approaches, such as experiments, experimental simulations, case studies, surveys, systematic literature reviews, and others to report on qualitative and/or quantitative data, findings and results. The discussion of lessons learned can complement the empirical results. The evaluation criteria for these papers focus on the soundness of the research questions, the appropriateness and correctness of the study design and data analysis, and considerations of threats to validity. Replication studies are welcome.  
 Submit your paper here: https://easychair.org/my/conference?conf=re25  .  
 Make sure you select the option “Research Papers (Main Track)”  
 Review Criteria   
 Each category of paper has its own review criteria, which reviewers will use for evaluation. Authors are encouraged to study these criteria as well. We also encourage them to read the paper “The ABC of Software Engineering Research” by Klaas-Jan Stol and Brian Fitzgerald, available in Open Access ( https://dl.acm.org/doi/10.1145/3241743  ), which highlights the inherent limitations of each study type. This is to guide the authors in their study design, and to help reviewers determine which aspects of the study design are open to criticism and which are not.  
 Review Criteria: Solution-focused Papers   
 • Novelty  : to what extent is the proposed solution novel with respect to the state-of-the-art? To what extent is related work considered? To what extent did the authors clarify their contribution?  
 • Potential Impact  : is the potential impact on research and practice clearly stated? Is the potential impact convincing? Has the proposed solution been preliminarily evaluated to show its potential impact (effectiveness, ease of use, or other relevant quality attributes of the proposed solution)?  
 • Soundness  : has the novel solution been developed following a well-motivated approach? Are the design or methodological choices of the proposed solution justified? Did the authors clearly state the research questions? Is the preliminary evaluation of the solution using rigorous and appropriate research methods? Are the conclusions of the preliminary evaluation logically derived from the data? Did the authors discuss the limitations of the proposed solution? Did the authors discuss the threats to validity of the preliminary evaluation?  
 • Verifiability  : did the authors provide guidelines on how to reuse their artifacts and replicate their results? Did the authors share their software, if any? Did the authors share their data?  
 • Presentation  : is the paper clearly presented and well-structured? To what extent can the content of the paper be understood by the general RE public? If highly technical content is presented, did the authors make an effort to also summarise their proposal in an intuitive way?  
 Review Criteria: Evaluation-focused Papers   
 • Novelty  : to what extent is the study novel with respect to the related literature? To what extent is related literature considered? To what extent did the authors clarify their contribution? To what extent does the study contribute to extending the body of knowledge in RE?  
 • Potential Impact  : is the potential impact on research and practice clearly stated? Is the potential impact convincing? Was the study carried out in a representative setting?  
 • Soundness  : Are the research methods justified? Are the research methods adequate for the problem at hand? Did the authors clearly state the research questions, data collection, and analysis? Are the conclusions of the evaluation logically derived from the data? Did the authors discuss the threats to validity?  
 • Verifiability  : did the authors provide guidelines on how to reuse their artifacts and replicate their results? Did the authors share their software? Did the authors share their data?  
 • Presentation  : is the paper clearly presented and well-structured? To what extent can the content of the paper be understood by the general RE public? If highly technical content is presented, did the authors make an effort to also summarise their study in an intuitive way?  
 NEW from RE’25: RE Open Data Initiative   
 RE’25 launches the RE Open Data Initiative  . This initiative aims to collect data from practitioners and researchers, which can be used by authors of all the tracks, including the Research Track, as evaluation data for their studies. So, if you are in one of these situations:  
 you have developed a solution and want to evaluate it on real-world data 
  you want to perform an empirical investigation analysing real-world data 
  Use the data from the RE Open Data Initiative!  
 Data will be released between December 2024 and the beginning of January 2025. For more information, click here  .  
 Open Science Policy   
 The RE 2025 Research Track has an open science policy with the steering principle that all research results should be accessible to the public and, if possible, empirical studies should be reproducible. In particular, we actively support the adoption of open data and open source principles and encourage all contributing authors to disclose (anonymized and curated) data to increase reproducibility and replicability. Note that sharing research data is not mandatory for submission or acceptance. However, sharing is expected to be the default, and non-sharing needs to be justified  . We recognize that reproducibility or replicability is not a goal in qualitative research and that, similar to industrial studies, qualitative studies often face challenges in sharing research data. For guidelines on how to report qualitative research to ensure the assessment of the reliability and credibility of research results, see the Q&A page   
 Upon submission to the research track, authors are asked  :  
 • to make their data available to the program committee (via upload of supplemental material or a link to an anonymous repository) – and provide instructions on how to access this data in the paper; or  
 • to include in the paper an explanation as to why this is not possible or desirable; and  
 • to indicate if they intend to make their data publicly available upon acceptance.  
 Supplementary material can be uploaded via the EasyChair site or anonymously linked from the paper submission. Although PC members are not required to look at this material, we strongly encourage authors to use supplementary material to provide access to anonymized data, whenever possible. Authors are asked to carefully review any supplementary material to ensure it conforms to the double-anonymous policy (see submission instructions). For example, code and data repositories may be exported to remove version control history, scrubbed of names in comments and metadata, and anonymously uploaded to a sharing site to support review.  
 Artifacts   
 The authors of accepted papers will have the opportunity to increase the visibility of their artifacts (software and data) and to obtain an artifact badge. Upon acceptance, the authors can submit their artifacts, which will be evaluated by a committee that determines their sustained availability and reusability.  
 The Artifact Evaluation Track  page is under development.  

 Formatting Instructions  
   
 The format of your paper must strictly adhere to the IEEEtran Proceedings Format. LaTeX users: please use the LaTeX class file IEEEtran v1.8  and the following configuration (without option ‘compsoc’ or ‘compsocconf’): \documentclass[conference]{IEEEtran}   
 Word users: please use this Word template  . See the official IEEE Templates page  for more information.  
 Please make sure that your submission:  
 does not exceed the respective page limit specified in the track call 
  is in PDF format, 
  is in letter page size, 
  does not have page numbers, 
  has all fonts embedded in the PDF file, 
  uses only scalable font types (like Type 1, TrueType) — bit-mapped font types (like Type 3) are not acceptable, 
  has all figures embedded in vector graphics (if not possible, use a high-resolution bitmap format of at least 300 dpi; do not use JPG, but a lossless format like PNG or GIF), 
  has all text in figures and tables large enough and readable when printed, 
  has a caption for every figure or table, 
  has the title and all headings properly capitalized 
  has no orphans and widows (cf. Section Help), and 
  does not use footnote references in the abstract. 
    
 Submission Instructions  
   
 Papers must be submitted electronically in PDF format via the RE’25 EasyChair  system. Select the RE’25 Research Track for your submission.  
 In order to guide the reviewing process, all authors who intend to submit a paper must first submit the title and abstract. Abstracts should describe explicit coverage of context, objectives, methods, and results and conclusions, and should not exceed 200 words.  
 Papers must not exceed 10 pages for the main body and up to 2 additional pages for the references. Submissions must be written in English and formatted according to the IEEE formatting instructions  . Submissions must be double-blinded in conformance with the instructions below.  
 Please note  : Papers that exceed the length specification, are not formatted correctly, or are not properly double-blinded will be desk-rejected without review. Only full paper submissions will be peer-reviewed. Abstract-only submissions will be discarded without further notice after the submission deadline. Accepted papers may require editing for clarity prior to publication and presentation. They will appear in the IEEE Digital Library.  
 Instructions for the Double-Blind Review Process   
 The RE’25 Research track will use a double-blind reviewing process. The goal of double-blind reviewing is to ensure that the reviewers can read and review your paper without having to know who any of the authors are, and hence avoid related bias. Of course, authors are allowed and encouraged to submit papers that build on their previously published work.  
 In order to prepare your submission for double-blind reviewing, please follow the instructions given below.  
 Omit all names and affiliations of authors from the title page, but keep sufficient space to re-introduce them in the final version should the paper be accepted. 
  Do not include any acknowledgements that might disclose your identity. Leave space in your submission to add such acknowledgements when the paper has been accepted. 
  Refer to your own work in the third person, as you would normally do with the work of others. You should not change the names of your own tools, approaches, or systems, since this would clearly compromise the review process; it would also violate the constraint that “no change is made to any technical details of the work”. Instead, refer to the authorship or provenance of tools, approaches, or systems in the third person, so that it is credible that another author could have written your paper. In particular, never blind references. 
  When providing supplementary material (e.g., tools, data repositories, source code, study protocols), do this via a website that does not disclose your identity. Please refer to the | Open Science Policy | in the Call for Papers with guidelines on how to anonymize such content. 
  Adhere to instruction 3 when citing previously published own work. 
  Remove identification metadata from the PDF file before submission (in Adobe Acrobat Reader, you can check their presence with File Properties, or Ctrl-D). 
  Important Policy Announcements   
 Papers submitted to RE’25 must be original. They will be reviewed under the assumption that they do not contain plagiarized material and have not been published nor submitted for review elsewhere while under consideration for RE’25.  
 RE’25 follows the IEEE policies  for cases of double submission and plagiarism  
   
 Submission Q&A  
   
 Empirical Studies and Sharing of Data    
 I am doing research with industry. What if I cannot share data from my research?  We absolutely welcome research with industry, as it often conveys important lessons about requirements engineering in practice – and we perfectly understand that industry data may be subject to confidentiality issues or legal requirements. If you cannot share data, please state the reason in the submission form and the paper; a typical wording would be “The raw data obtained in this study cannot be shared because of confidentiality agreements”. Having said that, even sharing a subset of your data (for instance, the data used for figures and tables in the paper, an anonymized subset, or one that aggregates over the entire dataset), analysis procedures, or scripts, would be useful. 
  I am doing user studies. What if I cannot share data from my empirical study?  We absolutely welcome user studies! However, we also perfectly understand that sharing raw data can be subject to constraints such as privacy issues. If you cannot share data, please state the reason in the submission form and the paper; a typical wording would be “The raw data obtained in this study cannot be shared because of privacy issues”. Having said that, even sharing a subset of your data (for instance, the data used for figures and tables in the paper, an anonymized subset, or one that aggregates over the entire dataset), analysis procedures, or scripts, would be useful. 
  I am doing qualitative research. What information should I include to help reviewers assess my research results and the readers use my results?  Best practices for addressing the reliability and credibility of qualitative research suggest providing detailed arguments and rationale for qualitative approaches, procedures, and analyses. Therefore, authors are advised to provide as much transparency as possible into these details of their study. For example, clearly explain details and decisions such as 1) context of study, 2) the participant-selection process and the theoretical basis for selecting those participants, 3) collection of data or evidence from participants, and 4) data analysis methods, e.g., justify their choice theoretically and how they relate to the original research questions, and make explicit how the themes and concepts were identified from the data. Further, provide sufficient detail to bridge the gap between the interpretation of findings presented and the collected evidence by, for example, numbering quotations and labeling sources. Similar to replicability in quantitative research, transparency aims to ensure a study’s methods are available for inspection and interpretation. However, replicability or repeatability is not the goal, as qualitative methods are inherently interpretive and emphasize context. As a consequence, reporting qualitative research might require more space in the paper; authors should consider providing enough evidence for their claims while being mindful with the use of space. Finally, when qualitative data is counted and used for quantitative methods, authors should report the technique and results in assessing rigour in data analysis procedures, such as inter-reliability tests or triangulation over different data sources or methods, and justify how they achieved rigour if no such methods were used. 
  I can make my data set / my tool available, but it may reveal my identity. What should I do?  See this question under “double-anonymous submissions”, below. 
  Double-Blind Submissions    
 I previously published an earlier version of this work in a venue that doesn’t have double-anonymous. What should I do about acknowledging that previous work?  If the work you are submitting for review has previously been published in a peer-reviewed venue or in a non-peer-reviewed venue (e.g., arXiv.org, or a departmental technical report), then it should be cited but in the third person so that it is not revealed that the cited work and the submitted paper share one or more authors. 
  Our submission makes use of work from a PhD or master’s thesis, dissertation, or report which has been published. Citing the dissertation might compromise anonymity. What should we do?  It is perfectly OK to publish work arising from a PhD or master’s degree, and there is no need to cite it in a submission to the RE Research Track because prior dissertation publication does not compromise novelty. In the final post-review, camera-ready version of the paper, please do cite the dissertation to acknowledge its contribution, but in any submission to the RE Research Track, please refrain from citing the dissertation to increase anonymity. You need not worry whether or not the dissertation has appeared. Your job is to ensure that your submission is readable and reviewable, without the reviewers needing to know the identities of the submission’s authors. You do not need to make it impossible for the reviewers to discover the authors’ identities. The referees will be trying hard not to discover the authors’ identity, so they will likely not be searching the web to check whether there is a dissertation related to this work. 
  What if we want to cite some unpublished work of our own (as motivation for example)?  If the unpublished paper is an earlier version of the paper you want to submit to the RE Research Track and is currently under review, then you have to wait until your earlier version is through its review process before you can build on it with further submissions (this would be considered double-submission and violates plagiarism policies and procedures). Otherwise, if the unpublished work is not an earlier version of the proposed submission, then you should simply make it available on a website, for example, and cite it in the third person to preserve anonymity, as you are doing with other work. 
  Can I disseminate a non-anonymized version of my submitted work by discussing it with colleagues, giving talks, publishing it at ArXiV, etc.?  You can discuss and present your work that is under submission at small meetings (e.g., job talks, visits to research labs, a Dagstuhl or Shonan meeting), but you should avoid broadly advertising it in a way that reaches the reviewers even if they are not searching for it. Therefore, the title of your submission must be different from preprints on ArXiV or similar sites. During review, you must not publicly use the submission title. Under these conditions, you are allowed to put your submission on your home page and present your work at small professional meetings. 
  What if we want to make available a tool, a data set, or some other resource, but it may reveal my identity?  Please refer to the Open Science Policy in the Call for Papers with guidelines on how to anonymize such content. If that is impossible, place a warning next to the link that this may reveal your identity. 

 Important Dates   AoE (UTC-12h)     

 Mon 3 Mar 2025  
  Abstract submission 
 Mon 10 Mar 2025  
  Full Paper Submission 
 Fri 23 May 2025  
  Notification 
 Mon 23 Jun 2025  
  Camera Ready 

 Submission Link   
   
   https://easychair.org/my/conference?conf=re25     
   
 Program Committee    
   
 Alessio Ferrari Program Co-Chair    
 CNR-ISTI   
 Italy 
  Norbert Seyff Program Co-Chair    
 University of Applied Sciences and Arts Northwestern Switzerland FHNW   
 Switzerland 
  João Araújo Program Committee    
 NOVA LINCS, Universidade NOVA de Lisboa   
 Portugal 
  Fatma Başak Aydemir Program Committee    
 Utrecht University   
 Netherlands 
  Muneera Bano Program Committee    
 CSIRO's Data61   
 Australia 
  Nelly Bencomo Program Committee    
 Durham University   
 United Kingdom 
  Dan Berry Program Committee    
 University of Waterloo   
 Canada 
  Domenico Bianculli Program Committee    
 University of Luxembourg   
 Luxembourg 
  Travis Breaux Program Committee    
 Carnegie Mellon University   
 United States 
  Giovanna Broccia Program Committee    
 ISTI-CNR, FMT Lab   
 Italy 
  Ruzanna Chitchyan Program Committee    
 University of Bristol   
 United Kingdom 
  Jane Cleland-Huang Program Committee    
 University of Notre Dame   
 United States 
  Benoit Combemale Program Committee    
 University of Rennes, Inria, CNRS, IRISA   
 France 
  Jacek Dąbrowski Program Committee    
 Lero - the Science Foundation Ireland Research Centre for Software   
 Ireland 
  Maya Daneva Program Committee    
 University of Twente   
 Netherlands 
  Oscar Dieste Program Committee    
 Universidad Politécnica de Madrid   
 Spain 
  Neil Ernst Program Committee    
 University of Victoria   
 Canada 
  Xavier Franch Program Committee    
 Universitat Politècnica de Catalunya   
 Spain 
  Julian Frattini Program Committee    
 Blekinge Institute of Technology   
 Sweden 
  Vincenzo Gervasi Program Committee    
 University of Pisa   
 Italy 
  Sepideh Ghanavati Program Committee    
 University of Maine   
 United States 
  Eduard C. Groen Program Committee    
 Fraunhofer IESE   
 Germany 
  Iris Groher Program Committee    
 Johannes Kepler University, Linz   
 Austria 
  Alicia M. Grubb Program Committee    
 Smith College   
 United States 
  Paul Grünbacher Program Committee    
 Johannes Kepler University Linz, Austria   
 Austria 
  Renata Guizzardi Program Committee    
 University of Twente, The Netherlands   
 Netherlands 
  Irit Hadar Program Committee    
 University of Haifa   
 Israel 
  Anne Hess Program Committee    
 Technical University of Applied Sciences Würzburg-Schweinfurt   
 Germany 
  Jennifer Horkoff Program Committee    
 Chalmers and the University of Gothenburg   
 Sweden 
  Emilio Insfran Program Committee    
 Universitat Politècnica de València, Spain   
 Spain 
  Klaas-Jan Stol Program Committee    
 Lero; University College Cork; SINTEF Digital   
 Ireland 
  Zhi Jin Program Committee    
 Peking University   
 China 
  Oliver Karras Program Committee    
 TIB - Leibniz Information Centre for Science and Technology   
 Germany 
  Eric Knauss Program Committee    
 Chalmers | University of Gothenburg   
 Sweden 
  Sylwia Kopczyńska Program Committee    
 Poznan University of Technology   
 Poland 
  Emmanuel Letier Program Committee    
 University College London   
 United Kingdom 
  Tong Li Program Committee    
 Beijing University of Technology   
 China 
  Grischa Liebel Program Committee    
 Reykjavik University   
 Iceland 
  Walid Maalej Program Committee    
 University of Hamburg   
 Germany 
  Sabrina Marczak Program Committee    
 PUCRS   
 Brazil 
  Mehdi Mirakhorli Program Committee    
 University of Hawaii at Manoa 
  Ana Moreira Program Committee    
 NOVA University of Lisbon and NOVA LINCS   
 Portugal 
  Nan Niu Program Committee    
 University of Cincinnati   
 United States 
  Nicole Novielli Program Committee    
 University of Bari   
 Italy 
  Barbara Paech Program Committee    
 Heidelberg University   
 Germany 
  Nitish Patkar Program Committee    
 FHNW   
 Switzerland 
  Birgit Penzenstadler Program Committee    
 Chalmers   
 Sweden 
  Anna Perini Program Committee    
 Fondazione Bruno Kessler   
 Italy 
  Kurt Schneider Program Committee    
 Leibniz Universität Hannover, Software Engineering Group   
 Germany 
  Paola Spoletini Program Committee    
 Kennesaw State University   
 United States 
  Jan-Philipp Steghöfer Program Committee    
 XITASO GmbH IT & Software Solutions   
 Germany 
  Angelo Susi Program Committee    
 Fondazione Bruno Kessler   
 Italy 
  Michael Unterkalmsteiner Program Committee    
 Blekinge Institute of Technology   
 Sweden 
  Colin C. Venter Program Committee    
 University of Huddersfield   
 United Kingdom 
  Michael Vierhauser Program Committee    
 University of Innsbruck   
 Austria 
  Tao Yue Program Committee    
 Beihang University   
 China 
  Liping Zhao Program Committee    
 University of Manchester   
 United Kingdom 
  Waad Alhoshan Program Committee    
 Al-Imam Mohammed Ibn Saud Islamic University   
 Saudi Arabia 
  James Tizard Program Committee    
 University of Auckland   
 New Zealand 
  Christoph Becker Program Committee    
 University of Toronto 
  Laura Semini Program Committee    
 Università di Pisa - Dipartimento di Informatica   
 Italy 
  Arpit Sharma Program Committee    
 Indian Institute of Science Education and Research Bhopal   
 India 

 x  Wed 4 Dec 13:45    

  Requirements Engineering 2025   
  using conf.researchr.org  ( v1.67.1  )  
   Support page    
     
 Tracks  
 Research Papers   
  RE@Next! Papers   
  Industrial Innovation Papers   
  Workshops   
  Journal-First   
  Artifacts   
  Posters and Tool Demos   
  Doctoral Symposium   
  RE Open Data Initiative   
  Tutorials    

 Attending  
 Venue: ADEIT, Fundación Universidad-Empresa, Valencia   
    
 Sign Up    

  