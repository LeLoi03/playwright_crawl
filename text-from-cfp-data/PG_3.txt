    

   Home 
  People 
  Research | Software 
  Datasets 
  Workshops 
  Publications 
  Teaching | Open Projects 
  Jobs 

  Paper accepted at Pacific Graphics 2024  
   21 August 2024    publications  , pg  , conference     
   
 (Yan et al., 2024)    
 We are pleased to announce that the following paper was accepted for publication at Pacific Graphics 2024  .  
 Congratulations to the authors!  
 GazeMoDiff: Gaze-guided Diffusion Model for Stochastic Human Motion Prediction  
 Haodong Yan  , Zhiming Hu  , Syn Schmitt, Andreas Bulling   
 Proc. 32nd Pacific Conference on Computer Graphics and Application (PG),  pp. 1–10,  2024  .  
 Abstract   Links   BibTeX   Project    
 Human motion prediction is important for many virtual and augmented reality (VR/AR) applications such as collision avoidance and realistic avatar generation. Existing methods have synthesised body motion only from observed past motion, despite the fact that human eye gaze is known to correlate strongly with body movements and is readily available in recent VR/AR headsets. We present GazeMoDiff – a novel gaze-guided denoising diffusion model to generate stochastic human motions. Our method first uses a gaze encoder and a motion encoder to extract the gaze and motion features respectively, then employs a graph attention network to fuse these features, and finally injects the gaze-motion features into a noise prediction network via a cross-attention mechanism to progressively generate multiple reasonable human motions in the future. Extensive experiments on the MoGaze and GIMO datasets demonstrate that our method outperforms the state-of-the-art methods by a large margin in terms of multi-modal final displacement error (17.3% on MoGaze and 13.3% on GIMO). We further conducted a human study (N=21) and validated that the motions generated by our method were perceived as both more precise and more realistic than those of prior methods. Taken together, these results reveal the significant information content available in eye gaze for stochastic human motion prediction as well as the effectiveness of our method in exploiting this information.   doi:    Paper: yan24_pg.pdf     @inproceedings{yan24_pg title = {GazeMoDiff: Gaze-guided Diffusion Model for Stochastic Human Motion Prediction}, author = {Yan, Haodong and Hu, Zhiming and Schmitt, Syn and Bulling, Andreas}, year = {2024}, doi = {}, pages = {1--10}, booktitle = {Proc. 32nd Pacific Conference on Computer Graphics and Application (PG)} } 
  Here are some related news you might like to read next:  
 Best Paper Honourable Mention Award at CSCW 
  Best Journal Paper Award at ISMAR 
  Paper accepted at WACV 2025 
  Paper accepted at UIST 2024 
  Paper accepted at ECAI 2024 
   « Paper accepted at WACV 2025  All news  Paper accepted in Frontiers in Cognition »    

  The Collaborative Artificial Intelligence group, headed by Prof. Dr. Andreas Bulling  , is within the Department of Computer Science at the University of Stuttgart, Germany. The group is affiliated with the Institute for Visualisation and Interactive Systems and the Cluster of Excellence "Data-integrated Simulation Science" (SimTech).  
   
 Links  
   
 University of Stuttgart 
  Department of Computer Science 
  Institute for Visualisation and Interactive Systems 
  SimTech Cluster of Excellence 
   Mastodon 
  YouTube 
    
 Contact Us  
   
 cai-office@vis.uni-stuttgart.de    
 University of Stuttgart   
 Institute for Visualisation and Interactive Systems  
  Collaborative Artificial Intelligence   
 Pfaffenwaldring 5a  
  70569 Stuttgart  
  Germany   

 © 2024 University of Stuttgart - Imprint  | Privacy Policy  | Last modified: 23 August 2024   

  